
@article{yang_review_2020,
	title = {Review of built heritage modelling: {Integration} of {HBIM} and other information techniques},
	volume = {46},
	issn = {1296-2074},
	shorttitle = {Review of built heritage modelling},
	url = {https://www.sciencedirect.com/science/article/pii/S129620742030385X},
	doi = {10.1016/j.culher.2020.05.008},
	abstract = {Built heritage documentation involves the 3D modelling of the geometry (typically using 3D computer graphics, photogrammetry and laser scanning techniques) and information management of semantic knowledge (i.e., using Geographic Information System (GIS) and ontology tools). The recent developed Building Information Modelling (BIM) technique combines 3D modelling and information management. One of its modern application is heritage documentation and has generated a new concept of Historic/Heritage Building Information Modelling (HBIM). This paper summarises the applications of these information techniques on the built heritage documentation. We utilise Web of Science Collection to monitor the publications on built heritage documentation. We analyse the research trend in heritage modelling by comparing the attention paid by researchers before and during the 2010s. The results show that photogrammetry is always the most popular method in heritage modelling. More and more works in heritage modelling have begun to use laser scanning, computer science, GIS and especially BIM techniques. Ontologies and 3D computer graphics are traditional ways for heritage documentation. Moreover, we pay attention to the roles of BIM on heritage documentation and conduct a detailed discussion on how to extend the HBIM capabilities by integrating with other techniques. The integration provides possible enhanced functions in HBIM, including accurate parametric modelling from computer graphics, automatic semantic segmentation of 3D point cloud from reality-based modelling, spatial information management and analysis by GIS, and knowledge modelling by ontology.},
	language = {en},
	urldate = {2023-02-10},
	journal = {Journal of Cultural Heritage},
	author = {Yang, Xiucheng and Grussenmeyer, Pierre and Koehl, Mathieu and Macher, Hélène and Murtiyoso, Arnadi and Landes, Tania},
	month = nov,
	year = {2020},
	keywords = {BIM, Built heritage, Geometric model, Knowledge, Parametric objects, Semantics},
	pages = {350--360},
	file = {ScienceDirect Snapshot:files/2/S129620742030385X.html:text/html;Versione accettata:files/3/Yang et al. - 2020 - Review of built heritage modelling Integration of.pdf:application/pdf},
}

@article{garcia-valldecabres_bim_2016,
	title = {{BIM} {Scientific} {Literature} {Review} for {Existing} {Buildings} and a {Theoretical} {Method}: {Proposal} for {Heritage} {Data} {Management} {Using} {HBIM}},
	shorttitle = {{BIM} {Scientific} {Literature} {Review} for {Existing} {Buildings} and a {Theoretical} {Method}},
	url = {https://ascelibrary.org/doi/10.1061/9780784479827.222},
	doi = {10.1061/9780784479827.222},
	abstract = {The building information modeling (BIM) technology is a methodology that allows the exchange of information efficiently; it is used by stakeholders who participate in the building life cycle. This methodology is successfully utilized for new buildings; however its implementation in heritage architecture is still emerging. The purposes of this research are to perform an analysis on the BIM state of the art for existing buildings, to identify the knowledge gap in historic buildings, and to propose a theoretical method for heritage architecture management. To achieve these objectives, a total of 65 articles and papers have been analyzed. These documents were grouped into five categories, and conclusions were drawn. Furthermore, a theoretical method was proposed by reviewing the BIM literature and by inventorying the monument’s needs. The results illustrate the emerging state of BIM for heritage architecture, also called historic building information modeling (HBIM); there are few practical applications so far, including database management of the historic monuments. The analysis aimed to propose a method to manage architectural patrimony. In conclusion, the creation of this HBIM method for movable and immovable heritage analysis, research, documentation, and management represents progress in how the exchange of information occurs between the different professionals and stakeholders involved in architectural patrimony. This research is part of the scientific project entitled: The Design of a Database, Management Model for the Information and Knowledge of Architectural Heritage; HAR2013-41614-R, subsidized by the Spanish Ministry of Economy and Competitiveness through the National Programme for Research Aimed at the Challenges of Society},
	language = {EN},
	urldate = {2023-02-10},
	author = {García-Valldecabres, Jorge and Pellicer, Eugenio and Jordan-Palomar, Isabel},
	month = may,
	year = {2016},
	note = {Publisher: American Society of Civil Engineers},
	pages = {2228--2238},
}

@article{murphy_historic_2009,
	title = {Historic building information modelling ({HBIM})},
	volume = {27},
	issn = {0263-080X},
	url = {https://doi.org/10.1108/02630800910985108},
	doi = {10.1108/02630800910985108},
	abstract = {Purpose – The purpose of this research is to outline in detail the procedure of remote data capture using laser scanning and the subsequent processing required in order to identify a new methodology for creating full engineering drawings (orthographic and 3D models) from laser scan and image survey data for historic structures. Design/methodology/approach – Historic building information modelling (HBIM) is proposed as a new system of modelling historic structures; the HBIM process begins with remote collection of survey data using a terrestrial laser scanner combined with digital cameras. A range of software programs is then used to combine the image and scan data. Findings – Meshing of the point cloud followed by texturing from the image data creates a framework for the creation of a 3D model. Mapping of BIM objects onto the 3D surface model is the final stage in the reverse engineering process, creating full 2D and 3D models including detail behind the object's surface concerning its methods of construction and material makeup, this new process is described as HBIM. Originality/value – The future research within this area will concentrate on three main stands. The initial strand is to attempt improve the application of geometric descriptive language to build complex parametric objects. The second stand is the development of a library of parametric based on historic data (from Vitruvius to 18th century architectural pattern books). Finally, while it is possible to plot parametric objects onto the laser scan data, there is need to identify intermediate software platforms to accelerate this stage within the HBIM framework.},
	number = {4},
	urldate = {2023-02-10},
	journal = {Structural Survey},
	author = {Murphy, Maurice and McGovern, Eugene and Pavia, Sara},
	month = jan,
	year = {2009},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Conservation, Information modelling, Lasers, Surveying},
	pages = {311--327},
	file = {Snapshot:files/6/html.html:text/html},
}

@inproceedings{dore_integration_2012,
	title = {Integration of {Historic} {Building} {Information} {Modeling} ({HBIM}) and {3D} {GIS} for recording and managing cultural heritage sites},
	doi = {10.1109/VSMM.2012.6365947},
	abstract = {This paper outlines a two stage approach for digitally recording cultural heritage sites. This approach involves a 3D modeling stage and the integration of the 3D model into a 3D GIS for further management and analysis. The modeling stage is carried out using a new concept; Historic Building Information Modeling (HBIM) which has been developed at the Dublin Institute of Technology [12]. Historic Building Information Modeling is a system for modeling historic structures from laser scan and photogrammetric data using Building Information Modeling (BIM) software. The HBIM process involves a reverse engineering solution whereby parametric objects representing architectural elements are mapped onto laser scan or photogrammetric survey data. A library of parametric architectural objects has been designed from historic manuscripts and architectural pattern books. These parametric objects were built using an embedded scripting language within the BIM software called Geometric Descriptive Language (GDL). These objects are combined and mapped onto the survey data to build the entire model. After the 3D model has been created the next stage involves integrating the 3D model into a 3D GIS for further analysis. The international framework for 3D city modeling, CityGML has been adopted for this purpose. CityGML provides an interoperable framework for modeling 3D geometries, semantics, topology and appearance properties [13]. The aim of this research is to bridge the gap between parametric CAD modeling and 3D GIS while using benefits from both systems to help document and analyze cultural heritage sites.},
	booktitle = {2012 18th {International} {Conference} on {Virtual} {Systems} and {Multimedia}},
	author = {Dore, C. and Murphy, M.},
	month = sep,
	year = {2012},
	keywords = {BIM, Semantics, 3D GIS, Buildings, CityGML, Cultural differences, Cultural Heritage, Data models, Laser modes, Laser Scanning, Libraries, Parametric Modeling, Semantic Modeling, Solid modeling},
	pages = {369--376},
	file = {Full text:files/8/Dore e Murphy - 2012 - Integration of Historic Building Information Model.pdf:application/pdf;IEEE Xplore Abstract Record:files/9/6365947.html:text/html},
}

@article{bruno_hbim_2019,
	title = {{HBIM} for {Conservation}: {A} {New} {Proposal} for {Information} {Modeling}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	shorttitle = {{HBIM} for {Conservation}},
	url = {https://www.mdpi.com/2072-4292/11/15/1751},
	doi = {10.3390/rs11151751},
	abstract = {Thanks to its capability of archiving and organizing all the information about a building, HBIM (Historical Building Information Modeling) is considered a promising resource for planned conservation of historical assets. However, its usage remains limited and scarcely adopted by the subjects in charge of conservation, mainly because of its rather complex 3D modeling requirements and a lack of shared regulatory references and guidelines as far as semantic data are concerned. In this study, we developed an HBIM methodology to support documentation, management, and planned conservation of historic buildings, with particular focus on non-geometric information: organized and coordinated storage and management of historical data, easy analysis and query, time management, flexibility, user-friendliness, and information sharing. The system is based on a standalone specific-designed database linked to the 3D model of the asset, built with BIM software, and it is highly adaptable to different assets. The database is accessible both with a developed desktop application, which acts as a plug-in for the BIM software, and through a web interface, implemented to ensure data sharing and easy usability by skilled and unskilled users. The paper describes in detail the implemented system, passing by semantic breaking down of the building, database design, as well as system architecture and capabilities. Two case studies, the Cathedral of Parma and Ducal Palace of Mantua (Italy), are then presented to show the results of the system’s application.},
	language = {en},
	number = {15},
	urldate = {2023-02-10},
	journal = {Remote Sensing},
	author = {Bruno, Nazarena and Roncella, Riccardo},
	month = jan,
	year = {2019},
	note = {Number: 15
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {cultural heritage, database design, Historic Building Information Modelling, information management, modeling metadata, semantic classification, survey metadata},
	pages = {1751},
	file = {Full Text PDF:files/13/Bruno e Roncella - 2019 - HBIM for Conservation A New Proposal for Informat.pdf:application/pdf},
}

@article{yang_hbim_2019,
	title = {{HBIM} {Modeling} from the {Surface} {Mesh} and {Its} {Extended} {Capability} of {Knowledge} {Representation}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2220-9964},
	url = {https://www.mdpi.com/2220-9964/8/7/301},
	doi = {10.3390/ijgi8070301},
	abstract = {Built heritage has been documented by reality-based modeling for geometric description and by ontology for knowledge management. The current challenge still involves the extraction of geometric primitives and the establishment of their connection to heterogeneous knowledge. As a recently developed 3D information modeling environment, building information modeling (BIM) entails both graphical and non-graphical aspects of the entire building, which has been increasingly applied to heritage documentation and generates a new issue of heritage/historic BIM (HBIM). However, HBIM needs to additionally deal with the heterogeneity of geometric shape and semantic knowledge of the heritage object. This paper developed a new mesh-to-HBIM modeling workflow and an integrated BIM management system to connect HBIM elements and historical knowledge. Using the St-Pierre-le-Jeune Church, Strasbourg, France as a case study, this project employs Autodesk Revit as a BIM environment and Dynamo, a built-in visual programming tool of Revit, to extend the new HBIM functions. The mesh-to-HBIM process segments the surface mesh, thickens the triangle mesh to 3D volume, and transfers the primitives to BIM elements. The obtained HBIM is then converted to the ontology model to enrich the heterogeneous knowledge. Finally, HBIM geometric elements and ontology semantic knowledge is joined in a unified BIM environment. By extending the capability of the BIM platform, the HBIM modeling process can be conducted in a time-saving way, and the obtained HBIM is a semantic model with object-oriented knowledge.},
	language = {en},
	number = {7},
	urldate = {2023-02-10},
	journal = {ISPRS International Journal of Geo-Information},
	author = {Yang, Xiucheng and Lu, Yi-Chou and Murtiyoso, Arnadi and Koehl, Mathieu and Grussenmeyer, Pierre},
	month = jul,
	year = {2019},
	note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {built heritage, HBIM, knowledge, mesh, ontology, semantic model},
	pages = {301},
	file = {Full Text PDF:files/15/Yang et al. - 2019 - HBIM Modeling from the Surface Mesh and Its Extend.pdf:application/pdf},
}

@article{quattrini_knowledge-based_2017,
	title = {Knowledge-based data enrichment for {HBIM}: {Exploring} high-quality models using the semantic-web},
	volume = {28},
	issn = {1296-2074},
	shorttitle = {Knowledge-based data enrichment for {HBIM}},
	url = {https://www.sciencedirect.com/science/article/pii/S1296207417300754},
	doi = {10.1016/j.culher.2017.05.004},
	abstract = {In the last decade, the paradigm Historical Building Information Modeling (HBIM) was investigated to exploit the possibilities offered by the application of BIM to historical buildings. In the Cultural Heritage domain, the BIM-oriented approach can produce 3D models that are data collector populated by both geometrical and non-geometrical information related to various themes: historical documents, monitoring data, structural information, conservation or restoration state and so on. The realization of a 3D model fully interoperable and rich in its informative content could represent a very important change towards a more efficient management of the historical real estate. The work presented in these pages outlines a novel approach to solve this interoperability issue, by developing and testing a workflow that exploits the advantages of BIM platforms and Semantic-Web technologies, enabling the user to query a repository composed of semantically structured and rich HBIM data. The presented pipeline follows four main steps: (i) the first step consists on modeling an ontology with the main information needs for the domain of interest, providing a data structure that can be leveraged to inform the data-enrichment phase and, later, to meaningfully query the data. (ii) Afterwards, the data enrichment was performed, by creating a set of shared parameters reflecting the properties in our domain ontology. (iii) To structure data in a machine-readable format, a data conversion was needed to represent the domain (ontology) and analyze data of specific buildings respectively; this step is mandatory to reuse the analysis data together with the 3D model, providing the end-user with a querying tool. (iv) As a final step in our workflow, we developed a demonstrative data exploration web application based on the faceted browsing paradigm and allowing to exploit both structured metadata and 3D visualization. This research demonstrates how is possible to represent a huge amount of specialized information models with appropriate LOD and Grade in BIM environment and then guarantee a complete interoperability with IFC/RDF format. Relying on semantically structured data (ontologies) and on the Linked Data stack appears a valid approach for addressing existing information system issues in the CH domain and constitutes a step forward in the management of repositories and web libraries devoted to historical buildings.},
	language = {en},
	urldate = {2023-02-10},
	journal = {Journal of Cultural Heritage},
	author = {Quattrini, Ramona and Pierdicca, Roberto and Morbidoni, Christian},
	month = nov,
	year = {2017},
	keywords = {Data Standardization, Interoperability, Ontologies, Representation workflow, Shared parameters, Taxonomies},
	pages = {129--139},
	file = {ScienceDirect Snapshot:files/17/S1296207417300754.html:text/html},
}

@article{jouan_digital_2019,
	title = {{DIGITAL} {TWIN}: {A} {HBIM}-{BASED} {METHODOLOGY} {TO} {SUPPORT} {PREVENTIVE} {CONSERVATION} {OF} {HISTORIC} {ASSETS} {THROUGH} {HERITAGE} {SIGNIFICANCE} {AWARENESS}},
	volume = {XLII-2},
	copyright = {© Author(s) 2019. This work is distributed under the Creative Commons Attribution 4.0 License.},
	issn = {1682-1750},
	shorttitle = {{DIGITAL} {TWIN}},
	url = {https://orbi.uliege.be/handle/2268/239023},
	doi = {10.5194/isprs-archives-XLII-2-W15-609-2019},
	abstract = {Historic Building Information Modeling (HBIM), Digital Twin (DT), Heritage documentation, preventive conservation. 
 
Abstract. During preliminary phases of conservation projects, a considerable amount of heterogeneous datasets are produced, gathered, analysed and interpreted. Abundant researches have gradually proven that Historic Building Information Modelling (HBIM) is a relevant alternative for the collaborative management of information related to existing structures. Apart from the obvious benefits of HBIM for information exchange among stakeholders during conservation project, the potential of such processes to support preservation strategies should not be neglected. Moreover, the recent developments of HBIM web-interfaces illustrate the need for additional investigation in strengthening the relationships between the digital model and the real-world to better support preventive conservation of heritage places. Besides, values-based approaches for the elaboration of conservation strategies have been gradually adopted in the last decades, both in academic and professional sector. In this paper, we propose a comprehensive methodology to structure and integrate the cultural significance of tangible and intangible elements into HBIM models to be further taken into account in the analysis and simulation of data. This article suggests the application of Digital Twin (DT) principles to support site managers in the preventive conservation of their assets. Based on the analysis and simulations of data captured by onsite sensors, threats to the site integrity and corresponding preventive solution can be predicted in the DT environment. The integration and structuration of Heritage Values in HBIM models allow further evaluation process to estimate the impact of each suggested interventions on the conservation of features of significance.},
	language = {English},
	number = {2019},
	urldate = {2023-02-10},
	journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Jouan, Pierre-André and Hallot, Pierre},
	month = aug,
	year = {2019},
	note = {Publisher: Copernicus, Goettingen, Germany},
	file = {Full Text PDF:files/19/Jouan e Hallot - 2019 - DIGITAL TWIN A HBIM-BASED METHODOLOGY TO SUPPORT .pdf:application/pdf},
}

@article{jordan-palomar_protocol_2018,
	title = {Protocol to {Manage} {Heritage}-{Building} {Interventions} {Using} {Heritage} {Building} {Information} {Modelling} ({HBIM})},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2071-1050},
	url = {https://www.mdpi.com/2071-1050/10/4/908},
	doi = {10.3390/su10040908},
	abstract = {The workflow in historic architecture projects presents problems related to the lack of clarity of processes, dispersion of information and the use of outdated tools. Different heritage organisations have showed interest in innovative methods to resolve those problems and improve cultural tourism for sustainable economic development. Building Information Modelling (BIM) has emerged as a suitable computerised system for improving heritage management. Its application to historic buildings is named Historic BIM (HBIM). HBIM literature highlights the need for further research in terms of the overall processes of heritage projects, its practical implementation and a need for better cultural documentation. This work uses Design Science Research to develop a protocol to improve the workflow in heritage interdisciplinary projects. Research techniques used include documentary analysis, semi-structured interviews and focus groups. HBIM is proposed as a virtual model that will hold heritage data and will articulate processes. As a result, a simple and visual HBIM protocol was developed and applied in a real case study. The protocol was named BIMlegacy and it is divided into eight phases: building registration, determine intervention options, develop design for intervention, planning the physical intervention, physical intervention, handover, maintenance and culture dissemination. It contemplates all the stakeholders involved.},
	language = {en},
	number = {4},
	urldate = {2023-02-10},
	journal = {Sustainability},
	author = {Jordan-Palomar, Isabel and Tzortzopoulos, Patricia and García-Valldecabres, Jorge and Pellicer, Eugenio},
	month = apr,
	year = {2018},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {BIM, cultural heritage, HBIM, heritage architecture, management, protocol},
	pages = {908},
	file = {Full Text PDF:files/23/Jordan-Palomar et al. - 2018 - Protocol to Manage Heritage-Building Interventions.pdf:application/pdf},
}

@misc{noauthor_leggere_nodate,
	title = {Leggere complicato: la letteratura ergodica},
	shorttitle = {Leggere complicato},
	url = {https://www.miracubi.it/percorsi-tematici/leggere-complicato-la-letteratura-ergodica/},
	abstract = {E' un termine coniato da Espen J. Aarseth nel suo libro “Cybertext - Perspectives on Ergodic Literature”. Il termine deriva dalle parole greche ergon, che significa "lavoro", e hodos, che significa "sentiero". È associato al concetto di cybertext (il cibertesto è l'organizzazione del testo al fine di analizzare l'influenza del media come parte integrante della dinamica letteraria) e descrive un processo cibertestuale che include una sequenza semiotica della quale i concetti tradizionali di "lettura" non tengono conto.

Il libro di Aarseth contiene la definizione più comunemente citata di letteratura ergodica:

Nella letteratura ergodica, è richiesto uno sforzo non banale per consentire al lettore di attraversare il testo. Se la letteratura ergodica deve avere un senso come concetto, deve esserci anche letteratura nonergodica, dove lo sforzo di attraversare il testo è banale, senza responsabilità extranoematiche (il termine noematico deriva da noema - dal gr. Nóema ‘pensiero’, uno dei tecnicismi usati in linguistica per indicare l’unità minima di significato, sul modello di morfema e fonema; lo sforzo extranoematico è dunque quello che non riguarda la decodifica/interpretazione del significato espresso verbalmente, ma che si va ad aggiungere ad essa) sul lettore eccetto, ad esempio, il movimento degli occhi e la rotazione periodica o arbitraria di pagine.
Oltre alla definizione di cui sopra, Aarseth ha spiegato la letteratura ergodica come binomio: un testo normale e una macchina in grado di produrre diverse manifestazioni di un testo. Una delle principali innovazioni del concetto di letteratura ergodica è che non è specifica del media fintanto che il media ha la capacità di produrre un'iterazione del testo. I ricercatori dei nuovi media hanno avuto la tendenza a concentrarsi sul media del testo, ad esempio un media cartaceo o elettronico. Aarseth ha rotto con questo assunto di base che il media fosse la distinzione più importante e ha sostenuto che la meccanica dei testi non deve essere specifica del media.

La letteratura ergodica non è definita dal media, ma dal modo in cui funziona il testo. Pertanto, sia i testi cartacei che quelli elettronici possono essere ergodici: "L'opera d'arte ergodica è quella che in senso materiale include le regole per il proprio uso, un'opera che ha determinati requisiti incorporati che distingue automaticamente tra utilizzatori capaci o incapaci."


Letteratura ergodica e cibertesto 

Il cibertesto è una sottocategoria della letteratura ergodica che Aarseth definisce come "testi che implicano il calcolo nella loro produzione di scriptons" (Aarseth, all’interno di “Cybertext” analizza la possibilità dell’esistenza di un tipo di letteratura con vita indipendente rispetto al medium da cui è veicolata, cioè il libro. Per analizzare questo tipo di testi, ci sono, perciò, due categorie da ricordare: i textons e gli scriptons. I textons sono elementi testuali che osservano regole precise e sono presenti in numero determinato. Gli scriptons, invece, sono le possibili combinazioni di tali elementi e sono, perciò, infinite).

Il processo di lettura del  materiale stampato, al contrario, implica uno sforzo extranoematico "banale", cioè semplicemente in movimento i propri occhi lungo le linee di testo e girando le pagine. Pertanto, la narrativa ipertestuale con varietà di nodi e collegamenti semplici è letteratura ergodica ma non cibertesto.

È richiesto uno sforzo non banale al lettore per attraversare il testo, in quanto il lettore deve selezionare costantemente quale collegamento seguire, ma un collegamento, quando cliccato, porterà sempre allo stesso nodo. Un chat bot (un chat bot è un software ideato per simulare un dialogo con un essere umano) come ELIZA è un cybertext perché quando il lettore digita una frase, la macchina di testo esegue effettivamente i calcoli al volo che generano una risposta testuale. Anche l'I Ching è citato come esempio di cybertext perché contiene le regole per la propria lettura. Il lettore esegue il calcolo ma le regole sono chiaramente incorporate nel testo stesso.

È stato affermato che queste distinzioni non sono del tutto chiare e gli studiosi discutono ancora i dettagli delle definizioni. Secondo la definizione di cui sopra, Finnegans Wake di Joyce, la Fenomenologia dello Spirito di hegel e l'Essere e il Nulla di Sartre sono considerati letteratura non ergodica in quanto richiedono solo "uno sforzo banale ... per attraversare il testo". Una pila di giornali macchiati e modellati, d'altra parte, è letteratura ergodica.

I concetti di cybertext e letteratura ergodica sono stati di fondamentale importanza per gli studi sui nuovi media, in particolare per gli approcci letterari ai testi digitali e agli studi sui giochi.
Fonti e approfondimenti
Accademia della Crusca - Ergodico in letteratura
Advister.it - Cos'è la letteratura ergodica
Sono solo libri.it - La letteratura ergodica
Tomshw.it - Letteratura ergodica: un'introduzione
Wikipedia - Cybertext (in inglese)
Icrewplay.com - La letteratura ergodica
Alcuni esempi per capirci qualcosa

Gli esempi forniti da Aarseth includono un gruppo eterogeneo di testi:


Iscrizioni murali dei templi nell'antico Egitto

Sono collegate bidimensionalmente (su una parete) o tridimensionalmente (da parete a parete o da stanza a stanza)
 
 
 
 
I Ching

Dell’I Ching si possono dire almeno tre cose singolari: che non ha età, che non è un libro e che è la massima approssimazione attraverso i segni alla vita stessa. Secondo la leggenda, gli otto trigrammi dell’I Ching (che non sono ideogrammi, ma sequenze di linee intere e spezzate) apparvero come segni incisi sul guscio di una tartaruga primordiale. Non si sa chi li abbia incisi: non certo un uomo e neppure un dio personale. Piuttosto: l’invisibile mano del cielo. Che cosa indicano gli otto trigrammi (e i sessantaquattro esagrammi in cui si compongono)? La totalità degli stati attraverso cui passa l’esistenza, attraverso cui passiamo noi nel momento in cui interroghiamo questo che fondamentalmente è un libro di oracoli. Ma a differenza degli oracoli occidentali, che inchiodano sempre alla lettera di una risposta e perciò contengono in sé qualcosa di rigido e sinistro, l’I Ching ci offre una situazione nel suo formarsi e nelle sue potenzialità, qualcosa di fluido, impalpabile, trascinante come è la vita stessa. E si può dire che nulla di scritto, dall’apparizione di quella testuggine cinese, si sia altrettanto avvicinato alla pulsazione segreta del mondo.

Opera enigmatica per definizione, che non si finisce mai di scoprire, l’I Ching ha provocato fino a oggi innumerevoli interpretazioni, edizioni, traduzioni.

[Fonte: Adelphi]
 
Calligrammes: poemes de la paix et de la guerre, 1913-1916
di Guillaume Apollinaire
Calligrammes è una raccolta di poesie pubblicata per la prima volta nel 1918. Calligrammes è noto per il modo in cui il carattere tipografico e la disposizione spaziale delle parole su una pagina svolgono un ruolo nel significato di ogni poesia tanto quanto le parole stesse - una forma chiamata calligramma. In questo senso, la raccolta può essere vista sia come poesia concreta che come poesia visiva.
Apollinaire ha descritto il suo lavoro come segue:
I Calligrammi sono un'idealizzazione della poesia in versi liberi e della precisione tipografica in un'epoca in cui la tipografia sta raggiungendo una brillante conclusione della sua carriera, agli albori dei nuovi mezzi di riproduzione che sono il cinema e il fonografo. (Guillaume Apollinaire, in una lettera ad André Billy)

[Fonte: Wikipedia]
 

Composizione n.1

di Marc Saporta

E' un innovativo romanzo-in-scatola pubblicato per la prima volta da Éditions du Seuil. Con Composizione N. 1 di Marc Saporta il romanzo innovativo diventa un'opera di maestria editoriale man mano che progredisce nel design e nel concetto estetico verso l'oggetto d'arte del libro. Composizione n. 1 è scritta in pagine sciolte non rilegate che possono essere rimescolate in una composizione casuale, un concetto sviluppato negli anni '60 quando John Cage sperimentò modi per liberare la composizione dalla determinazione autoritaria. La composizione casuale è un modo per creare una forma aperta in cui le pagine del romanzo possono essere lette in una struttura creata dal lettore. Se il lettore deve mischiare le pagine come "un mazzo di carte", allora la lettura del romanzo diventerà un gioco d'azzardo. Questo è un tema introdotto da Stéphane Mallarmé in Un coup de dés n'abolira jamais le hasard (1897), dove il disegno spaziale del poema tipografico afferma il futuro successo dell'inevitabile, il caso stesso, che non può essere abolito.

Gli eventi di Composizione n. 1 si svolgono a Parigi dove i personaggi hanno esperienze che mostrano un'intertestualità con una lettura futura, un momento in cui le trame hanno assunto un significato letterario. I personaggi sono guidati da X che istruisce il lettore a rimescolare le pagine, c'è Marianne "alla sua scrivania", Buisson che dice "Ci prendiamo cura di te dopo la scuola", Helga che "ronza come un insetto dorato al sole". ," e Dagmar che è "seduto sul divano basso". I personaggi di Composizione n. 1 sono studenti e la trama si sta gradualmente dispiegando davanti al lettore in uno stile che sembra futuristico, leggermente erotico e scritto in uno stile oggettivo di prosa con una molteplicità di interazioni che compongono un complesso cast di personalità.
[Fonte: David Detrich "Composition No. 1: An Innovative Novel-in-a-Box Inspired by Abstract Painting" in Innovative fiction magazine]
 
Centomila miliardi di poesie

di Raymond Queneau

Cent Mille Milliards de Poèmes, del 1961, di Raymond Queneau è un libro interattivo di poesia combinatoria. Come dice lo stesso Queneau nella prefazione: “Questo librettino permette a chiunque di comporre a piacimento centomila miliardi di sonetti; tutti regolari, s’intende. Perché questa è, dopo tutto, nient’altro che una sorta di macchina per la produzione di poesie; e queste sono sì in numero limitato ma abbastanza da poter permettere in teoria una lettura lunga quasi duecento milioni di anni (leggendo ventiquattro ore su ventiquattro)”.

Questo libro, infatti, grazie alla sua particolare tecnologia fisica, permette al lettore di diventare anche poeta, potendo comporre i suoi versi sotto forma di sonetti: due quartine seguite da due terzine, cioè quattordici versi in totale.
Il libro, paradossalmente, è composto solo di dieci fogli, scritti su entrambe le facciate. Il segreto per poter creare, potenzialmente, centomila miliardi di poesie, consiste nel mondo in cui questi fogli sono stati tagliati, ovvero in 14 strisce orizzontali contenenti ciascuna un verso. Tutte le bande orizzontali e i fogli sono ricombinabili, fino a poter creare un numero insormontabile di sonetti, che per poter essere letti tutti ci si impiegherebbero milioni di anni.
Come del resto in tutta la letteratura combinatoria, questo libro non è semplicemente una cosa da leggere, esso diventa anche una scatola di gioco, in cui il fruitore (perché non si tratta più di lettore) può costruire e smontare tutto a suo piacimento, per trovarsi alla fine del “gioco” con qualcosa di prodotto da sé.
Il fatto che Cent Milliard di Poèmes sia considerata una opera rivoluzionaria e innovativa consiste proprio nel meccanismo con cui esso funziona. Nel 1961, Raymond Queneau creò un libro che anticipava le modalità di sviluppo e di funzionamento dei più moderni software informatici.

[Fonte: Fabiola Stuppi in Interactive Storytelling and Art 2019]
 
In balia di una sorte avversa

di B. S. Johnson

E' un romanzo sperimentale dello scrittore inglese Bryan Stanley Johnson. Si tratta di un "libro in una scatola" (book in a box), in cui l'ordine dei capitoli viene stabilito dal lettore. Uscito in poche copie nel 1969, è diventato in breve tempo un oggetto da collezione. Nel 2004 la biografia di Johnson scritta da Jonathan Coe ha richiamato l'attenzione sulla sua opera, e il romanzo è stato ripubblicato nel 2008 dalla casa editrice statunitense New Directions. L'edizione in lingua italiana è invece del 2011 ed è l'unico libro dell'autore a essere tradotto in Italia.
Il romanzo si compone di 27 capitoli non rilegati racchiusi in una scatola. Il primo e l'ultimo, indicati come tali, sono fissi, mentre i fascicoli dei 25 centrali possono essere disposti a piacere dal lettore, che in questo modo ne stabilisce l'ordine e la scansione.

[Fonte: Wikipedia]
 
Zettel’s Traum

di Arno Schmidt
Schmidt iniziò a scrivere il romanzo nel dicembre 1963, quando lui e Hans Wollschläger iniziarono a tradurre in tedesco le opere di Edgar Allan Poe. Il romanzo è stato ispirato dal romanzo di James Joyce Finnegans Wake, in particolare dall'uso delle colonne da parte di Schmidt (il suo "SpaltenTechnik"), che secondo Schmidt è stato preso in prestito dal Wake.
Il gigantesco romanzo è stato pubblicato in formato folio con 1.334 pagine. La storia è raccontata principalmente su tre colonne mobili, presentando il testo sotto forma di note, collage e pagine dattiloscritte. La traduzione inglese del 2016 di John E. Woods ha 1.496 pagine e pesa 5,9 kg.
Il romanzo inizia intorno alle 4 del mattino di un giorno di mezza estate del 1968 nella brughiera di Lüneburg, nella Bassa Sassonia nord-orientale, nel nord della Germania, e si conclude venticinque ore dopo. Segue le vite del cinquantaquattrenne Daniel Pagenstecher, che riceve la visita dei traduttori Paul Jacobi e sua moglie Wilma e della loro figlia di sedici anni Franziska. La storia si occupa dei problemi della traduzione di Edgar Allan Poe in tedesco e dell'esplorazione dei temi che veicola, in particolare per quanto riguarda la sessualità.

[Fonte: Wikipedia]
 
Dizionario dei Chazari

di Milorad Pavić

Dizionario dei Chazari: romanzo Lessico (Serbo: Хазарски речник o Hazarski rečnik) è il primo romanzo dello scrittore serbo Milorad Pavić, pubblicato nel 1987.
Scritto originariamente in serbo, il romanzo è stato tradotto in molte lingue, incluso l'italiano.
È difficile individuare una trama in senso tradizionale, ma il fatto centrale del libro (la conversione religiosa di massa del popolo dei Chazari) è basata su un evento storico avvenuto alla fine dell'VIII secolo od all'inizio del IX, quando i regnanti e la nobilità chazara si convertirono al giudaismo seguiti da parte della popolazione.
Tuttavia, fin dall'inizio, Pavić mette in evidenza il proprio stile ispirato al fantastico di Borges: la maggior parte dei protagonisti e degli eventi del romanzo sono completamente inventati, così come la cultura attribuita nel libro ai Chazari, che fa ben poco riferimento all'evidenza letteraria od archeologica.
Il romanzo ha la struttura di tre piccole enciclopedie con riferimenti incrociati, ciascuna delle quali compilata sulla base delle fonti di una delle tre religioni monoteiste: il Cristianesimo (Libro Rosso), l'Islam (Libro Verde) e il Giudaismo (Libro Giallo). Data la sua struttura simile al dizionario, il romanzo può essere letto in una varietà di modi, piuttosto che dall'inizio alla fine. Ciò sfida i lettori a partecipare attivamente al romanzo cercando di ricombinare la storia mettendone assieme i pezzi, frammentati e, talvolta, contraddittori. Come spiega l'autore nell'introduzione al romanzo: "Non sarà necessario rispettare alcuna cronologia. Ciascun lettore potrà ricombinare in un'unità il proprio libro come in una partita di domino o di carte, e in ogni caso da questo dizionario, come da uno specchio, gli ritornerà esattamente quanto vi avrà investito, perché dalla verità - com'è scritto in una delle pagine di questo lessico - non si può ottenere più di quanto si sia ad essa offerto.
Il libro è stato pubblicato in due edizioni, una "maschile" ed una "femminile", che differiscono fra loro solo in un paragrafo.
Qualcuno ha ipotizzato che la descrizione dell'Impero dei Chazari, nel quale i Chazari pur essendo la popolazione più numerosa sono tuttavia dominati dagli altri, costituisca una rappresentazione allegorica della Jugoslavia. Lo stesso Pavić ha confermato che nel suo romanzo i Chazari rappresentano simbolicamente i Serbi.
[Fonte: Wikipedia]
 
Paesaggio dipinto con il tè

di Milorad Pavić

Paesaggio dipinto con il tè (Serbo: Предео сликан чајем o Predeo slikan cajem) è un romanzo dello scrittore serbo Milorad Pavić, pubblicato nel 1988.
In Italia è stato tradotto e pubblicato da Garzanti nel 1991 e non è stato più ristampato.
Il romanzo (così come gli altri scritti di Pavić) non segue una struttura classica (lettura dalla prima all'ultima pagina) ma si avvale piuttosto di una struttura ergodica (non si deve necessariamente leggere dalla prima all'ultima pagina ma si può seguire un ordine diverso).
La prima parte del romanzo segue le vicende dell'architetto Atanasio Svilar che cerca di capire come mai, seppur capace nel proprio mestiere, non sia mai riuscito a costruire un edificio. Per farlo seguirà le orme del padre che, disertore, era scomparso durante la Seconda Guerra Mondiale e si era probabilmente rifugiato nel Monastero di Hilandar sulle pendici del Monte Athos.
La seconda parte è presentata come un cruciverba da risolvere. Ogni successivo capitolo è affidato come definizione delle caselle orizzontali e verticali, ed al lettore è lasciata la libertà di proseguire la storia come meglio crede, seguendo i capitoli che preferisce.
[Fonte: Wikipedia]
 
Fuoco pallido
 
di Vladimir Nabokov

Nel dicembre del 1961, sei anni dopo la pubblicazione di Lolita, Nabokov termina Fuoco pallido, prodigio di invenzione e, per alcuni, summa della sua opera: romanzo audace e segreto, che risulta anche più sconcertante quanto alla forma, poiché è costituito da un magistrale poema di 999 versi con relativo commento.
Al centro del poema il sessantunenne John Shade, celebre poeta nonché professore al Wordsmith College di una immaginaria cittadina americana della Costa orientale. In quest’opera i ricordi di una vita si mescolano a interrogativi metafisici sull’«abisso immondo, intollerabile» della morte, divenuti sempre più pressanti dopo il suicidio della giovane figlia. Eppure il poema si chiude su un’ironica quanto serena dichiarazione di fede in un vago aldilà di cui l’arte, con la sua armonia, rappresenta una tacita promessa. Shade ignora che la morte, beffarda, è di nuovo in agguato.
Al centro del commento, invece, lo snob, egocentrico, bizzarro, importuno Charles Kinbote, visiting professor nella medesima università, nonché amico ed estimatore di Shade. Le sue note – ora pettegole, ora accademiche, ora nostalgiche – vorrebbero condurre il lettore a una corretta interpretazione del poema ricostruendo le affascinanti avventure del suo presunto ispiratore, vale a dire Kinbote stesso, esule di alto lignaggio da Zembla, regno immerso nelle brume di un’esotica Europa. Ma quelle note finiscono per suonare come un’esilarante parodia di due mondi contrapposti, l’aristocratica Zembla precipitata nella Rivoluzione Estremista e la borghese, prosaica, benpensante America che ha accolto il fuggitivo in pericolo.
Mirabile mimesi della realtà, Fuoco pallido ci guida così alla ricostruzione di uno scenario complesso attraverso tortuosi e frammentari percorsi che aprono interrogativi sempre nuovi: Kinbote è un re in esilio, un pedante profugo di terre lontane, o un soggetto psichiatrico afflitto da monomania? E il poema stesso è autentico, o non piuttosto una parodia, o magari un plagio?
Plurimi sono i livelli di realtà che si intersecano nel libro, i falsipiani che moltiplicano le prospettive dell’intreccio rendendolo vertiginoso: Fuoco pallido si avvia sereno come una pastorale, esplode in commedia festosa, si inerpica fino al culmine dolente di un’elegia, prende il largo sotto le sembianze di racconto avventuroso, ma la sua nota dominante resta quella tragica della solitudine.
 [Fonte: Adelphi]
La struttura del libro è particolarissima. Troviamo, nell’ordine:
• Una prefazione di un certo Charles Kinbote ad un lungo poema di 999 versi intitolato Fuoco pallido il cui autore è John Shade;
• L’intero poema di John Shade (“di gran lunga il più sublime dei poeti inventati”, dice Nabokov in un’intervista del 1965);
• Il commento al poema, che viene ripreso da Kinbote verso per verso per spiegarne il significato;
• Le note al commento, una sorta di lessico.
ELIZA

di Joseph Weizenbaum

ELIZA è un programma Chatterbot scritto nel 1966 da Joseph Weizenbaum che fa la parodia di un terapeuta Rogersiano, in buona parte rispondendo al paziente con domande ottenute dalla riformulazione delle affermazioni del paziente stesso. Così, per esempio, alla frase "Mi fa male la testa" il programma può ribattere con "Perché dici che ti fa male la testa?" oppure la risposta a "Mia madre mi odia" potrebbe essere "Chi altro nella tua famiglia ti odia?"
ELIZA fu chiamato così prendendo spunto da Eliza Doolittle, la fioraia dall'eloquio incolto e dialettale protagonista della commedia Pigmalione di George Bernard Shaw che, grazie al metodo d'insegnamento della ripetizione delle forme corrette di pronuncia, impara il raffinato modo di esprimersi delle classi più agiate.

La scelta della psicoterapia

È inaccurato dire che ELIZA simuli (o peggio, emuli) un terapeuta. Weizenbaum disse che Eliza è una parodia delle "domande di uno psicoterapeuta all'inizio di un intervento psichiatrico". Egli scelse la psicoterapia "per evitare il problema di dare al programma una vera conoscenza", la seduta psicoterapeutica è una di quelle poche situazioni in cui un essere umano può rispondere ad una affermazione con una domanda che parte da quella poca conoscenza del soggetto in discussione. Per esempio, in un contesto in cui alla domanda "Chi è il tuo compositore preferito?" può essere accettabile che si risponda con la domanda "Che ne dici di parlarmi del tuo compositore preferito?" o "Questa domanda ti interessa?"

Funzionamento

ELIZA procedeva analizzando e sostituendo semplici parole chiave in frasi preconfezionate. A seconda delle parole che l'utente immetteva nel programma, l'illusione di un interlocutore umano veniva smascherata o poteva continuare per diverse battute. Talvolta risultava talmente convincente che esistono aneddoti su persone così convinte di comunicare con un essere umano, da insistere per parecchi minuti. Tutto questo deriva dalla tendenza delle persone a dare alle parole significati che il computer certo non può attribuire.

Implementazioni e sviluppi

ELIZA fu incluso in un certo numero dei primi giochi per computer, con diversi tipi di interfaccia grafica. Don Daglow ha scritto una versione più sviluppata del programma denominato Ecala su un mainframe PDP-10 all'università di Pomona nel 1973 prima di scrivere il primo RPG, Dungeon (1975). È probabile che ELIZA fosse inoltre sul sistema in cui Will Crowther creò Adventure, il videogioco d'avventura del 1975 che ha dato origine al genere della fiction interattiva. Ma entrambi questi giochi sono comparsi circa nove anni dopo l'ELIZA originale.

Negli anni seguenti furono realizzati molti programmi basati su ELIZA, in differenti linguaggi oltre ad Ecala. Per esempio, nel 1980, una compagnia chiamata "Don't Ask Software", fondata da Randy Simon, creò una versione per Apple II, Atari e Commodore, che usava come parole quelle immesse dall'utente. In Spagna, Jordi Perez sviluppò il famoso Zebal nel 1993, scritto in Clipper per MS-DOS

MELIZA

Vi è poi un'applicazione curiosa di ELIZA su Google Earth: predisponendo la posizione su Marte (e più precisamente vicino alla Face of Mars) si può trovare accanto l'icona con la testa di un robot di nome MELIZA: premendo l'icona parte automaticamente una finta chat interplanetaria con un presunto essere alieno. Il dialogo è in inglese e reca le stesse funzioni del programma originale.

Originalità di ELIZA

Nel 1966, il computer interattivo (tramite telescrivente) era nuovo. Sarebbero passati quindici anni prima che il personal computer diventasse familiare al grande pubblico, e due decenni prima che la maggior parte delle persone incontrasse i primi tentativi di linguaggio naturale nei servizi di internet, come Ask.com o sistemi d'aiuto come Microsoft Office Clippy. Nonostante questi programmi avessero richiesto anni di ricerca e lavoro (mentre Ecala offuscò le funzionalità di ELIZA in meno di due settimane di lavoro di un singolo programmatore), ELIZA rimane una pietra miliare semplicemente perché fu la prima volta che un programmatore sviluppò un'interazione uomo-macchina con l'obiettivo di creare l'illusione (seppur breve) di un dialogo uomo-uomo.

[Fonte: Wikipedia]

 
Racter

di William Chamberlain e Thomas Etter

Racter è un programma per computer di intelligenza artificiale che genera in modo casuale prosa in lingua inglese. È stato pubblicato nel 1984 da Mindscape.
Racter, abbreviazione di narratore, è stato scritto da William Chamberlain e Thomas Etter. L'esistenza del programma è stata rivelata nel 1983 in un libro intitolato The Policeman's Beard Is Half Constructed (ISBN 0-446-38051-2), che è stato descritto come composto interamente dal programma. Secondo l'introduzione al libro di Chamberlain, il programma apparentemente funzionava su una macchina CP/M; è stato scritto in "BASIC compilato su un micro Z80 con 64K di RAM". Questa versione, il programma che presumibilmente ha scritto il libro, non è stata rilasciata al pubblico. La sofisticata architettura dichiarata del programma era probabilmente esagerata, come si è potuto verificare da un’indagine sul sistema di modelli di generazione del testo.
Tuttavia, nel 1984 Mindscape ha rilasciato una versione interattiva di Racter, sviluppata da Inrac Corporation, per computer compatibili con PC IBM, Amiga e Apple II. Il Racter pubblicato era simile a un chatterbot. Il programma BASIC che è stato rilasciato da Mindscape era molto meno sofisticato di qualsiasi cosa che avrebbe potuto scrivere la prosa abbastanza sofisticata di The Policeman's Beard. La versione commerciale di Racter potrebbe essere paragonata a una versione computerizzata di Mad Libs, il gioco in cui si riempiono gli spazi vuoti in anticipo e poi li si inserisce in un modello di testo per produrre un racconto surreale. La versione  commerciale del programma  provava ad analizzare gli input di testo, identificando nomi e verbi significativi, che poi rigurgitava per creare "conversazioni", collegando l'input dell'utente a modelli di frasi che poi combinava, insieme a moduli che coniugavano verbi inglesi.
Al contrario, il testo in The Policeman's Beard, oltre ad essere stato modificato da una grande quantità di output, sarebbe stato il prodotto di modelli e moduli specializzati di Chamberlain, che non erano inclusi nella versione commerciale del programma.

[Fonte: Wikipedia]
 
afternoon: a story

di Michael Joyce

afternoon: a story, scritto con la "a" minuscola, è un'opera di letteratura elettronica scritta nel 1987 dall'autore americano Michael Joyce. È stato pubblicato da Eastgate Systems nel 1990 ed è conosciuto come uno dei primi lavori di narrativa ipertestuale.
E' stato presentato al pubblico inizialmente come dimostrazione del sistema di creazione di ipertesti Storyspace, annunciato nel 1987 alla prima conferenza pomeridiana dell'Association for Computing Machinery Hypertext in un articolo di Michael Joyce e Jay David Bolter. Nel 1990 è stato pubblicato su dischetto e distribuito nella stessa forma da Eastgate Systems. È stata seguita da una serie di altre fiction ipertestuali di Storyspace, tra cui Victory Garden di Stuart Moulthrop, Patchwork Girl di Shelley Jackson e Marble Springs di Deena Larsen. Eastgate continua a pubblicare il lavoro negli anni 2010 e lo distribuisce su un'unità flash USB.
 
Trama e struttura
La fiction ipertestuale racconta la storia di Peter, un uomo da poco divorziato che ha assistito a un incidente d'auto. Ore dopo, sospetta che l'auto distrutta potrebbe aver coinvolto la sua ex moglie e il loro figlio.
La trama può cambiare ogni volta che viene letta se il lettore sceglie percorsi diversi.
 

Critica

afternoon è un'opera di letteratura elettronica molto discussa poiché è stata uno dei primi romanzi elettronici interattivi e pertanto oggetto di molti studi. Espen J. Aarseth dedica a afternoon un capitolo del suo libro Cybertext, definendolo un classico esempio di letteratura modernista. È più spesso pensato come un'opera di letteratura postmoderna, come evidenziato dalla sua inclusione nella Norton Anthology of Postmodern American Fiction. Anche in Writing Space di Jay David Bolter e The End of Books o Books Without End di J. Yellowlees Douglas si tratta di afternoon, così come in Mechanisms: New Media and the Forensic Imagination di Matthew G. Kirschenbaum. L'articolo di Gunnar Liestøl "Wittgenstein, Genette, and the Reader's Narrative in Hypertext" in Hyper / Text / Theory (1994) di George Landow utilizza la teoria della narratologia per comprendere afternoon e la tesi di laurea di Anna Gunders Hyperworks - On Digital Literature and Computer Games.

[Fonte: Wikipedia]
 

Dungeon multiutente

di Roy Trubshaw e Richard Bartle

I multi user dungeon (abbreviato in MUD, talvolta inteso come acronimo di multi user dimension o domain) sono una categoria di videogiochi di ruolo eseguiti su Internet attraverso il computer da più utenti. Si tratta di giochi testuali, dove i giocatori interagiscono con il mondo e gli altri utenti digitando dei comandi da tastiera.

Molti utenti possono connettersi contemporaneamente a un MUD. Ognuno di essi controlla un personaggio che si muove in un mondo virtuale organizzato in stanze e zone (una zona è un raggruppamento di più stanze: per esempio, una zona può essere una città e le stanze che contiene possono esserne le vie e gli edifici), e può interagire coi personaggi degli altri utenti o con quelli gestiti dal computer, progredire (acquisendo abilità) oppure anche morire. Molti MUD prevedono la possibilità, per i giocatori più esperti, di collaborare alla vita del MUD in questione insieme agli amministratori del gioco: dopo che il personaggio di un giocatore ha raggiunto il massimo livello possibile, diviene un "immortale" o una "divinità" (possono volerci anni di gioco), e acquisisce una parte dei poteri che hanno gli amministratori. Di solito, gli immortali usano queste nuove capacità proponendo sfide agli altri giocatori, dette quest, organizzando gare e mettendo in palio ricompense e altri premi, oppure consigliando i nuovi giocatori, a loro discrezione.

Alcuni MUD dispongono di comandi che consentono l'accessibilità anche a giocatori non vedenti o ipovedenti, permettendo loro di giocare e interagire con gli altri utenti.

l primo MUD (chiamato proprio M.U.D., in seguito meglio noto come MUD1) apparve nel 1978, compilato in BCPL. I MUD crebbero di popolarità durante i primi anni ottanta, quando i personal computer divennero relativamente economici e comparvero i primi modem, che permisero la connessione alle prime BBS. Lo sviluppo dei MUD avvenne prevalentemente in ambito accademico ed in particolare presso l'Università dell'Essex dove veniva giocato da parecchie persone, anche esterne all'università stessa. Scherzosamente MUD cambiò significato in "Multi-Undergrad Destroyer" poiché il tempo dedicatogli dagli studenti aumentava sempre più allontanandoli dal completamento degli studi.

Lo sviluppo del primissimo MUD è attribuito a Roy Trubshaw e Richard Bartle, dell'Università dell'Essex, che lo scrissero per un DEC PDP-10 come estensione multiutente di un altro gioco per PDP-10 chiamato Dungeon, che venne successivamente distribuito da Infocom sotto il nome di Zork. Zork a sua volta era ispirato ad un altro gioco testuale conosciuto come Colossal Cave Adventure.

Questi giochi, sia mono che multi-utente, traevano ispirazione dai giochi di ruolo da tavolo come Dungeons \& Dragons che proprio in quegli anni avevano raggiunto una notevole popolarità (Advanced Dungeons \& Dragons (AD\&D) venne pubblicato nel 1977).

Il legame così stretto tra i MUD e i giochi di ruolo da tavolo continuò negli anni anche grazie all'introduzione di nuove ambientazioni per AD\&D. Tra queste ebbero particolarmente fortuna le ambientazioni di Forgotten Realms e Dragonlance. Vennero sviluppati MUD anche sulla base degli altri giochi di ruolo che venivano alla luce come Vampiri: la masquerade, e Middle-earth Role Playing.

Nel 1985 apparve SHADES, il primo MUD commerciale accessibile dalla rete Prestel.

Sebbene gli scorsi anni abbiano visto un declino della popolarità dei MUD in favore delle avventure grafiche, i MUD continuano ad attrarre giocatori e sono accessibili tramite client telnet standard o con i client MUD specializzati.


[Fonte: Wikipedia]

 
TinyMUD

di James Aspnes

TinyMUD nacque da una stanca settimana di lavoro di James Aspnes, allora studente della Carnegie Mellon University (adesso insegna a Yale). Come base per lo sviluppo di TinyMUD Aspnes decise di utilizzare i sorgenti di Monster – un abbozzo di MUD scritto in Pascal per MVS e con sorgenti di pubblico dominio– con l’intenzione di mantenerne la flessibilità ma di renderlo più snello (TinyMUD infatti prevedeva di mantenere la definizione del database tutto su memoria, a differenza del padre che gestiva tutto su file). TinyMUD fu installato per la prima volta nel 1989 sulla porta 4201 della macchina “lancelot.avalon.cs.cmu.edu”.
Nonostante le ovvie limitazioni del programma – Aspnes infatti decise inizialmente di abbandonare il progetto quando TinyMUD andò in crash superando i 32 megabyte imposti come limite sulla grandezza dei processi – TinyMUD è, insieme ai suoi derivati TinyMUCK e TinyMOO, uno dei sistemi MUD più popolari su Internet. Con i server TinyMUD nacquero così le prime definizioni alternative al genere classico, si cominciò ad utilizzare dei termini come MUSH (Multi User SHared allucinations) e MOO (MUD Object Oriented). TinyMUD infatti si distingueva dai suoi predecessori soprattutto per il fatto che il gameplay era più orientato alla comunicazione e alla creazione di mondi che non al combattimento e alla mera esplorazione di caverne.

[Tratto dall’articolo di Paolo Matrascia Analisi storica e critica dei MUD in www.mud.it]},
	language = {it},
	urldate = {2023-02-12},
	file = {Snapshot:files/25/leggere-complicato-la-letteratura-ergodica.html:text/html},
}

@misc{noauthor_grande_2021,
	title = {Un grande giocattolo cartaceo (e digitale): il libro ergodico},
	shorttitle = {Un grande giocattolo cartaceo (e digitale)},
	url = {http://www.mastereditoria.it/ilblog/un-grande-giocattolo-cartaceo-e-digitale-il-libro-ergodico/},
	abstract = {La letteratura ergodica, poco nota ma dalle origini antiche, raccontata attraverso una serie di progetti editoriali italiani e internazionali.},
	language = {it-IT},
	urldate = {2023-02-12},
	journal = {il BLOG di EDITORIA},
	month = apr,
	year = {2021},
	file = {Snapshot:files/27/un-grande-giocattolo-cartaceo-e-digitale-il-libro-ergodico.html:text/html},
}

@misc{st2wok_il_2019,
	title = {{IL} {CERVELLO} {CHE} {LEGGE} {E} {LA} {LETTERATURA} {ERGODICA}},
	url = {https://ossessionicontaminazioni.wordpress.com/2019/02/20/il-cervello-che-legge-e-la-letteratura-ergodica/},
	abstract = {Recentemente ho letto il libro di Maryanne Wolf Lettore, vieni a casa. Il cervello che legge in un mondo digitale (Vita e Pensiero, 2018). Il tema del libro è l’analisi della neurofisiologia …},
	language = {it-IT},
	urldate = {2023-02-12},
	journal = {ossessionicontaminazioni},
	author = {{st2wok}},
	month = feb,
	year = {2019},
	file = {Snapshot:files/29/il-cervello-che-legge-e-la-letteratura-ergodica.html:text/html},
}

@misc{noauthor_casa_2020,
	title = {Casa di foglie, la letteratura ergodica e il senso della pagina scomposta},
	url = {https://ilrifugiodellircocervo.com/2020/02/10/casa-di-foglie-quando-persino-le-parole-fuggono-dalle-pagine/},
	abstract = {Casa di foglie, Mark Z. Danielewski (66thand2nd, 2019 – trad. S. Reggiani e L. Taiuti)   Quando ho sentito parlare di Casa di foglie la prima volta, il libro era già fuori commercio. Gli…},
	language = {it-IT},
	urldate = {2023-02-12},
	month = feb,
	year = {2020},
	file = {Snapshot:files/31/casa-di-foglie-quando-persino-le-parole-fuggono-dalle-pagine.html:text/html},
}

@misc{natale_di_2021,
	title = {Di una letteratura espansa},
	url = {http://marvinrivista.it/index.php/2021/06/11/di-una-letteratura-espansa/},
	abstract = {«La raccolta aggiunge un tassello al worldbuilding da cui proviene, sostanzia il mondo di "Casa di foglie" di una plancia di gioco più ampia. Rende l’istituto psichiatrico Three Attic Whalestoe, semplicemente, più vero».},
	language = {it-IT},
	urldate = {2023-02-12},
	journal = {MARVIN},
	author = {Natale, Flavio},
	month = jun,
	year = {2021},
	file = {Snapshot:files/33/di-una-letteratura-espansa.html:text/html},
}

@misc{noauthor_paolo_nodate,
	title = {Paolo {Albani} - {La} letteratura come gioco combinatorio},
	url = {https://site.unibo.it/griseldaonline/it/approfondimenti/paolo-albani-letteratura-gioco-combinatorio},
	abstract = {Griseldaonline è un sito dedicato alla ricerca letteraria, alla formazione didattica e al dialogo tra le discipline umanistiche. Saggi, ipertesti, interviste, percorsi iconografici: sono le diverse prospettive attraverso le quali Griselda si propone di guardare il complesso mondo letterario.},
	language = {it},
	urldate = {2023-02-12},
	file = {Snapshot:files/35/paolo-albani-letteratura-gioco-combinatorio.html:text/html},
}

@misc{noauthor_citta_nodate,
	title = {Le città invisibili e la letteratura combinatoria di {Calvino} - {Oscar} {Mondadori}},
	url = {https://www.oscarmondadori.it/approfondimenti/da-le-citta-invisibili-a-palomar-la-letteratura-combinatoria-di-italo-calvino/},
	urldate = {2023-02-12},
	file = {Le città invisibili e la letteratura combinatoria di Calvino - Oscar Mondadori:files/37/da-le-citta-invisibili-a-palomar-la-letteratura-combinatoria-di-italo-calvino.html:text/html},
}

@misc{grasso_narrativa_2016,
	title = {La narrativa combinatoria del {Novecento} e {Raymond} {Queneau}},
	url = {https://www.900letterario.it/focus-letteratura/narrativa-combinatoria-sperimentazione/},
	abstract = {Nella consapevolezza che la letteratura non può conservare i sui ruoli tradizionali, si muove anche},
	language = {it-IT},
	urldate = {2023-02-12},
	journal = {'900 Letterario {\textbar} Letteratura del '900, critica, eventi letterari, cinema, politica, attualità},
	author = {Grasso, Annalina},
	month = dec,
	year = {2016},
	file = {Snapshot:files/39/narrativa-combinatoria-sperimentazione.html:text/html},
}

@misc{patamia_arte_2020,
	title = {L'arte combinatoria di {Italo} {Calvino} in {Le} città invisibili},
	url = {https://rewriters.it/larte-combinatoria-di-italo-calvino-in-le-citta-invisibili/},
	abstract = {Nei dettagli di un luogo si nasconde un certo tipo di fascino sensoriale che cattura i nostri sensi imprimendo nella nostra mente un’immagine indelebile....},
	language = {it-IT},
	urldate = {2023-02-12},
	journal = {ReWriters},
	author = {Patamia, Fernanda},
	month = jul,
	year = {2020},
	file = {Snapshot:files/41/larte-combinatoria-di-italo-calvino-in-le-citta-invisibili.html:text/html},
}

@misc{noauthor_notitle_nodate,
	url = {https://www.andreamartines.it/scritti/la-letteratura-combinatoria/},
	urldate = {2023-02-12},
	file = {https\://www.andreamartines.it/scritti/la-letteratura-combinatoria/:files/43/la-letteratura-combinatoria.html:text/html},
}

@misc{pirola_lordine_2020,
	title = {L’ordine nella casualità},
	url = {https://prof-pirola.medium.com/lordine-nella-casualit%C3%A0-ab8ef11bc689},
	abstract = {La letteratura combinatoria},
	language = {en},
	urldate = {2023-02-12},
	journal = {Medium},
	author = {Pirola, Luca},
	month = apr,
	year = {2020},
	file = {Snapshot:files/45/lordine-nella-casualità-ab8ef11bc689.html:text/html},
}

@misc{gsm_beni_2021,
	title = {Beni culturali: il digital twin dell'{Oratorio} di {S}. {Giorgio}},
	shorttitle = {Beni culturali},
	url = {https://www.geosmartmagazine.it/2021/11/15/beni-culturali-digital-twin-oratorio-san-giorgio/},
	abstract = {Beni culturali: rilievi per la realizzazione del digital twin dell'oratorio di S. Giorgio con metodologie di Geomapping 3D di Geolander.it.},
	language = {it-IT},
	urldate = {2023-02-13},
	journal = {Geosmart Magazine},
	author = {GSM, redazione},
	month = nov,
	year = {2021},
	file = {Snapshot:files/48/beni-culturali-digital-twin-oratorio-san-giorgio.html:text/html},
}

@misc{noauthor_open_nodate,
	title = {Open {Innovation} - {Notizie}},
	url = {https://www.openinnovation.regione.lombardia.it/it/news/news/view?id=6656},
	language = {it},
	urldate = {2023-02-13},
	file = {Snapshot:files/50/view.html:text/html},
}

@misc{noauthor_innovazione_nodate,
	title = {Innovazione e tecnologia per i beni artistici e culturali},
	url = {https://poloinnovazioneict.org/news/innovazione-e-tecnologia-per-i-beni-artistici-e-culturali/},
	abstract = {L’allentamento delle limitazioni imposte dal lockdown sta gradualmente facendo ripartire la fruizione del patrimonio artistico, dopo un anno di drammatica contrazione. Tuttavia, la crisi pandemica ha contribuito a diffondere un grande interesse verso le opportunità offerte dal digitale. Sono, infatti, numerosi i casi di sperimentazione e adozione di soluzioni tecnologiche, nell’intento di assecondare la rivoluzione […]},
	language = {it-IT},
	urldate = {2023-02-13},
	journal = {Polo ICT},
	file = {Snapshot:files/51/innovazione-e-tecnologia-per-i-beni-artistici-e-culturali.html:text/html},
}

@misc{redazione_gli_2022,
	title = {Gli {NFT} e il difficile dialogo col mondo dei beni culturali},
	url = {https://www.piselliandpartners.com/news-di-settore/gli-nft-e-il-difficile-dialogo-col-mondo-dei-beni-culturali/},
	abstract = {Approfondimento a cura della Dott.ssa Serena Nardoni   NFT (Non-Fungible Token) è un acronimo ormai d’uso comune, anche grazie alla diffusione che i social media e i canali d’informazione hanno contribuito ad alimentare, soprattutto in conseguenza dell’imprevista accelerata sul fronte della smaterializzazione dei rapporti. Partendo dall’assunto che l’NFT non coincide con l’opera d’arte, ma ne rappresenta il…},
	language = {it-IT},
	urldate = {2023-02-13},
	journal = {Piselli \& Partners},
	author = {Redazione},
	month = jul,
	year = {2022},
	file = {Snapshot:files/53/gli-nft-e-il-difficile-dialogo-col-mondo-dei-beni-culturali.html:text/html},
}

@misc{noauthor_d-tech_nodate,
	title = {D-{TECH} - {Digital} {Twin} {Environment} for {Cultural} {Heritage}},
	url = {https://architettura.uniroma3.it/articoli/d-tech-digital-twin-environment-for-cultural-heritage-213801},
	abstract = {Il progetto D-TECH (Digital-Twin Environment for Cultural Heritage) finanziato dalla Regione Lazio e dal Miur nell’ambito del programma "Attuazione degli…},
	language = {it-IT},
	urldate = {2023-02-13},
	journal = {Dipartimento di Architettura},
	file = {Snapshot:files/55/d-tech-digital-twin-environment-for-cultural-heritage-213801.html:text/html},
}

@misc{noauthor_presentazione_nodate,
	title = {Presentazione della {Piattaforma} multimediale per la gestione dei beni culturali},
	url = {https://ict.enea.it/event/presentazione-della-piattaforma-multimediale-per-la-gestione-dei-beni-culturali/},
	abstract = {2022-05-18 09:00  - 2022-05-18 13:00},
	language = {it-IT},
	urldate = {2023-02-13},
	file = {Snapshot:files/57/presentazione-della-piattaforma-multimediale-per-la-gestione-dei-beni-culturali.html:text/html},
}

@misc{sando_digital_2022,
	title = {Digital twin: una risorsa per le imprese. {Cos}'è e come finanziarlo?},
	shorttitle = {Digital twin},
	url = {https://fasi.eu/it/articoli/20-approfondimenti/24382-digital-twin-risorsa-per-imprese-come-finanziarlo.html},
	abstract = {Le applicazioni del gemello digitale sono molteplici, dal settore energia ai beni culturali. Per capire come funziona e quali sono le sue potenzialità in azienda ne abbiamo parlato con Cineca, il consorzio interuniversitario nazionale per il supercalcolo.},
	language = {it-it},
	urldate = {2023-02-13},
	journal = {FASI},
	author = {Sando, Viola De},
	month = apr,
	year = {2022},
	file = {Snapshot:files/59/24382-digital-twin-risorsa-per-imprese-come-finanziarlo.html:text/html},
}

@misc{noauthor_digital_nodate,
	title = {Digital {Twin} - {Supporto} alla {Progettazione} ({Scan} to {BIM})},
	url = {https://rilievilaser.it/digital-twin/},
	abstract = {La Tecnologia Digitale a supporto della Progettazione (Scan to BIM): Digital Twin. Scopri cos è e a che cosa serve.},
	language = {it-IT},
	urldate = {2023-02-13},
	journal = {Rilievi Laser},
	file = {Snapshot:files/61/digital-twin.html:text/html},
}

@misc{masterandcommander_digital_2021,
	title = {Digital {Transformation} dei beni culturali e {Recovery} {Plan}},
	url = {https://www.carraro-lab.com/2021/06/29/digital-transformation-dei-beni-culturali/},
	abstract = {Corso per il sistema Museale della Provincia di Lucca L’evoluzione digitale del sistema museale e culturale sta per entrare in una significativa fase di accelerazione, anche […]},
	language = {it-IT},
	urldate = {2023-02-13},
	journal = {Carraro Lab},
	author = {masterandcommander},
	month = jun,
	year = {2021},
	file = {Snapshot:files/63/digital-transformation-dei-beni-culturali.html:text/html},
}

@misc{latronico_digital_2022,
	title = {Digital {Twin}: tutti i vantaggi di un’innovazione senza fine},
	shorttitle = {Digital {Twin}},
	url = {https://innovando.it/digital-twin-tutti-i-vantaggi-di-uninnovazione-senza-fine/},
	abstract = {Alla scoperta dei Gemelli Digitali, delle tecnologie che li supportano e di chi si servirà del più stimolante modello esistente di simulazione},
	language = {it-IT},
	urldate = {2023-02-13},
	journal = {Innovando.News - Giornale digitale svizzero sull'innovazione},
	author = {Latronico, Antonietta},
	month = mar,
	year = {2022},
	file = {Snapshot:files/65/digital-twin-tutti-i-vantaggi-di-uninnovazione-senza-fine.html:text/html},
}

@article{diara_ark-bim_2021,
	title = {{ARK}-{BIM}: {Open}-{Source} {Cloud}-{Based} {HBIM} {Platform} for {Archaeology}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	shorttitle = {{ARK}-{BIM}},
	url = {https://www.mdpi.com/2076-3417/11/18/8770},
	doi = {10.3390/app11188770},
	abstract = {In recent years, Historic Building Information Modelling (HBIM) methodology has strengthened the documentation and interpretation of archaeological contexts and is regarded as a breakthrough in relation to established methodologies and analyses. Change is also taking place regarding web and cloud-based solutions, and this work acknowledges the importance of cloud-based and web HBIM solutions applied to Cultural Heritage assets and archaeology. More than ever, online platforms are becoming useful services to ease data exchange and validation between collaborators and stakeholders, establishing multidisciplinary approaches. Despite the presence of different cloud-based platforms, Heritage asset documentation can hardly be managed by environments or software developed for architecture and construction design. For this reason, this project is strongly founded on four pillars: online documentation, collaboration, communication and accessibility. Cognisant of these needs, the paper is aimed at the development of a custom HBIM cloud platform for archaeology, on the basis of the BIMData open-source online environment. This platform, called ARK-BIM, can be considered a modular solution leaning on HTML, JavaScript, VueJS, XEOKIT and open-source languages.},
	language = {en},
	number = {18},
	urldate = {2023-02-25},
	journal = {Applied Sciences},
	author = {Diara, Filippo and Rinaudo, Fulvio},
	month = jan,
	year = {2021},
	note = {Number: 18
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {HBIM, accessibility, archaeology, cloud-based BIM, data exchange, web-development},
	pages = {8770},
	file = {Full Text PDF:files/67/Diara e Rinaudo - 2021 - ARK-BIM Open-Source Cloud-Based HBIM Platform for.pdf:application/pdf},
}

@article{cheng_ontology-based_2021,
	title = {Ontology-based {HBIM} for historic buildings with traditional woodwork in {Taiwan}},
	volume = {27},
	copyright = {Copyright (c) 2021 The Author(s). Published by Vilnius Gediminas Technical University.},
	issn = {1822-3605},
	url = {https://journals.vilniustech.lt/index.php/JCEM/article/view/14115},
	doi = {10.3846/jcem.2021.14115},
	abstract = {In recent years, the use of Historic Building Information Modeling (HBIM) has grown prevalent and thus provided a research opportunity. Differing from newly constructed buildings, structural components of historic buildings come with unique physical configurations and have amassed impressive amount of restoration data, all of which must be taken into consideration when incorporating Building Information Modeling. In terms of modelling, it is critical to determine the appropriate level of detail (LoD), level of information (LoI), especially the comprehensiveness and expandability of the database. International Committee for Documentation/Conceptual Reference Model (CIDOC CRM) is a widely accepted standard for ontology model. This study aims to integrate the HBIM and CIDOC CRM to construct a framework and comprehensive operational procedure for the modeling of traditional Minan architecture and a database with complete semantics archiving the background and restoration data. Autodesk A360 is ideal for collaborative. However, there are limitations when it comes to developing advanced models for data management or query; interactive experience; meeting model applications derived from future scenarios. Therefore, the study also offers a 3D modeling platform constructed using Unity, as well as a comparison of the platforms built with Unity, three.js and Autodesk A360 as a reference for users.
													Keyword : 
																											HBIM, 
																			CIDOC CRM, 
																			historic building, 
																			conservation, 
																			semantic data, 
																			ontology
																								
						
													
								How to Cite
								
									
										
  Cheng, Y.-M., Kuo, C.-L., \& Mou, C.-C. (2021). Ontology-based HBIM for historic buildings with traditional woodwork in Taiwan. Journal of Civil Engineering and Management, 27(1), 27-44. https://doi.org/10.3846/jcem.2021.14115

									
									
										
											More Citation Formats
											
										
										
																							
													
														ACM
													
												
																							
													
														ACS
													
												
																							
													
														APA
													
												
																							
													
														ABNT
													
												
																							
													
														Chicago
													
												
																							
													
														Harvard
													
												
																							
													
														IEEE
													
												
																							
													
														MLA
													
												
																							
													
														Turabian
													
												
																							
													
														Vancouver},
	language = {en},
	number = {1},
	urldate = {2023-02-25},
	journal = {Journal of Civil Engineering and Management},
	author = {Cheng, Ying-Mei and Kuo, Chiao-Ling and Mou, Chia-Ching},
	month = jan,
	year = {2021},
	note = {Number: 1},
	keywords = {HBIM, ontology, CIDOC CRM, conservation, historic building, semantic data},
	pages = {27--44},
	file = {Full Text PDF:files/70/Cheng et al. - 2021 - Ontology-based HBIM for historic buildings with tr.pdf:application/pdf},
}

@inproceedings{borin_connecting_2020,
	address = {Cham},
	series = {Springer {Series} in {Design} and {Innovation}},
	title = {Connecting {Historical} {Information} with {BIM} {Ontologies}. {HBIM} {Methods} for the {Visualization} of {Harris} {Matrix} for the {Torrione} in {Carpi}},
	isbn = {978-3-030-47979-4},
	doi = {10.1007/978-3-030-47979-4_65},
	abstract = {The presented work responds to the need to represent the Harris matrix in a three-dimensional BIM model, providing a clear reading of each of its elements through a visualization methodology reliable to the symbols and rules defined in the literature. The potential applications of these graphic strategies have been experimented in the case study of the Torrione in Carpi.},
	language = {en},
	booktitle = {Graphical {Heritage}},
	publisher = {Springer International Publishing},
	author = {Borin, Paolo and Bernardello, Rachele A. and Grigoletto, Anna},
	editor = {Agustín-Hernández, Luis and Vallespín Muniesa, Aurelio and Fernández-Morales, Angélica},
	year = {2020},
	keywords = {Knowledge, HBIM, Harris matrix, Parameters, Torrione, Visualization},
	pages = {757--770},
}

@incollection{marcello_balzani_modellazione_2022,
	title = {Modellazione semantica {HBIM} per la rappresentazione digitale dell’intervento sul patrimonio esistente},
	isbn = {978-88-351-4193-8},
	url = {https://series.francoangeli.it/index.php/oa/catalog/view/832/681/4962},
	abstract = {La documentazione digitale dell’intervento sul patrimonio culturale e sul costruito esistente attraverso l’elaborazione di modelli parametrici semanticamente arricchiti è una delle attuali principali sfide nella definizione ed applicazione di protocolli scan to HBIM. Le conseguenti possibilità di interazione, in ambienti digitali integrati, del sistema di relazioni – significato – associato alla rappresentazione geometrica-morfologica ed informativa dei manufatti architettonici – significante – sta ulteriormente modificando, nel contesto di una rivoluzione digitale avviata decenni orsono, il rapporto tra finalità progettuali e rappresentazione dell’architettura a favore, apparentemente, della maggiore discretizzazione delle forme e della standardizzazione semantica. Nell’ambito di un filone di ricerca che indaga il rapporto tra progetto, messaggio-linguaggio e rappresentazione, del quale sono qui riportati parte degli esiti di una ricerca finanziata svolta in partenariato pubblico-privato da quattro enti pubblici di ricerca ed oltre dieci imprese della catena del valore dell’intervento sul patrimonio esistente, è studiato il complesso rapporto tra le possibilità offerte dall’implementazione semantica di piattaforme HBIM open standard ed i requisiti – vincoli – che la visualizzazione di modelli parametrici semanticamente arricchiti attualmente impone.},
	language = {it},
	urldate = {2023-02-25},
	booktitle = {{DIALOGHI} / {DIALOGUES} • visioni e visualità / visions and visuality},
	publisher = {FrancoAngeli srl},
	author = {{Marcello Balzani}},
	month = sep,
	year = {2022},
	doi = {10.3280/oa-832-c173},
	file = {Marcello Balzani - 2022 - Modellazione semantica HBIM per la rappresentazion.pdf:files/76/Marcello Balzani - 2022 - Modellazione semantica HBIM per la rappresentazion.pdf:application/pdf},
}

@misc{noauthor_version_nodate,
	title = {Version 7.2.2 {\textbar} {CIDOC} {CRM}},
	url = {https://cidoc-crm.org/Version/version-7.2.2},
	urldate = {2023-02-25},
}

@inproceedings{pauwels_integrating_2013,
	title = {Integrating building information modelling and semantic web technologies for the management of built heritage information},
	volume = {1},
	doi = {10.1109/DigitalHeritage.2013.6743787},
	abstract = {The historical built environment is acknowledged as a valuable but complex material and cultural resource that needs to be preserved. Digital technologies give the opportunity to improve and expand the comprehension of the complex artefacts present in this built environment. Building information modelling (BIM) and semantic web technologies are two technologies that are often used for the documentation of the built environment and of cultural heritage resources. With our research, we investigate to what extent those technologies can be integrated and which advantages this combination can produce for the analysis and interpretation of our built environment. In this paper, we present the application of BIM software and semantic web technologies to a case study: the Book Tower in Ghent, Belgium. The Book Tower is one of the most important early 20th century buildings in the city of Ghent. Through the paper we will show how BIM and semantic web technologies were integrated, which advantages this combination can produce and which future developments could be considered. The recorded information can be essential to plan and manage a recovery plan and/or a maintenance program taking into consideration also aspects linked to cultural diversity and environmental sustainability.},
	booktitle = {2013 {Digital} {Heritage} {International} {Congress} ({DigitalHeritage})},
	author = {Pauwels, Pieter and Bod, Rens and Di Mascio, Danilo and De Meyer, Ronald},
	month = oct,
	year = {2013},
	keywords = {Buildings, Cultural differences, Ontologies, Documentation, Poles and towers, Resource description framework},
	pages = {481--488},
}

@article{acierno_architectural_2017,
	title = {Architectural heritage knowledge modelling: {An} ontology-based framework for conservation process},
	volume = {24},
	issn = {1296-2074},
	shorttitle = {Architectural heritage knowledge modelling},
	url = {https://www.sciencedirect.com/science/article/pii/S129620741630262X},
	doi = {10.1016/j.culher.2016.09.010},
	abstract = {This paper presents an ontology-based model to support the representation and management of information and knowledge during investigation activities for the conservation of architectural heritage. Despite the significant impact of information and communications technology (ICT) on architectural heritage, current approaches to its use in this context are often conceived only to provide flexible and reusable tools and methodologies, thus proposing oversimplified procedures that are ultimately insufficient for a truly accurate conservation project. A few experiences recently have focused much attention on the specifics of conservation. Although they have generally been concerned with the specific activities and knowledge domains related to conservation processes (such as cataloguing or monument damage), the importance of dealing with them in an integrated way is often neglected. Hence, each step of the process – such as the preliminary phase of knowledge acquisition, the summaries, which facilitate the assessment of value, diagnostics, design, the construction phase, and maintenance – is treated in isolation from all the other activities. This lack of synergy often compromises the final result. In order to deal with the complexity of representing historical architecture, and its conservation process, this proposed model defines four main knowledge domains (artefact – lifecycle – architectural heritage investigation process – actors), in which all the knowledge related to each artefact is formalized through semantic networks, in terms of entities, properties and relationships. Specific reasoning and inference rules allow checking of the model for coherence, in order to reduce information discrepancies, inconsistencies and errors. The proposed model offers a high level of accuracy in its capacity for description and, at the same time, a broad versatility within representation modelling, allowing such a reliable representation of multiple issues that eventually it may be required for every historical building, depending on its features and state of conservation. Moreover, the versatility of the model provides a suitable representation even for the different nature of the investigation activities results – whether analytical or hermeneutical. Finally, the knowledgebase has been connected with a building information modelling environment, providing an effective integration between geometrical and non-geometrical information.},
	language = {en},
	urldate = {2023-02-25},
	journal = {Journal of Cultural Heritage},
	author = {Acierno, Marta and Cursi, Stefano and Simeone, Davide and Fiorani, Donatella},
	month = mar,
	year = {2017},
	keywords = {Ontologies, Architectural heritage, Building information modelling, Investigation and conservation process, Knowledge modelling},
	pages = {124--133},
	file = {Full text:files/81/Acierno et al. - 2017 - Architectural heritage knowledge modelling An ont.pdf:application/pdf},
}

@article{de_luca_generic_2007,
	title = {A generic formalism for the semantic modeling and representation of architectural elements},
	volume = {23},
	issn = {1432-2315},
	url = {https://doi.org/10.1007/s00371-006-0092-5},
	doi = {10.1007/s00371-006-0092-5},
	abstract = {This article presents a methodological approach to the semantic description of architectural elements based both on theoretical reflections and research experiences. To develop this approach, a first process of extraction and formalization of architectural knowledge on the basis of the analysis of architectural treaties is proposed. Then, the identified features are used to produce a template shape library dedicated to buildings surveying. Finally, the problem of the overall model structuring and organization using semantic information is addressed for user handling purposes.},
	language = {en},
	number = {3},
	urldate = {2023-02-25},
	journal = {The Visual Computer},
	author = {De Luca, Livio and Véron, Philippe and Florenzano, Michel},
	month = mar,
	year = {2007},
	pages = {181--205},
	file = {Versione inviata:files/83/De Luca et al. - 2007 - A generic formalism for the semantic modeling and .pdf:application/pdf},
}

@article{de_luca_semantic-based_2011,
	series = {Virtual {Reality} in {Brazil}},
	title = {A semantic-based platform for the digital analysis of architectural heritage},
	volume = {35},
	issn = {0097-8493},
	url = {https://www.sciencedirect.com/science/article/pii/S0097849310001780},
	doi = {10.1016/j.cag.2010.11.009},
	abstract = {This essay focuses on the fields of architectural documentation and digital representation. We present a research paper concerning the development of an information system at the scale of architecture, taking into account the relationships that can be established between the representation of buildings (shape, dimension, state of conservation, hypothetical restitution) and heterogeneous information about various fields (such as the technical, the documentary or still the historical one). The proposed approach aims to organize multiple representations (and associated information) around a semantic description model with the goal of defining a system for the multi-field analysis of buildings.},
	language = {en},
	number = {2},
	urldate = {2023-02-26},
	journal = {Computers \& Graphics},
	author = {De Luca, Livio and Busayarat, Chawee and Stefani, Chiara and Véron, Philippe and Florenzano, Michel},
	month = apr,
	year = {2011},
	keywords = {Architectural heritage, Information systems, Internet, Multiple representations, Semantic description},
	pages = {227--241},
	file = {Versione inviata:files/85/De Luca et al. - 2011 - A semantic-based platform for the digital analysis.pdf:application/pdf},
}

@inproceedings{bruno_restoration_2018,
	title = {A {RESTORATION} {ORIENTED} {HBIM} {SYSTEM} {FOR} {CULTURAL} {HERITAGE} {DOCUMENTATION}: {THE} {CASE} {STUDY} {OF} {PARMA} {CATHEDRAL}},
	volume = {XLII-2},
	shorttitle = {A {RESTORATION} {ORIENTED} {HBIM} {SYSTEM} {FOR} {CULTURAL} {HERITAGE} {DOCUMENTATION}},
	url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-2/171/2018/},
	doi = {10.5194/isprs-archives-XLII-2-171-2018},
	abstract = {{\textless}p{\textgreater}{\textless}strong class="journal-contentHeaderColor"{\textgreater}Abstract.{\textless}/strong{\textgreater} The need to safeguard and preserve Cultural Heritage (CH) is increasing and especially in Italy, where the amount of historical buildings is considerable, having efficient and standardized processes of CH management and conservation becomes strategic. At the time being, there are no tools capable of fulfilling all the specific functions required by Cultural Heritage documentation and, due to the complexity of historical assets, there are no solution as flexible and customizable as CH specific needs require. Nevertheless, BIM methodology can represent the most effective solution, on condition that proper methodologies, tools and functions are made available. The paper describes an ongoing research on the implementation of a Historical BIM system for the Parma cathedral, aimed at the maintenance, conservation and restoration.{\textless}br{\textgreater} Its main goal was to give a concrete answer to the lack of specific tools required by Cultural Heritage documentation: organized and coordinated storage and management of historical data, easy analysis and query, time management, 3D modelling of irregular shapes, flexibility, user-friendliness, etc.{\textless}br{\textgreater} The paper will describe the project and the implemented methodology, focusing mainly on survey and modelling phases. In describing the methodology, critical issues about the creation of a HBIM will be highlighted, trying to outline a workflow applicable also in other similar contexts.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2023-02-26},
	booktitle = {The {International} {Archives} of the {Photogrammetry}, {Remote} {Sensing} and {Spatial} {Information} {Sciences}},
	publisher = {Copernicus GmbH},
	author = {Bruno, N. and Roncella, R.},
	month = may,
	year = {2018},
	note = {ISSN: 1682-1750},
	pages = {171--178},
	file = {Full Text PDF:files/87/Bruno e Roncella - 2018 - A RESTORATION ORIENTED HBIM SYSTEM FOR CULTURAL HE.pdf:application/pdf},
}

@article{rechichi_sharing_2016,
	title = {{SHARING} {HIGH}-{RESOLUTION} {MODELS} {AND} {INFORMATION} {ON} {WEB}: {THE} {WEB} {MODULE} {OF} {BIM3DSG} {SYSTEM}},
	volume = {XLI-B5},
	issn = {2194-9034},
	shorttitle = {{SHARING} {HIGH}-{RESOLUTION} {MODELS} {AND} {INFORMATION} {ON} {WEB}},
	url = {http://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLI-B5/703/2016/isprs-archives-XLI-B5-703-2016.pdf},
	doi = {10.5194/isprsarchives-XLI-B5-703-2016},
	abstract = {BIM3DSG system is described here. It is an ad hoc designed BIM system created for Cultural Heritage applications. It proposes some solutions to solve some issues related to the use of BIM in this field. First, it tries to resolve the problem of managing huge, complex, high resolution and heterogeneous 3D models, and then it offers a practical, easy and efficient solution for a wide sharing of data and information.},
	language = {en},
	urldate = {2023-02-26},
	journal = {ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Rechichi, F. and Mandelli, A. and Achille, C. and Fassi, F.},
	month = jun,
	year = {2016},
	pages = {703--710},
	file = {Rechichi et al. - 2016 - SHARING HIGH-RESOLUTION MODELS AND INFORMATION ON .pdf:files/88/Rechichi et al. - 2016 - SHARING HIGH-RESOLUTION MODELS AND INFORMATION ON .pdf:application/pdf},
}

@article{zhang_ontology-based_2013,
	title = {Ontology-{Based} {Partial} {Building} {Information} {Model} {Extraction}},
	volume = {27},
	copyright = {© 2013 American Society of Civil Engineers},
	issn = {1943-5487},
	url = {https://ascelibrary.org/doi/10.1061/%28ASCE%29CP.1943-5487.0000277},
	doi = {10.1061/(ASCE)CP.1943-5487.0000277},
	abstract = {The current application of building information modeling (BIM) in the construction industry is generally focused on using the complete building information model during the life cycle of the project. With more information being added to the model, the size of the model file and the difficulty to manipulate the model increase. However, different use scenarios may only require access to certain specific information stored in the model. In contrast with the ample research of ontology applications in construction knowledge management, research of ontology in construction modeling has been limited. Hence, the purpose of this study is to use ontology in the extraction of a partial building information model from the original complete model. The building information models covered in this study are in the Industry Foundation Classes (IFC) format, which is a widely supported open BIM standard. An ontology TBox is developed according to the existing IFC schema specifications. For each specific IFC model, an ontology ABox is generated at run time, combining the ontology TBox and the IFC instances in the model. The ABox works as an index in the partial model extraction algorithm. A prototype Java program based on the algorithm was developed to demonstrate and validate the algorithm using both a sample model and an IFC model from a real building. The results indicated that the use of ontology provides a valid way to deal with the technical complexity of IFC models.},
	language = {EN},
	number = {6},
	urldate = {2023-02-26},
	journal = {Journal of Computing in Civil Engineering},
	author = {Zhang, Le and Issa, Raja R. A.},
	month = nov,
	year = {2013},
	note = {Publisher: American Society of Civil Engineers},
	keywords = {Algorithms, Building information modeling (BIM), Building information models, Extraction algorithm, Industry Foundation Classes (IFC), Ontology, Partial model},
	pages = {576--584},
}

@article{previtali_ontology-based_2020,
	title = {An {Ontology}-{Based} {Representation} of {Vaulted} {System} for {HBIM}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/10/4/1377},
	doi = {10.3390/app10041377},
	abstract = {In recent years, many efforts have been invested in the cultural heritage digitization: surveying, modelling, diagnostic analysis and historic data collection. Nowadays, this effort is finalized in many cases towards historical building information modelling (HBIM). However, the architecture, engineering, construction and facility management (AEC-FM) domain is very fragmented and many experts operating with different data types and models are involved in HBIM projects. This prevents effective communication and sharing of the results not only among different professionals but also among different projects. Semantic web tools may significantly contribute in facilitating sharing, connection and integration of data provided in different domains and projects. The paper describes this aspect specifically focusing on managing the information and models acquired on the case of vaulted systems. Information is collected within a semantic based hub platform to perform cross correlation. Such functionality allows the reconstructing of the rich history of the construction techniques and skilled workers across Europe. To this purpose an ontology-based vaults database has been undertaken and an example of its implementation is presented. The developed ontology-based vaults database is a database that makes uses of a set of ontologies to effectively combine data and information from multiple heterogeneous sources. The defined ontologies provide a high-level schema of a data source and provides a vocabulary for user queries.},
	language = {en},
	number = {4},
	urldate = {2023-02-26},
	journal = {Applied Sciences},
	author = {Previtali, Mattia and Brumana, Raffaella and Stanga, Chiara and Banfi, Fabrizio},
	month = jan,
	year = {2020},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {HBIM, database, semantic web, vaulted systems ontology},
	pages = {1377},
	file = {Full Text PDF:files/92/Previtali et al. - 2020 - An Ontology-Based Representation of Vaulted System.pdf:application/pdf},
}

@inproceedings{brumana_hbim_2017,
	title = {{HBIM} {CHALLENGE} {AMONG} {THE} {PARADIGM} {OF} {COMPLEXITY}, {TOOLS} {AND} {PRESERVATION}: {THE} {BASILICA} {DI} {COLLEMAGGIO} 8 {YEARS} {AFTER} {THE} {EARTHQUAKE} ({L}’{AQUILA})},
	volume = {XLII-2-W5},
	shorttitle = {{HBIM} {CHALLENGE} {AMONG} {THE} {PARADIGM} {OF} {COMPLEXITY}, {TOOLS} {AND} {PRESERVATION}},
	url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-2-W5/97/2017/},
	doi = {10.5194/isprs-archives-XLII-2-W5-97-2017},
	abstract = {{\textless}p{\textgreater}{\textless}strong class="journal-contentHeaderColor"{\textgreater}Abstract.{\textless}/strong{\textgreater} In December 2012 ENIservizi (the Italian multi-national energy agency operating in many countries), after the Earthquake that occurred in April 2009, decided to undertake the project ‘Re-start from Collemaggio’ with the aim of giving new hope to the L’Aquila community, funding around 14 million Euro to restore the Basilica di Collemaggio. The Superintendence Office carried on the restoration project with the scientific support of the Università degli Studi de L’Aquila and the Università La Sapienza di Roma, under the coordination of the Politecnico di Milano. ENIservizi, aware of the BIM potential in the complex building and infrastructure domain in the world, required an advanced HBIM from the laser scanner and photogrammetric surveying to support the diagnostic analysis, the design project, the tender and the restoration itself, today still on course. {\textless}br{\textgreater}{\textless}br{\textgreater}Plans and vertical sections were delivered (2012) starting from the surveying campaigns (February and June 2013), together with the first HBIM advancement from the end of 2012 in support of the preliminary-definitive-executive steps of the restoration design project (2013-14-15). Five years later, this paper tries to make a synthesis of the different lessons learnt, in addition to the positive and critical aspects relating HBIM feasibility, sustainability and usefulness to the challenging restoration work. {\textless}br{\textgreater}{\textless}br{\textgreater}In particular, the Collemaggio BIM experience anticipated the new Italian Public Procurement Legislation (D.Lgs 50/2016, Nuovo Codice degli Appalti pubblici) aligned with to the EUPPD 24/2014: the EU Directive on Public Procurement asked all the 28 EU countries to adopt building informative modelling by February 2016 in order to support the whole LCM (Life Cycle Management), starting from the project and the intervention, through rewarding scores or mandatory regulations. Many analyses foresees to save from around 5\% to 15\% of the overall investment by adopting mature BIM (Level 3 to 5), particularly 4D remotely controlled BIM in support of the LCM, as in the case of maintenance and management process. The tender for Basilica restoration was published in 2015: the process was not developed enough to introduce selective criteria based on BIM adoption by the Construction Industry due to the lack of legislation at that time and the lack of BIM skills among the companies. Nevertheless ENIservizi also separately funded aside the HBIM of the Basilica to tackle an advanced BIM able to address decision-making processes in the heritage domain among the different actors: to support operators, architects, structural engineers, economic computation, construction site management and restoration, the theoretical and practical approach adopted by the HBIM, overcame the current logic based on sequential LoD (from simplex to complex, from the preliminary to the executive design) that is typical of new constructions in favour of a complex LoD approach that could guarantee management of the richness, unicity and multiplicity of each component and the maximum degree of knowledge in order to derive the decisions from the starting phases of the project. On the lesson learnt from this experience, the process of updating the current codification criteria (UNI11337-2009) was started with a draft proposal stimulating a debate for the future of HBIM adoption.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2023-02-26},
	booktitle = {The {International} {Archives} of the {Photogrammetry}, {Remote} {Sensing} and {Spatial} {Information} {Sciences}},
	publisher = {Copernicus GmbH},
	author = {Brumana, R. and Della Torre, S. and Oreni, D. and Previtali, M. and Cantini, L. and Barazzetti, L. and Franchi, A. and Banfi, F.},
	month = aug,
	year = {2017},
	note = {ISSN: 1682-1750},
	pages = {97--104},
	file = {Full Text PDF:files/94/Brumana et al. - 2017 - HBIM CHALLENGE AMONG THE PARADIGM OF COMPLEXITY, T.pdf:application/pdf},
}

@inproceedings{barazzetti_hbim_2015,
	title = {{HBIM} and augmented information: towards a wider user community of image and range-based reconstructions},
	volume = {XL-5-W7},
	shorttitle = {{HBIM} and augmented information},
	url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XL-5-W7/35/2015/},
	doi = {10.5194/isprsarchives-XL-5-W7-35-2015},
	abstract = {{\textless}p{\textgreater}{\textless}strong class="journal-contentHeaderColor"{\textgreater}Abstract.{\textless}/strong{\textgreater} This paper describes a procedure for the generation of a detailed HBIM which is then turned into a model for mobile apps based on augmented and virtual reality. Starting from laser point clouds, photogrammetric data and additional information, a geometric reconstruction with a high level of detail can be carried out by considering the basic requirements of BIM projects (parametric modelling, object relations, attributes). The work aims at demonstrating that a complex HBIM can be managed in portable devices to extract useful information not only for expert operators, but also towards a wider user community interested in cultural tourism.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2023-02-26},
	booktitle = {The {International} {Archives} of the {Photogrammetry}, {Remote} {Sensing} and {Spatial} {Information} {Sciences}},
	publisher = {Copernicus GmbH},
	author = {Barazzetti, L. and Banfi, F. and Brumana, R. and Oreni, D. and Previtali, M. and Roncoroni, F.},
	month = aug,
	year = {2015},
	note = {ISSN: 1682-1750},
	pages = {35--42},
	file = {Full Text PDF:files/96/Barazzetti et al. - 2015 - HBIM and augmented information towards a wider us.pdf:application/pdf},
}

@inproceedings{fassi_new_2015,
	title = {A {NEW} {IDEA} {OF} {BIM} {SYSTEM} {FOR} {VISUALIZATION}, {WEB} {SHARING} {AND} {USING} {HUGE} {COMPLEX} {3D} {MODELS} {FOR} {FACILITY} {MANAGEMENT}.},
	volume = {XL-5-W4},
	url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XL-5-W4/359/2015/},
	doi = {10.5194/isprsarchives-XL-5-W4-359-2015},
	abstract = {{\textless}p{\textgreater}{\textless}strong class="journal-contentHeaderColor"{\textgreater}Abstract.{\textless}/strong{\textgreater} The work is the final part of a multi-year research project on the Milan Cathedral, which focused on the complete survey and threedimensional modeling of the Great Spire (Fassi et al., 2011) and the two altars in the transept. The main purpose of the job was to prepare support data for the maintenance operations involving the cathedral since 2009 and still in progress. The research job had begun addressing our efforts to identify which methods would allow an expeditious but comprehensive measure of complex architectural structure as a whole. (Achille et al., 2012) The following research works were focused mainly to find an efficient method to visualize, use and share the realized 3D model.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2023-02-26},
	booktitle = {The {International} {Archives} of the {Photogrammetry}, {Remote} {Sensing} and {Spatial} {Information} {Sciences}},
	publisher = {Copernicus GmbH},
	author = {Fassi, F. and Achille, C. and Mandelli, A. and Rechichi, F. and Parri, S.},
	month = feb,
	year = {2015},
	note = {ISSN: 1682-1750},
	pages = {359--366},
	file = {Full Text PDF:files/98/Fassi et al. - 2015 - A NEW IDEA OF BIM SYSTEM FOR VISUALIZATION, WEB SH.pdf:application/pdf},
}

@article{talon_state_2017,
	title = {State of the {Art} of {HBIM} to {Develop} the {HBIM} of the {HeritageCare} {Project}},
	volume = {6},
	doi = {10.4018/IJ3DIM.2017070103},
	abstract = {The European project, HeritageCare, aims to develop a methodology to help managers preserve historic monuments. The methodology developed integrates the advantages of historical building information modelling (HBIM): 3D visualization, grouping of information (history, diagnostics, videos, etc.) under the same object, help with monitoring of maintenance, help with the planning of works, etc. First, this article develops a state of the art HBIM and its use: realization of a numerical model (tools and database of objects), help with the maintenance, and identification of the risks associated with the realization of the works. The second part is devoted to the presentation of the HeritageCare project: context and challenges, content and development of the HBIM part.},
	journal = {International Journal of 3-D Information Modeling},
	author = {Talon, Aurélie and Cauvin, Clémence and Alaa, Chateauneuf},
	month = jul,
	year = {2017},
	pages = {33--43},
}

@article{iwaniak_enriching_2016,
	title = {Enriching and improving the quality of linked data with {GIS}},
	volume = {8},
	doi = {10.1515/geo-2016-0020},
	abstract = {Standardization of methods for data exchange in GIS has along history predating the creation of World Wide Web. The advent of World Wide Web brought the emergence of new solutions for data exchange and sharing including; more recently, standards proposed by the W3C for data exchange involving Semantic Web technologies and linked data. Despite the growing interest in integration, GIS and linked data are still two separate paradigms for describing and publishing spatial data on the Web. At the same time, both paradigms offer complementary ways of representing real world phenomena and means of analysis using different processing functions. The complementarity of linked data and GIS can be leveraged to synergize both paradigms resulting in richer data content and more powerful inferencing. The article presents an approach aimed at integrating linked data with GIS. The approach relies on the use of GIS tools for integration, verification and enrichment of linked data. The GIS tools are employed to enrich linked data by furnishing access to collection of data resources, defining relationship between data resources, and subsequently facilitating GIS data integration with linked data. The proposed approach is demonstrated with examples using data from DBpedia, OSM, and tools developed by the authors for standard GIS software.},
	journal = {Open Geosciences},
	author = {Iwaniak, Adam and Kaczmarek, Iwona and Strzelecki, Marek and Łukowicz, Jaromar and Jankowski, Piotr},
	month = jun,
	year = {2016},
	file = {Full Text PDF:files/107/Iwaniak et al. - 2016 - Enriching and improving the quality of linked data.pdf:application/pdf},
}

@article{migacz_investigation_nodate,
	title = {Investigation of linked open data technologies for purposes of publishing georeferenced statistical data},
	language = {en},
	author = {Migacz, Mirosław},
	file = {Migacz - Investigation of linked open data technologies for.pdf:files/109/Migacz - Investigation of linked open data technologies for.pdf:application/pdf},
}

@inproceedings{svenningsson_artificial_2020,
	address = {New York, NY, USA},
	series = {{AICCC} 2019},
	title = {Artificial {Intelligence} in {Conversational} {Agents}: {A} {Study} of {Factors} {Related} to {Perceived} {Humanness} in {Chatbots}},
	isbn = {978-1-4503-7263-3},
	shorttitle = {Artificial {Intelligence} in {Conversational} {Agents}},
	url = {https://doi.org/10.1145/3375959.3375973},
	doi = {10.1145/3375959.3375973},
	abstract = {Artificial intelligence (AI) is gaining traction in service-oriented businesses in the form of chatbots. A chatbot is a popular type of social AI that uses natural language processing to communicate with users. Past studies have shown discrepancies in terms of whether or not a chatbot should communicate and behave like a human. This article aims to explore these discrepancies in order to provide a theoretical contribution of a list of factors related to perceived humanness in chatbots and how these may consequently lead to a positive user experience. The results suggest that a chatbot should have the following characteristics: avoiding small talk and maintaining a formal tone; identifying itself as a bot and asking how it can help; providing specific information and articulating itself with sophisticated choices of words and well-constructed sentences; asking follow-up questions during decision-making processes and; providing an apology when the context is not comprehensible, followed by a question or a statement to dynamically move a conversation forward. These results may have implications for designers working in the field of AI as well as for the wider debates and the broader discourse around the adoption of AI in society.},
	urldate = {2023-03-07},
	booktitle = {Proceedings of the 2019 2nd {Artificial} {Intelligence} and {Cloud} {Computing} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Svenningsson, Nina and Faraon, Montathar},
	month = feb,
	year = {2020},
	keywords = {AI, artificial intelligence, chatbot, conversation, design guideline, humanness, user experience},
	pages = {151--161},
	file = {Full Text PDF:files/112/Svenningsson e Faraon - 2020 - Artificial Intelligence in Conversational Agents .pdf:application/pdf},
}

@article{varitimiadis_graph-based_2021,
	title = {Graph-{Based} {Conversational} {AI}: {Towards} a {Distributed} and {Collaborative} {Multi}-{Chatbot} {Approach} for {Museums}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	shorttitle = {Graph-{Based} {Conversational} {AI}},
	url = {https://www.mdpi.com/2076-3417/11/19/9160},
	doi = {10.3390/app11199160},
	abstract = {Nowadays, museums are developing chatbots to assist their visitors and to provide an enhanced visiting experience. Most of these chatbots do not provide a human-like conversation and fail to deliver the complete requested knowledge by the visitors. There are plenty of stand-alone museum chatbots, developed using a chatbot platform, that provide predefined dialog routes. However, as chatbot platforms are evolving and AI technologies mature, new architectural approaches arise. Museums are already designing chatbots that are trained using machine learning techniques or chatbots connected to knowledge graphs, delivering more intelligent chatbots. This paper is surveying a representative set of developed museum chatbots and platforms for implementing them. More importantly, this paper presents the result of a systematic evaluation approach for evaluating both chatbots and platforms. Furthermore, the paper is introducing a novel approach in developing intelligent chatbots for museums. This approach emphasizes graph-based, distributed, and collaborative multi-chatbot conversational AI systems for museums. The paper accentuates the use of knowledge graphs as the key technology for potentially providing unlimited knowledge to chatbot users, satisfying conversational AI’s need for rich machine-understandable content. In addition, the proposed architecture is designed to deliver an efficient deployment solution where knowledge can be distributed (distributed knowledge graphs) and shared among different chatbots that collaborate when is needed.},
	language = {en},
	number = {19},
	urldate = {2023-03-07},
	journal = {Applied Sciences},
	author = {Varitimiadis, Savvas and Kotis, Konstantinos and Pittou, Dimitra and Konstantakis, Georgios},
	month = jan,
	year = {2021},
	note = {Number: 19
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {collaborative AI, conversational AI, distributed AI, knowledge graphs, multi-agent systems, museum chatbot},
	pages = {9160},
	file = {Full Text PDF:files/114/Varitimiadis et al. - 2021 - Graph-Based Conversational AI Towards a Distribut.pdf:application/pdf},
}

@incollection{gaia_engaging_2019,
	address = {Cham},
	series = {Springer {Series} on {Cultural} {Computing}},
	title = {Engaging {Museum} {Visitors} with {AI}: {The} {Case} of {Chatbots}},
	isbn = {978-3-319-97457-6},
	shorttitle = {Engaging {Museum} {Visitors} with {AI}},
	url = {https://doi.org/10.1007/978-3-319-97457-6_15},
	abstract = {This chapter explores the application of artificial intelligence (AI) Artificial Intelligence (AI)in museums and galleries in engaging their audiences, specifically through the development and use of chatbotChatbottechnologies. Through a case studyCase studyapproach, the chapter further provides a practical focus on the design and implementation of an audience development pilot in Milan involving four historic house museumsHistoric house museums(Case Museo di Milano). The pilot aimed to find new and interesting ways to engage teenagersTeenagersin visiting these museums through visualizing narrative using a convergence of chatbot and gamificationGamificationplatforms.},
	language = {en},
	urldate = {2023-03-07},
	booktitle = {Museums and {Digital} {Culture}: {New} {Perspectives} and {Research}},
	publisher = {Springer International Publishing},
	author = {Gaia, Giuliano and Boiano, Stefania and Borda, Ann},
	editor = {Giannini, Tula and Bowen, Jonathan P.},
	year = {2019},
	doi = {10.1007/978-3-319-97457-6_15},
	pages = {309--329},
}

@article{varitimiadis_towards_2020,
	title = {Towards implementing an {AI} chatbot platform for museums},
	volume = {1},
	copyright = {Copyright (c) 2020 Savvas Varitimiadis, Konstantinos Kotis, Andreas Skamagis, Alexandros Tzortzakakis, George Tsekouras, Dimitris Spiliotopoulos},
	issn = {2654-1866},
	url = {https://eproceedings.epublishing.ekt.gr/index.php/cicms/article/view/2732},
	doi = {10.12681/cicms.2732},
	abstract = {Recently, understanding their unique role in storytelling and aiming to attract more visitors, several museums have integrated modern ICT technologies. The problem with these technologies however is that gradually tend to be of no real interest to visitors, lack of significant interaction, cannot be continuously updated, and eventually distract visitors from experiencing the exhibits. Museum visitors do not need to be impressed by a technological application but need to learn about the stories of the exhibits in a creative, human-centered and interactive manner. This paper presents an ongoing work towards implementing a new interactive technological trend for museums, i.e., a museum chatbot platform, namely MuBot. The MuBot platform aims to provide museums the opportunity to create simple, interactive and human-friendly apps for their visitors. Such apps will integrate an intelligent chatbot that uses some of the most advanced AI technologies of Machine Learning, Natural Language Processing/Generation, and the Semantic Web. Museum visitors will be able to use a chatbot application that will be created through the MuBot platform, to chat with a ‘smart’ exhibit. They will be able to ask questions through text or voice (in natural language) and receive audible or written answers. The more the visitors ask, the more MuBot will learn and store new knowledge in its knowledge base. The paper presents a preliminary design of the proposed MuBot platform, experimenting with first prototype implementations using the well-known Dialogflow framework, as well as using a Knowledge Graph-based approach.},
	language = {en},
	number = {1},
	urldate = {2023-03-07},
	journal = {International Conference on Cultural Informatics, Communication \& Media Studies},
	author = {Varitimiadis, Savvas and Kotis, Konstantinos and Skamagis, Andreas and Tzortzakakis, Alexandros and Tsekouras, George and Spiliotopoulos, Dimitris},
	year = {2020},
	note = {Number: 1},
	file = {Full Text PDF:files/119/Varitimiadis et al. - 2020 - Towards implementing an AI chatbot platform for mu.pdf:application/pdf},
}

@inproceedings{colace_chars_2019,
	address = {New York, NY, USA},
	series = {{TESCA}'19},
	title = {{CHARS}: a {Cultural} {Heritage} {Adaptive} {Recommender} {System}},
	isbn = {978-1-4503-7015-8},
	shorttitle = {{CHARS}},
	url = {https://doi.org/10.1145/3364544.3364830},
	doi = {10.1145/3364544.3364830},
	abstract = {One of the most significative resource of a territory is represented by the Cultural Heritage (CH). CH may be seen as one of the scenarios where new technologies, for example adaptive systems able to promote services, can provide more interesting contributions and relevant information. The aim of this paper is to introduce a methodology to design a chatbot based on a Context-Aware System able to recommends contents and services according to context and users' profile. A first prototype able to support tourists during a visit to Paestum Archeological Park was developed with aim to test the proposed architecture. The first experimental results are encouraging and show the potentiality of the proposed methodology.},
	urldate = {2023-03-07},
	booktitle = {Proceedings of the 1st {ACM} {International} {Workshop} on {Technology} {Enablers} and {Innovative} {Applications} for {Smart} {Cities} and {Communities}},
	publisher = {Association for Computing Machinery},
	author = {Colace, Francesco and De Santo, Massimo and Lombardi, Marco and Santaniello, Domenico},
	month = nov,
	year = {2019},
	keywords = {Context-Aware Computing, e-Tourism, Natural Language Processing, Recommender System, Smart City},
	pages = {58--61},
	file = {Full Text PDF:files/121/Colace et al. - 2019 - CHARS a Cultural Heritage Adaptive Recommender Sy.pdf:application/pdf},
}

@inproceedings{boiano_chatbots_2018,
	title = {Chatbots and {New} {Audience} {Opportunities} for {Museums} and {Heritage} {Organisations}},
	url = {https://www.scienceopen.com/hosted-document?doi=10.14236/ewic/EVA2018.33},
	doi = {10.14236/ewic/EVA2018.33},
	abstract = {This paper explores how chatbots can offer opportunities for museums and galleries in engaging their audiences through recent developments, and through a case study approach focusing on the design and implementation of an audience development pilot in Milan involving four historic house museums ( Case Museo di Milano ). The pilot aimed to find new and interesting ways to engage teenagers in visiting these museums through visualising narrative using a convergence of chatbot technology and gamification.},
	urldate = {2023-03-07},
	publisher = {BCS Learning \& Development},
	author = {Boiano, Stefania and Borda, Ann and Gaia, Guiliano and Rossi, Stefania and Cuomo, Pietro},
	month = jul,
	year = {2018},
	file = {Full Text PDF:files/123/Boiano et al. - 2018 - Chatbots and New Audience Opportunities for Museum.pdf:application/pdf},
}

@inproceedings{pavlidis_towards_2019,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Towards a {Novel} {User} {Satisfaction} {Modelling} for {Museum} {Visit} {Recommender} {Systems}},
	isbn = {978-3-030-05819-7},
	doi = {10.1007/978-3-030-05819-7_6},
	abstract = {Modern recommender systems technology appeared in Cultural Heritage application relatively recently, particularly during the dawn of the 21st century. There is already a significant amount of relevant works in the bibliography, which has been primarily empowered by large-scale research and development projects. Various approaches have been adopted from the recommender systems technology, including collaborative filtering, content-based, knowledge-based and hybrid systems. In most of these approaches that focused on museum guidance, which is the focus of this paper, the museum has been assumed to be a form of a gallery and the visitor was treated primarily as a user in seek on engagement and enjoyment. The free museum roaming was the main form of visit that has been considered and targeted, while the educational factors and storytelling aspects have been markedly overlooked. In this paper a new framework for the user satisfaction modelling is being presented that quantifies user satisfaction based on a weighted combination of various probabilistic factors that are being estimated during a museum visit. The goal is to provide a model of user satisfaction that can be used for museum recommenders that could guide either free-roaming visits or guided-tour scenarios for visitors of various motivations and backgrounds.},
	language = {en},
	booktitle = {{VR} {Technologies} in {Cultural} {Heritage}},
	publisher = {Springer International Publishing},
	author = {Pavlidis, George},
	editor = {Duguleană, Mihai and Carrozzino, Marcello and Gams, Matjaž and Tanea, Iulian},
	year = {2019},
	keywords = {Artificial intelligence, Cultural heritage, Machine learning, Museum guide, Recommendation, Recommender system, User modelling, User satisfaction},
	pages = {60--75},
	file = {Full Text PDF:files/125/Pavlidis - 2019 - Towards a Novel User Satisfaction Modelling for Mu.pdf:application/pdf},
}

@misc{noauthor_semantic_nodate,
	title = {Semantic {Web} and {Web} {GIS}},
	url = {https://encyclopedia.pub/entry/6138},
	abstract = {The field of geographic information science and its associated technologies have undergone rapid technological advancement and geographic information systems (GIS) now have wide-ranging functional capabilities. The field is characterised by specific expertise, one with a longstanding history of forward thinking and a track record for ongoing innovation and with this, the field has adopted many disruptive technologies from the fields of computer and information sciences through this transition towards web GIS. Most interestingly in this regard is the (often limited) uptake of semantic web technologies by the field and its associated technologies, the lack of which has resulted in a technological disjoint between these fields. As the field seeks to make geospatial information more accessible to more users and in more contexts through \&lsquo;self-service\&rsquo; applications and web GIS applications, the use of these technologies is imperative to support the interoperability between distributed data sources and services.\&nbsp;},
	language = {en},
	urldate = {2023-03-07},
}

@article{huang_towards_2020,
	title = {Towards knowledge-based geovisualisation using {Semantic} {Web} technologies: a knowledge representation approach coupling ontologies and rules},
	volume = {13},
	issn = {1753-8947},
	shorttitle = {Towards knowledge-based geovisualisation using {Semantic} {Web} technologies},
	url = {https://doi.org/10.1080/17538947.2019.1604835},
	doi = {10.1080/17538947.2019.1604835},
	abstract = {Geovisualisation is a knowledge-intensive art in which both providers and users need to possess a wide range of knowledge. Current syntactic approaches to presenting visualisation information lack semantics on the one hand, and on the other hand are too bespoke. Such limitations impede the transfer, interpretation, and reuse of the geovisualisation knowledge. In this paper, we propose a knowledge-based approach to formally represent geovisualisation knowledge in a semantically-enriched and machine-readable manner using Semantic Web technologies. Specifically, we represent knowledge regarding cartographic scale, data portrayal and geometry source, which are three key aspects of geovisualisation in the contemporary web mapping era, coupling ontologies and semantic rules. The knowledge base enables inference for deriving the corresponding geometries and portrayals for visualisation under different conditions. A prototype system is developed in which geospatial linked data are used as underlying data, and some geovisualisation knowledge is formalised into a knowledge base to visualise the data and provide rich semantics to users. The proposed approach can partially form the foundation for the vision of web of knowledge for geovisualisation.},
	number = {9},
	urldate = {2023-03-07},
	journal = {International Journal of Digital Earth},
	author = {Huang, Weiming and Harrie, Lars},
	month = sep,
	year = {2020},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/17538947.2019.1604835},
	keywords = {Geovisuaisation, knowledge representation, ontologies, semantic rules, Semantic Web},
	pages = {976--997},
	file = {Full Text PDF:files/128/Huang e Harrie - 2020 - Towards knowledge-based geovisualisation using Sem.pdf:application/pdf},
}

@article{paez_bringing_2022,
	title = {Bringing {Federated} {Semantic} {Queries} to the {GIS}-{Based} {Scenario}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2220-9964},
	url = {https://www.mdpi.com/2220-9964/11/2/86},
	doi = {10.3390/ijgi11020086},
	abstract = {Geospatial data is increasingly being made available on the Web as knowledge graphs using Linked Data principles. This entails adopting the best practices for publishing, retrieving, and using data, providing relevant initiatives that play a prominent role in the Web of Data. Despite the appropriate progress related to the amount of geospatial data available, knowledge graphs still face significant limitations in the GIScience community since their use, consumption, and exploitation are scarce, especially considering that just a few developments retrieve and consume geospatial knowledge graphs from within GIS. To overcome these limitations and address some critical challenges of GIScience, standards and specific best practices for publishing, retrieving, and using geospatial data on the Web have appeared. Nevertheless, there are few developments and experiences that support the possibility of expressing queries across diverse knowledge graphs to retrieve and process geospatial data from different and distributed sources. In this scenario, we present an approach to request, retrieve, and consume (geospatial) knowledge graphs available at diverse and distributed platforms, prototypically implemented on Apache Marmotta, supporting SPARQL 1.1 and GeoSPARQL standards. Moreover, our approach enables the consumption of geospatial knowledge graphs through a lightweight web application or QGIS. The potential of this work is shown with two examples that use GeoSPARQL-based knowledge graphs.},
	language = {en},
	number = {2},
	urldate = {2023-03-07},
	journal = {ISPRS International Journal of Geo-Information},
	author = {Páez, Oswaldo and Vilches-Blázquez, Luis M.},
	month = feb,
	year = {2022},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {federated query, GeoSPARQL, geospatial data, knowledge graph, SPARQL},
	pages = {86},
	file = {Full Text PDF:files/130/Páez e Vilches-Blázquez - 2022 - Bringing Federated Semantic Queries to the GIS-Bas.pdf:application/pdf},
}

@article{mai_deeply_2019,
	title = {Deeply integrating {Linked} {Data} with {Geographic} {Information} {Systems}},
	volume = {23},
	issn = {1467-9671},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tgis.12538},
	doi = {10.1111/tgis.12538},
	abstract = {The realization that knowledge often forms a densely interconnected graph has fueled the development of graph databases, Web-scale knowledge graphs and query languages for them, novel visualization and query paradigms, as well as new machine learning methods tailored to graphs as data structures. One such example is the densely connected and global Linked Data cloud that contains billions of statements about numerous domains, including life science and geography. While Linked Data has found its way into everyday applications such as search engines and question answering systems, there is a growing disconnect between the classical ways in which Geographic Information Systems (GIS) are still used today and the open-ended, exploratory approaches used to retrieve and consume data from knowledge graphs such as Linked Data. In this work, we conceptualize and prototypically implement a Linked Data connector framework as a set of toolboxes for Esri's ArcGIS to close this gap and enable the retrieval, integration, and analysis of Linked Data from within GIS. We discuss how to connect to Linked Data endpoints, how to use ontologies to probe data and derive appropriate GIS representations on the fly, how to make use of reasoning, how to derive data that are ready for spatial analysis out of RDF triples, and, most importantly, how to utilize the link structure of Linked Data to enable analysis. The proposed Linked Data connector framework can also be regarded as the first step toward a guided geographic question answering system over geographic knowledge graphs.},
	language = {en},
	number = {3},
	urldate = {2023-03-07},
	journal = {Transactions in GIS},
	author = {Mai, Gengchen and Janowicz, Krzysztof and Yan, Bo and Scheider, Simon},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/tgis.12538},
	pages = {579--600},
	file = {Full Text PDF:files/132/Mai et al. - 2019 - Deeply integrating Linked Data with Geographic Inf.pdf:application/pdf},
}

@inproceedings{clarizia_context-aware_2019,
	title = {A {Context}-{Aware} {Chatbot} for {Tourist} {Destinations}},
	doi = {10.1109/SITIS.2019.00063},
	abstract = {The cultural heritage is one of the most important resources of the territory. It represents one of the scenarios where new technologies can provide more interesting contributions. In particular, adaptive systems and related services may increase the promotion of cultural heritage. In fact, tourists can use several services able to filter the huge amount of data present on the network in order to only provide relevant information. The aim of this paper is to introduce a chatbot based on a Context-Aware System. This chatbot recommends contents and services according to tourist profiles and context. For testing the proposed architecture, a prototype was developed in order to support tourists during a visit to some cultural sites in Campania: Paestum, Pompeii and Herculaneum. The first experimental results are encouraging and show the potential of the proposed approach.},
	booktitle = {2019 15th {International} {Conference} on {Signal}-{Image} {Technology} \& {Internet}-{Based} {Systems} ({SITIS})},
	author = {Clarizia, Fabio and Colace, Francesco and De Santo, Massimo and Lombardi, Marco and Pascale, Francesco and Santaniello, Domenico},
	month = nov,
	year = {2019},
	keywords = {Cultural differences, Context-Aware Computing, Chatbot, Computer architecture, Context modeling, Context-aware services, Information filters, Information Retrieval, Recommender Systems, Urban areas},
	pages = {348--354},
}

@inproceedings{svenningsson_artificial_2020-1,
	address = {New York, NY, USA},
	series = {{AICCC} 2019},
	title = {Artificial {Intelligence} in {Conversational} {Agents}: {A} {Study} of {Factors} {Related} to {Perceived} {Humanness} in {Chatbots}},
	isbn = {978-1-4503-7263-3},
	shorttitle = {Artificial {Intelligence} in {Conversational} {Agents}},
	url = {https://doi.org/10.1145/3375959.3375973},
	doi = {10.1145/3375959.3375973},
	abstract = {Artificial intelligence (AI) is gaining traction in service-oriented businesses in the form of chatbots. A chatbot is a popular type of social AI that uses natural language processing to communicate with users. Past studies have shown discrepancies in terms of whether or not a chatbot should communicate and behave like a human. This article aims to explore these discrepancies in order to provide a theoretical contribution of a list of factors related to perceived humanness in chatbots and how these may consequently lead to a positive user experience. The results suggest that a chatbot should have the following characteristics: avoiding small talk and maintaining a formal tone; identifying itself as a bot and asking how it can help; providing specific information and articulating itself with sophisticated choices of words and well-constructed sentences; asking follow-up questions during decision-making processes and; providing an apology when the context is not comprehensible, followed by a question or a statement to dynamically move a conversation forward. These results may have implications for designers working in the field of AI as well as for the wider debates and the broader discourse around the adoption of AI in society.},
	urldate = {2023-03-07},
	booktitle = {Proceedings of the 2019 2nd {Artificial} {Intelligence} and {Cloud} {Computing} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Svenningsson, Nina and Faraon, Montathar},
	month = feb,
	year = {2020},
	keywords = {AI, artificial intelligence, chatbot, conversation, design guideline, humanness, user experience},
	pages = {151--161},
	file = {Full Text PDF:files/136/Svenningsson e Faraon - 2020 - Artificial Intelligence in Conversational Agents .pdf:application/pdf},
}

@article{milano_recommender_2020,
	title = {Recommender systems and their ethical challenges},
	volume = {35},
	issn = {1435-5655},
	url = {https://doi.org/10.1007/s00146-020-00950-y},
	doi = {10.1007/s00146-020-00950-y},
	abstract = {This article presents the first, systematic analysis of the ethical challenges posed by recommender systems through a literature review. The article identifies six areas of concern, and maps them onto a proposed taxonomy of different kinds of ethical impact. The analysis uncovers a gap in the literature: currently user-centred approaches do not consider the interests of a variety of other stakeholders—as opposed to just the receivers of a recommendation—in assessing the ethical impacts of a recommender system.},
	language = {en},
	number = {4},
	urldate = {2023-03-07},
	journal = {AI \& SOCIETY},
	author = {Milano, Silvia and Taddeo, Mariarosaria and Floridi, Luciano},
	month = dec,
	year = {2020},
	pages = {957--967},
	file = {Full Text PDF:files/138/Milano et al. - 2020 - Recommender systems and their ethical challenges.pdf:application/pdf},
}

@article{varitimiadis_graph-based_2021-1,
	title = {Graph-{Based} {Conversational} {AI}: {Towards} a {Distributed} and {Collaborative} {Multi}-{Chatbot} {Approach} for {Museums}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	shorttitle = {Graph-{Based} {Conversational} {AI}},
	url = {https://www.mdpi.com/2076-3417/11/19/9160},
	doi = {10.3390/app11199160},
	abstract = {Nowadays, museums are developing chatbots to assist their visitors and to provide an enhanced visiting experience. Most of these chatbots do not provide a human-like conversation and fail to deliver the complete requested knowledge by the visitors. There are plenty of stand-alone museum chatbots, developed using a chatbot platform, that provide predefined dialog routes. However, as chatbot platforms are evolving and AI technologies mature, new architectural approaches arise. Museums are already designing chatbots that are trained using machine learning techniques or chatbots connected to knowledge graphs, delivering more intelligent chatbots. This paper is surveying a representative set of developed museum chatbots and platforms for implementing them. More importantly, this paper presents the result of a systematic evaluation approach for evaluating both chatbots and platforms. Furthermore, the paper is introducing a novel approach in developing intelligent chatbots for museums. This approach emphasizes graph-based, distributed, and collaborative multi-chatbot conversational AI systems for museums. The paper accentuates the use of knowledge graphs as the key technology for potentially providing unlimited knowledge to chatbot users, satisfying conversational AI’s need for rich machine-understandable content. In addition, the proposed architecture is designed to deliver an efficient deployment solution where knowledge can be distributed (distributed knowledge graphs) and shared among different chatbots that collaborate when is needed.},
	language = {en},
	number = {19},
	urldate = {2023-03-07},
	journal = {Applied Sciences},
	author = {Varitimiadis, Savvas and Kotis, Konstantinos and Pittou, Dimitra and Konstantakis, Georgios},
	month = jan,
	year = {2021},
	note = {Number: 19
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {collaborative AI, conversational AI, distributed AI, knowledge graphs, multi-agent systems, museum chatbot},
	pages = {9160},
	file = {Full Text PDF:files/142/Varitimiadis et al. - 2021 - Graph-Based Conversational AI Towards a Distribut.pdf:application/pdf},
}

@misc{noauthor_build_2021,
	title = {Build a {FAIR} {Knowledge} {Graph} {\textbar} {IDS} {Best} {Practices}},
	url = {https://maastrichtu-ids.github.io/best-practices/blog/2021/03/18/build-a-kg/},
	abstract = {Build a RDF Knowledge Graph from CSV files},
	language = {en},
	urldate = {2023-03-07},
	month = mar,
	year = {2021},
	file = {Snapshot:files/144/build-a-kg.html:text/html},
}

@inproceedings{bacci_hbim_2019,
	title = {{HBIM} {METHODOLOGIES} {FOR} {THE} {ARCHITECTURAL} {RESTORATION}. {THE} {CASE} {OF} {THE} {EX}-{CHURCH} {OF} {SAN} {QUIRICO} {ALL}’{OLIVO} {IN} {LUCCA}, {TUSCANY}},
	volume = {XLII-2-W11},
	url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-2-W11/121/2019/},
	doi = {10.5194/isprs-archives-XLII-2-W11-121-2019},
	abstract = {{\textless}p{\textgreater}{\textless}strong class="journal-contentHeaderColor"{\textgreater}Abstract.{\textless}/strong{\textgreater} In the last decade, in the field of conservation of historic buildings, several research projects have shown the potential of applying BIM technology to architectural heritage. However, the use of BIM for historic buildings (HBIM) is still evolving. This paper presents an application of Building Information Modelling targeted to the development of a restauration proposal for the ex-church of San Quirico all’Olivo in Lucca, Tuscany. Following a brief review of the state-of-the-art of BIM applied to architectural heritage, the paper shows the results of a study that included 3D architectural survey with Structure-from-Motion methodology, critical analysis of historical archival and bibliographic sources, analysis of the conservation status of the building, proposal for its conservation and enhancement.{\textless}/p{\textgreater}{\textless}p{\textgreater}HBIM methodology has been critically applied to all the phases of the project. This study also explores the possibility of organizing the BIM model into temporal phases, integrating documentation in a structured and easily accessible way. In our study, we also chose to link the 3D point cloud to the model, in order to increase the level of information; the 3D survey, therefore, is both the starting point for modelling, and represents a source of information within the model, to be recalled when required.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2023-03-08},
	booktitle = {The {International} {Archives} of the {Photogrammetry}, {Remote} {Sensing} and {Spatial} {Information} {Sciences}},
	publisher = {Copernicus GmbH},
	author = {Bacci, G. and Bertolini, F. and Bevilacqua, M. G. and Caroti, G. and Martínez-Espejo Zaragoza, I. and Martino, M. and Piemonte, A.},
	month = may,
	year = {2019},
	note = {ISSN: 1682-1750},
	pages = {121--126},
	file = {Full Text PDF:files/146/Bacci et al. - 2019 - HBIM METHODOLOGIES FOR THE ARCHITECTURAL RESTORATI.pdf:application/pdf},
}

@article{bruno_hbim_2019-1,
	title = {{HBIM} for {Conservation}: {A} {New} {Proposal} for {Information} {Modeling}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	shorttitle = {{HBIM} for {Conservation}},
	url = {https://www.mdpi.com/2072-4292/11/15/1751},
	doi = {10.3390/rs11151751},
	abstract = {Thanks to its capability of archiving and organizing all the information about a building, HBIM (Historical Building Information Modeling) is considered a promising resource for planned conservation of historical assets. However, its usage remains limited and scarcely adopted by the subjects in charge of conservation, mainly because of its rather complex 3D modeling requirements and a lack of shared regulatory references and guidelines as far as semantic data are concerned. In this study, we developed an HBIM methodology to support documentation, management, and planned conservation of historic buildings, with particular focus on non-geometric information: organized and coordinated storage and management of historical data, easy analysis and query, time management, flexibility, user-friendliness, and information sharing. The system is based on a standalone specific-designed database linked to the 3D model of the asset, built with BIM software, and it is highly adaptable to different assets. The database is accessible both with a developed desktop application, which acts as a plug-in for the BIM software, and through a web interface, implemented to ensure data sharing and easy usability by skilled and unskilled users. The paper describes in detail the implemented system, passing by semantic breaking down of the building, database design, as well as system architecture and capabilities. Two case studies, the Cathedral of Parma and Ducal Palace of Mantua (Italy), are then presented to show the results of the system’s application.},
	language = {en},
	number = {15},
	urldate = {2023-03-08},
	journal = {Remote Sensing},
	author = {Bruno, Nazarena and Roncella, Riccardo},
	month = jan,
	year = {2019},
	note = {Number: 15
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {cultural heritage, database design, Historic Building Information Modelling, information management, modeling metadata, semantic classification, survey metadata},
	pages = {1751},
	file = {Full Text PDF:files/150/Bruno e Roncella - 2019 - HBIM for Conservation A New Proposal for Informat.pdf:application/pdf},
}

@article{chalkias_developing_2023,
	title = {Developing and {Disseminating} a {New} {Historical} {Geospatial} {Database} from {Kitchener}’s 19th {Century} {Map} of {Cyprus}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2220-9964},
	url = {https://www.mdpi.com/2220-9964/12/2/74},
	doi = {10.3390/ijgi12020074},
	abstract = {Extraction and dissemination of historical geospatial data from early maps are major goals of historical geographic information systems (HGISs) in the context of the spatial humanities. This paper illustrates the process of interpreting, georeferencing, organizing, and visualizing the content of a historical map of Cyprus in the context of GISs and highlights the development of a national-scale spatial database of the island in the 19th century. This method was applied to Lord Kitchener’s historical map of Cyprus (published in 1885), which is considered the product of the first scientific topographic survey of Cyprus, is rich in geographic information about the area, and covers the entire island at a scale of 1:63,360. Previous attempts to create historical geodatabases have either focused on small areas or, when conducted on a national scale, have been thematically focused. The positional accuracy of the map was found to be 1.08 mm in map units, which was equivalent to 68.76 m on the ground. Accordingly, the main categories of geographic content (land cover, administrative units, settlements, transportation/communication networks, stream networks/water bodies, points of interest, annotations) were digitized from the georeferenced historical map. The Web-based application developed in this study supported the visualization of the historical geographic content of the map and its comparison with modern basemaps. The creation of the geodatabase presented in the study provides a template for similar studies and a basis for further development of the historical geodatabase of Cyprus.},
	language = {en},
	number = {2},
	urldate = {2023-03-08},
	journal = {ISPRS International Journal of Geo-Information},
	author = {Chalkias, Christos and Papadias, Evangelos and Vradis, Christoforos and Polykretis, Christos and Kalogeropoulos, Kleomenis and Psarogiannis, Athanasios and Chalkias, Georgios},
	month = feb,
	year = {2023},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Semantic Web, Cyprus, historical geospatial databases, historical GIS, historical maps, Horatio H. Kitchener, Linked Open Data, spatial humanities},
	pages = {74},
	file = {Full Text PDF:files/152/Chalkias et al. - 2023 - Developing and Disseminating a New Historical Geos.pdf:application/pdf},
}

@incollection{bruseker_cultural_2017,
	address = {Cham},
	series = {Quantitative {Methods} in the {Humanities} and {Social} {Sciences}},
	title = {Cultural {Heritage} {Data} {Management}: {The} {Role} of {Formal} {Ontology} and {CIDOC} {CRM}},
	isbn = {978-3-319-65370-9},
	shorttitle = {Cultural {Heritage} {Data} {Management}},
	url = {https://doi.org/10.1007/978-3-319-65370-9_6},
	abstract = {Building models for integrating the diverse data generated in Cultural Heritage disciplines is a long-term challenge both for securing presently generated knowledge and for making it progressively more widely accessible and interoperable into the future. This chapter reviews the multiple approaches undertaken to address this problem, finally proposing CIDOC CRM as the most robust solution for information integration in CH. The chapter begins by outlining the data challenge specific to the field and the main approaches that can be taken in facing it. Within this frame, it distinguishes knowledge engineering and formal ontology from other information modelling techniques as the necessary approach for tackling the broader data integration problem. It then outlines the basic principles of CIDOC CRM, the ISO standard formal ontology for CH. From there, an overview is given of some of the work that has been done both theoretically and in practice over the past five years in developing and implementing CRM as a practical data integration strategy in CH, particularly looking at model extensions to handle knowledge provenance across various disciplines and typical documentation and reasoning activities, as well as at successful implementation projects. Lastly, it summarizes the present potentials and challenges for using CIDOC CRM for solving the CH data management and integration puzzle. The intended audience of this chapter are specialists from all backgrounds within the broader domain of CH with an interest in data integration and CIDOC CRM.},
	language = {en},
	urldate = {2023-03-08},
	booktitle = {Heritage and {Archaeology} in the {Digital} {Age}: {Acquisition}, {Curation}, and {Dissemination} of {Spatial} {Cultural} {Heritage} {Data}},
	publisher = {Springer International Publishing},
	author = {Bruseker, George and Carboni, Nicola and Guillem, Anaïs},
	editor = {Vincent, Matthew L. and López-Menchero Bendicho, Víctor Manuel and Ioannides, Marinos and Levy, Thomas E.},
	year = {2017},
	doi = {10.1007/978-3-319-65370-9_6},
	pages = {93--131},
}

@misc{niccolucci_heritage_2023,
	title = {The {Heritage} {Digital} {Twin}: a bicycle made for two. {The} integration of digital methodologies into cultural heritage research},
	shorttitle = {The {Heritage} {Digital} {Twin}},
	url = {http://arxiv.org/abs/2302.07138},
	doi = {10.48550/arXiv.2302.07138},
	abstract = {The paper concerns the definition of a novel ontology for cultural heritage based on the concept of digital twin. The ontology, called Heritage Digital Twin ontology, is a compatible extension of the well-known CIDOC CRM ISO standard for cultural heritage documentation and incorporates all the different documentation systems presently in use for cultural heritage documentation. In the authors' view, it supports documentation interoperability at a higher level than the ones currently in use and enables effective cooperation among different users.},
	urldate = {2023-03-08},
	publisher = {arXiv},
	author = {Niccolucci, Franco and Markhoff, Béatrice and Theodoridou, Maria and Felicetti, Achille and Hermon, Sorin},
	month = feb,
	year = {2023},
	note = {arXiv:2302.07138 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Information Retrieval, E.1, H.2.3, H.3.1, J.5},
	file = {arXiv Fulltext PDF:files/156/Niccolucci et al. - 2023 - The Heritage Digital Twin a bicycle made for two..pdf:application/pdf;arXiv.org Snapshot:files/157/2302.html:text/html},
}

@article{luther_digital_2023,
	title = {Digital {Twins} and {Enabling} {Technologies} in {Museums} and {Cultural} {Heritage}: {An} {Overview}},
	volume = {23},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	shorttitle = {Digital {Twins} and {Enabling} {Technologies} in {Museums} and {Cultural} {Heritage}},
	url = {https://www.mdpi.com/1424-8220/23/3/1583},
	doi = {10.3390/s23031583},
	abstract = {This paper presents an overview of various types of virtual museums (ViM) as native artifacts or as digital twins (DT) of physical museums (PM). Depending on their mission and features, we discuss various enabling technologies and sensor equipment with their specific requirements and complexities, advantages and drawbacks in relation to each other at all stages of a DT’s life cycle. A DT is a virtual construct and embodies innovative concepts based on emerging technologies (ET) using adequate sensor configurations for (meta-)data import and exchange. Our keyword-based search for articles, conference papers, (chapters from) books and reviews yielded 43 contributions and 43 further important references from Industry 4.0, Tourism and Heritage 4.0. After closer examination, a reference corpus of 40 contributions was evaluated in detail and classified along with their variants of DT—content-, communication-, and collaboration-centric and risk-informed ViMs. Their system features correlate with different application areas (AA), new or improved technologies—mostly still under development—and sensors used. Our proposal suggests a template-based, generative approach to DTs using standardized metadata formats, expert/curator software and customers’/visitors’ engagement. It advocates for stakeholders’ collaboration as part of a comprehensive validation and verification assessment (V\&VA) throughout the DT’s entire life cycle.},
	language = {en},
	number = {3},
	urldate = {2023-03-08},
	journal = {Sensors},
	author = {Luther, Wolfram and Baloian, Nelson and Biella, Daniel and Sacher, Daniel},
	month = jan,
	year = {2023},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {digital twin, emerging technologies, sensor, virtual museum},
	pages = {1583},
	file = {Full Text PDF:files/159/Luther et al. - 2023 - Digital Twins and Enabling Technologies in Museums.pdf:application/pdf},
}

@misc{noauthor_definition_nodate,
	title = {Definition of the {CIDOC} {Conceptual} {Reference} {Model}},
	url = {https://www.cidoc-crm.org/sites/default/files/Documents/cidoc_crm_version_5.0.4.html},
	urldate = {2023-03-08},
}

@article{arico_scan--bim_2023,
	title = {A {Scan}-to-{BIM} {Approach} for the {Management} of {Two} {Arab}-{Norman} {Churches} in {Palermo} ({Italy})},
	volume = {6},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2571-9408},
	url = {https://www.mdpi.com/2571-9408/6/2/87},
	doi = {10.3390/heritage6020087},
	abstract = {The paper shows the results of the research activities carried out by the Department of Engineering at the University of Palermo (Italy), which assessed the application of the Heritage Building Information Modelling (HBIM) methodology through a Scan-to-BIM approach to two local churches belonging to the medieval period. This project was motivated by a renewed interest from the city administrators towards the conservation of cultural heritage dating back to the Arab-Norman domination in Sicily since one of the two buildings was included in the UNESCO World Heritage Sites list in 2015. The morpho-typological style of the churches has been acquired by high-detailed 3D surveys, which provided the base for two HBIM models suited to render the peculiarity of these buildings at their best. The BIM environment allowed both the geometrical representation of all the architectural elements and their further enrichment with the integration of non-geometric data and semantic signification through a knowledge-based workflow. This process led to a hierarchical organization of two high-accuracy digital replicas and to the creation of a database containing all of the architectural items typical of the Arab-Norman style, aimed to share the awareness of its conservation and to match all of the Cultural Heritage requirements. In the future, the features in this database can be shared with other specialists as reference objects for further studies on cultural heritage sites in the UNESCO list.},
	language = {en},
	number = {2},
	urldate = {2023-03-08},
	journal = {Heritage},
	author = {Aricò, Manuela and Lo Brutto, Mauro and Maltese, Antonino},
	month = feb,
	year = {2023},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {cultural heritage, HBIM, photogrammetry, point cloud, 3D modelling, laser scanner, Scan-to-BIM},
	pages = {1622--1644},
	file = {Full Text PDF:files/162/Aricò et al. - 2023 - A Scan-to-BIM Approach for the Management of Two A.pdf:application/pdf},
}

@article{mackinnon_ontological_2023,
	title = {The {Ontological} {Multiplicity} of {Digital} {Heritage} {Objects}: {3D} {Modelling} in the {Cherish} {Project}},
	volume = {6},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2571-9408},
	shorttitle = {The {Ontological} {Multiplicity} of {Digital} {Heritage} {Objects}},
	url = {https://www.mdpi.com/2571-9408/6/2/76},
	doi = {10.3390/heritage6020076},
	abstract = {Digital objects are now pervasively used across the heritage sciences, often as 3D models. However, the theoretical discussion of what these objects are, ontologically speaking, can be diverse, ranging, and inconclusive. This paper will focus on the Cherish Project, a European research initiative that used a range of methods—including drone-based photogrammetry and laser scanning— to create 3D models of coastal heritage landscapes that are at risk due to climate change. In specifically attending to the database storage schemes and software/platforms employed by Cherish, this paper explores how digital heritage objects can more broadly be discussed in terms of their ontological multiplicity, the multi-sitedness of their production and circulation, and their mobility across interfaces as they are formalised and circulated. In tracing these specific factors, this paper arrives at epistemological insights about how digital heritage objects factor into knowledge producing practices like Cherish, foregrounding critical questions about how these practices might be differently discussed, pursued, or imagined.},
	language = {en},
	number = {2},
	urldate = {2023-03-08},
	journal = {Heritage},
	author = {Mackinnon, Sterling},
	month = feb,
	year = {2023},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {heritage, 3D models, data, data assemblages, digital objects, knowledge production},
	pages = {1397--1410},
	file = {Full Text PDF:files/164/Mackinnon - 2023 - The Ontological Multiplicity of Digital Heritage O.pdf:application/pdf},
}

@inproceedings{lee_study_2023,
	address = {Cham},
	series = {Springer {Proceedings} in {Business} and {Economics}},
	title = {A {Study} on the {Application} of {Historic} {Building} {Information} {Modeling} ({HBIM}) for {XR} {Cultural} {Heritage} {Tourism}},
	isbn = {978-3-031-25390-4},
	doi = {10.1007/978-3-031-25390-4_18},
	abstract = {We would like to propose a plan to apply historic building information modeling (HBIM) for XR heritage tourism. It is significant that the XR heritage tourism content expresses not only a visually detailed image but also the value of heritage and its historical information together to convey the authenticity of the heritage to end-users. Such historical information has been managed in integrated forms using the HBIM methodology, but there is a few researches on the methodology using it as XR content. Therefore, we define the detailed stages of the level of historical information and propose an HBIM system to apply them to XR heritage tourism.},
	language = {en},
	booktitle = {Extended {Reality} and {Metaverse}},
	publisher = {Springer International Publishing},
	author = {Lee, Jongwook and Kim, Boram},
	editor = {Jung, Timothy and tom Dieck, M. Claudia and Correia Loureiro, Sandra Maria},
	year = {2023},
	keywords = {HBIM, Digital heritage, Heritage tourism, XR content},
	pages = {206--216},
}

@article{pattuelli_modeling_2011,
	title = {Modeling a domain ontology for cultural heritage resources: {A} user-centered approach},
	volume = {62},
	issn = {1532-2890},
	shorttitle = {Modeling a domain ontology for cultural heritage resources},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.21453},
	doi = {10.1002/asi.21453},
	abstract = {The use of primary source materials is recognized as key to supporting history and social studies education. The extensive digitization of library, museum, and other cultural heritage collections represents an important teaching resource. Yet, searching and selecting digital primary sources appropriate for classroom use can be difficult and time-consuming. This study investigates the design requirements and the potential usefulness of a domain-specific ontology to facilitate access to, and use of, a collection of digital primary source materials developed by the Library of the University of North Carolina at Chapel Hill. During a three-phase study, an ontology model was designed and evaluated with the involvement of social studies teachers. The findings revealed that the design of the ontology was appropriate to support the information needs of the teachers and was perceived as a potentially useful tool to enhance collection access. The primary contribution of this study is the introduction of an approach to ontology development that is user-centered and designed to facilitate access to digital cultural heritage materials. Such an approach should be considered on a case-by-case basis in relation to the size of the ontology being built, the nature of the knowledge domain, and the type of end users targeted.},
	language = {en},
	number = {2},
	urldate = {2023-03-08},
	journal = {Journal of the American Society for Information Science and Technology},
	author = {Pattuelli, M. Cristina},
	year = {2011},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.21453},
	pages = {314--342},
}

@inproceedings{doulgerakis_estia_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{ESTIA}: {Disaster} {Management} {Platform} for {Cultural} {Heritage} {Sites}},
	isbn = {978-3-030-73043-7},
	shorttitle = {{ESTIA}},
	doi = {10.1007/978-3-030-73043-7_39},
	abstract = {ESTIA is a research and innovation project that aspires to develop a comprehensive platform allowing the forecast, detection and management of incidents that are related with the risk of structural fires within Cultural Heritage (CH) settlements and sites. ESTIA aims to (a) enhance the management and preservation of CH, (b) limit the risks of fire incidents within traditional settlements and CH sites, (c) provide competent authorities with tools for training, coordination and support for an efficient response to fire incidents, (d) effectively protect and guide inhabitants and visitors, (e) suppress structural damages in historic buildings, historic settlements and CH sites and assets, (f) support and promote cultural events and tourism in harmony with the particular requirements of CH preservation. By incorporating advanced procedures for the semi-automatic digitization of the CH built environment as well as an advanced system that simulates the development of the complex phenomena of fire propagation and human crowd behaviour, the platform is an effective tool that on one hand, assists competent authorities in assessing the fire related risks and on the other, serves as a training tool and offers fire management capabilities for first responders and civil protection officers.},
	language = {en},
	booktitle = {Digital {Heritage}. {Progress} in {Cultural} {Heritage}: {Documentation}, {Preservation}, and {Protection}},
	publisher = {Springer International Publishing},
	author = {Doulgerakis, Adam and Kanellos, Anastasios and Thomopoulos, Stelios C. A. and Ioannakis, George Alexios and Arnaoutoglou, Fotios and Pistofidis, Petros and Koutsoudis, Anestis and Pappou, Theodora and Protopsaltis, Byron and Gkouskos, Stelios},
	editor = {Ioannides, Marinos and Fink, Eleanor and Cantoni, Lorenzo and Champion, Erik},
	year = {2021},
	keywords = {3D modelling, Annotation, Crowd simulation, Fire incident prediction, Fire incident risk assessment, Fire propagation simulation, Geometry analysis, Historic buildings, Historic settlements, Ontological segmentation, Photogrammetry, Structural fire, Tangible cultural heritage, Visual analysis},
	pages = {474--481},
	file = {Full Text PDF:files/168/Doulgerakis et al. - 2021 - ESTIA Disaster Management Platform for Cultural H.pdf:application/pdf},
}

@article{mammoli_modeling_2021,
	title = {Modeling the {Fourth} {Dimension} of {Architectural} {Heritage}: {Enabling} {Processes} for a {Sustainable} {Conservation}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2071-1050},
	shorttitle = {Modeling the {Fourth} {Dimension} of {Architectural} {Heritage}},
	url = {https://www.mdpi.com/2071-1050/13/9/5173},
	doi = {10.3390/su13095173},
	abstract = {This study focuses on modeling the fourth dimension of historic architectures with an HBIM approach and special regard to stratigraphic analysis. The goal is to push the limits of current technology to understand the history of buildings, with impacts on protecting their authenticity; it is pursued with a practitioners-oriented methodology able to make aware models of their phases. The target audience are experts in the field of heritage conservation, while the outcome is to support long-term strategies for the sustainable management of heritage. Contents follow this structure: (1) Introduction: this section frames the benefits of affirming heritage’s physical authenticity and managing risks; it clarifies assumptions and the research aim; (2) State of the Art: this highlights the topic relevance, which is not yet fully resolved, focusing on semantics, critical-interpretative data control, and on the automation of some crucial results; (3) Materials and Methods: this describes the integrated workflow, including the photogrammetric acquisition, modeling, and data enrichment, the semi-automatic Harris matrix construction, and the optimization of laser data; (4) Results: this presents the results of modelling stratigraphic units, enriching them with information according to a semantics coherent with the conservation process, to govern the temporal relations while automating key outputs; (5) Discussion: this section refines the implemented solutions and introduce future works.},
	language = {en},
	number = {9},
	urldate = {2023-03-08},
	journal = {Sustainability},
	author = {Mammoli, Raissa and Mariotti, Chiara and Quattrini, Ramona},
	month = jan,
	year = {2021},
	note = {Number: 9
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {HBIM, Harris matrix, architectural heritage, authenticity, sustainable conservation},
	pages = {5173},
	file = {Full Text PDF:files/170/Mammoli et al. - 2021 - Modeling the Fourth Dimension of Architectural Her.pdf:application/pdf},
}

@article{croce_semantic_2021,
	title = {From the {Semantic} {Point} {Cloud} to {Heritage}-{Building} {Information} {Modeling}: {A} {Semiautomatic} {Approach} {Exploiting} {Machine} {Learning}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	shorttitle = {From the {Semantic} {Point} {Cloud} to {Heritage}-{Building} {Information} {Modeling}},
	url = {https://www.mdpi.com/2072-4292/13/3/461},
	doi = {10.3390/rs13030461},
	abstract = {This work presents a semi-automatic approach to the 3D reconstruction of Heritage-Building Information Models from point clouds based on machine learning techniques. The use of digital information systems leveraging on three-dimensional (3D) representations in architectural heritage documentation and analysis is ever increasing. For the creation of such repositories, reality-based surveying techniques, such as photogrammetry and laser scanning, allow the fast collection of reliable digital replicas of the study objects in the form of point clouds. Besides, their output is raw and unstructured, and the transition to intelligible and semantic 3D representations is still a scarcely automated and time-consuming process requiring considerable human intervention. More refined methods for 3D data interpretation of heritage point clouds are therefore sought after. In tackling these issues, the proposed approach relies on (i) the application of machine learning techniques to semantically label 3D heritage data by identification of relevant geometric, radiometric and intensity features, and (ii) the use of the annotated data to streamline the construction of Heritage-Building Information Modeling (H-BIM) systems, where purely geometric information derived from surveying is associated with semantic descriptors on heritage documentation and management. The “Grand-Ducal Cloister” dataset, related to the emblematic case study of the Pisa Charterhouse, is discussed.},
	language = {en},
	number = {3},
	urldate = {2023-03-08},
	journal = {Remote Sensing},
	author = {Croce, Valeria and Caroti, Gabriella and De Luca, Livio and Jacquot, Kévin and Piemonte, Andrea and Véron, Philippe},
	month = jan,
	year = {2021},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {3D survey, classification, H-BIM, heritage, laser scanning, machine learning, photogrammetry, point cloud, Random Forest, semantic annotation},
	pages = {461},
	file = {Full Text PDF:files/172/Croce et al. - 2021 - From the Semantic Point Cloud to Heritage-Building.pdf:application/pdf},
}

@incollection{staab_ontologies_2009,
	address = {Berlin, Heidelberg},
	title = {Ontologies for {Cultural} {Heritage}},
	isbn = {978-3-540-70999-2 978-3-540-92673-3},
	url = {http://link.springer.com/10.1007/978-3-540-92673-3_21},
	language = {en},
	urldate = {2023-03-08},
	booktitle = {Handbook on {Ontologies}},
	publisher = {Springer Berlin Heidelberg},
	author = {Doerr, Martin},
	editor = {Staab, Steffen and Studer, Rudi},
	year = {2009},
	doi = {10.1007/978-3-540-92673-3_21},
	pages = {463--486},
	file = {Doerr - 2009 - Ontologies for Cultural Heritage.pdf:files/173/Doerr - 2009 - Ontologies for Cultural Heritage.pdf:application/pdf},
}

@book{pramartha_digital_2017,
	title = {Digital {Preservation} of {Cultural} {Heritage}: {An} {Ontology}- {Based} {Approach}},
	shorttitle = {Digital {Preservation} of {Cultural} {Heritage}},
	abstract = {The project aims to design and build a digital portal which will document, organise, and preserve aspects of Balinese cultural heritage and related knowledge for the benefit of the wider community and the younger generations in particular. We present the details of our research dealing with one aspect of Balinese culture, the Balinese traditional communication system (kulkul), undertaken in the Indonesian island of Bali. This knowledge is held largely in tacit form in the Balinese community and tends to be poorly documented and fragmented. A basic ontology of key kulkul-related concepts and terms and their interrelationships was developed to support the semantic searching and browsing of the online portal and related resources. Much of the content for the portal was acquired through community-based crowdsourcing. We also discuss the procedures employed evaluate the digital portal prototype.},
	author = {Pramartha, Cokorda and Davis, Joseph and Kuan, Kevin},
	month = dec,
	year = {2017},
}

@article{oneill_digital_2022,
	title = {Digital cultural heritage standards: from silo to semantic web},
	volume = {37},
	issn = {1435-5655},
	shorttitle = {Digital cultural heritage standards},
	url = {https://doi.org/10.1007/s00146-021-01371-1},
	doi = {10.1007/s00146-021-01371-1},
	abstract = {This paper is a survey of standards being used in the domain of digital cultural heritage with focus on the Metadata Encoding and Transmission Standard (METS) created by the Library of Congress in the United States of America. The process of digitization of cultural heritage requires silo breaking in a number of areas—one area is that of academic disciplines to enable the performance of rich interdisciplinary work. This lays the foundation for the emancipation of the second form of silo which are the silos of knowledge, both traditional and born digital, held in individual institutions, such as galleries, libraries, archives and museums. Disciplinary silo breaking is the key to unlocking these institutional knowledge silos. Interdisciplinary teams, such as developers and librarians, work together to make the data accessible as open data on the “semantic web”. Description logic is the area of mathematics which underpins many ontology building applications today. Creating these ontologies requires a human–machine symbiosis. Currently in the cultural heritage domain, the institutions’ role is that of provider of this  open data to the national aggregator which in turn can make the data available to the trans-European aggregator known as Europeana. Current ingests to the aggregators are in the form of machine readable cataloguing metadata which is limited in the richness it provides to disparate object descriptions. METS can provide this richness.},
	language = {en},
	number = {3},
	urldate = {2023-03-08},
	journal = {AI \& SOCIETY},
	author = {O’Neill, Brenda and Stapleton, Larry},
	month = sep,
	year = {2022},
	pages = {891--903},
	file = {Full Text PDF:files/178/O’Neill e Stapleton - 2022 - Digital cultural heritage standards from silo to .pdf:application/pdf},
}

@book{tamper_text_2023,
	title = {From {Text} to {Knowledge}: {Methods}, {Tools}, and {Applications} for {Digital} {Humanities} {Based} on {Linked} {Data}},
	isbn = {978-952-64-1151-4},
	shorttitle = {From {Text} to {Knowledge}},
	url = {https://aaltodoc.aalto.fi:443/handle/123456789/119827},
	abstract = {The digitization of Cultural Heritage collections has enabled the use of computational methods such as Natural Language Processing (NLP) on textual collections. These methods have been used widely in Digital Humanities (DH) to study digitized contents with automated processes. The Semantic Web and linked data technologies have been applied to describe document collections and their metadata in library and museum collections. They provide infrastructure for connecting different collections by linking them using shared vocabularies that describe metadata values and fields.  
Linked data is also used in Finnish museum and library collections. It is commonly used to modeling document metadata, such as author, or title of a piece of work. Also, the content of a document in a collection is usually described using manually assigned keywords. Other information about the content is often scarce and finding documents related to an actor can be laborious. This thesis studies and presents novel models, methods, and tools for transforming and enriching document collections automatically to linked data. Linked data technology helps to link together documents of a collection based on their metadata, e.g., author, or publisher. It can be also used to link documents based on information extracted about the content, such as actors mentioned in text.  
The aim of this thesis is to study how the NLP methods and linked data can be used to study digitized document collections, such as biographies. Research in this thesis is conducted by designing, implementing, and evaluating proof-of-concept systems, tools, and data for real life use cases. The research follows the principles of the design science and action research.  
The thesis presents a toolkit that can be used to model, transform, and enrich biographical text document collections to linked data to improve collection's information retrieval and interoperability internally and with other collections. The data model for describing text document collection's content and features, e.g., keywords and mentioned names, creates a foundation for building intelligent services based on the linked data such as network or linguistic analysis. These services can be used to visualize the interlinked data by showing the relations between themes or actors. In addition, the linked-data-based datasets can be used as an input for NLP tools to create data analytical visualizations and applications. This approach can be also used to evaluate the quality and content of text document collections for DH research. The prototypes created for data transformation, enrichment, and information visualization can be also applied to other document collections.},
	language = {en},
	urldate = {2023-03-08},
	publisher = {Aalto University},
	author = {Tamper, Minna},
	year = {2023},
	note = {Accepted: 2023-02-24T10:00:10Z
ISSN: 1799-4942 (electronic)},
	file = {Full Text PDF:files/180/Tamper - 2023 - From Text to Knowledge Methods, Tools, and Applic.pdf:application/pdf},
}

@article{varniene-janssen_ontologies_2020,
	title = {Ontologies and {Technologies} for {Integrating} and {Accessing} {Digital} {Cultural} {Heritage}: {Lithuanian} {Approach}},
	volume = {88},
	issn = {2783-6207},
	shorttitle = {Ontologies and {Technologies} for {Integrating} and {Accessing} {Digital} {Cultural} {Heritage}},
	url = {https://www.journals.vu.lt/IM/article/view/14768},
	doi = {10.15388/Im.2020.88.32},
	number = {0},
	journal = {Information \& Media},
	author = {Varnienė-Janssen, Regina and Šermokas, Albertas},
	month = apr,
	year = {2020},
	pages = {66--82},
	file = {Full text:files/184/Varnienė-Janssen e Šermokas - 2020 - Ontologies and Technologies for Integrating and Ac.pdf:application/pdf;Ontologies and Technologies for Integrating and Accessing Digital Cultural Heritage\: Lithuanian Approach | Information & Media:files/185/14768.html:text/html},
}

@incollection{winer_review_2014,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Review of {Ontology} {Based} {Storytelling} {Devices}},
	isbn = {978-3-642-45324-3},
	url = {https://doi.org/10.1007/978-3-642-45324-3_12},
	abstract = {A great deal of research concerning mechanisms to interpret, manipulate and generate stories in different media has been carried out. The basic concepts related to ontologies and their components are introduced. We review then the role of ontologies in storytelling including the distinction between fabula, suzjet and narrative. Several recent innovative initiatives that provide interesting devices for storytelling through the implementations of ontologies are reviewed.},
	language = {en},
	urldate = {2023-03-09},
	booktitle = {Language, {Culture}, {Computation}. {Computing} of the {Humanities}, {Law}, and {Narratives}: {Essays} {Dedicated} to {Yaacov} {Choueka} on the {Occasion} of {His} 75th {Birthday}, {Part} {II}},
	publisher = {Springer},
	author = {Winer, Dov},
	editor = {Dershowitz, Nachum and Nissan, Ephraim},
	year = {2014},
	doi = {10.1007/978-3-642-45324-3_12},
	keywords = {ontology, semantic web, AI, meaning, narrative, semantics, semiotics, stories, story generation, storytelling},
	pages = {394--405},
}

@inproceedings{casillo_ontological_2016,
	address = {New York, NY, USA},
	series = {{MISNC}, {SI}, {DS} 2016},
	title = {An {Ontological} {Approach} to {Digital} {Storytelling}},
	isbn = {978-1-4503-4129-5},
	url = {https://doi.org/10.1145/2955129.2955147},
	doi = {10.1145/2955129.2955147},
	abstract = {In order to identify a personalized story, suitable for the needs of large masses of visitors and tourists, our work has been aimed at the definition of appropriate models and solutions of fruition that make the visit experience more appealing and immersive. This paper proposes the characteristic functionalities of narratology and of the techniques of storytelling for the dynamic creation of experiential stories on a sematic basis. Therefore, it represents a report about sceneries, implementation models and architectural and functional specifications of storytelling for the dynamic creation of functional contents for the visit. Our purpose is to indicate an approach for the realization of a dynamic storytelling engine that can allow the dynamic supply of narrative contents, not necessarily predetermined and pertinent to the needs and the dynamic behaviors of the users. In particular, we have chosen to employ an adaptive, social and mobile approach, using an ontological model in order to realize a dynamic digital storytelling system, able to collect and elaborate social information and contents about the users giving them a personalized story on the basis of the place they are visiting. A case of study and some experimental results are presented and discussed.},
	urldate = {2023-03-09},
	booktitle = {Proceedings of the {The} 3rd {Multidisciplinary} {International} {Social} {Networks} {Conference} on {SocialInformatics} 2016, {Data} {Science} 2016},
	publisher = {Association for Computing Machinery},
	author = {Casillo, Mario and Colace, Francesco and De Santo, Massimo and Lemma, Saverio and Lombardi, Marco and Pietrosanto, Antonio},
	month = aug,
	year = {2016},
	keywords = {Ontologies, Adaptive Systems, Digital Storytelling, Mobile Applications, Social Networks},
	pages = {1--8},
}

@misc{smed_digital_2019,
	type = {chapter},
	title = {The {Digital} {Campfire}: {An} {Ontology} of {Interactive} {Digital} {Storytelling}},
	copyright = {Access limited to members},
	shorttitle = {The {Digital} {Campfire}},
	url = {https://www.igi-global.com/chapter/the-digital-campfire/www.igi-global.com/chapter/the-digital-campfire/214121},
	abstract = {Interactive digital storytelling (IDS) allows a human user to become an active part in a story and to affect how the story unfolds. To understand IDS systems, we need to consider the partakers present in them as well as their roles and interconnections. In this chapter, the authors discern four part...},
	language = {en},
	urldate = {2023-03-09},
	journal = {Modern Perspectives on Virtual Communications and Social Networking},
	author = {Smed, Jouni and Suovuo, Tomi “bgt” and Trygg, Natasha and Skult, Petter and Hakonen, Harri},
	year = {2019},
	doi = {10.4018/978-1-5225-5715-9.ch007},
	note = {ISBN: 9781522557159
Pages: 174-195
Publisher: IGI Global},
}

@article{meghini_representing_2021,
	title = {Representing narratives in digital libraries: {The} narrative ontology},
	volume = {12},
	issn = {1570-0844},
	shorttitle = {Representing narratives in digital libraries},
	url = {https://content.iospress.com/articles/semantic-web/sw200421},
	doi = {10.3233/SW-200421},
	abstract = {Digital Libraries (DLs), especially in the Cultural Heritage domain, are rich in narratives. Every digital object in a DL tells some kind of story, regardless of the medium, the genre, or the type of the object. However, DLs do not offer services abo},
	language = {en},
	number = {2},
	urldate = {2023-03-09},
	journal = {Semantic Web},
	author = {Meghini, Carlo and Bartalesi, Valentina and Metilli, Daniele},
	month = jan,
	year = {2021},
	note = {Publisher: IOS Press},
	pages = {241--264},
	file = {Full text:files/192/Meghini et al. - 2021 - Representing narratives in digital libraries The .pdf:application/pdf},
}

@inproceedings{mulholland_curate_2012,
	address = {Heraklion, Crete, Greece},
	title = {Curate and storyspace: an ontology and web-based environment for describing curatorial narratives},
	shorttitle = {Curate and storyspace},
	url = {http://2012.eswc-conferences.org/},
	abstract = {Existing metadata schemes and content management systems used by museums focus on describing the heritage objects that the museum holds in its collection. These are used to manage and describe individual heritage objects according to properties such as artist, date and preservation requirements. Curatorial narratives, such as physical or online exhibitions tell a story that spans across heritage objects and have a meaning that does not necessarily reside in the individual heritage objects themselves. Here we present curate, an ontology for describing curatorial narratives. This draws on structuralist accounts that  distinguish the narrative from the story and plot, and also a detailed analysis of two museum exhibitions and the curatorial processes that contributed to them. Storyspace, our web based interface and API to the ontology, is being used by curatorial staff in two museums to model curatorial narratives and the processes through which they are constructed.},
	language = {en},
	urldate = {2023-03-09},
	author = {Mulholland, Paul and Wolff, Annika and Collins, Trevor},
	year = {2012},
	file = {Full Text PDF:files/197/Mulholland et al. - 2012 - Curate and storyspace an ontology and web-based e.pdf:application/pdf;Snapshot:files/198/34177.html:text/html},
}

@misc{noauthor_open_nodate-1,
	title = {Open {Archives} {Initiative} - {Object} {Exchange} and {Reuse}},
	url = {https://www.openarchives.org/ore/},
	urldate = {2023-03-09},
}

@misc{noauthor_skos_nodate,
	title = {{SKOS} {Simple} {Knowledge} {Organization} {System} {Reference}},
	url = {https://www.w3.org/TR/skos-reference/},
	urldate = {2023-03-09},
	file = {SKOS Simple Knowledge Organization System Reference:files/201/skos-reference.html:text/html},
}

@misc{noauthor_dcmi_nodate,
	title = {{DCMI} {Metadata} {Terms}},
	url = {https://www.dublincore.org/specifications/dublin-core/dcmi-terms/},
	abstract = {This document is an up-to-date specification of all metadata terms maintained by the Dublin Core Metadata Initiative, including properties, vocabulary encoding schemes, syntax encoding schemes, and classes.},
	language = {en},
	urldate = {2023-03-09},
	file = {Snapshot:files/203/dcmi-terms.html:text/html},
}

@misc{noauthor_edm_nodate,
	title = {{EDM} - {Mapping} guidelines - {Europeana} {Knowledge} {Base} - {Confluence}},
	url = {https://europeana.atlassian.net/wiki/spaces/EF/pages/987791389/EDM+-+Mapping+guidelines},
	urldate = {2023-03-09},
}

@misc{noauthor_web_2017,
	title = {Web {Annotation} {Vocabulary}},
	url = {https://www.w3.org/TR/annotation-vocab/},
	language = {en},
	urldate = {2023-03-09},
	month = feb,
	year = {2017},
	file = {Snapshot:files/206/annotation-vocab.html:text/html},
}

@article{caffo_digital_2014,
	series = {10th {Italian} {Research} {Conference} on {Digital} {Libraries}, {IRCDL} 2014},
	title = {Digital {Cultural} {Heritage} {Projects}: {Opportunities} and {Future} {Challenges}},
	volume = {38},
	issn = {1877-0509},
	shorttitle = {Digital {Cultural} {Heritage} {Projects}},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050914013635},
	doi = {10.1016/j.procs.2014.10.003},
	abstract = {This paper reports on the state of the art of pertinent initiatives managed at the national level by the Central Institute for the Union Catalogue of Italian Libraries and Bibliographic Information (ICCU), which is an institute of the Italian Ministry of Cultural Heritage, Activities and Tourism (MiBACT).},
	language = {en},
	urldate = {2023-03-09},
	journal = {Procedia Computer Science},
	author = {Caffo, Rossella},
	month = jan,
	year = {2014},
	keywords = {access to cultural heritage resources, CulturaItalia, Digital Cultural Heritage (DCH), Internet Culturale},
	pages = {12--17},
	file = {ScienceDirect Full Text PDF:files/208/Caffo - 2014 - Digital Cultural Heritage Projects Opportunities .pdf:application/pdf;ScienceDirect Snapshot:files/209/S1877050914013635.html:text/html},
}

@article{fresa_data_2013,
	title = {A {Data} {Infrastructure} for {Digital} {Cultural} {Heritage}: {Characteristics}, {Requirements} and {Priority} {Services}},
	volume = {7},
	issn = {1753-8548},
	shorttitle = {A {Data} {Infrastructure} for {Digital} {Cultural} {Heritage}},
	url = {https://www.euppublishing.com/doi/abs/10.3366/ijhac.2013.0058},
	doi = {10.3366/ijhac.2013.0058},
	abstract = {The European amount of digitized material is growing very rapidly, as national, regional and European programmes support the digitization processes by museums, libraries, archives, archaeological s...},
	number = {supplement},
	urldate = {2023-03-09},
	journal = {International Journal of Humanities and Arts Computing},
	author = {Fresa, Antonella},
	month = mar,
	year = {2013},
	note = {Publisher: Edinburgh University Press},
	pages = {29--46},
	file = {EUP Snapshot:files/211/ijhac.2013.html:text/html},
}

@article{walsh_user_2016,
	title = {User {Categories} for {Digital} {Cultural} {Heritage}: {First} {International} {Workshop} on {Accessing} {Cultural} {Heritage} at {Scale}},
	volume = {1611},
	shorttitle = {User {Categories} for {Digital} {Cultural} {Heritage}},
	url = {http://ceur-ws.org/Vol-1611/},
	abstract = {Increasingly information systems and services are being tailored to the needs of individuals and groups through the use of user-centred design techniques. In this paper we consider the ways in which the users of digital cultural heritage have been previously characterised and grouped. Despite recognising the importance of adopting user-centred techniques, there appears to be little prior work that has compared user groupings across user studies. Through a preliminary review of previous literature we compare ways in which users have been categorised and provide points for open discussion. The dimensions of domain knowledge, technical experience and motivation provide a way of distinguishing previously identified groups. We believe discussions about user categories and models is warranted and will help in the future design of digital cultural heritage services.},
	urldate = {2023-03-09},
	journal = {Not Known},
	author = {Walsh, David and Clough, Paul and Foster, Jonathan},
	month = jun,
	year = {2016},
	keywords = {Digital Cultural Heritage, User Modelling, User Studies},
	pages = {3--9},
}

@misc{noauthor_prov-o_nodate,
	title = {{PROV}-{O}: {The} {PROV} {Ontology}},
	url = {https://www.w3.org/TR/prov-o/},
	urldate = {2023-03-10},
	file = {PROV-O\: The PROV Ontology:files/220/prov-o.html:text/html},
}

@article{ciccarese_pav_2013,
	title = {{PAV} ontology: provenance, authoring and versioning},
	volume = {4},
	issn = {2041-1480},
	shorttitle = {{PAV} ontology},
	url = {http://jbiomedsem.biomedcentral.com/articles/10.1186/2041-1480-4-37},
	doi = {10.1186/2041-1480-4-37},
	language = {en},
	number = {1},
	urldate = {2023-03-10},
	journal = {Journal of Biomedical Semantics},
	author = {Ciccarese, Paolo and Soiland-Reyes, Stian and Belhajjame, Khalid and Gray, Alasdair JG and Goble, Carole and Clark, Tim},
	year = {2013},
	pages = {37},
	file = {Full text:files/222/Ciccarese et al. - 2013 - PAV ontology provenance, authoring and versioning.pdf:application/pdf},
}

@misc{noauthor_frbroo_nodate,
	title = {{FRBRoo} v. 3.0 {\textbar} {FRBRoo}},
	url = {https://www.cidoc-crm.org/frbroo/ModelVersion/frbroo-v.-3.0},
	urldate = {2023-03-10},
	file = {FRBRoo v. 3.0 | FRBRoo:files/224/frbroo-v.-3.html:text/html},
}

@article{group_ifla_2018,
	title = {{IFLA} {Library} {Reference} {Model}: {A} {Conceptual} {Model} for {Bibliographic} {Information}},
	copyright = {CC BY 4.0},
	shorttitle = {{IFLA} {Library} {Reference} {Model}},
	url = {https://repository.ifla.org/handle/123456789/40},
	abstract = {IFLA Library Reference Model (LRM) is a high-level conceptual reference model developed within an entity-relationship modelling framework. It is the consolidation of the separately developed IFLA conceptual models: FRBR, FRAD, FRSAD. 
IFLA LRM was developed to resolve inconsistencies between the three separate models. Every user task, entity, attribute and relationship from the original three models was examined, definitions had to be revised, but also some remodelling was required in order to develop a meaningful consolidation. The result is a single, streamlined, and logically consistent model that covers all aspects of bibliographic data and that at the same time brings the modelling up-to-date with current conceptual modelling practices. 
IFLA LRM was designed to be used in linked data environments and to support and promote the use of bibliographic data in linked data environments.},
	language = {en},
	urldate = {2023-03-10},
	author = {Group, IFLA Functional Requirements for Bibliographic Records (FRBR) Review and Riva, Pat and Le Boeuf, Patrick and Žumer, Maja},
	month = jan,
	year = {2018},
	note = {Accepted: 2020-12-17T15:13:08Z
Publisher: International Federation of Library Associations and Institutions (IFLA)},
	file = {Full Text PDF:files/226/Group et al. - 2018 - IFLA Library Reference Model A Conceptual Model f.pdf:application/pdf},
}

@misc{noauthor_r2rml_nodate,
	title = {{R2RML}: {RDB} to {RDF} {Mapping} {Language}},
	url = {https://www.w3.org/TR/r2rml/},
	urldate = {2023-03-10},
}

@article{barthelemy_towards_2022,
	title = {Towards a standard-based open data ecosystem: analysis of {DCAT}-{AP} use at national and {European} level},
	volume = {18},
	issn = {1740-7494},
	shorttitle = {Towards a standard-based open data ecosystem},
	url = {https://www.inderscienceonline.com/doi/abs/10.1504/EG.2022.121856},
	doi = {10.1504/EG.2022.121856},
	abstract = {In Europe, an open government data ecosystem is being developed. This ecosystem is implemented using various technologies and platforms. In fact, the use of a common metadata standard for describing datasets and open data portals, i.e., the DCAT-AP specification, appears as the lingua franca that connects an, otherwise, fragmented environment. In this context, the standard-based consolidation of open data promotes the subsidiarity principle, allowing open data portal owners to choose platforms and internal representations based on their specific requirements. However, the portal owners must provide an export with DCAT-AP compliant metadata about the dataset they store. In this paper we provide a detailed study of how the DCAT-AP specification is used in practice, both at the national and the European level. Consequently, we also identify issues, challenges, and opportunities for improvements that can be used as input for the next revision cycle of the standard. Essentially, our goal is to contribute towards the enrichment of a growing and promising European open data ecosystem.},
	number = {2},
	urldate = {2023-03-10},
	journal = {Electronic Government, an International Journal},
	author = {Barthelemy, Florian and Cochez, Michael and Dimitriadis, Iraklis and Karim, Naila and Loutas, Nikolaos and Magnisalis, Ioannis and Comet, Lina Molinas and Peristeras, Vassilios and Wyns, Brecht},
	month = jan,
	year = {2022},
	note = {Publisher: Inderscience Publishers},
	keywords = {DCAT-AP, data standards, DCAT, interoperability, metadata, open data, open data portals},
	pages = {137--180},
}

@article{gasperoni_categorizzazione_nodate,
	title = {Categorizzazione degli open-data italiani sul proﬁlo europeo dei metadati {DCAT}-{AP}},
	language = {it},
	author = {Gasperoni, Simone},
	file = {Gasperoni - Categorizzazione degli open-data italiani sul proﬁ.pdf:files/290/Gasperoni - Categorizzazione degli open-data italiani sul proﬁ.pdf:application/pdf},
}

@misc{noauthor_ebscohost_nodate,
	title = {{EBSCOhost} {\textbar} 140484459 {\textbar} {Metadata} {Editor}: a web graphical tool for the {DCAT}-{AP} extensions {RDF} metadata generation.},
	url = {https://web.p.ebscohost.com/abstract?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=10297006&AN=140484459&h=6wC%2fzdRRq7539N0BYBvcrdpJXUrkSfLToVys3bDhoUTLG%2b092GiUI6VmG6fLCDxx0nXQ0roiCYv72mm0zOqdsg%3d%3d&crl=c&resultNs=AdminWebAuth&resultLocal=ErrCrlNotAuth&crlhashurl=login.aspx%3fdirect%3dtrue%26profile%3dehost%26scope%3dsite%26authtype%3dcrawler%26jrnl%3d10297006%26AN%3d140484459},
	urldate = {2023-03-10},
	file = {EBSCOhost | 140484459 | Metadata Editor\: a web graphical tool for the DCAT-AP extensions RDF metadata generation.:files/293/abstract.html:text/html},
}

@article{bottazzi_italian_2021,
	title = {The {Italian} open data meteorological portal: {MISTRAL}},
	volume = {28},
	issn = {1469-8080},
	shorttitle = {The {Italian} open data meteorological portal},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/met.2004},
	doi = {10.1002/met.2004},
	abstract = {At the national level, in Italy, observational and forecast data are collected by various public bodies and are often kept in various small, heterogeneous and non-interoperable repositories, released under different licenses, thus limiting the usability for external users. In this context, MISTRAL (the Meteo Italian SupercompuTing PoRtAL) was launched as the first Italian meteorological open data portal, with the aim of promoting the reuse of meteorological data sets available at national level coverage. The MISTRAL portal provides (and archives) meteorological data from various observation networks, both public and private, and forecast data that are generated and post-processed within the Consortium for Small-scale Modeling-Limited Area Model Italia (COSMO-LAMI) agreement using high performance computing (HPC) facilities. Also incorporated is the Italy Flash Flood use case, implemented with the collaboration of European Centre for Medium-Range Weather Forecasts (ECMWF), which exploits cutting edge advances in HPC-based post-processing of ensemble precipitation forecasts, for different model resolutions, and applies those to deliver novel blended-resolution forecasts specifically for Italy. Finally, in addition to providing architectures for the acquisition and display of observational data, MISTRAL also delivers an interactive system for visualizing forecast data of different resolutions as superimposed multi-layer maps.},
	language = {en},
	number = {4},
	urldate = {2023-03-10},
	journal = {Meteorological Applications},
	author = {Bottazzi, Michele and Scipione, Gabriella and Marras, Gian Franco and Trotta, Giuseppe and D'Antonio, Mattia and Chiavarini, Beatrice and Caroli, Cinzia and Montanari, Margherita and Bassini, Sanzio and Gascón, Estíbaliz and Hewson, Timothy and Montani, Andrea and Cesari, Davide and Minguzzi, Enrico and Paccagnella, Tiziana and Pelosini, Renata and Bertolotto, Paolo and Monaco, Luca and Forconi, Martina and Giovannini, Luca and Cacciamani, Carlo and Passeri, Luca Delli and Pieralice, Andrea},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/met.2004},
	keywords = {open data, forecast, HPC, meteorological, MISTRAL, observation},
	pages = {e2004},
	file = {Full Text PDF:files/296/Bottazzi et al. - 2021 - The Italian open data meteorological portal MISTR.pdf:application/pdf},
}

@article{tomoyose_vocabularies_2022,
	title = {Vocabularies for {Publishing} {Research} {Data}},
	volume = {60},
	issn = {0163-9374},
	url = {https://doi.org/10.1080/01639374.2021.2011812},
	doi = {10.1080/01639374.2021.2011812},
	abstract = {Research data are essential for the development of science, and one of the issues to be addressed is its organization and representation. Based on these basic concepts of Information Science, we seek to explore the Data Catalog Vocabulary (DCAT) and the vocabularies used by it in the context of research data publication. We assert that the use of metadata vocabularies to represent research data is necessary to improve access, findability, interoperability, and the retrieval of datasets. We verify that DCAT enables the standardization of catalogs and datasets through specific terms for this purpose, presenting itself as an adequate vocabulary to represent the research data.},
	number = {1},
	urldate = {2023-03-10},
	journal = {Cataloging \& Classification Quarterly},
	author = {Tomoyose, Kazumi and Arakaki, Ana Carolina Simionato},
	month = jan,
	year = {2022},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/01639374.2021.2011812},
	keywords = {controlled vocabularies, Data Catalog Vocabulary (DCAT), information representation, metadata standards, research data},
	pages = {69--85},
}

@inproceedings{bartalesi_steps_2016,
	address = {Dagstuhl, Germany},
	series = {{OpenAccess} {Series} in {Informatics} ({OASIcs})},
	title = {Steps {Towards} a {Formal} {Ontology} of {Narratives} {Based} on {Narratology}},
	volume = {53},
	isbn = {978-3-95977-020-0},
	url = {http://drops.dagstuhl.de/opus/volltexte/2016/6705},
	doi = {10.4230/OASIcs.CMN.2016.4},
	urldate = {2023-03-10},
	booktitle = {7th {Workshop} on {Computational} {Models} of {Narrative} ({CMN} 2016)},
	publisher = {Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik},
	author = {Bartalesi, Valentina and Meghini, Carlo and Metilli, Daniele},
	editor = {Miller, Ben and Lieto, Antonio and Ronfard, Rémi and Ware, Stephen G. and Finlayson, Mark A.},
	year = {2016},
	note = {ISSN: 2190-6807},
	keywords = {Ontology, Narrative},
	pages = {4:1--4:10},
	file = {Full Text PDF:files/306/Bartalesi et al. - 2016 - Steps Towards a Formal Ontology of Narratives Base.pdf:application/pdf;Snapshot:files/307/6705.html:text/html},
}

@inproceedings{lombardo_ontologies_2013,
	title = {Ontologies for the metadata annotation of stories},
	volume = {2},
	doi = {10.1109/DigitalHeritage.2013.6744747},
	abstract = {Semantic web and ontology technologies offer cultural heritage the conceptualization of a number of domains of interest. A relevant issue in the annotation of digital heritage is the abstraction of concepts that underlie a number of cultural heritage items, conceived for different media, in libraries and collections. This is the case for a category we call dramatic items, expressed in a large number of media (e.g., novels, screenplay, stage performance, videogames, audiovisuals, the latter including feature films, TV series, music videoclips). The primary notion of story underpins the dramatic media. This paper presents an ontology for the representation of the story elements in media heritage. Story elements are employed to describe the dramatic qualities (e.g., the agents or characters of a story, their goals, their conflicts), abstracting from the specific media in which they appear. An annotation schema derived from the ontology was employed in a web platform for the annotation of the dramatic metadata on the digital heritage items (in textual and audiovisual form). Formal reasoning on the metadata representation points out a number of issues that are of interest for scholars and enthusiast of the drama cultural heritage, so are useful in research, teaching, and fruition.},
	booktitle = {2013 {Digital} {Heritage} {International} {Congress} ({DigitalHeritage})},
	author = {Lombardo, Vincenzo and Pizzo, Antonio},
	month = oct,
	year = {2013},
	keywords = {Cultural differences, Ontologies, Visualization, Encoding, Media, Motion pictures, TV},
	pages = {153--160},
	file = {IEEE Xplore Abstract Record:files/309/6744747.html:text/html},
}

@book{tandon_endangered_2016,
	address = {Paris},
	title = {Endangered heritage: emergency evacuation of heritage collections},
	isbn = {978-92-3-100162-8 978-92-9077-247-7},
	shorttitle = {Endangered heritage},
	language = {en},
	publisher = {United Nations Educational, Scientific and Cultural Organization (UNESCO)},
	author = {Tandon, Aparna},
	editor = {UNESCO and International Centre for the Study of the Preservation {and} the Restoration of Cultural Property},
	year = {2016},
	file = {Tandon - 2016 - Endangered heritage emergency evacuation of herit.pdf:files/314/Tandon - 2016 - Endangered heritage emergency evacuation of herit.pdf:application/pdf},
}

@article{lopez_linking_2018,
	title = {Linking {HBIM} graphical and semantic information through the {Getty} {AAT}: {Practical} application to the {Castle} of {Torrelobatón}},
	volume = {364},
	issn = {1757-899X},
	shorttitle = {Linking {HBIM} graphical and semantic information through the {Getty} {AAT}},
	url = {https://dx.doi.org/10.1088/1757-899X/364/1/012100},
	doi = {10.1088/1757-899X/364/1/012100},
	abstract = {The current approaches for the built heritage documentation and modelling are to collecting, organizing and integrating immovable assets’ data into a single graphic-semantic structure using BIM tools. This is the key issue to shifting from point clouds to HBIM. Although fully automation is not possible, practical approaches for the conversion of point clouds into HBIM elements grouped in libraries have recently appeared to meet the particular characteristics of historic buildings in an equivalent way to the libraries of elements already available for contemporary building and civil works. In spite of the graphic information on the built heritage elements is semantically rich in itself, linking the families of modelled elements with the Getty Art \& Architecture Thesaurus (AAT) as worldwide well-known controlled vocabulary, allows not only the automation but the consistency in cataloguing of required elements, as well as more efficient retrieval of information in a standardized way. This so useful graphic-semantic linking is particularly applied to the Castle of Torrelobatón to make up the HBIM meaningful set of fundamental elements of the defensive architecture from the Middle Age to the Renaissance in Europe, of which this Castle is a representative example.},
	language = {en},
	number = {1},
	urldate = {2023-03-11},
	journal = {IOP Conference Series: Materials Science and Engineering},
	author = {López, F. J. and Lerones, P. M. and Llamas, J. and Gómez-García-Bermejo, J. and Zalama, E.},
	month = jun,
	year = {2018},
	note = {Publisher: IOP Publishing},
	pages = {012100},
	file = {IOP Full Text PDF:files/320/López et al. - 2018 - Linking HBIM graphical and semantic information th.pdf:application/pdf},
}

@article{bonduel_framework_2021,
	title = {A {Framework} for a {Linked} {Data}-based {Heritage} {BIM}},
	url = {https://lirias.kuleuven.be/3416395},
	abstract = {Collaborative built heritage projects require that a large variety of stakeholders, often using different tools and datasets, collaborate efficiently to conserve a valuable heritage building. Despite the opportunities of a thorough digitization, the general adoption and exchange of structured data during such projects is currently lower compared to other sectors of the construction domain focusing on new buildings. Besides conventional Building Information Modeling (BIM) applications and related exchange formats such as IFC (Industry Foundation Classes), researchers have been studying the potential of standardized Semantic Web Technologies (SWT), including Linked Data graphs, to improve the modeling of structured building data and its exchange over the Web.
In this thesis, it is argued that the (Heritage) BIM concept can be implemented using SWT, resulting in a framework for a Linked Data-based Heritage BIM (LD-based HBIM), instead of relying on conventional BIM technology alone. The application of SWT requires the availability of a shared data structure, documented in so-called web ontologies, to obtain rich and interoperable building descriptions. A network of modular ontologies is proposed in contrast to a few large and complex ontologies. In many cases, terminology documented in these modular ontologies is expected to be applicable beyond the heritage domain, e.g. for the description of new buildings or other types of constructions. Besides ontologies, workflows and proof-of-concept applications are considered valuable to demonstrate how the LD-based HBIM framework can be applied in practice.
First, the characteristics and application of SWT in built heritage projects, besides other data technologies, are studied through a literature review. Second, current workflows in the Flemish built heritage sector and opportunities for digitization are collected through semi-structured interviews with stakeholders. The results of this stakeholder analysis are used to derive five thematic sets of requirements - including overall needs and requirements related to the description of buildings in general, geometry, damage and construction dataset metadata - as the benchmark for the development of the LD-based HBIM framework. Using the benchmark requirements, an ontology network is prepared consisting of existing, transformed and, wherever necessary, new ontologies.
In the proposed ontology network, a division is made between (1) concise core ontologies for the description of buildings and related aspects, (2) extending ontologies and taxonomies for properties, geometry metadata and classification, and (3) a separate set of terminology for construction dataset metadata. According to best practices, existing ontologies such as BOT (building topology) and DCAT (general dataset metadata) are reused wherever possible. The OMG (geometry linking), OPM (properties versioning) and DOT (damage linking and topology) ontologies are newly developed together with other researchers. The new CTO (construction tasks), ConTax (taxonomies management) and CDC (construction dataset context) ontologies are a direct result of this research. Existing taxonomies related to the classification of construction components, spatial building zones and materials are transformed to make them suitable for application with the core ontologies. In addition, new taxonomies are prepared for properties (CP and BHP), geometry formats (FOG) and the classification of damages (MDCS-O and MWV-D) and tasks (MVW-T). Finally, the new GOM ontology can be combined with OMG and FOG to facilitate the reuse of geometry descriptions in any existing geometry format. Different workflows, accompanied by existing and newly developed demo applications, for the authoring of building datasets are identified and analyzed. The modeling of construction dataset metadata and the exchange of datasets are documented in a higher-level workflow. The developed ontology network is applied in five example cases, inspired by two built heritage projects in Ghent, to demonstrate the new functionalities of the developed LD-based HBIM framework.
The developed ontology network proves valuable for the description of unique and potentially complex heritage buildings thanks to its modularity, concise core ontologies and extendable taxonomies for classification and properties. A large part of the developed ontologies can be reused to describe other types of constructions. The thesis demonstrates how technical and semantic interoperability can be established by applying the LD-based HBIM framework while creating, exchanging and reusing construction datasets.},
	language = {eng},
	urldate = {2023-03-11},
	author = {Bonduel, Mathias and Klein, Ralf and Vergauwen, Maarten and Pauwels, Pieter},
	month = may,
	year = {2021},
	file = {Snapshot:files/322/3416395.html:text/html},
}

@article{ferretti_comprehensive_2022,
	title = {A {Comprehensive} {HBIM} to {XR} {Framework} for {Museum} {Management} and {User} {Experience} in {Ducal} {Palace} at {Urbino}},
	volume = {5},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2571-9408},
	url = {https://www.mdpi.com/2571-9408/5/3/81},
	doi = {10.3390/heritage5030081},
	abstract = {Digitization of Cultural and Museum Heritage represents one of the most engaging challenges that would ensure a sustainable and ethical approach for next generations; digital technology’s pervasiveness imposes a comprehensive management of architectural heritage by producing facsimiles of buildings and artworks and by testing robust methodologies, with the final result of providing effective multipurpose models. In this context, the main goal of the present paper is to develop a semantically aware HBIM model that includes an intelligent objects parametrization, leveraging Extended Reality (XR) technologies and digital curation of contents to pursue the preservation of Cultural Heritage (CH) as a whole. This research is implemented in the case study of the Ducal Palace of Urbino that houses the National Gallery of Marche. It was chosen as a remarkable example of a museum located in an architectural complex with a relevant historical background and fine detail of shapes and mouldings. In Italy, as in other European scenarios, museums and their collections need suitable dissemination and management systems that take advantage of the recent digital paradigms. The challenging approach is to exploit existing platforms and software and to adopt a cognitive modelling process, able to develop tools supporting managers and museum curators while enabling user experiences using immersive and interactive features. In order to stress the workflow, this work proposes the use of families with high Level of Detail (LOD) and high Level of Information (LOI). The present article provides, as well, an accurate data enrichment process specifically designed for a gallery’s artworks such as paintings and sculptures, in line with the national and international policies. The study presents a robust and reproducible methodology for digital musealization and management, focusing, as future overall objectives, towards a greater merging between the HBIM approach and XR technologies, also facilitated by training new professional figures with more in-depth digital skills.},
	language = {en},
	number = {3},
	urldate = {2023-03-11},
	journal = {Heritage},
	author = {Ferretti, Umberto and Quattrini, Ramona and D’Alessio, Mirco},
	month = sep,
	year = {2022},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {HBIM, ontology, user experience, virtual museum, collection management system, extended reality (XR), IFC, mixed reality and museums, virtual reality (VR)},
	pages = {1551--1571},
	file = {Full text:files/324/Ferretti et al. - 2022 - A Comprehensive HBIM to XR Framework for Museum Ma.pdf:application/pdf},
}

@misc{noauthor_abc_2017,
	title = {The {ABC} {Method}: a risk management approach to the preservation of cultural heritage {\textbar} {ICCROM}},
	shorttitle = {The {ABC} {Method}},
	url = {https://www.iccrom.org/publication/abc-method-risk-management-approach-preservation-cultural-heritage},
	abstract = {This manual offers a comprehensive understanding of risk management applied to the preservation of heritage assets, whether collections, buildings or sites. It…},
	language = {en},
	urldate = {2023-03-11},
	month = mar,
	year = {2017},
	file = {Snapshot:files/326/abc-method-risk-management-approach-preservation-cultural-heritage.html:text/html},
}

@misc{buzzanca_managing_2022,
	title = {Managing risks to cultural heritage with the {ABC} {System} - {Kermes}},
	url = {https://www.kermes-restauro.it/managing-risks-to-cultural-heritage-with-the-abc-system/, https://www.kermes-restauro.it/managing-risks-to-cultural-heritage-with-the-abc-system/},
	abstract = {On 4 November 2022, ICCROM, Casa de Oswaldo Cruz (Fiocruz), and CCI held a virtual launch event to announce the ABC System.},
	language = {it-IT},
	urldate = {2023-03-11},
	author = {Buzzanca, Giancarlo:},
	month = nov,
	year = {2022},
	file = {Snapshot:files/328/managing-risks-to-cultural-heritage-with-the-abc-system.html:text/html},
}

@book{hernandez_structural_2021,
	title = {Structural {Studies}, {Repairs} and {Maintenance} of {Heritage} {Architecture} {XVII} \& {Earthquake} {Resistant} {Engineering} {Structures} {XIII}},
	isbn = {978-1-78466-429-9},
	abstract = {Structural Studies, Repairs and Maintenance of Heritage Architecture XVII The importance of retaining the built cultural heritage cannot be overstated. Rapid development and inappropriate conservation techniques are threatening many heritage unique sites in different parts of the world. Selected papers presented at the 17th International Conference on Studies, Repairs and Maintenance of Heritage Architecture are included in this volume. They address a series of topics related to the historical aspects and the reuse of heritage buildings, as well as technical issues on the structural integrity of different types of buildings, such as those constructed with materials as varied as iron and steel, concrete, masonry, wood or earth. Restoration processes require the appropriate characterisation of those materials, the modes of construction and the structural behaviour of the building. This knowledge can be gained through a series of material characterisation techniques, preferably via non-destructive tests. Modern computer simulation can provide accurate results demonstrating the stress state of the building and possible failure mechanisms affecting its stability. Of particular importance are studies related to their dynamic and earthquake behaviour aiming to provide an assessment of the seismic vulnerability of heritage buildings.Contributions originate from scientists, architects, engineers and restoration experts from all over the world and deal with different aspects of heritage buildings, including how to formulate regulatory policies, to ensure effective ways of preserving the architectural heritage. Earthquake Resistant Engineering Structures XIII Papers presented at the 13th International Conference on Earthquake Resistant Engineering Structures form this volume and cover basic and applied research in the various fields of earthquake engineering relevant to the design of structures.Major earthquakes and associated effects such as tsunamis continue to stress the need to carry out more research on those topics. The problems will intensify as population pressure results in buildings in regions of high seismic vulnerability. A better understanding of these phenomena is required to design earthquake resistant structures and to carry out risk assessments and vulnerability studies.The problem of protecting the built environment in earthquake-prone regions involves not only the optimal design and construction of new facilities but also the upgrading and rehabilitation of existing structures including heritage buildings. The type of highly specialized retrofitting employed to protect the built heritage is an important area of research.The included papers cover such topics as Seismic hazard and tsunamis; Building performance during earthquakes; Structural vulnerability; Seismic isolation and energy dissipation; Passive earthquake protection systems.},
	language = {en},
	publisher = {WIT Press},
	author = {Hernández, S. and Marseglia, G.},
	month = jul,
	year = {2021},
	note = {Google-Books-ID: Dnc5EAAAQBAJ},
	keywords = {Architecture / Design, Drafting, Drawing \& Presentation, Architecture / Historic Preservation / General, Technology \& Engineering / Civil / Earthquake, Technology \& Engineering / Structural},
}

@article{coelho_risk_2020,
	title = {Risk management as a strategy for sustainable conservation: studies for the {Oswaldo} {Cruz} {Foundation}’s cultural heritage},
	copyright = {Copyright (c) 2020},
	issn = {1647-2098},
	shorttitle = {Risk management as a strategy for sustainable conservation},
	url = {https://revistas.ucp.pt/index.php/ecr/article/view/9584},
	doi = {10.34632/ecr.2020.9584},
	abstract = {The Oswaldo Cruz Foundation (Fiocruz) is a Brazilian public institution that holds a diverse range of collections and historical buildings. A medium-term program was established to implement risk management plans for the Foundation’s cultural property. This paper presents the research outcomes and strategies adopted to mitigate the identified risks. The work’s results have been fundamental for the definition of actions that aim to minimize the need for large-scale interventions in cultural assets, reducing the amount of material and financial resources used and avoiding the removal and replacement of large volumes of preexisting materials, minimizing energy consumption and waste generation.},
	language = {en},
	number = {11},
	urldate = {2023-03-11},
	journal = {Estudos de Conservação e Restauro},
	author = {Coelho, Carla Maria Teixeira and Pinheiro, Marcos José de Araújo and Sá, Bruno Teixeira de},
	month = jan,
	year = {2020},
	note = {Number: 11},
	keywords = {Collections, Historical buildings, Preventive conservation, Risk management, Sustainability},
	pages = {6--18},
	file = {Full Text PDF:files/334/Coelho et al. - 2020 - Risk management as a strategy for sustainable cons.pdf:application/pdf},
}

@article{paoli_disasters_2020,
	title = {Disasters and {Cultural} {Heritage}: planning for prevention, emergency management and risk reduction},
	volume = {949},
	issn = {1757-899X},
	shorttitle = {Disasters and {Cultural} {Heritage}},
	url = {https://dx.doi.org/10.1088/1757-899X/949/1/012084},
	doi = {10.1088/1757-899X/949/1/012084},
	abstract = {The need to investigate the topic of risk management of cultural heritage and to work on the regulatory framework relating to its protection and enhancement become even more urgent in light of the recent seismic events that hit the Italian territory. The current emergency planning methods against natural or human-induced hazards have proven to be deficient. Reflecting on the way we normally conceive the cultural assets, the question is not only how to protect our heritage, but how to shift our perception to conceive it as a positive asset, and not only a responsibility. Cultural heritage is not only a document of the identity of a community and a territory, but it can also be the keystone for reconstruction and building resilience to disasters. Starting from this awareness, this paper introduces a methodology for the analysis heritage sites aiming at proposing risk reduction strategies that consider the participatory dialogue between different professional figures. The approach is based on the consolidated methodological framework identified by UNESCO, ICCROM and ICOMOS. The study entails a preliminary evaluation of the most hazardous events, threats and risks that can impact on the heritage values. By considering a worst-case scenario, the procedure allows for modelling and stressing the post-event resilience of the site or cultural asset under consideration. The results of the investigation highlight the potential of this procedure in practical terms. In fact, its adaptability to different scales and contexts responds to the common need of a rapid, integrated methodology for risk assessment. Finally, the paper discusses the current prevention policies involving cultural heritage, focusing on the need to balance conservation and active protection issues to those of safety.},
	language = {en},
	number = {1},
	urldate = {2023-03-11},
	journal = {IOP Conference Series: Materials Science and Engineering},
	author = {Paoli, Rosa Grazia De and Miceli, Enrica Di and Giuliani, Francesca},
	month = nov,
	year = {2020},
	note = {Publisher: IOP Publishing},
	pages = {012084},
	file = {IOP Full Text PDF:files/337/Paoli et al. - 2020 - Disasters and Cultural Heritage planning for prev.pdf:application/pdf},
}

@article{giuliani_risk-reduction_2021,
	title = {A risk-reduction framework for urban cultural heritage: a comparative study on {Italian} historic centres},
	volume = {11},
	issn = {2044-1266},
	shorttitle = {A risk-reduction framework for urban cultural heritage},
	url = {https://doi.org/10.1108/JCHMSD-07-2020-0099},
	doi = {10.1108/JCHMSD-07-2020-0099},
	abstract = {Purpose The purpose of this paper is to present and validate a large-scale methodology for risk assessment and management in cultural heritage sites, taking into account their specific tangible or intangible values. Emphasis is given to historic centres that are key resources in building resilience to disasters but are also highly vulnerable due to several factors, such as the characteristics of the built environment, the community and social life, the lack of risk awareness and maintenance and finally the poor regulatory framework for their management and valorisation. Design/methodology/approach The multi-step procedure starts from the assessment of the attributes of cultural heritage in order to identify priorities and address the analysis. Then, it evaluates the primary and secondary hazards in the area, the vulnerabilities and threats of the site and the impacts of the chain of events. Finally, it allows for calibrating a site-specific set of mitigation, preparedness, response and recovery measures. Findings The application to two case studies in the Italian peninsula, the historic centres of San Gimignano and Reggio Calabria, allows for identifying research gaps and practical opportunities towards the adoption of common guidelines for the selection of safety measures. Originality/value By providing a qualitative assessment of risks, the research points out the potentialities of the methodology in the disaster risk management of cultural heritage due to its capacity to be comprehensive and inclusive towards disciplines and professionals.},
	number = {4},
	urldate = {2023-03-11},
	journal = {Journal of Cultural Heritage Management and Sustainable Development},
	author = {Giuliani, Francesca and De Paoli, Rosa Grazia and Di Miceli, Enrica},
	month = jan,
	year = {2021},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Cultural heritage, Disaster risk reduction, Disasters, Historic urban landscape, Management, Resilience, Vulnerability, World heritage},
	pages = {499--515},
	file = {Full Text PDF:files/339/Giuliani et al. - 2021 - A risk-reduction framework for urban cultural heri.pdf:application/pdf},
}

@inproceedings{fenlon_modeling_2019,
	title = {Modeling {Digital} {Humanities} {Collections} as {Research} {Objects}},
	doi = {10.1109/JCDL.2019.00029},
	abstract = {Advancing digital libraries to increase the sustainability and usefulness of digital scholarship depends on identifying and developing data models capable of representing increasingly complex scholarly products. This paper considers the potential for an emergent model of scientific communication, the \textit{research objects} data model, to accommodate the complexities of digital humanities collections. Digital humanities collections aggregate and enrich diverse sources of evidence and context, serving simultaneously as "publications" and dynamic, interactive platforms for research. The research objects model is an alternative to traditional formats of publication, facilitating aggregation and description of all of the inputs and outputs of a research process, ranging from datasets to papers to executable code. This model increasingly underpins research infrastructures in some scientific domains, yet its efficacy for representing humanities scholarship, and for undergirding humanities cyberinfrastructure, remains largely untested. This study offers a qualitative content analysis of digital humanities collections relying on a content/context analytical framework for characterizing collection components and their interrelationships. This study then maps those components and relationships into a research objects model to identify the model's strengths and limitations for representing diverse digital humanities scholarship.},
	booktitle = {2019 {ACM}/{IEEE} {Joint} {Conference} on {Digital} {Libraries} ({JCDL})},
	author = {Fenlon, Katrina},
	month = jun,
	year = {2019},
	keywords = {Libraries, Metadata, Analytical models, data models, digital humanities, digital libraries, research objects, Object recognition, Scholarships, Sustainable development},
	pages = {138--147},
	file = {Full text:files/341/Fenlon - 2019 - Modeling Digital Humanities Collections as Researc.pdf:application/pdf;IEEE Xplore Abstract Record:files/342/8791110.html:text/html},
}

@article{gangemi_publishing_2017,
	title = {The {Publishing} {Workflow} {Ontology} ({PWO})},
	volume = {8},
	issn = {1570-0844},
	url = {https://content.iospress.com/articles/semantic-web/sw230},
	doi = {10.3233/SW-160230},
	abstract = {In this paper we introduce the Publishing Workflow Ontology (PWO ), i.e., an OWL 2 DL ontology for the description of workflows that is particularly suitable for formalising typical publishing processes such as the publication of articles in journals},
	language = {en},
	number = {5},
	urldate = {2023-03-11},
	journal = {Semantic Web},
	author = {Gangemi, Aldo and Peroni, Silvio and Shotton, David and Vitali, Fabio},
	month = jan,
	year = {2017},
	note = {Publisher: IOS Press},
	pages = {703--718},
	file = {Full text:files/344/Gangemi et al. - 2017 - The Publishing Workflow Ontology (PWO).pdf:application/pdf},
}

@incollection{gangemi_ontology_2009,
	address = {Berlin, Heidelberg},
	series = {International {Handbooks} on {Information} {Systems}},
	title = {Ontology {Design} {Patterns}},
	isbn = {978-3-540-92673-3},
	url = {https://doi.org/10.1007/978-3-540-92673-3_10},
	abstract = {Computational ontologies in the context of information systems are artifacts that encode a description of some world, for some purpose. Under the assumption that there exist classes of problems that can be solved by applying common solutions (as it has been experienced in software engineering), we envision small, task-oriented ontologies with explicit documentation of design rationales. In this chapter, we describe components called Ontology Design Patterns (OP), and methods that support pattern-based ontology design.},
	language = {en},
	urldate = {2023-03-11},
	booktitle = {Handbook on {Ontologies}},
	publisher = {Springer},
	author = {Gangemi, Aldo and Presutti, Valentina},
	editor = {Staab, Steffen and Studer, Rudi},
	year = {2009},
	doi = {10.1007/978-3-540-92673-3_10},
	keywords = {Design Pattern, Domain Ontology, Ontology Design, Ontology Engineering, Reference Ontology},
	pages = {221--243},
}

@misc{smartprotocols_smart_nodate,
	title = {{SMART} {Protocols}},
	url = {https://smartprotocols.github.io/},
	abstract = {Using Semantics and Natural Language Processing in Experimental Protocols},
	language = {en},
	urldate = {2023-03-12},
	journal = {SMART Protocols},
	author = {SMARTProtocols},
	file = {Snapshot:files/348/smartprotocols.github.io.html:text/html},
}

@article{anzures-garcia_workflow_2018,
	title = {A {Workflow} {Ontology} to {Support} {Knowledge} {Management} in a {Group}’s {Organizational} {Structure}},
	volume = {22},
	issn = {1405-5546},
	url = {http://www.scielo.org.mx/scielo.php?script=sci_abstract&pid=S1405-55462018000100163&lng=es&nrm=iso&tlng=en},
	doi = {10.13053/cys-22-1-2781},
	language = {en},
	number = {1},
	urldate = {2023-03-12},
	journal = {Computación y Sistemas},
	author = {Anzures-García, Mario and Sánchez-Gálvez, Luz A. and Hornos, Miguel J. and Paderewski-Rodríguez, Patricia and Anzures-García, Mario and Sánchez-Gálvez, Luz A. and Hornos, Miguel J. and Paderewski-Rodríguez, Patricia},
	month = mar,
	year = {2018},
	note = {Publisher: Instituto Politécnico Nacional, Centro de Investigación en Computación},
	pages = {163--178},
	file = {Full Text PDF:files/350/Anzures-García et al. - 2018 - A Workflow Ontology to Support Knowledge Managemen.pdf:application/pdf},
}

@book{brooks_story_2011,
	title = {Story {Engineering}},
	isbn = {978-1-59963-281-0},
	abstract = {What makes a good story or a screenplay great?The vast majority of writers begin the storytelling process with only a partial understanding where to begin. Some labor their entire lives without ever learning that successful stories are as dependent upon good engineering as they are artistry. But the truth is, unless you are master of the form, function and criteria of successful storytelling, sitting down and pounding out a first draft without planning is an ineffective way to begin.Story Engineering starts with the criteria and the architecture of storytelling, the engineering and design of a story--and uses it as the basis for narrative. The greatest potential of any story is found in the way six specific aspects of storytelling combine and empower each other on the page. When rendered artfully, they become a sum in excess of their parts.You'll learn to wrap your head around the big pictures of storytelling at a professional level through a new approach that shows how to combine these six core competencies which include:   • Four elemental competencies of concept, character, theme, and story structure (plot)   • Two executional competencies of scene construction and writing voiceThe true magic of storytelling happens when these six core competencies work together in perfect harmony. And the best part? Anyone can do it!},
	language = {en},
	publisher = {Penguin},
	author = {Brooks, Larry},
	month = jan,
	year = {2011},
	note = {Google-Books-ID: ICBjDwAAQBAJ},
	keywords = {Language Arts \& Disciplines / Writing / Authorship, Language Arts \& Disciplines / Writing / Composition, Language Arts \& Disciplines / Writing / Fiction Writing},
}

@book{onega_narratology_2014,
	title = {Narratology: {An} {Introduction}},
	isbn = {978-1-317-89060-7},
	shorttitle = {Narratology},
	abstract = {This text provides an excellent introduction and overview of Narratology, a rapidly growing field in the humanities. Literary narratologists have provided many key concepts and analytical tools which are widely used in the interdisciplinary analysis of such narrative features as plot, point of view, speech presentation, ideological perspective and interpretation.The introduction explains the central concepts of narratology, their historical development, and draws together contemporary trends from many different disciplines into common focus. It offers a compendium of the development of narratology from classical poetics to the present.The essays are all prefaced by individual forewords helping the reader to place each individual selection in context. Recent developments are assessed across disciplines, highlighting the mutual influences of narratology and deconstruction, psychoanalysis, feminism, film and media studies.},
	language = {en},
	publisher = {Routledge},
	author = {Onega, Susana and Landa, Jose Angel Garcia},
	month = sep,
	year = {2014},
	note = {Google-Books-ID: FBGPBAAAQBAJ},
	keywords = {Literary Criticism / General, Literary Criticism / Semiotics \& Theory},
}

@book{fludernik_introduction_2009,
	title = {An {Introduction} to {Narratology}},
	isbn = {978-1-134-05877-8},
	abstract = {An Introduction to Narratology is an accessible, practical guide to narratological theory and terminology and its application to literature.  In this book, Monika Fludernik outlines:     the key concepts of style, metaphor and metonymy, and the history of narrative forms  narratological approaches to interpretation and the linguistic aspects of texts, including new cognitive developments in the field how students can use narratological theory to work with texts, incorporating detailed practical examples a glossary of useful narrative terms, and suggestions for further reading. This textbook offers a comprehensive overview of the key aspects of narratology by a leading practitioner in the field. It demystifies the subject in a way that is accessible to beginners, but also reflects recent theoretical developments and narratology’s increasing popularity as a critical tool.},
	language = {en},
	publisher = {Routledge},
	author = {Fludernik, Monika},
	month = feb,
	year = {2009},
	note = {Google-Books-ID: vkmot9nVbWgC},
	keywords = {Literary Criticism / General, Literary Criticism / Semiotics \& Theory, Language Arts \& Disciplines / Rhetoric, Social Science / Media Studies},
}

@article{darby_form_2001,
	title = {Form and {Context}: {An} {Essay} in the {History} of {Narratology}},
	volume = {22},
	issn = {0333-5372},
	shorttitle = {Form and {Context}},
	url = {https://doi.org/10.1215/03335372-22-4-829},
	doi = {10.1215/03335372-22-4-829},
	abstract = {This essay compares two distinct traditions of narrative theory: on the one hand, that of structuralist narratology as it emerged in the 1960s and in its various subsequent manifestations; on the other, that of German-languageErzähltheorie as codified in the 1950s, with a prehistory dating back to German classicism. Having mapped the connections between these traditions, this essay then concentrates on exploring how narratology, unlike German narrative theory, has come to broaden its project exponentially since its first critical incarnation as a strictly formalist poetics. While the German tradition has concentrated on rhetoric and voice (with reception theory constituting a largely separate area of inquiry), narratology, which frames the text within a symmetry of real, implied, and fictional intelligences, has always had the potential to pose questions about how narrative functions in relation to a surrounding world of ideas. Of the two only narratology can therefore theorize both authorship and reading. In specific terms, this essay argues that the controversial narratological abstraction of implied authorship represents the only point at which a negotiation between textual and contextual worlds can logically take place. Evidence of how crucial such theorization has been in the development of contextualist narratology is sought in the examination of a test case, namely the much-disputed project of feminist narratology.},
	number = {4},
	urldate = {2023-03-12},
	journal = {Poetics Today},
	author = {Darby, David},
	month = dec,
	year = {2001},
	pages = {829--852},
	file = {Snapshot:files/359/Form-and-Context-An-Essay-in-the-History-of.html:text/html},
}

@book{huhn_handbook_2014,
	title = {Handbook of {Narratology}:},
	isbn = {978-3-11-031634-6},
	shorttitle = {Handbook of {Narratology}},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110316469/html},
	urldate = {2023-03-12},
	publisher = {DE GRUYTER},
	editor = {Hühn, Peter and Meister, Jan Christoph and Pier, John and Schmid, Wolf},
	month = aug,
	year = {2014},
	doi = {10.1515/9783110316469},
}

@article{damiano_ontological_2013,
	title = {Ontological {Representations} of {Narratives}: a {Case} {Study} on {Stories} and {Actions}},
	shorttitle = {Ontological {Representations} of {Narratives}},
	url = {http://drops.dagstuhl.de/opus/volltexte/2013/4149/},
	doi = {10.4230/OASICS.CMN.2013.76},
	abstract = {In this paper, we describe the narrative ontological model encompassed in the Labyrinth system. The aim of the system is to allow users to explore a digital archive by following the narrative relations among the resources contained in it. Targeted at cultural heritage applications, the Labyrinth project relies on the notion of “cultural archetype”, i.e., a core representation encompassing archetypical stories and characters, exploited as a conceptual framework for the access to archives of heterogeneous media objects. In particular, we describe how the system leverages various types of ontological reasoning to let narrative relations emerge between artworks, and exemplify how these relations are exploited by the system to provide the user with a narrative conceptual framework she or he is familiar with in the exploration of the archive.},
	language = {en},
	urldate = {2023-03-12},
	author = {Damiano, Rossana and Lieto, Antonio},
	collaborator = {Herbstritt, Marc},
	year = {2013},
	note = {Artwork Size: 18 pages
Medium: application/pdf
Publisher: Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik GmbH, Wadern/Saarbruecken, Germany},
	keywords = {000 Computer science, knowledge, general works, Computer Science},
	pages = {18 pages},
	file = {Damiano e Lieto - 2013 - Ontological Representations of Narratives a Case .pdf:files/453/Damiano e Lieto - 2013 - Ontological Representations of Narratives a Case .pdf:application/pdf},
}

@inproceedings{jewell_ontomedia_2005,
	title = {{OntoMedia}: {An} {Ontology} for the {Representation} of {Heterogeneous} {Media}},
	shorttitle = {{OntoMedia}},
	abstract = {With the emergence of the Semantic Web, a shared vocabulary is necessary to annotate the vast collection of heterogeneous media already in existence. The OntoMedia ontology aims to provide a meaningful set of relationships which may enable this process, while being suited to mapping and extension. In this paper we outline the salient features of our ontology as well as initial applications and comparisons to existing technologies.},
	author = {Jewell, Michael and Lawrence, K. and Tuffield, Mischa and Prugel-Bennett, Adam and Millard, David and Schraefel, m.c and Shadbolt, Nigel},
	month = jan,
	year = {2005},
}

@inproceedings{lombardo_drammar_2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Drammar: {A} {Comprehensive} {Ontological} {Resource} on {Drama}},
	isbn = {978-3-030-00668-6},
	shorttitle = {Drammar},
	doi = {10.1007/978-3-030-00668-6_7},
	abstract = {This paper reports about the release of a comprehensive ontological resource on drama, called Drammar. Drama is pervasive across cultures and is realized through disparate media items. Drammar has been designed with the goals to describe and encode the core dramatic qualities and to serve as a knowledge base underlying a number of applications. The impact of the resource is displayed through its direct application in a few tasks and its extension to serve in novel projects in the digital humanities.},
	language = {en},
	booktitle = {The {Semantic} {Web} – {ISWC} 2018},
	publisher = {Springer International Publishing},
	author = {Lombardo, Vincenzo and Damiano, Rossana and Pizzo, Antonio},
	editor = {Vrandečić, Denny and Bontcheva, Kalina and Suárez-Figueroa, Mari Carmen and Presutti, Valentina and Celino, Irene and Sabou, Marta and Kaffee, Lucie-Aimée and Simperl, Elena},
	year = {2018},
	keywords = {Digital humanities, Drama, Wiki},
	pages = {103--118},
}

@misc{noauthor_suggested_nodate,
	title = {The {Suggested} {Upper} {Merged} {Ontology} ({SUMO}) - {Ontology} {Portal}},
	url = {https://www.ontologyportal.org/},
	urldate = {2023-03-12},
	file = {The Suggested Upper Merged Ontology (SUMO) - Ontology Portal:files/463/www.ontologyportal.org.html:text/html},
}

@misc{noauthor_ontology_nodate,
	title = {Ontology for {Media} {Resources} 1.0},
	url = {https://www.w3.org/TR/mediaont-10/},
	urldate = {2023-03-12},
	file = {Ontology for Media Resources 1.0:files/465/mediaont-10.html:text/html},
}

@article{pasqual_linked_2022,
	title = {Linked open data per la valorizzazione di collezioni culturali: il dataset {mythLOD}},
	volume = {62},
	copyright = {Copyright (c) 2022 Valentina Pasqual, Francesca Tomasi},
	issn = {2239-6152},
	shorttitle = {Linked open data per la valorizzazione di collezioni culturali},
	url = {https://aibstudi.aib.it/article/view/13301},
	doi = {10.2426/aibstudi-13301},
	abstract = {The formal representation of cultural metadata has always been a challenge, considering the heterogeneity of cultural objects and especially when dealing with experts’ interpretation over them.This paper presents an overview of the mythLOD dataset production as the Mythologiae digital collection revalorisation into linked open data format. The research aims then to explore Mythologiae data leveraging semantic web potentialities, focusing over the formal representation of experts’ analysis when associating visual artworks (and their interpretations) to literary sources.The workflow of the project consisted of data model definition, data cleaning and entity linking, conversion (from tabular data to graph) and testing activity (domain experts review over competency questions and two designed on-purpose data visualizations). The result is the mythLOD platform, which present the dataset and the detailed documentation of the research. Additionally, the platform hosts the two data visualization spaces which have been implemented – the online catalogue and the storytelling experiment over Aeneid – as a user friendly testing unit for the dataset and an additional tool for documenting the project and exploring the collection.},
	language = {it},
	number = {1},
	urldate = {2023-03-12},
	journal = {AIB studi},
	author = {Pasqual, Valentina and Tomasi, Francesca},
	month = may,
	year = {2022},
	note = {Number: 1},
	keywords = {semantic web, Linked Open Data, citazioni canoniche, collezione semantica, ermeneutica digitale, Mythologiae, workflow},
	pages = {149--168},
	file = {Full Text PDF:files/506/Pasqual e Tomasi - 2022 - Linked open data per la valorizzazione di collezio.pdf:application/pdf},
}

@article{daquino_knowledge_2020,
	title = {Knowledge {Representation} of digital {Hermeneutics} of archival and literary {Sources}},
	url = {https://www.torrossa.com/it/resources/an/4692427},
	doi = {10.4403/jlis.it-12642},
	abstract = {Compra online il PDF di Knowledge Representation of digital Hermeneutics of archival and literary Sources, Daquino, Marilena,Pasqual, Valentina,Tomasi, Francesca - EUM-Edizioni Università di Macerata - Articolo},
	language = {it},
	urldate = {2023-03-12},
	journal = {Knowledge Representation of digital Hermeneutics of archival and literary Sources},
	author = {Daquino, Marilena},
	year = {2020},
	note = {Publisher: EUM-Edizioni Università di Macerata},
	pages = {59--76},
}

@article{pasqual_mima_nodate,
	title = {{MIMA}: a data model to represent multi-disciplinary analysis on manuscripts. {Use} case on {Pellegrino} {Prisciani}’s {Historiae} {Ferrariae}},
	abstract = {This research aims to explore and advance scholars’ understanding of the coexistence of multiple interpretations in a formal framework, by providing a practical solution to represent them. The state of the art, the adopted methodology and approach, and the results applied on a significant case study are shown. The research has been narrowed by working on a use case – the collection of lectures called Scrivere, rappresentare, conoscere nel rinascimento. Pellegrino Prisciani, un intellettuale eclettico tra la corte e il mondo. As a result, MIMA (Multi-disciplinary Interpretations model on Manuscript Apparatus) aims to formally represent these aspects by leveraging Semantic Web technologies and the systematic reuse of already existing ontologies.},
	language = {en},
	author = {Pasqual, Valentina and Daquino, Marilena and Tomasi, Francesca},
	file = {Pasqual et al. - MIMA a data model to represent multi-disciplinary.pdf:files/508/Pasqual et al. - MIMA a data model to represent multi-disciplinary.pdf:application/pdf},
}

@inproceedings{damiano_exploring_2022,
	address = {New York, NY, USA},
	series = {{UMAP} '22 {Adjunct}},
	title = {Exploring {Values} in {Museum} {Artifacts} in the {SPICE} project: a {Preliminary} {Study}},
	isbn = {978-1-4503-9232-7},
	shorttitle = {Exploring {Values} in {Museum} {Artifacts} in the {SPICE} project},
	url = {https://doi.org/10.1145/3511047.3537662},
	doi = {10.1145/3511047.3537662},
	abstract = {This document describes the rationale, the implementation and a preliminary evaluation of a semantic reasoning tool developed in the EU H2020 SPICE project to enhance the diversity of perspectives experienced by museum visitors. The tool, called DEGARI 2.0 for values, relies on the commonsense reasoning framework , and exploits an ontological model formalizing the Haidt’s theory of moral values to associate museum items with combined values and emotions. Within a museum exhibition, this tool can suggest cultural items that are associated not only with the values of already experienced or preferred objects, but also with novel items with different value stances, opening the visit experience to more inclusive interpretations of cultural content. The system has been preliminarily tested, in the context of the SPICE project, on the collection of the Hecht Museum of Haifa.},
	urldate = {2023-03-12},
	booktitle = {Adjunct {Proceedings} of the 30th {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {Association for Computing Machinery},
	author = {Damiano, Rossana and Kuflik, Tsvi and Wecker, Alan J. and Striani, Manuel and Lieto, Antonio and Bruni, Luis and Kadastik, Nele and Pedersen, Thomas A.},
	month = jul,
	year = {2022},
	keywords = {Commonsense Reasoning, Description Logics, Explainable AI, Moral Foundations Theory, Value recommendations},
	pages = {391--396},
	file = {Full Text PDF:files/555/Damiano et al. - 2022 - Exploring Values in Museum Artifacts in the SPICE .pdf:application/pdf},
}

@article{lieto_degari_2023,
	title = {{DEGARI} 2.0: {A} diversity-seeking, explainable, and affective art recommender for social inclusion},
	volume = {77},
	issn = {1389-0417},
	shorttitle = {{DEGARI} 2.0},
	url = {https://www.sciencedirect.com/science/article/pii/S1389041722000456},
	doi = {10.1016/j.cogsys.2022.10.001},
	abstract = {We present DEGARI 2.0 (Dynamic Emotion Generator And ReclassIfier): an explainable, affective-based, art recommender relying on the commonsense reasoning framework TCL and exploiting an ontological model formalizing the Plutchik’s theory of emotions. The main novelty of this system relies on the development of diversity-seeking affective recommendations obtained by exploiting the spatial structure of the Plutchik’s ‘wheel of emotion’. In particular, such development allows to classify and to suggest, to museum users, cultural items able to evoke not only the very same emotions of already experienced or preferred objects (e.g. within a museum exhibition), but also novel items sharing different emotional stances. The system’s goal, therefore, is to break the filter bubble effect and open the users’ view towards more inclusive and empathy-based interpretations of cultural content. The system has been tested, in the context of the EU H2020 SPICE project, on the community of deaf people and on the collection of the GAM Museum of Turin. We report the results and the lessons learnt concerning both the acceptability and the perceived explainability of the received diversity-seeking recommendations.},
	language = {en},
	urldate = {2023-03-12},
	journal = {Cognitive Systems Research},
	author = {Lieto, Antonio and Pozzato, Gian Luca and Striani, Manuel and Zoia, Stefano and Damiano, Rossana},
	month = jan,
	year = {2023},
	keywords = {Explainable AI, Commonsense reasoning, Description logics, Diversity-seeking emotional recommendations},
	pages = {1--17},
	file = {ScienceDirect Snapshot:files/557/S1389041722000456.html:text/html;Versione inviata:files/558/Lieto et al. - 2023 - DEGARI 2.0 A diversity-seeking, explainable, and .pdf:application/pdf},
}

@inproceedings{gualandi_fare_2022,
	address = {online},
	title = {Fare {Open} {Science} nelle scienze umane},
	copyright = {cc\_by\_4},
	url = {http://amsacta.unibo.it/7049/},
	doi = {10/2022},
	abstract = {Come tradurre nella pratica di ricerca quotidiana i principi della Open Science? Quali strumenti utilizzare per aprire ogni passo del ciclo di ricerca? Lo sentiamo dall’esperienza concreta di due ricercatori di area umanistica che ci raccontano due progetti attualmente in corso: SPICE, incentrato su strumenti e metodi per supportare la citizen curation, e un progetto congiunto di indagine sul concetto di dato nelle Scienze Umane, nell’ottica di perimetrare la gestione FAIR dei dati in queste discipline.},
	language = {it},
	urldate = {2023-03-12},
	author = {Gualandi, Bianca and Peroni, Silvio},
	month = oct,
	year = {2022},
	file = {Full Text PDF:files/560/Gualandi e Peroni - 2022 - Fare Open Science nelle scienze umane.pdf:application/pdf;Snapshot:files/561/7049.html:text/html},
}

@inproceedings{bruni_towards_2020,
	address = {Ischia, Italy},
	title = {Towards {Advanced} {Interfaces} for {Citizen} {Curation}},
	url = {http://avi2ch-20.di.unito.it/index.html},
	abstract = {The SPICE project builds on the growing trend for museums, rather than providing an authoritative view, to present multiple voices related to their collection and exhibitions. In SPICE, an approach we term citizen curation is proposed as a way of supporting visitors to share their own interpretations of museum objects and reflect on the variety of interpretations contributed by others. In order to capture a wide range of voices, interfaces will be designed specifically to engage minority groups that tend to be under-represented in cultural activities. To achieve this goal, the interface will need to be intuitive, aesthetic and accessible for different audiences. The paper presents the challenges we face and initial proposals for engaging visitors in citizen curation.},
	language = {en},
	urldate = {2023-03-12},
	author = {Bruni, Luis Emilio and Daga, Enrico and Damiano, Rossana and Diaz, Lily and Kuflik, Tsvi and Lieto, Antonio and Gangemi, Aldo and Mulholland, Paul and Peroni, Silvio and Pescarin, Sofia and Wecker, Alan},
	month = sep,
	year = {2020},
	file = {Full Text PDF:files/564/Bruni et al. - 2020 - Towards Advanced Interfaces for Citizen Curation.pdf:application/pdf;Snapshot:files/565/72524.html:text/html},
}

@article{garozzo_culto_2017,
	title = {{CULTO}: {AN} {ONTOLOGY}-{BASED} {ANNOTATION} {TOOL} {FOR} {DATA} {CURATION} {INCULTURAL} {HERITAGE}},
	volume = {XLII-2/W5},
	issn = {2194-9034},
	shorttitle = {{CULTO}},
	url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-2-W5/267/2017/},
	doi = {10.5194/isprs-archives-XLII-2-W5-267-2017},
	abstract = {This paper proposes CulTO, a software tool relying on a computational ontology for Cultural Heritage domain modelling, with a specific focus on religious historical buildings, for supporting cultural heritage experts in their investigations. It is specifically thought to support annotation, automatic indexing, classification and curation of photographic data and text documents of historical buildings. CULTO also serves as a useful tool for Historical Building Information Modeling (H-BIM) by enabling semantic 3D data modeling and further enrichment with non-geometrical information of historical buildings through the inclusion of new concepts about historical documents, images, decay or deformation evidence as well as decorative elements into BIM platforms.},
	language = {en},
	urldate = {2023-03-12},
	journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Garozzo, R. and Murabito, F. and Santagati, C. and Pino, C. and Spampinato, C.},
	month = aug,
	year = {2017},
	pages = {267--274},
	file = {Garozzo et al. - 2017 - CULTO AN ONTOLOGY-BASED ANNOTATION TOOL FOR DATA .pdf:files/566/Garozzo et al. - 2017 - CULTO AN ONTOLOGY-BASED ANNOTATION TOOL FOR DATA .pdf:application/pdf},
}

@article{hogan_apollo_2016,
	title = {The {Apollo} {Structured} {Vocabulary}: an {OWL2} ontology of phenomena in infectious disease epidemiology and population biology for use in epidemic simulation},
	volume = {7},
	issn = {2041-1480},
	shorttitle = {The {Apollo} {Structured} {Vocabulary}},
	url = {https://jbiomedsem.biomedcentral.com/articles/10.1186/s13326-016-0092-y},
	doi = {10.1186/s13326-016-0092-y},
	language = {en},
	number = {1},
	urldate = {2023-03-12},
	journal = {Journal of Biomedical Semantics},
	author = {Hogan, William R. and Wagner, Michael M. and Brochhausen, Mathias and Levander, John and Brown, Shawn T. and Millett, Nicholas and DePasse, Jay and Hanna, Josh},
	month = dec,
	year = {2016},
	pages = {50},
	file = {Full text:files/588/Hogan et al. - 2016 - The Apollo Structured Vocabulary an OWL2 ontology.pdf:application/pdf},
}

@article{walls_semantics_2014,
	title = {Semantics in {Support} of {Biodiversity} {Knowledge} {Discovery}: {An} {Introduction} to the {Biological} {Collections} {Ontology} and {Related} {Ontologies}},
	volume = {9},
	issn = {1932-6203},
	shorttitle = {Semantics in {Support} of {Biodiversity} {Knowledge} {Discovery}},
	url = {https://dx.plos.org/10.1371/journal.pone.0089606},
	doi = {10.1371/journal.pone.0089606},
	language = {en},
	number = {3},
	urldate = {2023-03-12},
	journal = {PLoS ONE},
	author = {Walls, Ramona L. and Deck, John and Guralnick, Robert and Baskauf, Steve and Beaman, Reed and Blum, Stanley and Bowers, Shawn and Buttigieg, Pier Luigi and Davies, Neil and Endresen, Dag and Gandolfo, Maria Alejandra and Hanner, Robert and Janning, Alyssa and Krishtalka, Leonard and Matsunaga, Andréa and Midford, Peter and Morrison, Norman and Tuama, Éamonn Ó. and Schildhauer, Mark and Smith, Barry and Stucky, Brian J. and Thomer, Andrea and Wieczorek, John and Whitacre, Jamie and Wooley, John},
	editor = {Bajic, Vladimir B.},
	month = mar,
	year = {2014},
	pages = {e89606},
	file = {Full text:files/589/Walls et al. - 2014 - Semantics in Support of Biodiversity Knowledge Dis.pdf:application/pdf},
}

@article{andreshernandez_knowledge_2020,
	title = {Knowledge representation and data sharing to unlock crop variation for nutritional food security},
	volume = {60},
	issn = {0011-183X, 1435-0653},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/csc2.20092},
	doi = {10.1002/csc2.20092},
	language = {en},
	number = {2},
	urldate = {2023-03-12},
	journal = {Crop Science},
	author = {Andrés‐Hernández, Liliana and Baten, Abdul and Azman Halimi, Razlin and Walls, Ramona and King, Graham J.},
	month = mar,
	year = {2020},
	pages = {516--529},
}

@article{hogan_therapeutic_2017,
	title = {Therapeutic indications and other use-case-driven updates in the drug ontology: anti-malarials, anti-hypertensives, opioid analgesics, and a large term request},
	volume = {8},
	issn = {2041-1480},
	shorttitle = {Therapeutic indications and other use-case-driven updates in the drug ontology},
	url = {https://jbiomedsem.biomedcentral.com/articles/10.1186/s13326-017-0121-5},
	doi = {10.1186/s13326-017-0121-5},
	language = {en},
	number = {1},
	urldate = {2023-03-12},
	journal = {Journal of Biomedical Semantics},
	author = {Hogan, William R. and Hanna, Josh and Hicks, Amanda and Amirova, Samira and Bramblett, Baxter and Diller, Matthew and Enderez, Rodel and Modzelewski, Timothy and Vasconcelos, Mirela and Delcher, Chris},
	month = dec,
	year = {2017},
	pages = {10},
	file = {Full text:files/591/Hogan et al. - 2017 - Therapeutic indications and other use-case-driven .pdf:application/pdf},
}

@article{buttigieg_environment_2013,
	title = {The environment ontology: contextualising biological and biomedical entities},
	volume = {4},
	issn = {2041-1480},
	shorttitle = {The environment ontology},
	url = {http://jbiomedsem.biomedcentral.com/articles/10.1186/2041-1480-4-43},
	doi = {10.1186/2041-1480-4-43},
	language = {en},
	number = {1},
	urldate = {2023-03-12},
	journal = {Journal of Biomedical Semantics},
	author = {Buttigieg, Pier and Morrison, Norman and Smith, Barry and Mungall, Christopher J and Lewis, Suzanna E and {the ENVO Consortium}},
	year = {2013},
	pages = {43},
	file = {Full text:files/592/Buttigieg et al. - 2013 - The environment ontology contextualising biologic.pdf:application/pdf},
}

@article{hur_development_2015,
	title = {Development and application of an interaction network ontology for literature mining of vaccine-associated gene-gene interactions},
	volume = {6},
	issn = {2041-1480},
	url = {http://jbiomedsem.biomedcentral.com/articles/10.1186/2041-1480-6-2},
	doi = {10.1186/2041-1480-6-2},
	language = {en},
	number = {1},
	urldate = {2023-03-12},
	journal = {Journal of Biomedical Semantics},
	author = {Hur, Junguk and Özgür, Arzucan and Xiang, Zuoshuang and He, Yongqun},
	month = dec,
	year = {2015},
	pages = {2},
	file = {Full text:files/594/Hur et al. - 2015 - Development and application of an interaction netw.pdf:application/pdf},
}

@article{leebens-mack_taking_2006,
	title = {Taking the {First} {Steps} towards a {Standard} for {Reporting} on {Phylogenies}: {Minimum} {Information} about a {Phylogenetic} {Analysis} ({MIAPA})},
	volume = {10},
	issn = {1536-2310, 1557-8100},
	shorttitle = {Taking the {First} {Steps} towards a {Standard} for {Reporting} on {Phylogenies}},
	url = {http://www.liebertpub.com/doi/10.1089/omi.2006.10.231},
	doi = {10.1089/omi.2006.10.231},
	language = {en},
	number = {2},
	urldate = {2023-03-12},
	journal = {OMICS: A Journal of Integrative Biology},
	author = {Leebens-Mack, Jim and Vision, Todd and Brenner, Eric and Bowers, John E. and Cannon, Steven and Clement, Mark J. and Cunningham, Clifford W. and DePamphilis, Claude and DeSalle, Rob and Doyle, Jeff J. and Eisen, Jonathan A. and Gu, Xun and Harshman, John and Jansen, Robert K. and Kellogg, Elizabeth A. and Koonin, Eugene V. and Mishler, Brent D. and Philippe, Hervé and Pires, J. Chris and Qiu, Yin-Long and Rhee, Seung Y. and Sjölander, Kimmen and Soltis, Douglas E. and Soltis, Pamela S. and Stevenson, Dennis W. and Wall, Kerr and Warnow, Tandy and Zmasek, Christian},
	month = jun,
	year = {2006},
	pages = {231--237},
	file = {Versione accettata:files/595/Leebens-Mack et al. - 2006 - Taking the First Steps towards a Standard for Repo.pdf:application/pdf},
}

@techreport{stefancsik_ontology_2023,
	type = {preprint},
	title = {The {Ontology} of {Biological} {Attributes} ({OBA}) - {Computational} {Traits} for the {Life} {Sciences}},
	url = {http://biorxiv.org/lookup/doi/10.1101/2023.01.26.525742},
	abstract = {Abstract
          Existing phenotype ontologies were originally developed to represent phenotypes that manifest as a character state in relation to a wild-type or other reference. However, these do not include the phenotypic trait or attribute categories required for the annotation of genome-wide association studies (GWAS), Quantitative Trait Loci (QTL) mappings or any population-focused measurable trait data. Moreover, variations in gene expression in response to environmental disturbances even without any genetic alterations can also be associated with particular biological attributes. The integration of trait and biological attribute information with an ever increasing body of chemical, environmental and biological data greatly facilitates computational analyses and it is also highly relevant to biomedical and clinical applications.
          The Ontology of Biological Attributes (OBA) is a formalised, species-independent collection of interoperable phenotypic trait categories that is intended to fulfil a data integration role. OBA is a standardised representational framework for observable attributes that are characteristics of biological entities, organisms, or parts of organisms. OBA has a modular design which provides several benefits for users and data integrators, including an automated and meaningful classification of trait terms computed on the basis of logical inferences drawn from domain-specific ontologies for cells, anatomical and other relevant entities. The logical axioms in OBA also provide a previously missing bridge that can computationally link Mendelian phenotypes with GWAS and quantitative traits. The term components in OBA provide semantic links and enable knowledge and data integration across specialised research community boundaries, thereby breaking silos.},
	language = {en},
	urldate = {2023-03-12},
	institution = {Bioinformatics},
	author = {Stefancsik, Ray and Balhoff, James P. and Balk, Meghan A. and Ball, Robyn and Bello, Susan M. and Caron, Anita R. and Chessler, Elissa and de Souza, Vinicius and Gehrke, Sarah and Haendel, Melissa and Harris, Laura W. and Harris, Nomi L. and Ibrahim, Arwa and Koehler, Sebastian and Matentzoglu, Nicolas and McMurry, Julie A. and Mungall, Christopher J. and Munoz-Torres, Monica C. and Putman, Tim and Robinson, Peter and Smedley, Damian and Sollis, Elliot and Thessen, Anne E and Vasilevsky, Nicole and Walton, David O. and Osumi-Sutherland, David},
	month = jan,
	year = {2023},
	doi = {10.1101/2023.01.26.525742},
	file = {Full text:files/597/Stefancsik et al. - 2023 - The Ontology of Biological Attributes (OBA) - Comp.pdf:application/pdf},
}

@article{ramirez_spider_2019,
	title = {The {Spider} {Anatomy} {Ontology} ({SPD})—{A} {Versatile} {Tool} to {Link} {Anatomy} with {Cross}-{Disciplinary} {Data}},
	volume = {11},
	issn = {1424-2818},
	url = {https://www.mdpi.com/1424-2818/11/10/202},
	doi = {10.3390/d11100202},
	abstract = {Spiders are a diverse group with a high eco-morphological diversity, which complicates anatomical descriptions especially with regard to its terminology. New terms are constantly proposed, and definitions and limits of anatomical concepts are regularly updated. Therefore, it is often challenging to find the correct terms, even for trained scientists, especially when the terminology has obstacles such as synonyms, disputed definitions, ambiguities, or homonyms. Here, we present the Spider Anatomy Ontology (SPD), which we developed combining the functionality of a glossary (a controlled defined vocabulary) with a network of formalized relations between terms that can be used to compute inferences. The SPD follows the guidelines of the Open Biomedical Ontologies and is available through the NCBO BioPortal (ver. 1.1). It constitutes of 757 valid terms and definitions, is rooted with the Common Anatomy Reference Ontology (CARO), and has cross references to other ontologies, especially of arthropods. The SPD offers a wealth of anatomical knowledge that can be used as a resource for any scientific study as, for example, to link images to phylogenetic datasets, compute structural complexity over phylogenies, and produce ancestral ontologies. By using a common reference in a standardized way, the SPD will help bridge diverse disciplines, such as genomics, taxonomy, systematics, evolution, ecology, and behavior.},
	language = {en},
	number = {10},
	urldate = {2023-03-12},
	journal = {Diversity},
	author = {Ramírez, Martín J. and Michalik, Peter},
	month = oct,
	year = {2019},
	pages = {202},
	file = {Full text:files/599/Ramírez e Michalik - 2019 - The Spider Anatomy Ontology (SPD)—A Versatile Tool.pdf:application/pdf},
}

@article{midford_vertebrate_2013,
	title = {The vertebrate taxonomy ontology: a framework for reasoning across model organism and species phenotypes},
	volume = {4},
	issn = {2041-1480},
	shorttitle = {The vertebrate taxonomy ontology},
	url = {https://jbiomedsem.biomedcentral.com/articles/10.1186/2041-1480-4-34},
	doi = {10.1186/2041-1480-4-34},
	abstract = {Abstract
            
              Background
              A hierarchical taxonomy of organisms is a prerequisite for semantic integration of biodiversity data. Ideally, there would be a single, expansive, authoritative taxonomy that includes extinct and extant taxa, information on synonyms and common names, and monophyletic supraspecific taxa that reflect our current understanding of phylogenetic relationships.
            
            
              Description
              As a step towards development of such a resource, and to enable large-scale integration of phenotypic data across vertebrates, we created the Vertebrate Taxonomy Ontology (VTO), a semantically defined taxonomic resource derived from the integration of existing taxonomic compilations, and freely distributed under a Creative Commons Zero (CC0) public domain waiver. The VTO includes both extant and extinct vertebrates and currently contains 106,947 taxonomic terms, 22 taxonomic ranks, 104,736 synonyms, and 162,400 cross-references to other taxonomic resources. Key challenges in constructing the VTO included (1) extracting and merging names, synonyms, and identifiers from heterogeneous sources; (2) structuring hierarchies of terms based on evolutionary relationships and the principle of monophyly; and (3) automating this process as much as possible to accommodate updates in source taxonomies.
            
            
              Conclusions
              
                The VTO is the primary source of taxonomic information used by the Phenoscape Knowledgebase (
                http://phenoscape.org/
                ), which integrates genetic and evolutionary phenotype data across both model and non-model vertebrates. The VTO is useful for inferring phenotypic changes on the vertebrate tree of life, which enables queries for candidate genes for various episodes in vertebrate evolution.},
	language = {en},
	number = {1},
	urldate = {2023-03-12},
	journal = {Journal of Biomedical Semantics},
	author = {Midford, Peter E and Dececchi, Thomas Alex and Balhoff, James P and Dahdul, Wasila M and Ibrahim, Nizar and Lapp, Hilmar and Lundberg, John G and Mabee, Paula M and Sereno, Paul C and Westerfield, Monte and Vision, Todd J and Blackburn, David C},
	month = dec,
	year = {2013},
	pages = {34},
	file = {Full text:files/600/Midford et al. - 2013 - The vertebrate taxonomy ontology a framework for .pdf:application/pdf},
}

@article{midford_teleost_2010,
	title = {The {Teleost} {Taxonomy} {Ontology}},
	issn = {1756-0357},
	url = {https://www.nature.com/articles/npre.2010.4629.1},
	doi = {10.1038/npre.2010.4629.1},
	abstract = {Abstract
            
              The Teleost Taxonomy Ontology (TTO) is an ontology of taxonomic groups and associated names for fish (not just teleosts). This ontology has served as a source of names and taxonomic structure within the Phenoscape project since early 2008. Although the TTO is based on Eschmeyer's Catalog of Fishes (CoF) and incorporates all valid species and genus names, it is also extended by the curation needs of the Phenoscape project. Names of fossil taxa not included in the CoF as well as references to specimens identi*ed only to genus (e.g.,
              Eigenmannia sp.
              (Fink and Fink 1981)) are incorporated into the TTO as required by the curation needs of the Phenoscape project. As Phenoscape receives updates to the CoF, a tool called TTOUpdate merges the changes into the TTO.},
	language = {en},
	urldate = {2023-03-12},
	journal = {Nature Precedings},
	author = {Midford, Peter and Balhoff, James and Dahdul, Wasila and Kothari, Cartik and Lapp, Hilmar and Lundberg, John and Mabee, Paula and Vision, Todd and Westerfield, Monte},
	month = jul,
	year = {2010},
	file = {Full text:files/601/Midford et al. - 2010 - The Teleost Taxonomy Ontology.pdf:application/pdf},
}

@techreport{molloy_laura_eosc_2021,
	title = {{EOSC} {Co}-creation funded project 074: {Delivery} of a proof of concept for {terms4FAIRskills}: {Technical} report},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	shorttitle = {{EOSC} {Co}-creation funded project 074},
	url = {https://zenodo.org/record/4705219},
	abstract = {This report sets out the aims, activities and outputs of EOSC Co-creation funded project 074, 'Delivery of a proof of concept for terms4FAIRskills', which developed a proof of concept version of a terminology for describing the knowledge and skills for making and keeping data FAIR. This activity has been produced with the support of EOSCSecretariat.eu, which has received funding from the European Union's Horizon Programme call H2020-INFRAEOSC-2018-4, Grant Agreement number 831644.},
	language = {en},
	urldate = {2023-03-12},
	institution = {Zenodo},
	author = {Molloy, Laura and McQuilton, Peter and Le Franc, Yann},
	month = mar,
	year = {2021},
	doi = {10.5281/ZENODO.4705219},
	note = {Version Number: 1.0.0},
	keywords = {FAIR data, ontology development, skills development, terminology development},
}

@article{malone_software_2014,
	title = {The {Software} {Ontology} ({SWO}): a resource for reproducibility in biomedical data analysis, curation and digital preservation},
	volume = {5},
	issn = {2041-1480},
	shorttitle = {The {Software} {Ontology} ({SWO})},
	url = {https://doi.org/10.1186/2041-1480-5-25},
	doi = {10.1186/2041-1480-5-25},
	abstract = {Biomedical ontologists to date have concentrated on ontological descriptions of biomedical entities such as gene products and their attributes, phenotypes and so on. Recently, effort has diversified to descriptions of the laboratory investigations by which these entities were produced. However, much biological insight is gained from the analysis of the data produced from these investigations, and there is a lack of adequate descriptions of the wide range of software that are central to bioinformatics. We need to describe how data are analyzed for discovery, audit trails, provenance and reproducibility.},
	number = {1},
	urldate = {2023-03-12},
	journal = {Journal of Biomedical Semantics},
	author = {Malone, James and Brown, Andy and Lister, Allyson L. and Ison, Jon and Hull, Duncan and Parkinson, Helen and Stevens, Robert},
	month = jun,
	year = {2014},
	keywords = {Ontology Engineering, Biomedical Ontology, Ontology Development, Software License, User Story},
	pages = {25},
	file = {Full Text PDF:files/604/Malone et al. - 2014 - The Software Ontology (SWO) a resource for reprod.pdf:application/pdf;Snapshot:files/605/2041-1480-5-25.html:text/html},
}

@article{mulholland_enabling_2020,
	title = {Enabling {Multiple} {Voices} in the {Museum}: {Challenges} and {Approaches}},
	volume = {6},
	issn = {2364-2122},
	shorttitle = {Enabling {Multiple} {Voices} in the {Museum}},
	url = {https://www.degruyter.com/document/doi/10.14361/dcs-2020-0213/html},
	doi = {10.14361/dcs-2020-0213},
	abstract = {Article Enabling Multiple Voices in the Museum: Challenges and Approaches was published on December 1, 2020 in the journal Digital Culture \& Society (volume 6, issue 2).},
	language = {en},
	number = {2},
	urldate = {2023-03-12},
	journal = {Digital Culture \& Society},
	author = {Mulholland, Paul and Daga, Enrico and Daquino, Marilena and Díaz-Kommonen, Lily and Gangemi, Aldo and Kulfik, Tsvi and Wecker, Alan J. and Maguire, Mark and Peroni, Silvio and Pescarin, Sofia},
	month = dec,
	year = {2020},
	note = {Publisher: transcript Verlag},
	pages = {259--266},
	file = {Versione accettata:files/607/Mulholland et al. - 2020 - Enabling Multiple Voices in the Museum Challenges.pdf:application/pdf},
}

@article{daga_integrating_2022,
	title = {Integrating {Citizen} {Experiences} in {Cultural} {Heritage} {Archives}: {Requirements}, {State} of the {Art}, and {Challenges}},
	volume = {15},
	issn = {1556-4673},
	shorttitle = {Integrating {Citizen} {Experiences} in {Cultural} {Heritage} {Archives}},
	url = {https://doi.org/10.1145/3477599},
	doi = {10.1145/3477599},
	abstract = {Digital archives of memory institutions are typically concerned with the cataloguing of artefacts of artistic, historical, and cultural value. Recently, new forms of citizen participation in cultural heritage have emerged, producing a wealth of material spanning from visitors’ experiential feedback on exhibitions and cultural artefacts to digitally mediated interactions like the ones happening on social media platforms. Citizen curation is proposed in the context of the European project SPICE (Social Participation, Cohesion, and Inclusion through Cultural Engagement) as a methodology for producing, collecting, interpreting, and archiving people’s responses to cultural objects, with the aim of favouring the emergence of multiple, sometimes conflicting, viewpoints and motivating users and memory institutions to reflect upon them. We argue that citizen curation urges to rethink the nature of computational infrastructures supporting data management of memory institutions, bringing novel challenges that include issues of distribution, authoritativeness, interdependence, privacy, and rights management. To approach these issues, we survey relevant literature toward a distributed, Linked Data infrastructure, with a focus on identifying the roles and requirements involved in such an infrastructure. We show how existing research can contribute significantly in facing the challenges raised by citizen curation and discuss challenges and opportunities from the socio-technical standpoint.},
	number = {1},
	urldate = {2023-03-12},
	journal = {Journal on Computing and Cultural Heritage},
	author = {Daga, Enrico and Asprino, Luigi and Damiano, Rossana and Daquino, Marilena and Agudo, Belen Diaz and Gangemi, Aldo and Kuflik, Tsvi and Lieto, Antonio and Maguire, Mark and Marras, Anna Maria and Pandiani, Delfina Martinez and Mulholland, Paul and Peroni, Silvio and Pescarin, Sofia and Wecker, Alan},
	month = jan,
	year = {2022},
	keywords = {semantic web, Cultural heritage, citizen curation},
	pages = {11:1--11:35},
	file = {Full text:files/609/Daga et al. - 2022 - Integrating Citizen Experiences in Cultural Herita.pdf:application/pdf},
}

@article{ceccaroni_opportunities_2019,
	title = {Opportunities and {Risks} for {Citizen} {Science} in the {Age} of {Artificial} {Intelligence}},
	volume = {4},
	issn = {2057-4991},
	url = {http://theoryandpractice.citizenscienceassociation.org/articles/10.5334/cstp.241/},
	doi = {10.5334/cstp.241},
	language = {en},
	number = {1},
	urldate = {2023-03-12},
	journal = {Citizen Science: Theory and Practice},
	author = {Ceccaroni, Luigi and Bibby, James and Roger, Erin and Flemons, Paul and Michael, Katina and Fagan, Laura and Oliver, Jessica L.},
	month = nov,
	year = {2019},
	pages = {29},
	file = {Ceccaroni et al. - 2019 - Opportunities and Risks for Citizen Science in the.pdf:files/610/Ceccaroni et al. - 2019 - Opportunities and Risks for Citizen Science in the.pdf:application/pdf},
}

@article{eitzel_citizen_2017,
	title = {Citizen {Science} {Terminology} {Matters}: {Exploring} {Key} {Terms}},
	copyright = {cc\_by},
	issn = {2057-4991},
	shorttitle = {Citizen {Science} {Terminology} {Matters}},
	url = {https://eprints.whiterose.ac.uk/117418/},
	abstract = {Much can be at stake depending on the choice of words used to describe citizen science, because terminology impacts how knowledge is developed. Citizen science is a quickly evolving field that is mobilizing people’s involvement in information development, social action and justice, and large-scale information gathering. Currently, a wide variety of terms and expressions are being used to refer to the concept of ‘citizen science’ and its practitioners. Here, we explore these terms to help provide guidance for the future growth of this field. We do this by reviewing the theoretical, historical, geopolitical, and disciplinary context of citizen science terminology; discussing what citizen science is and reviewing related terms; and providing a collection of potential terms and definitions for ‘citizen science’ and people participating in citizen science projects. This collection of terms was generated primarily from the broad knowledge base and on-the-ground experience of the authors, by recognizing the potential issues associated with various terms. While our examples may not be systematic or exhaustive, they are intended to be suggestive and invitational of future consideration. In our collective experience with citizen science projects, no single term is appropriate for all contexts. In a given citizen science project, we suggest that terms should be chosen carefully and their usage explained; direct communication with participants about how terminology affects them and what they would prefer to be called also should occur. We further recommend that a more systematic study of terminology trends in citizen science be conducted.},
	language = {en},
	urldate = {2023-03-12},
	journal = {Citizen Science: Theory and Practice},
	author = {Eitzel, Melissa and Cappadonna, Jessica and Santos-Lang, Chris and Duerr, Ruth and West, Sarah Elizabeth and Virapongse, Arika and Kyba, Christopher and Bowser, Anne and Cooper, Caren and Sforzi, Andrea and Metcalfe, Anya and Harris, Edward and Thiel, Martin and Haklay, Mordechai and Ponciano, Lesandro and Roche, Joseph and Ceccaroni, Luidi and Shilling, Fraser and Dorler, Daniel and Heigl, Florian and Kiessling, Tim and Davis, Brittany and Jiang, Qijun},
	month = jun,
	year = {2017},
	note = {Num Pages: 20
Publisher: York},
	pages = {1--20},
	file = {Full Text PDF:files/613/Eitzel et al. - 2017 - Citizen Science Terminology Matters Exploring Key.pdf:application/pdf;Snapshot:files/614/117418.html:text/html},
}

@article{higgins_citizen_2016,
	title = {Citizen {OBservatory} {WEB} ({COBWEB}): {A} {Generic} {Infrastructure} {Platform} to {Facilitate} the {Collection} of {Citizen} {Science} data for {Environmental} {Monitoring}},
	volume = {11},
	copyright = {\#\#submission.copyrightStatement\#\#},
	issn = {1725-0463},
	shorttitle = {Citizen {OBservatory} {WEB} ({COBWEB})},
	url = {https://ijsdir.sadl.kuleuven.be/index.php/ijsdir/article/view/406},
	doi = {10.2902/ijsdir.v11i0.406},
	abstract = {The mass uptake of internet connected, GPS enabled mobile devices has resulted in a surge of citizens active in making a huge variety of environmental observations.  The use and reuse potential of these data is significant but currently compromised by a lack of interoperability.  Useable standards either don’t exist, are neglected, poorly understood or tooling is unavailable.  Large volumes of data are being created but exist in silos.  This is a complex problem requiring sophisticated solutions balanced with the need to present sometimes unsophisticated users with comprehensible and useable software.  COBWEB has addressed this challenge by using the UNESCO World Network of Biosphere Reserves as a testbed for researching and developing a generic crowdsourcing infrastructure platform for environmental monitoring.   The solution arrived at provides tools for the creation of mobile Applications which generate data compliant with open interoperability standards and facilitate integration with Spatial Data Infrastructures.  COBWEB is a research project and the components of the COBWEB platform are at different Technology Readiness Levels. This paper outlines how the overall solution was arrived at, describes the main components developed and points to quality assurance, integration of sensors, interoperability and associated standardisation as key areas requiring further attention.},
	language = {en},
	number = {0},
	urldate = {2023-03-12},
	journal = {International Journal of Spatial Data Infrastructures Research},
	author = {Higgins, Christopher Iain and Williams, Jamie and Leibovici, Didier G. and Simonis, Ingo and Davis, Mason J. and Muldoon, Conor and Genuchten, Paul van and O'Hare, Gregory and Wiemann, Stefan},
	month = jun,
	year = {2016},
	note = {Number: 0},
	keywords = {semantics, interoperability, access control, biological monitoring, citizen science, crowdsourcing, environmental governance, Open Geospatial Consortium, privacy, sensors, spatial data infrastructure, standards},
	file = {Full Text PDF:files/616/Higgins et al. - 2016 - Citizen OBservatory WEB (COBWEB) A Generic Infras.pdf:application/pdf},
}

@article{milchev_ontological_2022,
	title = {An ontological model to support citizen science in the field of invasive species research},
	volume = {9},
	url = {https://sciendo.com/article/10.2478/asn-2022-0003},
	doi = {10.2478/asn-2022-0003},
	abstract = {Abstract
Advances in information technology developments have led to improved ways and means of sharing information and good practices in various areas of social development. Providing the necessary tools enables Citizen Sciences (CS) to play an important role in raising awareness and engaging various stakeholders in the prevention of invasive alien species (IAS). In Bulgaria, up until this point, it is poorly developed, and this is largely due to the lack of information to the general public regarding the categorization of species, pathways of introduction and their negative impact. The article examines the possibilities for introduction and use of an advanced ontological model in the area of invasive alien species research, which will aid the process of involving a wide range of stakeholders in various initiatives that will contribute to preventing the introduction and spread of IAS. The researched approach using the advantages of modern information and communication technologies includes acquaintance with the basic concepts in the area of IAS, the processes related to their introduction and spread, as well as taking into account the existing interrelationships, which would provide opportunities for early detection and the rapid eradication of IAS. The developed model will also be applied to measures and policies},
	language = {en},
	number = {1},
	urldate = {2023-03-12},
	journal = {Acta Scientifica Naturalis},
	author = {Milchev, Radoslav and Milchev, Galin and Tomov, Rumen},
	month = mar,
	year = {2022},
	pages = {23--32},
	file = {Full Text PDF:files/618/Milchev et al. - 2022 - An ontological model to support citizen science in.pdf:application/pdf},
}

@misc{frimpong_design_2018,
	type = {info:eu-repo/semantics/{masterThesis}},
	title = {The design and prototyping of an ontology for integrating citizen science datasets},
	url = {http://essay.utwente.nl/85865/},
	abstract = {Citizen Science is an approach to science that uses the general public in conducting scientific studies about a phenomenon or an occurrence in nature. Citizen Science makes room for the general public to measure, map and record occurrences of events on the earth's surface. These activities generate the various data and information. Most importantly, natural and environmentaldatasets resulting from Citizen Science projects have  several  qualities  which  can  be  used  to  increase  scientific  knowledge  and  to  aid  in  the  scientific knowledge discovery. Therefore, different efforts have been made to use such information. It is evidentthat potential knowledge and information can be obtainedthrough the integration of the different datasets from the different citizen science programs. The integration of these datasets is mostly a challenge due to non-interoperability and incompatibilityamong the different datasets. These challenges most often come from semi-structured  heterogeneous  data  sources. An  essential  requirement  for  Citizen  Science  communities appears to be a standard medium to manage the generated data and allow to integrate these datasets with other datasets for sharing and reuse. This research seeks to propose a solution for solving and managing the non-interoperability and  incompatibility among Citizen Science datasetsby building an  ontology for data integration in Citizen Science. The design of the citizen science ontology for data integration was developedby  the  fusion  of  the IEEE  standard for software  development  and  the  Generic  Ontology  Development Framework.  The  ontology  was  built  using  both  spatial  and non-spatialrelations  in  Citizen  Science  for mapping  concepts  and  knowledge.  It  was  finally  implemented  in  an  OWL  format.  The  Citizen  Science ontology serves as a surrogate for structuring and modelling different datasets to have a commonstructure to make them compatibleand interoperable. The designed ontology was used to model different datasets in Citizen Science using the Karma Data Integration tool. The modelled and combined dataset was tested using SPARQL  for  the  different  information  contained  in  the  different  datasets.  The  results  proved  that  the ontology is a potential tool for modelling and transforming different datasets to make them compatible with each other in the Citizen Science domain.},
	language = {en},
	urldate = {2023-03-12},
	author = {Frimpong, Joseph Yaw},
	month = feb,
	year = {2018},
	note = {Publisher: University of Twente},
}

@article{haller_modular_2019,
	title = {The modular {SSN} ontology: {A} joint {W3C} and {OGC} standard specifying the semantics of sensors, observations, sampling, and actuation},
	volume = {10},
	issn = {1570-0844},
	shorttitle = {The modular {SSN} ontology},
	url = {https://content.iospress.com/articles/semantic-web/sw320},
	doi = {10.3233/SW-180320},
	abstract = {The joint W3C (World Wide Web Consortium) and OGC (Open Geospatial Consortium) Spatial Data on the Web (SDW) Working Group developed a set of ontologies to describe sensors, actuators, samplers as well as their observations, actuation, and sampling a},
	language = {en},
	number = {1},
	urldate = {2023-03-12},
	journal = {Semantic Web},
	author = {Haller, Armin and Janowicz, Krzysztof and Cox, Simon J. D. and Lefrançois, Maxime and Taylor, Kerry and Le Phuoc, Danh and Lieberman, Joshua and García-Castro, Raúl and Atkinson, Rob and Stadler, Claus},
	month = jan,
	year = {2019},
	note = {Publisher: IOS Press},
	pages = {9--32},
	file = {Full text:files/621/Haller et al. - 2019 - The modular SSN ontology A joint W3C and OGC stan.pdf:application/pdf},
}

@inproceedings{daquino_historical_2015,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Historical {Context} {Ontology} ({HiCO}): {A} {Conceptual} {Model} for {Describing} {Context} {Information} of {Cultural} {Heritage} {Objects}},
	isbn = {978-3-319-24129-6},
	shorttitle = {Historical {Context} {Ontology} ({HiCO})},
	doi = {10.1007/978-3-319-24129-6_37},
	abstract = {Communities addressing the problem of a shareable description of cultural heritage objects agree that a data-centric and context oriented approach should be reached in order to exchange and reuse heterogenous information. Here we present HiCO, an OWL 2 DL ontology aiming to outline relevant issues related to the workflow for stating, and formalizing, authoritative assertions about context information. The conceptual model outlines requirements for defining an authoritative statement and focuses on how a description of context information can be carried out when data are extracted from full-text of documents.},
	language = {en},
	booktitle = {Metadata and {Semantics} {Research}},
	publisher = {Springer International Publishing},
	author = {Daquino, Marilena and Tomasi, Francesca},
	editor = {Garoufallou, Emmanouel and Hartley, Richard J. and Gaitanou, Panorea},
	year = {2015},
	keywords = {Linked Open Data, Authoritativeness, FRBR, Scholarly editions, TEI},
	pages = {424--436},
}

@article{daquino_creating_2022,
	title = {Creating {RESTful} {APIs} over {SPARQL} endpoints using {RAMOSE}},
	volume = {13},
	issn = {1570-0844},
	url = {https://content.iospress.com/articles/semantic-web/sw210439},
	doi = {10.3233/SW-210439},
	abstract = {Semantic Web technologies are widely used for storing RDF data and making them available on the Web through SPARQL endpoints, queryable using the SPARQL query language. While the use of SPARQL endpoints is strongly supported by Semantic Web experts,},
	language = {en},
	number = {2},
	urldate = {2023-03-12},
	journal = {Semantic Web},
	author = {Daquino, Marilena and Heibi, Ivan and Peroni, Silvio and Shotton, David},
	month = jan,
	year = {2022},
	note = {Publisher: IOS Press},
	pages = {195--213},
	file = {Full Text PDF:files/624/Daquino et al. - 2022 - Creating RESTful APIs over SPARQL endpoints using .pdf:application/pdf},
}

@misc{daquino_clef_2022,
	title = {{CLEF}. {A} {Linked} {Open} {Data} native system for {Crowdsourcing}},
	url = {http://arxiv.org/abs/2206.08259},
	doi = {10.48550/arXiv.2206.08259},
	abstract = {Collaborative data collection initiatives are increasingly becoming pivotal to cultural institutions and scholars, to boost the population of born-digital archives. For over a decade, organisations have been leveraging Semantic Web technologies to design their workflows, ensure data quality, and a means for sharing and reusing (Linked Data). Crucially, scholarly projects that leverage cultural heritage data to collaboratively develop new resources would benefit from agile solutions to simplify the Linked Data production workflow via user-friendly interfaces. To date, only a few pioneers have abandoned legacy cataloguing and archiving systems to fully embrace the Linked Open Data (LOD) paradigm and manage their catalogues or research products through LOD-native management systems. In this article we present Crowdsourcing Linked Entities via web Form (CLEF), an agile LOD-native platform for collaborative data collection, peer-review, and publication. We detail design choices as motivated by two case studies, from the Cultural Heritage and scholarly domains respectively, and we discuss benefits of our solution in the light of prior works. In particular, the strong focus on user-friendly interfaces for producing FAIR data, the provenance-aware editorial process, and the integration with consolidated data management workflows, distinguish CLEF as a novel attempt to develop Linked Data platforms for cultural heritage.},
	urldate = {2023-03-12},
	publisher = {arXiv},
	author = {Daquino, Marilena and Wigham, Mari and Daga, Enrico and Giagnolini, Lucia and Tomasi, Francesca},
	month = jun,
	year = {2022},
	note = {arXiv:2206.08259 [cs]},
	keywords = {Computer Science - Digital Libraries},
	file = {arXiv Fulltext PDF:files/626/Daquino et al. - 2022 - CLEF. A Linked Open Data native system for Crowdso.pdf:application/pdf;arXiv.org Snapshot:files/627/2206.html:text/html},
}

@article{hu_metadata_2015,
	title = {Metadata {Topic} {Harmonization} and {Semantic} {Search} for {Linked}-{Data}-{Driven} {Geoportals}: {A} {Case} {Study} {Using} {ArcGIS} {Online}},
	volume = {19},
	issn = {1467-9671},
	shorttitle = {Metadata {Topic} {Harmonization} and {Semantic} {Search} for {Linked}-{Data}-{Driven} {Geoportals}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tgis.12151},
	doi = {10.1111/tgis.12151},
	abstract = {Geoportals provide integrated access to geospatial resources, and enable both authorities and the general public to contribute and share data and services. An essential goal of geoportals is to facilitate the discovery of the available resources. Such a process relies heavily on the quality of metadata. While multiple metadata standards have been established, data contributers may adopt different standards when sharing their data via the same geoportal. This is especially the case for user-generated content where various terms and topics can be introduced to describe similar datasets. While this heterogeneity provides a wealth of perspectives, it also complicates resource discovery. With the fast development of the Semantic Web technologies, there is a rise of Linked-Data-driven portals. Although these novel portals open up new ways to organize metadata and retrieve resources, they lack effective semantic search methods. This article addresses the two challenges discussed above, namely the topic heterogeneity brought by multiple metadata standards and the lack of established semantic search in Linked-Data-driven geoportals. To harmonize the metadata topics, we employ a natural language processing method, namely Labeled Latent Dirichlet Allocation (LLDA), and train it using standardized metadata from Data.gov. With respect to semantic search, we construct thematic and geographic matching features from the textual metadata descriptions, and train a regression model via a human participants experiment. We evaluate our methods by examining their performances in addressing the two issues. Finally, we implement a semantics-enabled and Linked-Data-driven prototypical geoportal using a sample dataset from Esri's ArcGIS Online.},
	language = {en},
	number = {3},
	urldate = {2023-03-12},
	journal = {Transactions in GIS},
	author = {Hu, Yingjie and Janowicz, Krzysztof and Prasad, Sathya and Gao, Song},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/tgis.12151},
	pages = {398--416},
	file = {Snapshot:files/639/tgis.html:text/html;Versione inviata:files/643/Hu et al. - 2015 - Metadata Topic Harmonization and Semantic Search f.pdf:application/pdf},
}

@article{hor_design_2021,
	title = {{DESIGN} {AND} {EVALUATION} {OF} {A} {BIM}-{GIS} {INTEGRATED} {INFORMATION} {MODEL} {USING} {RDF} {GRAPH} {DATABASE}},
	volume = {VIII-4/W2-2021},
	issn = {2194-9050},
	url = {https://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/VIII-4-W2-2021/175/2021/},
	doi = {10.5194/isprs-annals-VIII-4-W2-2021-175-2021},
	abstract = {The semantic integration modeling of BIM industry foundations classes and GIS City-geographic markup language are a milestone for many applications that involve both domains of knowledge. In this paper, we propose a system design architecture, and implementation of Extraction, Transformation and Loading (ETL) workflows of BIM and GIS model into RDF graph database model, these workflows were created from functional components and ontological frameworks supporting RDF SPARQL and graph databases Cypher query languages. This paper is about full understanding of whether RDF graph database is suitable for a BIM-GIS integrated information model, and it looks deeper into the assessment of translation workflows and evaluating performance metrics of a BIM-GIS integrated data model managed in an RDF graph database, the process requires designing and developing various pipelines of workflows with semantic tools in order to get the data and its structure into an appropriate format and demonstrate the potential of using RDF graph databases to integrate, manage and analyze information and relationships from both GIS and BIM models, the study also has introduced the concepts of Graph-Model occupancy indexes of nodes, attributes and relationships to measure queries outputs and giving insights on data richness and performance of the resulting BIM-GIS semantically integrated model.},
	language = {en},
	urldate = {2023-03-12},
	journal = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Hor, A.-H. and Sohn, G.},
	month = oct,
	year = {2021},
	pages = {175--182},
	file = {Hor e Sohn - 2021 - DESIGN AND EVALUATION OF A BIM-GIS INTEGRATED INFO.pdf:files/640/Hor e Sohn - 2021 - DESIGN AND EVALUATION OF A BIM-GIS INTEGRATED INFO.pdf:application/pdf},
}

@article{patroumpas_triplegeo_nodate,
	title = {{TripleGeo}: an {ETL} {Tool} for {Transforming} {Geospatial} {Data} into {RDF} {Triples}},
	abstract = {Integrating data from heterogeneous sources has led to the development of Extract-Transform-Load (ETL) systems and methodologies, as a means of addressing modern interoperability challenges. A few such tools have been available for converting between geospatial formats, but none speciﬁcally addressing the emerging needs of geospatially-enabled RDF stores. In this paper, we introduce TripleGeo, an open-source ETL utility that can extract geospatial features from various sources and transform them into triples for subsequent loading into RDF stores. TripleGeo can directly access both geometric representations and thematic attributes either from standard geographic formats or widely used DBMSs. It can also reproject input geometries on-the-ﬂy into a different Coordinate Reference System, before exporting the resulting triples into a variety of notations. Most importantly, TripleGeo supports the recent GeoSPARQL standard endorsed by the Open GeoSpatial Consortium, although it can extract geometries into other vocabularies as well. This tool has been validated against OpenStreetMap layers with millions of geometries, opening up perspectives to add more functionality and to address much bigger data volumes.},
	language = {en},
	author = {Patroumpas, Kostas and Alexakis, Michalis and Giannopoulos, Giorgos and Athanasiou, Spiros},
	file = {Patroumpas et al. - TripleGeo an ETL Tool for Transforming Geospatial.pdf:files/642/Patroumpas et al. - TripleGeo an ETL Tool for Transforming Geospatial.pdf:application/pdf},
}

@article{kyzirakos_geotriples_2018,
	title = {{GeoTriples}: {Transforming} geospatial data into {RDF} graphs using {R2RML} and {RML} mappings},
	volume = {52-53},
	issn = {1570-8268},
	shorttitle = {{GeoTriples}},
	url = {https://www.sciencedirect.com/science/article/pii/S1570826818300428},
	doi = {10.1016/j.websem.2018.08.003},
	abstract = {A lot of geospatial data has become available at no charge in many countries recently. Geospatial data that is currently made available by government agencies usually do not follow the linked data paradigm. In the few cases where government agencies do follow the linked data paradigm (e.g., Ordnance Survey in the United Kingdom), specialized scripts have been used for transforming geospatial data into RDF. In this paper we present the open source tool GeoTriples which generates and processes extended R2RML and RML mappings that transform geospatial data from many input formats into RDF. GeoTriples allows the transformation of geospatial data stored in raw files (shapefiles, CSV, KML, XML, GML and GeoJSON) and spatially-enabled RDBMS (PostGIS and MonetDB) into RDF graphs using well-known vocabularies like GeoSPARQL and stSPARQL, but without being tightly coupled to a specific vocabulary. GeoTriples has been developed in European projects LEO and Melodies and has been used to transform many geospatial data sources into linked data. We study the performance of GeoTriples experimentally using large publicly available geospatial datasets, and show that GeoTriples is very efficient and scalable especially when its mapping processor is implemented using Apache Hadoop.},
	language = {en},
	urldate = {2023-03-12},
	journal = {Journal of Web Semantics},
	author = {Kyzirakos, Kostis and Savva, Dimitrianos and Vlachopoulos, Ioannis and Vasileiou, Alexandros and Karalis, Nikolaos and Koubarakis, Manolis and Manegold, Stefan},
	month = oct,
	year = {2018},
	pages = {16--32},
	file = {Full text:files/647/Kyzirakos et al. - 2018 - GeoTriples Transforming geospatial data into RDF .pdf:application/pdf;ScienceDirect Snapshot:files/646/S1570826818300428.html:text/html},
}

@inproceedings{peroni_simplified_2017,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Simplified} {Agile} {Methodology} for {Ontology} {Development}},
	isbn = {978-3-319-54627-8},
	doi = {10.1007/978-3-319-54627-8_5},
	abstract = {In this paper we introduce SAMOD, a.k.a. Simplified Agile Methodology for Ontology Development, a novel agile methodology for the development of ontologies by means of small steps of an iterative workflow that focuses on creating well-developed and documented models starting from exemplar domain descriptions. In addition, we discuss the results of an experiment where we asked nine people (with no or limited expertise in Semantic Web technologies and Ontology Engineering) to use SAMOD for developing a small ontology.},
	language = {en},
	booktitle = {{OWL}: {Experiences} and {Directions} – {Reasoner} {Evaluation}},
	publisher = {Springer International Publishing},
	author = {Peroni, Silvio},
	editor = {Dragoni, Mauro and Poveda-Villalón, María and Jimenez-Ruiz, Ernesto},
	year = {2017},
	keywords = {Agile ontology development methodology, Conceptual modelling, Knowledge engineering, Ontology engineering, OWL Ontologies, SAMOD, Test-driven development},
	pages = {55--69},
}

@misc{noauthor_poster-template-horizontal-1-purringtonjpg_nodate,
	title = {poster-template-horizontal-1-purrington.jpg (1200×750)},
	url = {https://colinpurrington.com/wp-content/uploads/2019/06/poster-template-horizontal-1-purrington.jpg},
	urldate = {2023-03-13},
	file = {poster-template-horizontal-1-purrington.jpg (1200×750):files/720/poster-template-horizontal-1-purrington.html:text/html},
}

@misc{noauthor_poster_nodate,
	title = {Poster {Session} {Tips}},
	url = {http://www.personal.psu.edu/drs18/postershow/},
	urldate = {2023-03-13},
}

@inproceedings{dandrea_3d-icons_2013,
	title = {{3D}-{ICONS} {METADATA} {SCHEMA} {FOR} {3D} {OBJECTS}},
	url = {https://www.semanticscholar.org/paper/3D-ICONS-METADATA-SCHEMA-FOR-3D-OBJECTS-D%27Andrea-Fernie/e1fd7114f7275ae08fb49f2b15218d2b4cfe8b85},
	abstract = {Semantic Scholar extracted view of "3D-ICONS METADATA SCHEMA FOR 3D OBJECTS" by Andrea D'Andrea et al.},
	urldate = {2023-03-13},
	author = {D'Andrea, Andrea and Fernie, K.},
	year = {2013},
}

@article{dandrea_3d-icons_nodate,
	title = {{3D}-{ICONS}: oggetti digitali archeologici {3D}},
	abstract = {As the general public is becoming increasingly familiar with 3D content, the challenge of 3D-ICONS project was to provide high quality 3D cultural heritage content to Europeana. Particularly the project addressed to exploiting existing tools and methods and to integrate them in a complete supply chain of 3D digitisation to contribute a significant collection of 3D content. 3D-ICONS digitised a series of architectural and archaeological masterpieces of worldwide and European cultural significance and provided 3D models and related digital content to Europeana. The project has had as one of its main objectives the quality control of 3D data and establishing a metadata schema to support the provenance and paradata required for quality assurance of 3D models. The paper shows the achievements reached by the project.},
	language = {it},
	author = {D’Andrea, Andrea},
	file = {D’Andrea - 3D-ICONS oggetti digitali archeologici 3D.pdf:files/740/D’Andrea - 3D-ICONS oggetti digitali archeologici 3D.pdf:application/pdf},
}

@article{dandrea_3d-icons_nodate-1,
	title = {{3D}-{ICONS}: oggetti digitali archeologici {3D}},
	abstract = {As the general public is becoming increasingly familiar with 3D content, the challenge of 3D-ICONS project was to provide high quality 3D cultural heritage content to Europeana. Particularly the project addressed to exploiting existing tools and methods and to integrate them in a complete supply chain of 3D digitisation to contribute a significant collection of 3D content. 3D-ICONS digitised a series of architectural and archaeological masterpieces of worldwide and European cultural significance and provided 3D models and related digital content to Europeana. The project has had as one of its main objectives the quality control of 3D data and establishing a metadata schema to support the provenance and paradata required for quality assurance of 3D models. The paper shows the achievements reached by the project.},
	language = {it},
	author = {D’Andrea, Andrea},
	file = {D’Andrea - 3D-ICONS oggetti digitali archeologici 3D.pdf:files/744/D’Andrea - 3D-ICONS oggetti digitali archeologici 3D.pdf:application/pdf},
}

@misc{noauthor_lode_nodate,
	title = {{LODE}: {An} ontology for {Linking} {Open} {Descriptions} of {Events}},
	url = {https://linkedevents.org/ontology/#sec-introduction},
	urldate = {2023-03-13},
	file = {LODE\: An ontology for Linking Open Descriptions of Events:files/787/ontology.html:text/html},
}

@inproceedings{spiliotopoulos_semantics-driven_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Semantics-{Driven} {Conversational} {Interfaces} for {Museum} {Chatbots}},
	isbn = {978-3-030-50267-6},
	doi = {10.1007/978-3-030-50267-6_20},
	abstract = {This work addresses the challenges of creating usable and personalized conversational interfaces for broad, yet applicable, domains that require user engagement and learning, such as museum chatbots. Whether the chatbots are standalone or coupled with virtual agents or real-life robots, the functional requirements for interaction that targets specific learning aspects would be expected to be more or less similar. This work reports on experimental semantics-driven conversational interface design for chatbots in museum settings, targeting visitors to converse about exhibits and learn information about their style, the artists, the era, and other aspects related to them. Depending on the semantics (presentation, learning, exploration), chatbot scenarios were designed and evaluated by participants in a formative evaluation. The evaluation show that user requirement perception manifests in expectations on the semantic level, instead of just the technical level. The results between the scenarios are compared to see how the semantics considered for the design transferred to the implementation and to the user perception.},
	language = {en},
	booktitle = {Culture and {Computing}},
	publisher = {Springer International Publishing},
	author = {Spiliotopoulos, Dimitris and Kotis, Konstantinos and Vassilakis, Costas and Margaris, Dionisis},
	editor = {Rauterberg, Matthias},
	year = {2020},
	keywords = {Semantics, Chatbots, Conversational interfaces, Cultural technology},
	pages = {255--266},
	file = {Full Text PDF:files/920/Spiliotopoulos et al. - 2020 - Semantics-Driven Conversational Interfaces for Mus.pdf:application/pdf},
}

@inproceedings{varitimiadis_talking_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {“{Talking}” {Triples} to {Museum} {Chatbots}},
	isbn = {978-3-030-50267-6},
	doi = {10.1007/978-3-030-50267-6_22},
	abstract = {The paper presents recent work on the design and development of AI chatbots for museums using Knowledge Graphs (KGs). The utilization of KGs as a key technology for implementing chatbots raises not only issues related to the representation and structuring of exhibits’ knowledge in suitable formalism and models, but also issues related to the translation of natural language dialogues to and from the selected technology for the formal representation and structuring of information and knowledge. Moreover, such a translation must be as transparent as possible to visitors, towards a realistic human-like question-answering process. The paper reviews and evaluates a number of recent approaches for the use of KGs in developing AI chatbots, as well as key tools that provide solutions for natural language translation and the querying of Knowledge Bases and Linked Open Data sources. This evaluation aims to provide answers to issues that are identified within the proposed MuBot approach for designing and implementing AI chatbots for museums. The paper also presents Cretan MuBot, the first experimental KG/Ontology-based AI chatbot of the MuBot Platform, which is under development in the Heracleum Archaeological Museum.},
	language = {en},
	booktitle = {Culture and {Computing}},
	publisher = {Springer International Publishing},
	author = {Varitimiadis, Savvas and Kotis, Konstantinos and Spiliotopoulos, Dimitris and Vassilakis, Costas and Margaris, Dionisis},
	editor = {Rauterberg, Matthias},
	year = {2020},
	keywords = {Chatbots, Knowledge Graphs, Museums, NLP, RDF triples},
	pages = {281--299},
	file = {Full Text PDF:files/922/Varitimiadis et al. - 2020 - “Talking” Triples to Museum Chatbots.pdf:application/pdf},
}

@article{cantone_epidoc_2019,
	title = {An {EpiDoc} ontological perspective: the epigraphs of the {Castello} {Ursino} {Civic} {Museum} of {Catania} via {CIDOC} {CRM}},
	volume = {30},
	copyright = {cc\_by\_nc\_nd},
	issn = {1120-6861},
	shorttitle = {An {EpiDoc} ontological perspective},
	url = {http://www.archcalc.cnr.it/indice/PDF30/10_Cantone_et_al.pdf},
	abstract = {The rich epigraphic heritage of the Castello Ursino Civic Museum of Catania has been studied by the EpiCUM project that encoded it in EpiDoc TEI XML, an XML based standard digital representation for cultural heritage contents. The project made the epigraphic heritage available in a digital museum: under the guise of the ‘Voci di Pietra’ exhibition, a selection of epigraphs were presented, implementing innovative presentation modalities thanks to a smart use of technological and digital means. Information contained in the epigraphs was semantically reorganized in a unique homogeneous container, the EpiONT ontology, constructed according to the Linked Open Data paradigm and to consolidated international standards. The encoding of the ancient texts, by the TEI standard and its EpiDoc subset, is wedded to the paradigmatic semantic web model for museums and cultural heritage. The EpiONT ontology is currently populated by 580 epigraphs collected in the Castello Ursino Civic Museum. Designed according to the CIDOC CRM standard, it makes use of the SKOS vocabularies of the EAGLE project concerning material, execution technique, type of inscription, and type of support of an epigraph. The EpiONT ontology additionally can handle any uncertainty in the origin and place of discovery of the epigraphs.},
	language = {en},
	urldate = {2023-03-15},
	journal = {Archeologia e Calcolatori},
	author = {Cantone, D. and Cristofaro, S. and Nicolosi-Asmundo, M. and Prado, F. and Santamaria, D. F. and Spampinato, D.},
	year = {2019},
	note = {Publisher: Edizioni All'Insegna del Giglio},
	pages = {139--157},
	file = {Full Text PDF:files/973/Cantone et al. - 2019 - An EpiDoc ontological perspective the epigraphs o.pdf:application/pdf;Snapshot:files/972/19350.html:text/html},
}

@article{bogdani_archeofoss_2021,
	title = {{ArcheoFOSS} {XIV} 2020 : {Open} {Software}, {Hardware}, {Processes}, {Data} and {Formats} in {Archaeological} {Research} : {Proceedings} of the 14th {International} {Conference}, 15-17 {October} 2020},
	shorttitle = {{ArcheoFOSS} {XIV} 2020},
	url = {https://www.torrossa.com/en/resources/an/5245157},
	abstract = {Purchase online the PDF of ArcheoFOSS XIV 2020, Bogdani, Julian,Rosati, Paolo,Montalbano, Riccardo, 1985- - Archaeopress - E-book},
	language = {en},
	urldate = {2023-03-15},
	journal = {ArcheoFOSS XIV 2020},
	author = {Bogdani, Julian},
	year = {2021},
	note = {Publisher: Archaeopress},
	pages = {1--204},
}

@inproceedings{alvarez_sharing_2010,
	address = {Berlin, Heidelberg},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Sharing {Epigraphic} {Information} as {Linked} {Data}},
	isbn = {978-3-642-16552-8},
	doi = {10.1007/978-3-642-16552-8_21},
	abstract = {The diffusion of epigraphic data has evolved in the last years from printed catalogues to indexed digital databases shared through the Web. Recently, the open EpiDoc specifications have resulted in an XML-based schema for the interchange of ancient texts that uses XSLT to render typographic representations. However, these schemas and representation systems are still not providing a way to encode computational semantics and semantic relations between pieces of epigraphic data. This paper sketches an approach to bring these semantics into an EpiDoc based schema using the Ontology Web Language (OWL) and following the principles and methods of information sharing known as “linked data”. The paper describes the general principles of the OWL mapping of the EpiDoc schema and how epigraphic data can be shared in RDF format via dereferenceable URIs that can be used to build advanced search, visualization and analysis systems.},
	language = {en},
	booktitle = {Metadata and {Semantic} {Research}},
	publisher = {Springer},
	author = {Álvarez, Fernando-Luis and García-Barriocanal, Elena and Gómez-Pantoja, Joaquín-L.},
	editor = {Sánchez-Alonso, Salvador and Athanasiadis, Ioannis N.},
	year = {2010},
	keywords = {Semantic Web, EpiDoc, Epigraphy, linked data, OWL},
	pages = {222--234},
}

@article{espinosa_espinosa_epigraphy_2021,
	title = {Epigraphy in the {Digital} {Age} : {Opportunities} and {Challenges} in the {Recording}, {Analysis} and {Dissemination} of {Inscriptions}},
	shorttitle = {Epigraphy in the {Digital} {Age}},
	url = {https://www.torrossa.com/en/resources/an/5054799},
	abstract = {Purchase online the PDF of Epigraphy in the Digital Age, Espinosa Espinosa, David,Velázquez Soriano, Isabel - Archaeopress - E-book},
	language = {en},
	urldate = {2023-03-15},
	journal = {Epigraphy in the Digital Age},
	author = {Espinosa Espinosa, David},
	year = {2021},
	note = {Publisher: Archaeopress},
	pages = {1--258},
}

@article{calvanese_ontology-based_2016,
	series = {Mining the {Humanities}: {Technologies} and {Applications}},
	title = {Ontology-based data integration in {EPNet}: {Production} and distribution of food during the {Roman} {Empire}},
	volume = {51},
	issn = {0952-1976},
	shorttitle = {Ontology-based data integration in {EPNet}},
	url = {https://www.sciencedirect.com/science/article/pii/S0952197616000099},
	doi = {10.1016/j.engappai.2016.01.005},
	abstract = {Semantic technologies are rapidly changing the historical research. Over the last decades, an immense amount of new quantifiable data have been accumulated, and made available in interchangeable formats, in social sciences and humanities, opening up new possibilities for solving old questions and posing new ones. This paper introduces a framework that eases the access of scholars to historical and cultural data about food production and commercial trade system during the Roman Empire, distributed across different data sources. The proposed approach relies on the Ontology-Based Data Access (OBDA) paradigm, where the different datasets are virtually integrated by a conceptual layer (an ontology) that provides to the user a clear point of access and a unified and unambiguous conceptual view.},
	language = {en},
	urldate = {2023-03-15},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Calvanese, Diego and Liuzzo, Pietro and Mosca, Alessandro and Remesal, José and Rezk, Martin and Rull, Guillem},
	month = may,
	year = {2016},
	keywords = {E-Culture, EPNet, Knowledge Representation and Reasoning, Ontology-Based Data Access, Ontology-Based Data Integration, Ontop},
	pages = {212--229},
	file = {Full text:files/1141/Calvanese et al. - 2016 - Ontology-based data integration in EPNet Producti.pdf:application/pdf;ScienceDirect Snapshot:files/1140/S0952197616000099.html:text/html},
}

@book{prag_i_2019,
	title = {I. {Sicily}: {Building} a {Digital} {Corpus} of the {Inscriptions} of {Ancient} {Sicily}},
	isbn = {978-3-11-060719-2},
	shorttitle = {I. {Sicily}},
	url = {https://ora.ox.ac.uk/objects/uuid:90fbe6a1-7cc3-4cde-8a82-02d1242949bb},
	abstract = {This paper presents the I.Sicily project. We focus first upon its original rationale and construction, since this provides explanations for the particular choices and approaches adopted, before exploring some of the challenges faced, as well as current and future developments. We believe that I.Sicily offers an interesting case study of a deliberately open-ended, continuous work-in-progress corpus. The project is constructed on the assumption that collaboration is key to its success, and that collaboration will only increase. We examine the potential for the creation of linked open data, which we consider essential to creating the primary point of reference for the study of Sicilian epigraphy, and to the creation of a resource to support and facilitate research while simultaneously enhancing and supporting the accessibility of Sicilian epigraphy. This last aim is served both directly through the project’s web-interface, and indirectly by supporting and facilitating the work of the institutions which curate the majority of the material: we conclude with an illustration of a wide-ranging, museum-based, community collaboration.},
	language = {en},
	urldate = {2023-03-15},
	publisher = {De Gruyter},
	author = {Prag, J. and Chartrand, J.},
	year = {2019},
	file = {Full Text PDF:files/1143/Prag e Chartrand - 2019 - I. Sicily Building a Digital Corpus of the Inscri.pdf:application/pdf},
}

@article{murano_crmtex_nodate,
	title = {{CRMtex}. {An} ontological model for ancient textual entities},
	abstract = {This poster presents the CRMtex, an ontological model based on CIDOC CRM developed since 2015 to support the study of ancient documents by identifying relevant textual entities and by modelling the scientific process related to the investigation of ancient texts and their features in order to foster integration with other cultural heritage research fields.},
	language = {en},
	author = {Murano, Francesca and Felicetti, Achille},
	file = {Murano e Felicetti - CRMtex. An ontological model for ancient textual e.pdf:files/1144/Murano e Felicetti - CRMtex. An ontological model for ancient textual e.pdf:application/pdf},
}

@article{liuzzo_modeling_2021,
	title = {Modeling execution techniques of inscriptions},
	volume = {12},
	issn = {1570-0844},
	url = {https://content.iospress.com/articles/semantic-web/sw200395},
	doi = {10.3233/SW-200395},
	abstract = {The paper discusses a small ontology to describe the features of the execution techniques of inscriptions, based on a recent contribution discussing the classification methodologies. The modeling is done on the basis of existing recent attempts to mo},
	language = {en},
	number = {2},
	urldate = {2023-03-15},
	journal = {Semantic Web},
	author = {Liuzzo, Pietro Maria and Evangelisti, Silvia},
	month = jan,
	year = {2021},
	note = {Publisher: IOS Press},
	pages = {181--190},
}

@book{rodriguez_arqueologiy_2022,
	title = {Arqueología y {Téchne}: {Métodos} formales, nuevos enfoques: {Archaeology} and {Techne}: {Formal} methods, new approaches},
	isbn = {978-1-80327-182-8 978-1-80327-181-1},
	shorttitle = {Arqueología y {Téchne}},
	url = {http://www.jstor.org/stable/10.2307/j.ctv2b07v2z},
	language = {en},
	urldate = {2023-03-15},
	publisher = {Archaeopress Publishing Ltd},
	editor = {Rodríguez, José Remesal and González, Jordi Pérez},
	month = feb,
	year = {2022},
	doi = {10.2307/j.ctv2b07v2z},
	file = {Rodríguez e González - 2022 - Arqueología y Téchne Métodos formales, nuevos enf.pdf:files/1148/Rodríguez e González - 2022 - Arqueología y Téchne Métodos formales, nuevos enf.pdf:application/pdf},
}

@article{goerz_eden_nodate,
	title = {{EDEN} – {The} {Erlangen} {Epigraphic} {Web} {Database} of {Ancient} {Inscriptions}},
	language = {en},
	author = {Goerz, Guenther and Scholz, Martin},
	file = {Goerz e Scholz - EDEN – The Erlangen Epigraphic Web Database of Anc.pdf:files/1150/Goerz e Scholz - EDEN – The Erlangen Epigraphic Web Database of Anc.pdf:application/pdf},
}

@inproceedings{janiak_matching_2020,
	title = {Matching {Ontology} and {Encoding} for {South} and {Southeast} asian {Epigraphy}: {Experiences} so far within the {DHARMA} project},
	shorttitle = {Matching {Ontology} and {Encoding} for {South} and {Southeast} asian {Epigraphy}},
	url = {https://hal.science/hal-03140468},
	language = {en},
	urldate = {2023-03-15},
	author = {Janiak, Axelle},
	month = feb,
	year = {2020},
	file = {Snapshot:files/1153/hal-03140468.html:text/html},
}

@inproceedings{remesal_epnet_2014,
	title = {The {EPNet} {Project}. {Production} and distribution of food during the {Roman} {Empire}: {Economics} and {Political} {Dynamics}},
	copyright = {Open Access},
	isbn = {978-88-98533-42-8},
	shorttitle = {The {EPNet} {Project}. {Production} and distribution of food during the {Roman} {Empire}},
	url = {https://upcommons.upc.edu/handle/2117/85564},
	language = {eng},
	urldate = {2023-03-15},
	publisher = {Sapienza Università Editrice},
	author = {Remesal, José and Díaz-Guilera, Albert and Rondelli, Bernardo and Rubio, Xavier and Aguilera, Antonio and Martín-Arroyo, Daniel and Mosca, Alessandro and Rull, Guillem},
	year = {2014},
	note = {Accepted: 2016-04-12T13:03:00Z},
	keywords = {Epigraphy, Amphora, Àrees temàtiques de la UPC::Enginyeria mecànica, Big data, Computer simulation, Història--Metodologia, Historical research, Imperi, Network, Roma--Història--30 aC-476 dC, Roman economy, Roman Empire. History \& Archaeology, Roman policy, Simulació per ordinador},
	pages = {455--464},
	file = {Full Text PDF:files/1155/Remesal et al. - 2014 - The EPNet Project. Production and distribution of .pdf:application/pdf},
}

@article{ellwood_project_2018,
	title = {Project {Paleo}: {Citizen} {Curation} and {Community} {Science} at the {Natural} {History} {Museum} of {Los} {Angeles} {County}},
	copyright = {© 2018. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
	shorttitle = {Project {Paleo}},
	url = {https://www.proquest.com/docview/2169991446/abstract/571CC932FE1F4947PQ/1},
	doi = {10.3897/biss.2.25980},
	abstract = {The School and Teacher Programs of the Natural History Museum of Los Angeles County have partnered with the La Brea Tar Pits and Museum (LBTPM) and the Invertebrate Paleontology (LACMIP) collection to create two “citizen curation” exercises dubbed “Project Paleo”. Classroom kits were created with unsorted fossils from either LBPTM or from a local invertebrate paleontological field site, to be sorted and identified by local elementary and middle school students and then returned to the museum for curation, analysis, and research purposes. Each kit contains background information about the project and fossils, and an identification guide to assist the students and teachers. The “Project Paleo: Rancho La Brea” kit contains three tablespoons of unsorted fossil matrix from LBTPM’s Project 23. Groups of students learn about past and present food webs of the Los Angeles Basin, then sort the matrix into several categories (bones, plants, other fossils, and rocks) using a guide with drawn examples of each. An online iNaturalist (inaturalist.org) project also serves as an identification resource as well as a platform by which students can contribute photos for identification by staff researchers. This project is aimed at middle schoolers and over 700 students have used the sorting kits.
Results will help to recreate past ecosystems of Southern California and help to inform a National Science Foundation (NSF) funded project, “A Mouse’s Eye View of Rancho La Brea”. The “Project Paleo: Marine Invertebrates of Southern California” kit produced by LACMIP, contains approximately two cups of washed but unsorted coarse fossil matrix from a salvaged (now destroyed) construction site. This kit is aimed at 5th grade Los Angeles Unified School District classrooms and homeschooling families. Students are asked to sort fossils by species and use included identification cards to identify the sorted fossils to the best of their ability.
Results of this project will be included in an NSF funded digitization project and will contribute to research on the paleoecology of Pleistocene Southern California. Early evaluation of both kits has shown positive feedback from students and educators, as well as some room to improve instructions to students. These kits are designed to conform to Next Generation Science Standards while generating useful data for museum scientists. Collections staff are able to outsource the curation of critical data to students who get the experience of handling real museum fossils and contributing to the body of paleontological research.},
	language = {English},
	urldate = {2023-03-15},
	journal = {Biodiversity Information Science and Standards},
	author = {Ellwood, Elizabeth and Estes-Smargiassi, Kathryn and Graham, Noel and Takeuchi, Gary and Hendy, Austin and Porter, Molly and Lindsey, Emily},
	month = jun,
	year = {2018},
	note = {Place: Sofia, Bulgaria
Publisher: Pensoft Publishers
Section: Conference Abstract},
	keywords = {education, food web, fossil, microfossil, paleontology},
	file = {Full Text PDF:files/1157/Ellwood et al. - 2018 - Project Paleo Citizen Curation and Community Scie.pdf:application/pdf},
}

@inproceedings{schneider_engaging_2015,
	address = {New York, NY, USA},
	series = {{IHC} '15},
	title = {Engaging citizens with news stories through social curation: a design research project},
	isbn = {978-1-4503-5362-5},
	shorttitle = {Engaging citizens with news stories through social curation},
	url = {https://doi.org/10.1145/3148456.3148495},
	doi = {10.1145/3148456.3148495},
	abstract = {We report on our design of Acropolis, a social computing platform that allows citizens to build and share their own narratives about long-running news stories of political nature. A key goal of this research project is to explore the following design opportunity: how can we re-design news stories in order to engage citizens in their reading and curation? We have hypothesized that one way of achieving this goal would be by effectively supporting user-curated narratives, yet allowing users to socially engage in different perspectives and plots in a story. Using a research through design methodology, we conclude the first cycle of this study with a set of design recommendations for building similar platforms.},
	urldate = {2023-03-15},
	booktitle = {Proceedings of the 14th {Brazilian} {Symposium} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Schneider, Daniel and de Souza, Jano},
	month = nov,
	year = {2015},
	keywords = {crowdsourcing, design research, engagement with news, political stories, social curation, user-curated narratives},
	pages = {1--10},
}

@article{proctor_digital_2010,
	title = {Digital: {Museum} as {Platform}, {Curator} as {Champion}, in the {Age} of {Social} {Media}},
	volume = {53},
	shorttitle = {Digital},
	doi = {10.1111/j.2151-6952.2009.00006.x},
	journal = {Curator: The Museum Journal},
	author = {Proctor, Nancy},
	month = jan,
	year = {2010},
	pages = {35--43},
}

@inproceedings{monroy-hernandez_new_2013,
	address = {New York, NY, USA},
	series = {{CSCW} '13},
	title = {The new war correspondents: the rise of civic media curation in urban warfare},
	isbn = {978-1-4503-1331-5},
	shorttitle = {The new war correspondents},
	url = {https://doi.org/10.1145/2441776.2441938},
	doi = {10.1145/2441776.2441938},
	abstract = {In this paper we examine the information sharing practices of people living in cities amid armed conflict. We describe the volume and frequency of microblogging activity on Twitter from four cities afflicted by the Mexican Drug War, showing how citizens use social media to alert one another and to comment on the violence that plagues their communities. We then investigate the emergence of civic media "curators," individuals who act as "war correspondents" by aggregating and disseminating information to large numbers of people on social media. We conclude by outlining the implications of our observations for the design of civic media systems in wartime.},
	urldate = {2023-03-15},
	booktitle = {Proceedings of the 2013 conference on {Computer} supported cooperative work},
	publisher = {Association for Computing Machinery},
	author = {Monroy-Hernández, Andrés and boyd, danah and Kiciman, Emre and De Choudhury, Munmun and Counts, Scott},
	month = feb,
	year = {2013},
	keywords = {crowdsourcing, civic media, crisis informatics, curation, latin america, mexico, microblogging, news, social computing, social media, twitter, war},
	pages = {1443--1452},
	file = {Versione inviata:files/1162/Monroy-Hernández et al. - 2013 - The new war correspondents the rise of civic medi.pdf:application/pdf},
}

@article{cox_digital_2009,
	title = {Digital {Curation} and the {Citizen} {Archivist}},
	copyright = {attached},
	url = {http://d-scholarship.pitt.edu/2692/},
	abstract = {The increasing array and power of personal digital recordkeeping systems promises both to make it more difficult for established archives to acquire personal and family archives and less likely that individuals might wish to donate personal and family digital archives to archives, libraries, museums, and other institutions serving as documentary repositories. This paper provides a conceptual argument for how projects such as the Digital Curation one ought to consider developing spinoffs for archivists training private citizens how to preserve, manage, and use digital personal and family archives. Rethinking how we approach the public, which will increasingly face difficult challenges in caring for their digital archives, also brings with it substantial promise in informing them about the nature and importance of the archival mission. Can the Digital Curation project provide tools that canbe used for working with the public?},
	language = {en},
	urldate = {2023-03-15},
	journal = {Digital Curation: Practice, Promises \& Prospects},
	author = {Cox, Richard J.},
	month = apr,
	year = {2009},
	note = {Publisher: University of North Carolina School of Information and Library Science},
	pages = {102--109},
	file = {Full Text PDF:files/1164/Cox - 2009 - Digital Curation and the Citizen Archivist.pdf:application/pdf;Snapshot:files/1165/2692.html:text/html},
}

@article{murray_accessible_2021,
	title = {Accessible data curation and analytics for international-scale citizen science datasets},
	volume = {8},
	copyright = {2021 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-021-01071-x},
	doi = {10.1038/s41597-021-01071-x},
	abstract = {The Covid Symptom Study, a smartphone-based surveillance study on COVID-19 symptoms in the population, is an exemplar of big data citizen science. As of May 23rd, 2021, over 5 million participants have collectively logged over 360 million self-assessment reports since its introduction in March 2020. The success of the Covid Symptom Study creates significant technical challenges around effective data curation. The primary issue is scale. The size of the dataset means that it can no longer be readily processed using standard Python-based data analytics software such as Pandas on commodity hardware. Alternative technologies exist but carry a higher technical complexity and are less accessible to many researchers. We present ExeTera, a Python-based open source software package designed to provide Pandas-like data analytics on datasets that approach terabyte scales. We present its design and capabilities, and show how it is a critical component of a data curation pipeline that enables reproducible research across an international research group for the Covid Symptom Study.},
	language = {en},
	number = {1},
	urldate = {2023-03-15},
	journal = {Scientific Data},
	author = {Murray, Benjamin and Kerfoot, Eric and Chen, Liyuan and Deng, Jie and Graham, Mark S. and Sudre, Carole H. and Molteni, Erika and Canas, Liane S. and Antonelli, Michela and Klaser, Kerstin and Visconti, Alessia and Hammers, Alexander and Chan, Andrew T. and Franks, Paul W. and Davies, Richard and Wolf, Jonathan and Spector, Tim D. and Steves, Claire J. and Modat, Marc and Ourselin, Sebastien},
	month = nov,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Epidemiology, Research data},
	pages = {297},
	file = {Full Text PDF:files/1167/Murray et al. - 2021 - Accessible data curation and analytics for interna.pdf:application/pdf},
}

@article{lagoze_ebird_2014,
	title = {{eBird}: {Curating} {Citizen} {Science} {Data} for {Use} by {Diverse} {Communities}},
	volume = {9},
	copyright = {Copyright (c)},
	issn = {1746-8256},
	shorttitle = {{eBird}},
	url = {http://www.ijdc.net/article/view/9.1.71},
	doi = {10.2218/ijdc.v9i1.302},
	abstract = {In this paper we describe eBird, a highly successful citizen science project. With over 150,000 participants worldwide and an accumulation of over 140,000,000 bird observations globally in the last decade, eBird has evolved into a major tool for scientific investigations in diverse fields such as ornithology, computer science, statistics, ecology and climate change. eBird’s impact in scientific research is grounded in careful data curation practices that pay attention to all stages of the data lifecycle, and attend to the needs of stakeholders engaged in that data lifecycle. We describe the important aspects of eBird, paying particular attention to the mechanisms to improve data quality; describe the data products that are available to the global community; investigate some aspects of the downloading community; and demonstrate significant results that derive from the use of openly-available eBird data.},
	language = {en},
	number = {1},
	urldate = {2023-03-15},
	journal = {International Journal of Digital Curation},
	author = {Lagoze, Carl},
	month = jul,
	year = {2014},
	note = {Number: 1},
	keywords = {curation, DCC, digital curation, digital preservation, IJDC, International Journal of Digital Curation, preservation},
	pages = {71--82},
	file = {Full Text PDF:files/1169/Lagoze - 2014 - eBird Curating Citizen Science Data for Use by Di.pdf:application/pdf},
}

@article{doerr_currently_nodate,
	title = {Currently maintained by {Francesca} {Murano} and {Achille} {Felicetti}.},
	language = {en},
	author = {Doerr, Martin and Murano, Francesca and Felicetti, Achille},
	file = {Doerr et al. - Currently maintained by Francesca Murano and Achil.pdf:files/1190/Doerr et al. - Currently maintained by Francesca Murano and Achil.pdf:application/pdf},
}

@article{felicetti_scripta_2017,
	title = {Scripta manent: a {CIDOC} {CRM} semiotic reading of ancient texts},
	volume = {18},
	issn = {1432-1300},
	shorttitle = {Scripta manent},
	url = {https://doi.org/10.1007/s00799-016-0189-z},
	doi = {10.1007/s00799-016-0189-z},
	abstract = {This paper tries to identify the most important concepts involved in the study of ancient texts and proposes the use of CIDOC CRM to encode them and to model the scientific process of investigation related to the study of ancient texts to foster integration with other cultural heritage research fields. After identifying the key concepts, assessing the available technologies and analysing the entities provided by CIDOC CRM and by its extensions, we introduce more specific classes to be used as the basis for creating a new extension, CRMtex, which is more responsive to the specific needs of the various disciplines involved (including papyrology, palaeography, codicology and epigraphy).},
	language = {en},
	number = {4},
	urldate = {2023-03-16},
	journal = {International Journal on Digital Libraries},
	author = {Felicetti, Achille and Murano, Francesca},
	month = nov,
	year = {2017},
	keywords = {EpiDoc, Ancient manuscripts, CIDOC CRM extensions, CRMtex},
	pages = {263--270},
	file = {Full Text PDF:files/1193/Felicetti e Murano - 2017 - Scripta manent a CIDOC CRM semiotic reading of an.pdf:application/pdf},
}

@article{felicetti_modellazione_2021,
	title = {La modellazione semantica delle entità testuali: {Il} modello {CRMtex} e la descrizione ontologica dei testi antichi},
	copyright = {Copyright (c) 2021},
	issn = {2532-8816},
	shorttitle = {La modellazione semantica delle entità testuali},
	url = {https://umanisticadigitale.unibo.it/article/view/13674},
	doi = {10.6092/issn.2532-8816/13674},
	abstract = {This paper presents\&nbsp;CRMtex, an ontological model based on CIDOC CRM developed since 2015 to support the study of ancient documents. The model is intended to\&nbsp;identify relevant textual entities and to model the scientific process related to the investigation of ancient texts and their features in order to foster integration with other Cultural Heritage research fields.\&nbsp;CRMtex is able to identify and define in a clear and unambiguous way the main entities involved in the study and edition of ancient handwritten texts and to describe them by means of appropriate ontological instruments in a multidisciplinary perspective.\&nbsp;The CRMtex model also provides tools for managing this kind of complexity by defining classes and properties for describing a handwritten text in all its aspects, from its creation (and/or destruction) in the past, down to its present conservation, investigation and study by scholars, including its transcription, translation, interpretation and publication. The full compatibility of CRMtex with the CIDOC CRM ontology and its extensions ensures persistent interoperability of data encoded by means of its entities with other semantic information produced in cultural heritage and Digital Humanities.},
	language = {it},
	number = {11},
	urldate = {2023-03-16},
	journal = {Umanistica Digitale},
	author = {Felicetti, Achille and Murano, Francesca},
	year = {2021},
	note = {Number: 11},
	keywords = {Epigraphy},
	pages = {163--175},
	file = {Full Text PDF:files/1195/Felicetti e Murano - 2021 - La modellazione semantica delle entità testuali I.pdf:application/pdf},
}

@article{riva_lrmoo_2022,
	title = {{LRMoo}, a high-level model in an object-oriented framework},
	copyright = {CC BY 4.0},
	url = {https://repository.ifla.org/handle/123456789/2217},
	abstract = {The LRMoo model brings the IFLA Library Reference Model (IFLA LRM) into the CIDOC Conceptual Reference Model (CRM) family of models by providing an object-oriented version of the model that is designed as an extension to CIDOC CRM. LRMoo is developed from FRBRoo, which was based on the FR family of models. In comparison to FRBRoo, LRMoo is streamlined and at a higher level of generality, while retaining full expressivity. Aspects of the model have been revised to align more closely with the IFLA LRM model, such as the handling of aggregation and representative expression attributes. Properties have been added to correspond to certain IFLA LRM relationships between works and expressions that were not declared in FRBRoo. The classes that represent the creation events of the main WEMI classes, F27 Work Creation and F28 Expression Creation, were revised. Specialized examples have been replaced with ones chosen to aid in comprehension of the model.},
	language = {en},
	urldate = {2023-03-16},
	author = {Riva, Pat and Žumer, Maja and Aalberg, Trond},
	month = oct,
	year = {2022},
	note = {Accepted: 2022-10-27T13:20:12Z
Publisher: International Federation of Library Associations and Institutions (IFLA)},
	file = {Full Text PDF:files/1197/Riva et al. - 2022 - LRMoo, a high-level model in an object-oriented fr.pdf:application/pdf},
}

@inproceedings{riva_frbroo_2017,
	title = {{FRBRoo}, the {IFLA} {Library} {Reference} {Model}, and now {LRMoo} : a circle of development},
	copyright = {cc\_by\_4},
	shorttitle = {{FRBRoo}, the {IFLA} {Library} {Reference} {Model}, and now {LRMoo}},
	url = {https://library.ifla.org/id/eprint/2130/},
	abstract = {IFLA's conceptual models for bibliographic information are maintained in two forms, entity-relationship modelling and object-oriented modelling. The two formalisms have different strengths and purposes, but the choice does not have a crucial effect on the model itself. As the models have developed in phases, the insights gained in one round of development have regularly informed and influenced the next development. This paper illustrates the influences and adaptation of ideas using examples from the most recently approved models: FRBRoo version 2.4 (2016) and IFLA LRM (2017), continuing to current work to create LRMoo.},
	language = {en},
	urldate = {2023-03-16},
	author = {Riva, Pat and Žumer, Maja},
	year = {2017},
	file = {Full Text PDF:files/1199/Riva e Žumer - 2017 - FRBRoo, the IFLA Library Reference Model, and now .pdf:application/pdf;Snapshot:files/1200/2130.html:text/html},
}

@misc{noauthor_vocabularies_nodate,
	title = {Vocabularies {\textbar} {EAGLE} {Portal}},
	url = {https://www.eagle-network.eu/resources/vocabularies/},
	language = {en-US},
	urldate = {2023-03-16},
	file = {Snapshot:files/1233/vocabularies.html:text/html},
}

@article{felicetti_cidoc_nodate,
	title = {{CIDOC} {CRM} and {Epigraphy}: a {Hermeneutic} {Challenge}},
	abstract = {This paper identiﬁes the main concepts involved in the study of epigraphy and proposes the use of CIDOC CRM to encode epigraphic concepts and to model the scientiﬁc process of investigation related to the study of epigraphy. After analysing the existing CIDOC CRM entities and those provided by the CRMsci and CRMarchaeo extensions, we introduce more speciﬁc epigraphic classes to be used as the basis for creating a new extension, CRMepi, which is more responsive to the speciﬁc needs of this discipline.},
	language = {en},
	author = {Felicetti, Achille and Murano, Francesca and Ronzino, Paola and Niccolucci, Franco},
	file = {Felicetti et al. - CIDOC CRM and Epigraphy a Hermeneutic Challenge.pdf:files/1264/Felicetti et al. - CIDOC CRM and Epigraphy a Hermeneutic Challenge.pdf:application/pdf},
}

@article{pasqual_linked_2022-1,
	title = {Linked open data per la valorizzazione di collezioni culturali: il dataset {mythLOD}},
	volume = {62},
	copyright = {Copyright (c) 2022 Valentina Pasqual, Francesca Tomasi},
	issn = {2239-6152},
	shorttitle = {Linked open data per la valorizzazione di collezioni culturali},
	url = {https://aibstudi.aib.it/article/view/13301},
	doi = {10.2426/aibstudi-13301},
	abstract = {The formal representation of cultural metadata has always been a challenge, considering the heterogeneity of cultural objects and especially when dealing with experts’ interpretation over them.This paper presents an overview of the mythLOD dataset production as the Mythologiae digital collection revalorisation into linked open data format. The research aims then to explore Mythologiae data leveraging semantic web potentialities, focusing over the formal representation of experts’ analysis when associating visual artworks (and their interpretations) to literary sources.The workflow of the project consisted of data model definition, data cleaning and entity linking, conversion (from tabular data to graph) and testing activity (domain experts review over competency questions and two designed on-purpose data visualizations). The result is the mythLOD platform, which present the dataset and the detailed documentation of the research. Additionally, the platform hosts the two data visualization spaces which have been implemented – the online catalogue and the storytelling experiment over Aeneid – as a user friendly testing unit for the dataset and an additional tool for documenting the project and exploring the collection.},
	language = {it},
	number = {1},
	urldate = {2023-03-16},
	journal = {AIB studi},
	author = {Pasqual, Valentina and Tomasi, Francesca},
	month = may,
	year = {2022},
	note = {Number: 1},
	keywords = {semantic web, Linked Open Data, citazioni canoniche, collezione semantica, ermeneutica digitale, Mythologiae, workflow},
	pages = {149--168},
	file = {Full Text PDF:files/1296/Pasqual e Tomasi - 2022 - Linked open data per la valorizzazione di collezio.pdf:application/pdf},
}

@book{hooland_linked_2014,
	title = {Linked {Data} for {Libraries}, {Archives} and {Museums}: {How} to clean, link and publish your metadata},
	isbn = {978-1-85604-964-1},
	shorttitle = {Linked {Data} for {Libraries}, {Archives} and {Museums}},
	abstract = {This highly practical handbook teaches you how to unlock the value of your existing metadata through cleaning, reconciliation, enrichment and linking and how to streamline the process of new metadata creation.Libraries, archives and museums are facing up to the challenge of providing access to fast growing collections whilst managing cuts to budgets. Key to this is the creation, linking and publishing of good quality metadata as Linked Data that will allow their collections to be discovered, accessed and disseminated in a sustainable manner.   This highly practical handbook teaches you how to unlock the value of your existing metadata through cleaning, reconciliation, enrichment and linking and how to streamline the process of new metadata creation.  Metadata experts Seth van Hooland and Ruben Verborgh introduce the key concepts of metadata standards and Linked Data and how they can be practically applied to existing metadata, giving readers the tools and understanding to achieve maximum results with limited resources. Readers will learn how to critically assess and use (semi-)automated methods of managing metadata through hands-on exercises within the book and on the accompanying website. Each chapter is built around a case study from institutions around the world, demonstrating how freely available tools are being successfully used in different metadata contexts.This handbook delivers the necessary conceptual and practical understanding to empower practitioners to make the right decisions when making their organisations resources accessible on the Web.Key topics include: - The value of metadata Metadata creation – architecture, data models and standards - Metadata cleaning - Metadata reconciliation - Metadata enrichment through Linked Data and named-entity recognition - Importing and exporting metadata - Ensuring a sustainable publishing model.Readership: This will be an invaluable guide for metadata practitioners and researchers within all cultural heritage contexts, from library cataloguers and archivists to museum curatorial staff. It will also be of interest to students and academics within information science and digital humanities fields. IT managers with responsibility for information systems, as well as strategy heads and budget holders, at cultural heritage organisations, will find this a valuable decision-making aid.},
	language = {en},
	publisher = {Facet Publishing},
	author = {Hooland, Seth van and Verborgh, Ruben},
	month = jun,
	year = {2014},
	note = {Google-Books-ID: nuEqDgAAQBAJ},
	keywords = {Language Arts \& Disciplines / Library \& Information Science / Archives \& Special Libraries, Language Arts \& Disciplines / Library \& Information Science / Digital \& Online Resources, Language Arts \& Disciplines / Library \& Information Science / General},
}

@article{goy_ontologies_2015,
	title = {Ontologies and historical archives: {A}\&nbsp;way\&nbsp;to\&nbsp;tell new stories},
	volume = {10},
	issn = {1570-5838},
	shorttitle = {Ontologies and historical archives},
	url = {https://content.iospress.com/articles/applied-ontology/ao152},
	doi = {10.3233/AO-150152},
	abstract = {Historical documentary heritage has a high potential for supporting citizens’ awareness of their culture and identity. However, to exploit this potential, access tools are needed, which integrate data from heterogeneous sources and provide an effecti},
	language = {en},
	number = {3-4},
	urldate = {2023-03-16},
	journal = {Applied Ontology},
	author = {Goy, Anna and Magro, Diego and Rovera, Marco},
	month = jan,
	year = {2015},
	note = {Publisher: IOS Press},
	pages = {331--338},
	file = {Full text:files/1325/Goy et al. - 2015 - Ontologies and historical archives A&nbsp\;way&nbs.pdf:application/pdf},
}

@article{daquino_knowledge_2020-1,
	title = {Knowledge {Representation} of digital {Hermeneutics} of archival and literary {Sources}},
	volume = {11},
	copyright = {Copyright (c)},
	issn = {2038-1026},
	url = {https://jlis.fupress.net/index.php/jlis/article/view/35},
	doi = {10.4403/jlis.it-12642},
	abstract = {Scholarly analysis of archival, library, and literary sources results in a variety of digital artefacts meant to foster knowledge discovery and new research enquiries. Guidelines and standards to formally represent disciplinary information are available (e.g. XML schemas, ontologies, vocabularies). However, digital artefacts rarely address reusable structured information on the hermeneutical approach adopted by scholars when validating hypotheses. As a consequence, reproducibility and assessment of research results is hampered, and comparing online contradictory information is still a hard task. In this work we show how to leverage Semantic Web technologies in a high-level, portable data model for representing hermeneutical aspects related to cross-disciplinary analysis of archival and literary sources. We showcase three representative scenarios in the Cultural Heritage domain where the model is applied, and we describe benefits and limits of our solution.},
	language = {en},
	number = {3},
	urldate = {2023-03-16},
	journal = {JLIS.it},
	author = {Daquino, Marilena and Pasqual, Valentina and Tomasi, Francesca},
	month = sep,
	year = {2020},
	note = {Number: 3},
	keywords = {Semantic Web, Archival linked data, Data model, Digital hermeneutics},
	pages = {59--76},
	file = {Full Text PDF:files/1411/Daquino et al. - 2020 - Knowledge Representation of digital Hermeneutics o.pdf:application/pdf},
}

@inproceedings{daquino_historical_2015-1,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Historical {Context} {Ontology} ({HiCO}): {A} {Conceptual} {Model} for {Describing} {Context} {Information} of {Cultural} {Heritage} {Objects}},
	isbn = {978-3-319-24129-6},
	shorttitle = {Historical {Context} {Ontology} ({HiCO})},
	doi = {10.1007/978-3-319-24129-6_37},
	abstract = {Communities addressing the problem of a shareable description of cultural heritage objects agree that a data-centric and context oriented approach should be reached in order to exchange and reuse heterogenous information. Here we present HiCO, an OWL 2 DL ontology aiming to outline relevant issues related to the workflow for stating, and formalizing, authoritative assertions about context information. The conceptual model outlines requirements for defining an authoritative statement and focuses on how a description of context information can be carried out when data are extracted from full-text of documents.},
	language = {en},
	booktitle = {Metadata and {Semantics} {Research}},
	publisher = {Springer International Publishing},
	author = {Daquino, Marilena and Tomasi, Francesca},
	editor = {Garoufallou, Emmanouel and Hartley, Richard J. and Gaitanou, Panorea},
	year = {2015},
	keywords = {Linked Open Data, Authoritativeness, FRBR, Scholarly editions, TEI},
	pages = {424--436},
}

@article{ciotti_formal_2016,
	title = {Formal {Ontologies}, {Linked} {Data}, and {TEI} {Semantics}},
	copyright = {For this publication a Creative Commons Attribution 4.0 International license has been granted by the author(s) who retain full copyright.},
	issn = {2162-5603},
	url = {https://journals.openedition.org/jtei/1480},
	doi = {10.4000/jtei.1480},
	abstract = {The debate on the semantic role of markup languages has been quite lively and the TEI community has played an active part in it. It is commonly acknowledged that markup conveys semantic information. However, XML is a poor language for semantic data modeling. Several proposals have previously been drawn up in the past to provide XML with formalized and computable semantics. In our opinion, the formalisms offered by the Semantic Web paradigm are mature enough to build a workable semantic extension of the TEI.         Our model distinguishes three semantic layers in the TEI: one general and shared intensional semantic layer; one idiolectal specialized layer; and finally an extensional semantics. Our proposal is directed toward the first two layers. We propose to build such semantic layers by adopting a set of OWL formal ontologies.         Furnishing the TEI with a semantics based on a formal ontology could have interesting outcomes: facilitating the management of and research using document collections in open and multi-standard contexts; aiding interoperability with other relevant standards in the digital cultural heritage context; and providing users with advanced formal tools to semantically define their interpretations of the texts and enable innovative computational processing. In order to allow a semantic interoperability between standards, the TEI ontology has to be aligned to other models; likewise mapping and merging procedures have to be evaluated. Finally, the idea of migrating XML/TEI documents following this semantic model into a linked open data dimension requires that we face important issues in order to facilitate the data interchange in the cloud.         However, the cost and the practical complexity of such an extension are notable, and several theoretical problems, format choices, and implementation details are still to be defined.},
	language = {en},
	number = {Issue 9},
	urldate = {2023-03-17},
	journal = {Journal of the Text Encoding Initiative},
	author = {Ciotti, Fabio and Tomasi, Francesca},
	month = sep,
	year = {2016},
	note = {Number: Issue 9
Publisher: Text Encoding Initiative Consortium},
	keywords = {ontology, Semantic Web, linked data, modeling, text encoding theory, XML semantics},
	file = {Full Text PDF:files/1629/Ciotti e Tomasi - 2016 - Formal Ontologies, Linked Data, and TEI Semantics.pdf:application/pdf},
}

@article{ciotti_formal_2018,
	title = {A {Formal} {Ontology} for the {Text} {Encoding} {Initiative}},
	copyright = {Copyright (c) 2018 Fabio Ciotti},
	issn = {2532-8816},
	url = {https://umanisticadigitale.unibo.it/article/view/8174},
	doi = {10.6092/issn.2532-8816/8174},
	abstract = {This article presents the rationale and the proposal of a preliminary architecture of a formal ontology of the Text Encoding Initiative markup language. The reasons to have a formal and machine-readable semantics for TEI are manifold. In the first place, it would have a number of pragmatic and technical benefits, like better support for semantic interoperability in text encoding practices, easier cross-corpora query processing, seamless integration with Linked Open Data ecosystem. In second place, it would give a formalized account of the quasi-formal notion of the TEI abstract model, fostering the consistency and soundness of the TEI model. Given the complexity of the TEI encoding schema, such an ontology must necessarily have a very complex architecture, and its thorough definition will be a time consuming intellectual activity: in a first stage, we propose to limit its scope to a well-defined subdomain of the TEI, and to build it adopting pre-existing meta-ontology like EARMARK. The final part of the article gives some preliminary details of this design},
	language = {en},
	number = {3},
	urldate = {2023-03-17},
	journal = {Umanistica Digitale},
	author = {Ciotti, Fabio},
	month = nov,
	year = {2018},
	note = {Number: 3},
	keywords = {ontology},
	file = {Full Text PDF:files/1631/Ciotti - 2018 - A Formal Ontology for the Text Encoding Initiative.pdf:application/pdf},
}

@inproceedings{ciotti_text_2016,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Text {Encoding} {Initiative} {Semantic} {Modeling}. {A} {Conceptual} {Workflow} {Proposal}},
	isbn = {978-3-319-41938-1},
	doi = {10.1007/978-3-319-41938-1_5},
	abstract = {In this paper we present a proposal for the XML TEI semantic enhancement, through an ontological modelization based on a three level approach: an ontological generalization of the TEI schema; an intensional semantics of TEI elements; an extensional semantics of the markup content. A possible TEI enhancement will be the result of these three levels dialogue and combination. We conclude with the ontology mapping issue and a Linked Open Data suggestion for digital libraries based on XML TEI semantically enriched model.},
	language = {en},
	booktitle = {Digital {Libraries} on the {Move}},
	publisher = {Springer International Publishing},
	author = {Ciotti, Fabio and Daquino, Marilena and Tomasi, Francesca},
	editor = {Calvanese, Diego and De Nart, Dario and Tasso, Carlo},
	year = {2016},
	keywords = {Interoperability, Ontology, Digital libraries, TEI, LOD, XML},
	pages = {48--60},
}

@article{eide_ontologies_2014,
	title = {Ontologies, {Data} {Modeling}, and {TEI}},
	copyright = {For this publication a Creative Commons Attribution 4.0 International license has been granted by the author(s) who retain full copyright.},
	issn = {2162-5603},
	url = {https://journals.openedition.org/jtei/1191},
	doi = {10.4000/jtei.1191},
	abstract = {This paper discusses the relationships between TEI and ontologies from the perspective of computer-based modeling, understood here as a way to establish meaning. The distinctions between creation and use of models as well as between modeling for production and modeling for understanding are presented and compared with other categorizations or models of modeling. One method of establishing meaning in TEI documents is achieved via linking mechanisms between TEI and external ontologies. How such linking can be done and what it may imply for the semantic openness and usability of TEI documents is the practical focus of this article.},
	language = {en},
	number = {Issue 8},
	urldate = {2023-03-17},
	journal = {Journal of the Text Encoding Initiative},
	author = {Eide, Øyvind},
	month = dec,
	year = {2014},
	note = {Number: Issue 8
Publisher: Text Encoding Initiative Consortium},
	keywords = {ontologies, linked data, CIDOC-CRM, conceptual modeling, interchange},
	file = {Full Text PDF:files/1635/Eide - 2014 - Ontologies, Data Modeling, and TEI.pdf:application/pdf},
}

@article{ore_tei_2009,
	title = {{TEI} and cultural heritage ontologies: {Exchange} of information?},
	volume = {24},
	issn = {0268-1145},
	shorttitle = {{TEI} and cultural heritage ontologies},
	url = {https://doi.org/10.1093/llc/fqp010},
	doi = {10.1093/llc/fqp010},
	abstract = {The content in information systems and virtual reconstructions in the cultural heritage sector is to a large degree directly based on information deduced from the study of texts. In many cases, even if the texts are available electronically, the links from the deduced facts to the original texts are not available and in many cases very costly to re-establish. Reproducibility of results is a core concept in text-based research as in all research. Thus, such links should be expressed explicitly in the systems and in accordance with the data standards developed in the fields of text encoding and conceptual modelling. To do this it is necessary to create a combined understanding of text encoding represented by the TEI guidelines and the understanding of conceptual models represented by initiatives like the CIDOC CRM and FRBRoo. In this article, we study a part of this complex by comparing the expressive power of the real world descriptions TEI P5 by mapping central parts of the CIDOC CRM onto TEI P5. It is clear that the TEI P5 has moved a great step in the direction towards an event-oriented model compared with TEI P4. Our use of CIDOC CRM as a yardstick shows that the expressiveness of TEI P5 can be greatly improved by extending the scope of very restricted elements like the relation element and adding a few new elements to the TEI.},
	number = {2},
	urldate = {2023-03-17},
	journal = {Literary and Linguistic Computing},
	author = {Ore, Christian-Emil and Eide, Øyvind},
	month = jun,
	year = {2009},
	pages = {161--172},
}

@article{ciotti_tei_2014,
	title = {{TEI}, {Ontologies}, {Linked} {Open} {Data}: {Geolat} and {Beyond}},
	copyright = {For this publication a Creative Commons Attribution 4.0 International license has been granted by the author(s) who retain full copyright.},
	issn = {2162-5603},
	shorttitle = {{TEI}, {Ontologies}, {Linked} {Open} {Data}},
	url = {https://journals.openedition.org/jtei/1365},
	doi = {10.4000/jtei.1365},
	abstract = {This paper presents the rationales and the logical architecture of Geolat — Geography for Latin Literature, a project for the enrichment of Latin literature which makes use of a complex mix of TEI markup, Semantic Web technologies and formal ontologies. The purpose of Geolat is the annotation of the geographical and personal references in a corpus of Latin TEI encoded texts. These annotations are linked to a set of ontologies that give them formal semantics, and can finally be exposed the as linked open data, in order to improve the documents’ interoperability with other existing LOD and to enhance information retrieval possibilities. The paper is organized as follows: first we introduce the project in order to explain the steps needed to complete it (section 2); then we describe the ontological modeling and the TEI encoding in Geolat, by focusing on both places and persons (section 3). We then discuss the annotation data model (section 4). In conclusion, we introduce some future directions (section 5).},
	language = {en},
	number = {Issue 8},
	urldate = {2023-03-17},
	journal = {Journal of the Text Encoding Initiative},
	author = {Ciotti, Fabio and Lana, Maurizio and Tomasi, Francesca},
	month = dec,
	year = {2014},
	note = {Number: Issue 8
Publisher: Text Encoding Initiative Consortium},
	keywords = {ontology, Semantic Web, Linked Open Data, digital annotation, geotagging, personography},
	file = {Full Text PDF:files/1638/Ciotti et al. - 2014 - TEI, Ontologies, Linked Open Data Geolat and Beyo.pdf:application/pdf},
}

@article{bradley_exploring_2019,
	title = {Exploring a {Model} for the {Semantics} of {Medieval} {Legal} {Charters}},
	volume = {13},
	issn = {1753-8548},
	url = {https://www.euppublishing.com/doi/abs/10.3366/ijhac.2017.0184},
	doi = {10.3366/ijhac.2017.0184},
	abstract = {This paper describes several aspects of a formal digital semantic model that expresses some issues presented by medieval charters. Surprisingly, perhaps, this model does not deal directly with a ch...},
	number = {1-2},
	urldate = {2023-03-17},
	journal = {International Journal of Humanities and Arts Computing},
	author = {Bradley, John and Broun, Dauvit and Rio, Alice and Hammond, Matthew},
	month = oct,
	year = {2019},
	note = {Publisher: Edinburgh University Press},
	keywords = {medieval legal charters, people of Medieval Scotland, prosopography, prosopography of Anglo-Saxon England, structured historical data, the making of Charlemagne's Europe},
	pages = {136--154},
	file = {EUP Snapshot:files/1641/ijhac.2017.html:text/html;Versione inviata:files/1640/Bradley et al. - 2019 - Exploring a Model for the Semantics of Medieval Le.pdf:application/pdf},
}

@book{spadini_graph_2021,
	address = {Norderstedt},
	series = {Schriften des {Instituts} für {Dokumentologie} und {Editorik}},
	title = {Graph data-models and semantic web technologies in scholarly digital editing},
	isbn = {978-3-7543-4369-2},
	language = {en},
	number = {Band 15},
	publisher = {BoD – Books on Demand},
	editor = {Spadini, Elena and Tomasi, Francesca and Vogeler, Georg},
	year = {2021},
	file = {Spadini et al. - 2021 - Graph data-models and semantic web technologies in.pdf:files/1644/Spadini et al. - 2021 - Graph data-models and semantic web technologies in.pdf:application/pdf},
}

@book{spadini_graph_2021-1,
	address = {Norderstedt},
	series = {Schriften des {Instituts} für {Dokumentologie} und {Editorik}},
	title = {Graph data-models and semantic web technologies in scholarly digital editing},
	isbn = {978-3-7543-4369-2},
	language = {en},
	number = {Band 15},
	publisher = {BoD – Books on Demand},
	editor = {Spadini, Elena and Tomasi, Francesca and Vogeler, Georg},
	year = {2021},
	file = {Spadini et al. - 2021 - Graph data-models and semantic web technologies in.pdf:files/1649/Spadini et al. - 2021 - Graph data-models and semantic web technologies in.pdf:application/pdf},
}

@article{berners-lee_semantic_2001,
	title = {The {Semantic} {Web}},
	volume = {284},
	issn = {0036-8733},
	url = {https://www.scientificamerican.com/article/the-semantic-web},
	doi = {10.1038/scientificamerican0501-34},
	language = {en},
	number = {5},
	urldate = {2023-03-17},
	journal = {Scientific American},
	author = {Berners-Lee, Tim and Hendler, James and Lassila, Ora},
	month = may,
	year = {2001},
	pages = {34--43},
	file = {Berners-Lee et al. - 2001 - The Semantic Web.pdf:files/1651/Berners-Lee et al. - 2001 - The Semantic Web.pdf:application/pdf},
}

@article{hinkelmanns_text_2019,
	title = {Text {Graph} {Ontology}: {A} {Semantic} {Web} approach to represent genetic scholarly editions},
	shorttitle = {Text {Graph} {Ontology}},
	url = {https://uni-salzburg.elsevierpure.com/en/publications/text-graph-ontology-a-semantic-web-approach-to-represent-genetic-},
	doi = {10.5281/zenodo.3457076},
	language = {English},
	urldate = {2023-03-17},
	author = {Hinkelmanns, Peter},
	month = sep,
	year = {2019},
	file = {Snapshot:files/1654/text-graph-ontology-a-semantic-web-approach-to-represent-genetic-.html:text/html},
}

@article{neilson_reframing_2019,
	title = {Reframing marine resource management with relational ontologies and hybrid entanglements: {Fishing} for empathy between {Azorean} fishers and scientists},
	volume = {105},
	issn = {0308-597X},
	shorttitle = {Reframing marine resource management with relational ontologies and hybrid entanglements},
	url = {https://www.sciencedirect.com/science/article/pii/S0308597X18301970},
	doi = {10.1016/j.marpol.2019.04.004},
	abstract = {Springing from research on the knowledge regimes that affect small-scale fishers and scientists who engage in fisheries governance, in the Azores Islands, Portugal, this article explores how knowledge and communication practices are related to our understandings of the ocean world. It uses diverse social sciences to reframe the marine ecological crisis and re-imagine a broad mix of world views co-existing. It discusses the limitations of the ontology and epistemology born from a hegemonic way of understanding The World, which grew out of the grand narrative of modernity and the colonial power that established Europe as the centre of World History, and condemned Nature to be merely resources whose sole purpose is to serve the dominant economic system. In contrast, Southern world views acknowledge the world's ontological multiplicity, showing us the relationality, hybridity and pluriverse of socio-ecological entanglements and imaginations. Drawing upon debates amongst contemporary critical scholars and activists from an environmental sociology and political ecology perspective, this article challenges normative Northern/Western sciences and how they influence the way researchers understand marine and maritime issues. It examines the implications of ontology on the current oceanic crisis focusing specifically in marine resource management and fisheries policy. Using a diverse source of social sciences it explores the dominant assumptions of the One-World world view and suggests a framework of empathy for diverse scientists and fishers to appreciate their commonalities to better work together across otherwise seemingly insurmountable differences in ways of knowing in order to imagine and create as of yet, unimagined, governance that will support the continual wellbeing of ocean ecosystems and coastal fishing communities.},
	language = {en},
	urldate = {2023-03-18},
	journal = {Marine Policy},
	author = {Neilson, Alison Laurie and São Marcos, Rita},
	month = jul,
	year = {2019},
	keywords = {Ontology, Azores, Fisheries, Governance, Hybridity, Nature/culture divide},
	pages = {30--37},
	file = {ScienceDirect Snapshot:files/1851/S0308597X18301970.html:text/html},
}

@inproceedings{ji_research_2020,
	address = {Singapore},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Research on {Domain} {Ontology} {Modeling} and {Formal} {Expression} of {Ocean} {Flow} {Field}},
	isbn = {9789811561061},
	doi = {10.1007/978-981-15-6106-1_25},
	abstract = {With the continuous acquisition of multi-source marine data, the issue of semantic heterogeneity among ocean flow field phenomena had become the main difficulty for data sharing and analyzing of ocean flow field. For the reason that there was still no complete semantic shared knowledge system for ocean flow field at present, based on extensive reference to marine expertise and related standards, with the idea of ontology, the paper established the hierarchical system of ocean flow field domain knowledge. Through the semantic analysis of the relationship between concepts and attributes of ocean flow field domain ontology and the space-time relationship between ocean flow field instances, the paper proposed an ontology expression model based on a six-tuple, and constructed a basic structure that integrated concepts, attributes, relationships and instance sets together. And through extended modeling key words for Web Ontology Language (OWL), taking the western boundary current as an example, the paper gave the formal expression and description for semantic information based on OWL. The paper’s research could provide a theoretical basis for knowledge sharing and data mining in the field of ocean flow field.},
	language = {en},
	booktitle = {Geoinformatics in {Sustainable} {Ecosystem} and {Society}},
	publisher = {Springer},
	author = {Ji, Min and Zang, Shenglu and Sun, Yong and Li, Ting and Xu, Yaru},
	editor = {Xie, Yichun and Li, Yong and Yang, Ji and Xu, Jianhui and Deng, Yingbin},
	year = {2020},
	keywords = {OWL, Knowledge description, Ocean flow field, Ocean ontology, Semantic analysis},
	pages = {336--351},
}

@misc{wulff_pattern_2023,
	type = {chapter},
	title = {Pattern {Analysis} in {Marine} {Data} {Classification} and {Recognition}: {A} {Plea} for {Ontologies}},
	copyright = {Access limited to members},
	shorttitle = {Pattern {Analysis} in {Marine} {Data} {Classification} and {Recognition}},
	url = {https://www.igi-global.com/chapter/pattern-analysis-in-marine-data-classification-and-recognition/www.igi-global.com/chapter/pattern-analysis-in-marine-data-classification-and-recognition/316579},
	abstract = {With the advent of upcoming new patterns to handle (e.g., big data and semantic annotation), to encourage research to detect and identify objects, the development of the internet of things in the ocean requires the interconnection of all equipment (sensors) to observe the oceans. By serving as a com...},
	language = {en},
	urldate = {2023-03-18},
	journal = {Handbook of Research on Technological Advances of Library and Information Science in Industry 5.0},
	author = {Wulff, Enrique},
	year = {2023},
	doi = {10.4018/978-1-6684-4755-0.ch008},
	note = {ISBN: 9781668447550
Pages: 142-159
Publisher: IGI Global},
}

@inproceedings{zarate_lobd_2021,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {{LOBD}: {Linked} {Data} {Dashboard} for {Marine} {Biodiversity}},
	isbn = {978-3-030-84825-5},
	shorttitle = {{LOBD}},
	doi = {10.1007/978-3-030-84825-5_11},
	abstract = {In this paper we describe new features and data visualization components of Linked Open Biodiversity Data (LOBD), an application that uses Linked Data to link information extracted from Global Biodiversity Information Facility (GBIF) with different linked open datasets such as Wikidata, NCBI Taxonomy and OpenCitation, to visually present the information as a scientific dashboard. The application allows to complement information about marine Biodiversity with information not initially available. To demonstrate this, a use case is presented.},
	language = {en},
	booktitle = {Cloud {Computing}, {Big} {Data} \& {Emerging} {Topics}},
	publisher = {Springer International Publishing},
	author = {Zárate, Marcos and Buckle, Carlos},
	editor = {Naiouf, Marcelo and Rucci, Enzo and Chichizola, Franco and De Giusti, Laura},
	year = {2021},
	keywords = {Linked data, Marine biodiversity, Semantic interoperability, Wikidata},
	pages = {151--164},
}

@article{martin-rodilla_conceptualization_2019,
	title = {Conceptualization and {Non}-{Relational} {Implementation} of {Ontological} and {Epistemic} {Vagueness} of {Information} in {Digital} {Humanities}},
	volume = {6},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2227-9709},
	url = {https://www.mdpi.com/2227-9709/6/2/20},
	doi = {10.3390/informatics6020020},
	abstract = {Research in the digital humanities often involves vague information, either because our objects of study lack clearly defined boundaries, or because our knowledge about them is incomplete or hypothetical, which is especially true in disciplines about our past (such as history, archaeology, and classical studies). Most techniques used to represent data vagueness emerged from natural sciences, and lack the expressiveness that would be ideal for humanistic contexts. Building on previous work, we present here a conceptual framework based on the ConML modelling language for the expression of information vagueness in digital humanities. In addition, we propose an implementation on non-relational data stores, which are becoming popular within the digital humanities. Having clear implementation guidelines allow us to employ search engines or big data systems (commonly implemented using non-relational approaches) to handle the vague aspects of information. The proposed implementation guidelines have been validated in practice, and show how we can query a vagueness-aware system without a large penalty in analytical and processing power.},
	language = {en},
	number = {2},
	urldate = {2023-03-18},
	journal = {Informatics},
	author = {Martin-Rodilla, Patricia and Gonzalez-Perez, Cesar},
	month = jun,
	year = {2019},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {knowledge representation, conceptual modelling, ConML, digital humanities, imprecision, non-relational databases, uncertainty, vagueness},
	pages = {20},
	file = {Full Text PDF:files/1856/Martin-Rodilla e Gonzalez-Perez - 2019 - Conceptualization and Non-Relational Implementatio.pdf:application/pdf},
}

@inproceedings{bradley_combining_nodate,
	title = {Combining the {Factoid} {Model} with {TEI}: examples and conceptual challenges},
	shorttitle = {Combining the {Factoid} {Model} with {TEI}},
	url = {https://hcommons.org/deposits/item/hc:42095/},
	abstract = {The Factoid Model arose out of various prosopographies undertaken in partnerships with King’s College London’s Department of Digital Humanities (KCL DH). It first appeared in a rudimentary form in the 1990s, but in more recent times has stimulated significant interest from historians who are trying to apply formal data structures such as RDF to historical ideas. Its central idea is the factoid which has been described as “a spot in a source that says something about a person or persons.” (https://www.kcl.ac.uk/factoid-prosopography/about). By being this "spot in a source", the factoid acts as a kind of nexus, or gathering point, between the historical source, the historical persons, and other aspects of the historical society being studied: historical events, of course, but also, for example, what occupations or offices operated in that society. Perhaps because the factoid model comes out of the paradigm of highly structured data, the text itself, the “spot”, that is the factoid has not been explicitly given in any of KCL DH’s factoid prosopographies. TEI, of course, has been developed to represent things about textual sources. Since the factoid model is centered on spots in textual sources, is it possible to link the factoid concept to its text by bringing the two structural approaches together? TEI provides a “personography” approach to historical persons in the Guidelines, section 13: see a particular striking example in section 13.3.2.2 (Personal Events), but not all of the structure represented in the factoid model is demonstrated there. In this presentation have examined how factoids can be represented completely in terms of slightly extended TEI markup, drawing examples from experimental markup that has been applied to the materials in the Records of Early English Drama (London) project. We also introduce some of the conceptual and technical challenges that arise from this approach.},
	language = {en-US},
	urldate = {2023-03-18},
	author = {Bradley, John and Jakacki, Diane},
	file = {Full Text PDF:files/1858/Bradley e Jakacki - Combining the Factoid Model with TEI examples and.pdf:application/pdf},
}

@article{bleeker_agree_2019,
	title = {Agree to disagree: {Modelling} co-existing scholarly perspectives on literary text},
	volume = {34},
	issn = {2055-7671},
	shorttitle = {Agree to disagree},
	url = {https://doi.org/10.1093/llc/fqz061},
	doi = {10.1093/llc/fqz061},
	abstract = {This essay addresses two open challenge in the domain of digital scholarly editing: (1) formally defining the meaning of markup, and (2) allowing the reuse and exchange of textual data through a distributed editorial workflow that allows the editing of texts from multiple, diverging yet co-existing perspectives. We argue that successfully addressing these issues would promote the distribution and exchange of scholarly knowledge, on a technical as well as a theoretical level. The essay introduces ongoing work on a new data model for text called ‘TAG’ (Text-as-Graph) and its reference implementation ‘Alexandria’. The essay outlines how TAG, based on a hypergraph for text, can improve the modeling of complex literary texts, and how Alexandria supports the exchange of markup files in a way that sustains scholarly discourse. We discuss three components of TAG: first, the markup technology stack allows for the formal definition of the meaning of markup (‘markup semantics’); secondly, users can add multiple layers of markup that each represent an alternative perspective on text; and finally the editorial workflow is set up in a git-like distributed version management system. As a result, the TAG model provides for the synthesis of dispersed scholarly practices and the advancement of academic discourse.},
	number = {4},
	urldate = {2023-03-18},
	journal = {Digital Scholarship in the Humanities},
	author = {Bleeker, Elli and Buitendijk, Bram and Haentjens Dekker, Ronald},
	month = dec,
	year = {2019},
	pages = {844--854},
	file = {Full text:files/1860/Bleeker et al. - 2019 - Agree to disagree Modelling co-existing scholarly.pdf:application/pdf},
}

@article{cursi_linking_2022,
	title = {Linking external knowledge to heritage {BIM}},
	volume = {141},
	issn = {0926-5805},
	url = {https://www.sciencedirect.com/science/article/pii/S092658052200317X},
	doi = {10.1016/j.autcon.2022.104444},
	abstract = {The application of the Building Information Modelling (BIM) process to Built Heritage (HBIM) is a growing practice in processes and activities aimed at the investigation, documentation, and conservation of architectural heritage. However, it still raises some questions, such as the compatibility between the formalisation of information in the BIM model; and what limitations are inherent in current software implementations to establish a connection with external resources. On this basis, this paper aims at reviewing which methods are currently experimented to improve the level of semantic enrichment and to extend the knowledge representation domain offered today by the most common BIM authoring tools in an HBIM process. The analysis distinguishes two approaches that differ in the role played by external databases and the objectives pursued. Conclusions were drawn highlighting common needs for overcoming technical and conceptual limitations imposed by the use of proprietary BIM authoring tools, and differences in application perspectives and effectiveness.},
	language = {en},
	urldate = {2023-03-18},
	journal = {Automation in Construction},
	author = {Cursi, Stefano and Martinelli, Letizia and Paraciani, Nicolò and Calcerano, Filippo and Gigliarelli, Elena},
	month = sep,
	year = {2022},
	keywords = {BIM, Built heritage, HBIM, Interoperability, Ontologies, Database design, Semantic-enrichment},
	pages = {104444},
	file = {ScienceDirect Snapshot:files/1862/S092658052200317X.html:text/html},
}

@misc{noauthor_cnr_nodate,
	title = {{CNR} {ExploRA}},
	url = {https://publications.cnr.it/doc/434135},
	urldate = {2023-03-18},
	file = {CNR ExploRA:files/1864/434135.html:text/html},
}

@article{beretta_nbspchallenge_2021,
	title = {A\&nbsp;challenge for historical research: {Making} data {FAIR} using a collaborative ontology management environment ({OntoME})},
	volume = {12},
	issn = {1570-0844},
	shorttitle = {A\&nbsp;challenge for historical research},
	url = {https://content.iospress.com/articles/semantic-web/sw200416},
	doi = {10.3233/SW-200416},
	abstract = {This paper addresses the issue of interoperability of data generated by historical research and heritage institutions in order to make them re-usable for new research agendas according to the FAIR principles. After introducing the symogih.org project},
	language = {en},
	number = {2},
	urldate = {2023-03-18},
	journal = {Semantic Web},
	author = {Beretta, Francesco},
	month = jan,
	year = {2021},
	note = {Publisher: IOS Press},
	pages = {279--294},
	file = {Full Text PDF:files/1866/Beretta - 2021 - A&nbsp\;challenge for historical research Making d.pdf:application/pdf},
}

@article{smith_aboutness_2015,
	title = {Aboutness: {Towards} {Foundations} for the {Information} {Artifact} {Ontology}},
	abstract = {The Information Artifact Ontology (IAO) was created to serve as a domain‐neutral resource for the representation of types of information content entities (ICEs) such as documents, data‐bases, and digital images. We identify a series of problems with the current version of the IAO and suggest solutions designed to advance our understanding of the relations between ICEs and associated cognitive representations in the minds of human subjects. This requires embedding IAO in a larger framework of ontologies, including most importantly the Mental Functioning Ontology (MFO). It also requires a careful treatment of the aboutness relations between ICEs and associated cognitive representations and their targets in reality.},
	language = {en},
	author = {Smith, Barry and Ceusters, Werner},
	year = {2015},
	file = {Smith e Ceusters - 2015 - Aboutness Towards Foundations for the Information.pdf:files/1867/Smith e Ceusters - 2015 - Aboutness Towards Foundations for the Information.pdf:application/pdf},
}

@article{schwartz_modeling_2022,
	title = {Modeling a {Born}-{Digital} {Factoid} {Prosopography} using the {TEI} and {Linked} {Data}},
	copyright = {For this publication a Creative Commons Attribution 4.0 International license has been granted by the author(s) who retain full copyright.},
	issn = {2162-5603},
	url = {https://journals.openedition.org/jtei/3979},
	doi = {10.4000/jtei.3979},
	abstract = {Although the TEI has traditionally been used for encoding text, its combination of structured and semi-structured data has made it a compelling choice for born-digital, linked-data resources as well. Our intent here is to demonstrate the advantages it offers for digital prosopographies along with a model that can be used for them. Syriac Persons, Events, and Relations (SPEAR) is a born-digital prosopography project in the field of Syriac studies. Where traditional prosopographies focused on prose descriptions of individual persons of significance, SPEAR follows recent developments in research methodologies that instead produce prosopographical factoids. Factoids are structured data about persons drawn from the analysis of historical texts. Most factoid prosopographies use relational databases to model data. Instead, SPEAR uses a customized TEI schema to model factoids that can be queried and visualized in an XML database as well as serialized in HTML for human viewers and in RDF for data sharing. The TEI’s provisions for structured and semi-structured data make it ideal for encoding data from heterogeneous historical source material. Moreover, its linking capabilities connect SPEAR data to related data sets. By modeling prosopographical factoids, and not the source texts themselves, SPEAR offers an example of how a born-digital, data-oriented approach to using the TEI can circumvent some of the challenges posed by the tree structure of XML. It also disrupts traditional understandings of data and stand-off markup through combining linked open data approaches with the use of the TEI.},
	language = {en},
	urldate = {2023-03-18},
	journal = {Journal of the Text Encoding Initiative},
	author = {Schwartz, Daniel L. and Gibson, Nathan P. and Torabi, Katayoun},
	month = mar,
	year = {2022},
	note = {Publisher: Text Encoding Initiative Consortium},
	keywords = {Linked Open Data, prosopography, factoids, stand-off markup, Syriac studies},
	file = {Full Text PDF:files/1870/Schwartz et al. - 2022 - Modeling a Born-Digital Factoid Prosopography usin.pdf:application/pdf},
}

@article{pasin_factoid-based_2015,
	title = {Factoid-based prosopography and computer ontologies: towards an integrated approach},
	volume = {30},
	issn = {2055-7671},
	shorttitle = {Factoid-based prosopography and computer ontologies},
	url = {https://doi.org/10.1093/llc/fqt037},
	doi = {10.1093/llc/fqt037},
	abstract = {Structured Prosopography provides a formal model for representing prosopography: a branch of historical research that traditionally has focused on the identification of people that appear in historical sources. Since the 1990s, KCL’s Department of Digital Humanities has been involved in the development of structured prosopographical databases using a general ‘factoid-oriented’ model of structure that links people to the information about them via spots in primary sources that assert that information. Recent developments, particularly the World Wide Web, and its related technologies around the Semantic Web, have promoted the possibility to both interconnecting dispersed data, and allowing it to be queried semantically. To the purpose of making available our prosopographical databases on the Semantic Web, in this article we review the principles behind our established factoid-based model and reformulate it using a more interoperable approach, based on knowledge representation principles and formal ontologies. In particular, we are going to focus primarily on a high-level semantic analysis of the factoid notion, on its relation to other cultural heritage standards such as CIDOC-CRM, and on the modularity and extensibility of the proposed solutions.},
	number = {1},
	urldate = {2023-03-18},
	journal = {Digital Scholarship in the Humanities},
	author = {Pasin, Michele and Bradley, John},
	month = apr,
	year = {2015},
	pages = {86--97},
	file = {Snapshot:files/1872/352888.html:text/html},
}

@article{bradley_exploring_2019-1,
	title = {Exploring a {Model} for the {Semantics} of {Medieval} {Legal} {Charters}},
	volume = {13},
	issn = {1753-8548},
	url = {https://www.euppublishing.com/doi/abs/10.3366/ijhac.2017.0184},
	doi = {10.3366/ijhac.2017.0184},
	abstract = {This paper describes several aspects of a formal digital semantic model that expresses some issues presented by medieval charters. Surprisingly, perhaps, this model does not deal directly with a ch...},
	number = {1-2},
	urldate = {2023-03-18},
	journal = {International Journal of Humanities and Arts Computing},
	author = {Bradley, John and Broun, Dauvit and Rio, Alice and Hammond, Matthew},
	month = oct,
	year = {2019},
	note = {Publisher: Edinburgh University Press},
	keywords = {medieval legal charters, people of Medieval Scotland, prosopography, prosopography of Anglo-Saxon England, structured historical data, the making of Charlemagne's Europe},
	pages = {136--154},
	file = {Versione inviata:files/1874/Bradley et al. - 2019 - Exploring a Model for the Semantics of Medieval Le.pdf:application/pdf},
}

@techreport{bodard_modeling_2021,
	title = {Modeling {Epigraphy} with an {Ontology}},
	url = {https://zenodo.org/record/4639508},
	abstract = {This document is maintained by the Ontology Working Group of Epigraphy.info. (https://epigraphy-info.github.io/epigraphy-info/) Any request or contribution should be made via the Epigraphic Ontology Mailing List of the Epigraphic Ontology WG {\textless}epont@googlegroups.com{\textgreater} Contributors are listed alphabetically. Not all listed contributors have confirmed.},
	urldate = {2023-03-19},
	institution = {Zenodo},
	author = {Bodard and Cayless and Cenati and Cooley and Elliott and Evangelisti and Felicetti and Granados and Grieshaber and Gruber and Hershkowitz and Hill and Kiiskinen and Kollatz and Levivier and Liuzzo and Luciani and Mannocci and Mataix and Murano and Murphy and Mylonas and Prag and Razanajao and Stoyanova and Tsolakis and Tupman and Vagionakis and Vitale and Weise},
	month = mar,
	year = {2021},
	doi = {10.5281/zenodo.4639508},
	keywords = {ontology, Linked Data, epigraphy, model description, RDF},
	file = {Zenodo Full Text PDF:files/1876/Bodard et al. - 2021 - Modeling Epigraphy with an Ontology.pdf:application/pdf},
}

@article{soldatova_ontology_2006,
	title = {An ontology of scientific experiments},
	volume = {3},
	url = {https://royalsocietypublishing.org/doi/abs/10.1098/rsif.2006.0134},
	doi = {10.1098/rsif.2006.0134},
	abstract = {The formal description of experiments for efficient analysis, annotation and sharing of results is a fundamental part of the practice of science. Ontologies are required to achieve this objective. A few subject-specific ontologies of experiments currently exist. However, despite the unity of scientific experimentation, no general ontology of experiments exists. We propose the ontology EXPO to meet this need. EXPO links the SUMO (the Suggested Upper Merged Ontology) with subject-specific ontologies of experiments by formalizing the generic concepts of experimental design, methodology and results representation. EXPO is expressed in the W3C standard ontology language OWL-DL. We demonstrate the utility of EXPO and its ability to describe different experimental domains, by applying it to two experiments: one in high-energy physics and the other in phylogenetics. The use of EXPO made the goals and structure of these experiments more explicit, revealed ambiguities, and highlighted an unexpected similarity. We conclude that, EXPO is of general value in describing experiments and a step towards the formalization of science.},
	number = {11},
	urldate = {2023-03-19},
	journal = {Journal of The Royal Society Interface},
	author = {Soldatova, Larisa N and King, Ross D},
	month = jun,
	year = {2006},
	note = {Publisher: Royal Society},
	keywords = {ontology, artificial intelligence, metadata, annotation, formalization},
	pages = {795--803},
	file = {Full text:files/1878/Soldatova e King - 2006 - An ontology of scientific experiments.pdf:application/pdf},
}

@article{hettne_structuring_2014,
	title = {Structuring research methods and data with the research object model: genomics workflows as a case study},
	volume = {5},
	issn = {2041-1480},
	shorttitle = {Structuring research methods and data with the research object model},
	url = {https://doi.org/10.1186/2041-1480-5-41},
	doi = {10.1186/2041-1480-5-41},
	abstract = {One of the main challenges for biomedical research lies in the computer-assisted integrative study of large and increasingly complex combinations of data in order to understand molecular mechanisms. The preservation of the materials and methods of such computational experiments with clear annotations is essential for understanding an experiment, and this is increasingly recognized in the bioinformatics community. Our assumption is that offering means of digital, structured aggregation and annotation of the objects of an experiment will provide necessary meta-data for a scientist to understand and recreate the results of an experiment. To support this we explored a model for the semantic description of a workflow-centric Research Object (RO), where an RO is defined as a resource that aggregates other resources, e.g., datasets, software, spreadsheets, text, etc. We applied this model to a case study where we analysed human metabolite variation by workflows.},
	language = {en},
	number = {1},
	urldate = {2023-03-19},
	journal = {Journal of Biomedical Semantics},
	author = {Hettne, Kristina M. and Dharuri, Harish and Zhao, Jun and Wolstencroft, Katherine and Belhajjame, Khalid and Soiland-Reyes, Stian and Mina, Eleni and Thompson, Mark and Cruickshank, Don and Verdes-Montenegro, Lourdes and Garrido, Julian and de Roure, David and Corcho, Oscar and Klyne, Graham and van Schouwen, Reinout and ‘t Hoen, Peter A. C. and Bechhofer, Sean and Goble, Carole and Roos, Marco},
	month = sep,
	year = {2014},
	keywords = {Digital libraries, Genome wide association study, Scientific workflows, Semantic web models},
	pages = {41},
	file = {Full Text PDF:files/1880/Hettne et al. - 2014 - Structuring research methods and data with the res.pdf:application/pdf},
}

@article{krystek_research_2017,
	title = {{RESEARCH} {OBJECT} {AS} {MECHANISM} {FOR} {ENSURING} {RESEARCH} {EXPERIMENT} {REPRODUCIBILITY} {WITHIN} {VIRTUAL} {RESEARCH} {ENVIRONMENT}},
	volume = {21},
	copyright = {Copyright (c) 2021},
	issn = {1428-6394},
	url = {https://journal.mostwiedzy.pl/TASKQuarterly/index},
	doi = {10.17466/tq2017/21.4/x},
	abstract = {A Research Object (RO) is defined as a semantically rich aggregation of resources that bundles together essential information relating to experiments and investigations. This information is not limited merely to the data used and the methods employed to produce and analyze such data, but it may also include the people involved in the investigation as well as other important metadata that describe the characteristics, inter-dependencies, context and dynamics of the aggregated resources. As such, a research object can encapsulate scientific knowledge and provide a mechanism for sharing and discovering assets of reusable research and scientific knowledge within and across relevant communities, and in a way that supports reliability and reproducibility of investigation results. While there are no pre-defined constraints related to the type of resources a research object can contain, the following usually apply in the context of scientific research: data used and results produced; methods employed to produce and analyze data; scientific workflows implementing such methods; provenance and settings; people involved in the investigation; annotations about these resources, which are essential to the understanding and interpretation of the scientific outcomes captured by a research object. The example research object contains a workflow, input data and results, along with a paper that presents the results and links to the investigators responsible. Annotations on each of the resources (and on the research object itself) provide additional information and characterize, e.g. the provenance of the results. Therefore, exploitation of the RO model should be considered as a way to provide additional reliability and reproducibility of the research. The concept of the RO was introduced to the environment created in the EVER-EST project in the form of Virtual Research Environment (VRE). a group of Earth Scientists, who are observing, analyzing and modeling processes that take place on land and see, was examined against their needs and expectations about the possible improvements in their scientific work. The results show that scientist expectations are focused on knowledge sharing and reuse, and new forms of scholarly communications beyond pdf articles as supporting tools of knowledge cross-fertilization between their members. The Research Object concept seems a natural answer for these needs. However, the model, in order to be sufficient and usable, must become a part of the working environment and needs to be integrated with the actual tools. Therefore, great efforts have been undertaken to create a generic, technical solution – VRE, which implements the expected functionalities. In this article we present a concept of the VRE as a tool that takes advantage of the Research Object model in order to integrate and simplify the information exchange, as well as persist, share and discover assets of the reusable research. Moreover, we are presenting example scenarios of the VRE usage in the four different Earth Science domains.},
	language = {en},
	number = {4},
	urldate = {2023-03-19},
	journal = {TASK Quarterly},
	author = {Krystek, Marcin and Mazurek, Cezary and Palma, Raul and Pukacki, Juliusz and Gomez-Perez, Jose Manuel},
	month = dec,
	year = {2017},
	note = {Number: 4},
	keywords = {evolution},
	pages = {379--389},
	file = {Full Text PDF:files/1882/Krystek et al. - 2017 - RESEARCH OBJECT AS MECHANISM FOR ENSURING RESEARCH.pdf:application/pdf},
}

@article{mina_nanopublications_2015,
	title = {Nanopublications for exposing experimental data in the life-sciences: a {Huntington}’s {Disease} case study},
	volume = {6},
	issn = {2041-1480},
	shorttitle = {Nanopublications for exposing experimental data in the life-sciences},
	url = {https://doi.org/10.1186/2041-1480-6-5},
	doi = {10.1186/2041-1480-6-5},
	abstract = {Data from high throughput experiments often produce far more results than can ever appear in the main text or tables of a single research article. In these cases, the majority of new associations are often archived either as supplemental information in an arbitrary format or in publisher-independent databases that can be difficult to find. These data are not only lost from scientific discourse, but are also elusive to automated search, retrieval and processing. Here, we use the nanopublication model to make scientific assertions that were concluded from a workflow analysis of Huntington’s Disease data machine-readable, interoperable, and citable. We followed the nanopublication guidelines to semantically model our assertions as well as their provenance metadata and authorship. We demonstrate interoperability by linking nanopublication provenance to the Research Object model. These results indicate that nanopublications can provide an incentive for researchers to expose data that is interoperable and machine-readable for future use and preservation for which they can get credits for their effort. Nanopublications can have a leading role into hypotheses generation offering opportunities to produce large-scale data integration.},
	language = {en},
	number = {1},
	urldate = {2023-03-19},
	journal = {Journal of Biomedical Semantics},
	author = {Mina, Eleni and Thompson, Mark and Kaliyaperumal, Rajaram and Zhao, Jun and der Horst, van Eelke and Tatum, Zuotian and Hettne, Kristina M. and Schultes, Erik A. and Mons, Barend and Roos, Marco},
	month = feb,
	year = {2015},
	keywords = {Interoperability, Data integration, Huntington’s disease, Nanopublication, Provenance, Research object, Workflows},
	pages = {5},
	file = {Full Text PDF:files/1884/Mina et al. - 2015 - Nanopublications for exposing experimental data in.pdf:application/pdf},
}

@misc{belhajjame_research_2014,
	title = {The {Research} {Object} {Suite} of {Ontologies}: {Sharing} and {Exchanging} {Research} {Data} and {Methods} on the {Open} {Web}},
	shorttitle = {The {Research} {Object} {Suite} of {Ontologies}},
	url = {http://arxiv.org/abs/1401.4307},
	doi = {10.48550/arXiv.1401.4307},
	abstract = {Research in life sciences is increasingly being conducted in a digital and online environment. In particular, life scientists have been pioneers in embracing new computational tools to conduct their investigations. To support the sharing of digital objects produced during such research investigations, we have witnessed in the last few years the emergence of specialized repositories, e.g., DataVerse and FigShare. Such repositories provide users with the means to share and publish datasets that were used or generated in research investigations. While these repositories have proven their usefulness, interpreting and reusing evidence for most research results is a challenging task. Additional contextual descriptions are needed to understand how those results were generated and/or the circumstances under which they were concluded. Because of this, scientists are calling for models that go beyond the publication of datasets to systematically capture the life cycle of scientific investigations and provide a single entry point to access the information about the hypothesis investigated, the datasets used, the experiments carried out, the results of the experiments, the people involved in the research, etc. In this paper we present the Research Object (RO) suite of ontologies, which provide a structured container to encapsulate research data and methods along with essential metadata descriptions. Research Objects are portable units that enable the sharing, preservation, interpretation and reuse of research investigation results. The ontologies we present have been designed in the light of requirements that we gathered from life scientists. They have been built upon existing popular vocabularies to facilitate interoperability. Furthermore, we have developed tools to support the creation and sharing of Research Objects, thereby promoting and facilitating their adoption.},
	urldate = {2023-03-19},
	publisher = {arXiv},
	author = {Belhajjame, Khalid and Zhao, Jun and Garijo, Daniel and Hettne, Kristina and Palma, Raul and Corcho, Óscar and Gómez-Pérez, José-Manuel and Bechhofer, Sean and Klyne, Graham and Goble, Carole},
	month = feb,
	year = {2014},
	note = {arXiv:1401.4307 [cs]},
	keywords = {Computer Science - Digital Libraries},
	file = {arXiv Fulltext PDF:files/1887/Belhajjame et al. - 2014 - The Research Object Suite of Ontologies Sharing a.pdf:application/pdf;arXiv.org Snapshot:files/1888/1401.html:text/html},
}

@article{bechhofer_research_2010,
	title = {Research {Objects}: {Towards} {Exchange} and {Reuse} of {Digital} {Knowledge}},
	copyright = {2010 The Author(s)},
	issn = {1756-0357},
	shorttitle = {Research {Objects}},
	url = {https://www.nature.com/articles/npre.2010.4626.1},
	doi = {10.1038/npre.2010.4626.1},
	abstract = {What will researchers be publishing in the future? Whilst there is little question that the Web will be the publication platform, as scholars move away from paper towards digital content, there is a need for mechanisms that support the production of self-contained units of knowledge and facilitate the publication, sharing and reuse of such entities. In this paper we discuss the notion of research objects, semantically rich aggregations of resources, that can possess some scientific intent or support some research objective. We present a number of principles that we expect such objects and their associated services to follow.},
	language = {en},
	urldate = {2023-03-19},
	journal = {Nature Precedings},
	author = {Bechhofer, Sean and De Roure, David and Gamble, Matthew and Goble, Carole and Buchan, Iain},
	month = jul,
	year = {2010},
	note = {Publisher: Nature Publishing Group},
	keywords = {general, Life Sciences},
	pages = {1--1},
	file = {Full Text PDF:files/1890/Bechhofer et al. - 2010 - Research Objects Towards Exchange and Reuse of Di.pdf:application/pdf},
}

@article{garcia-silva_enabling_2019,
	title = {Enabling {FAIR} research in {Earth} {Science} through research objects},
	volume = {98},
	issn = {0167-739X},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X18314638},
	doi = {10.1016/j.future.2019.03.046},
	abstract = {Data-intensive science communities are progressively adopting FAIR practices that enhance the visibility of scientific breakthroughs and enable reuse. At the core of this movement, research objects contain and describe scientific information and resources in a way compliant with the FAIR principles and sustain the development of key infrastructure and tools. This paper provides an account of the challenges, experiences and solutions involved in the adoption of FAIR around research objects over several Earth Science disciplines. During this journey, our work has been comprehensive, with outcomes including: an extended research object model adapted to the needs of earth scientists; the provisioning of digital object identifiers (DOI) to enable persistent identification and to give due credit to authors; the generation of content-based, semantically rich, research object metadata through natural language processing, enhancing visibility and reuse through recommendation systems and third-party search engines; and various types of checklists that provide a compact representation of research object quality as a key enabler of scientific reuse. All these results have been integrated in ROHub, a platform that provides research object management functionality to a wealth of applications and interfaces across different scientific communities. To monitor and quantify the community uptake of research objects, we have defined indicators and obtained measures via ROHub that are also discussed herein.},
	language = {en},
	urldate = {2023-03-19},
	journal = {Future Generation Computer Systems},
	author = {Garcia-Silva, Andres and Gomez-Perez, Jose Manuel and Palma, Raul and Krystek, Marcin and Mantovani, Simone and Foglini, Federica and Grande, Valentina and De Leo, Francesco and Salvi, Stefano and Trasatti, Elisa and Romaniello, Vito and Albani, Mirko and Silvagni, Cristiano and Leone, Rosemarie and Marelli, Fulvio and Albani, Sergio and Lazzarini, Michele and Napier, Hazel J. and Glaves, Helen M. and Aldridge, Timothy and Meertens, Charles and Boler, Fran and Loescher, Henry W. and Laney, Christine and Genazzio, Melissa A. and Crawl, Daniel and Altintas, Ilkay},
	month = sep,
	year = {2019},
	keywords = {Earth Science, FAIR principles, Research infrastructure, Research objects, Semantic technologies},
	pages = {550--564},
	file = {ScienceDirect Snapshot:files/1892/S0167739X18314638.html:text/html;Versione inviata:files/1893/Garcia-Silva et al. - 2019 - Enabling FAIR research in Earth Science through re.pdf:application/pdf},
}

@inproceedings{carragain_lightweight_2019,
	title = {A lightweight approach to research object data packaging},
	url = {https://research.manchester.ac.uk/en/publications/a-lightweight-approach-to-research-object-data-packaging},
	doi = {10.5281/zenodo.3250687},
	language = {English},
	urldate = {2023-03-19},
	author = {Carragáin, Eoghan Ó and Goble, Carole and Sefton, Peter and Soiland-Reyes, Stian},
	month = jun,
	year = {2019},
	file = {Full Text PDF:files/1895/Carragáin et al. - 2019 - A lightweight approach to research object data pac.pdf:application/pdf},
}

@article{gonzalez-beltran_peer-reviewed_2015,
	title = {From {Peer}-{Reviewed} to {Peer}-{Reproduced} in {Scholarly} {Publishing}: {The} {Complementary} {Roles} of {Data} {Models} and {Workflows} in {Bioinformatics}},
	volume = {10},
	issn = {1932-6203},
	shorttitle = {From {Peer}-{Reviewed} to {Peer}-{Reproduced} in {Scholarly} {Publishing}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0127612},
	doi = {10.1371/journal.pone.0127612},
	abstract = {Motivation Reproducing the results from a scientific paper can be challenging due to the absence of data and the computational tools required for their analysis. In addition, details relating to the procedures used to obtain the published results can be difficult to discern due to the use of natural language when reporting how experiments have been performed. The Investigation/Study/Assay (ISA), Nanopublications (NP), and Research Objects (RO) models are conceptual data modelling frameworks that can structure such information from scientific papers. Computational workflow platforms can also be used to reproduce analyses of data in a principled manner. We assessed the extent by which ISA, NP, and RO models, together with the Galaxy workflow system, can capture the experimental processes and reproduce the findings of a previously published paper reporting on the development of SOAPdenovo2, a de novo genome assembler. Results Executable workflows were developed using Galaxy, which reproduced results that were consistent with the published findings. A structured representation of the information in the SOAPdenovo2 paper was produced by combining the use of ISA, NP, and RO models. By structuring the information in the published paper using these data and scientific workflow modelling frameworks, it was possible to explicitly declare elements of experimental design, variables, and findings. The models served as guides in the curation of scientific information and this led to the identification of inconsistencies in the original published paper, thereby allowing its authors to publish corrections in the form of an errata. Availability SOAPdenovo2 scripts, data, and results are available through the GigaScience Database: http://dx.doi.org/10.5524/100044; the workflows are available from GigaGalaxy: http://galaxy.cbiit.cuhk.edu.hk; and the representations using the ISA, NP, and RO models are available through the SOAPdenovo2 case study website http://isa-tools.github.io/soapdenovo2/. Contact: philippe.rocca-serra@oerc.ox.ac.uk and susanna-assunta.sansone@oerc.ox.ac.uk.},
	language = {en},
	number = {7},
	urldate = {2023-03-19},
	journal = {PLOS ONE},
	author = {González-Beltrán, Alejandra and Li, Peter and Zhao, Jun and Avila-Garcia, Maria Susana and Roos, Marco and Thompson, Mark and Horst, Eelke van der and Kaliyaperumal, Rajaram and Luo, Ruibang and Lee, Tin-Lap and Lam, Tak-wah and Edmunds, Scott C. and Sansone, Susanna-Assunta and Rocca-Serra, Philippe},
	month = jul,
	year = {2015},
	note = {Publisher: Public Library of Science},
	keywords = {Ontologies, Animal genomics, Computer software, Experimental design, Genomics, Human genomics, Invertebrate genomics, Reproducibility},
	pages = {e0127612},
	file = {Full Text PDF:files/1897/González-Beltrán et al. - 2015 - From Peer-Reviewed to Peer-Reproduced in Scholarly.pdf:application/pdf},
}

@misc{gonzalez-beltran_peer-reviewed_2014,
	title = {From peer-reviewed to peer-reproduced: a role for data standards, models and computational workflows in scholarly publishing},
	copyright = {© 2014, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	shorttitle = {From peer-reviewed to peer-reproduced},
	url = {https://www.biorxiv.org/content/10.1101/011973v1},
	doi = {10.1101/011973},
	abstract = {Motivation: Reproducing the results from a scientific paper can be challenging due to the absence of data and the computational tools required for their analysis. In addition, details relating to the procedures used to obtain the published results can be difficult to discern due to the use of natural language when reporting how experiments have been performed. The Investigation/Study/Assay (ISA), Nanopublications (NP) and Research Objects (RO) models are conceptual data modelling frameworks that can structure such information from scientific papers. Computational workflow platforms can also be used to reproduce analyses of data in a principled manner. We assessed the extent by which ISA, NP and RO models, together with the Galaxy workflow system, can capture the experimental processes and reproduce the findings of a previously published paper reporting on the development of SOAPdenovo2, a de novo genome assembler.
Results: Executable workflows were developed using Galaxy which reproduced results that were consistent with the published findings. A structured representation of the information in the SOAPdenovo2 paper was produced by combining the use of ISA, NP and RO models. By structuring the information in the published paper using these data and scientific workflow modelling frameworks, it was possible to explicitly declare elements of experimental design, variables and findings. The models served as guides in the curation of scientific information and this led to the identification of inconsistencies in the original published paper, thereby allowing its authors to publish corrections in the form of an errata.
Availability: SOAPdenovo2 scripts, data and results are available through the GigaScience Database: http://dx.doi.org/10.5524/100044; the workflows are available from GigaGalaxy: http://galaxy.cbiit.cuhk.edu.hk; and the representations using the ISA, NP and RO models are available through the SOAPdenovo2 case study website http://isa-tools.github.io/soapdenovo2/. Contact: philippe.rocca-serra\{at\}oerc.ox.ac.uk and susanna.assunta-sansone\{at\}oerc.ox.ac.uk},
	language = {en},
	urldate = {2023-03-19},
	publisher = {bioRxiv},
	author = {González-Beltrán, Alejandra N. and Li, Peter and Zhao, Jun and Avila-Garcia, Maria Susana and Roos, Marco and Thompson, Mark and Horst, Eelke van der and Kaliyaperumal, Rajaram and Luo, Ruibang and Lee, Tin-Lap and Lam, Tak-wah and Edmunds, Scott C. and Sansone, Susanna-Assunta and Rocca-Serra, Philippe},
	month = dec,
	year = {2014},
	note = {Pages: 011973
Section: New Results},
	file = {Full Text PDF:files/1899/González-Beltrán et al. - 2014 - From peer-reviewed to peer-reproduced a role for .pdf:application/pdf},
}

@inproceedings{gomez-perez_towards_2017,
	title = {Towards a {Human}-{Machine} {Scientific} {Partnership} {Based} on {Semantically} {Rich} {Research} {Objects}},
	doi = {10.1109/eScience.2017.40},
	abstract = {A research object is a single information unit encapsulating all the knowledge relevant to a particular scientific investigation, their associated metadata and the context where such resources were produced and came into play. Aimed at enhancing the preservation, reuse and scholarly communication of data-intensive science, research objects are both technical and social artifacts that represent a partnership between scientific communities and the computational support required in nowadays science. In this paper, we explore such partnership, identifying the lack of appropriate machine-readable metadata as one of its main inhibitors, and address the semantic enrichment of research objects as one key aspect towards its establishment. Focused on the specific needs of Earth Science communities, we propose extensions to research object representation models and present novel methods and tools to enrich research object metadata through automatic means. Finally, we validate the approach through the implementation of a recommender system that exploits the resulting metadata to facilitate research object discovery and reuse, enabling humans and machines to work together and accelerate the research life cycle.},
	booktitle = {2017 {IEEE} 13th {International} {Conference} on e-{Science} (e-{Science})},
	author = {Gomez-Perez, Jose Manuel and Palma, Raul and Garcia-Silva, Andres},
	month = oct,
	year = {2017},
	keywords = {Semantics, Ontologies, Metadata, Earth, earth science, knowledge sharing and reuse, recommender system, research objects, scientific knowledge preservation, semantic enrichment, Vocabulary},
	pages = {266--275},
	file = {IEEE Xplore Abstract Record:files/1901/8109145.html:text/html},
}

@inproceedings{gomez-perez_when_2013,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {When {History} {Matters} - {Assessing} {Reliability} for the {Reuse} of {Scientific} {Workflows}},
	isbn = {978-3-642-41338-4},
	doi = {10.1007/978-3-642-41338-4_6},
	abstract = {Scientific workflows play an important role in computational research as essential artifacts for communicating the methods used to produce research findings. We are witnessing a growing number of efforts that treat workflows as first-class artifacts for sharing and exchanging scientific knowledge, either as part of scholarly articles or as stand-alone objects. However, workflows are not born to be reliable, which can seriously damage their reusability and trustworthiness as knowledge exchange instruments. Scientific workflows are commonly subject to decay, which consequently undermines their reliability over their lifetime. The reliability of workflows can be notably improved by advocating scientists to preserve a minimal set of information that is essential to assist the interpretations of these workflows and hence improve their potential for reproducibility and reusability. In this paper we show how, by measuring and monitoring the completeness and stability of scientific workflows over time we are able to provide scientists with a measure of their reliability, supporting the reuse of trustworthy scientific knowledge.},
	language = {en},
	booktitle = {The {Semantic} {Web} – {ISWC} 2013},
	publisher = {Springer},
	author = {Gómez-Pérez, José Manuel and García-Cuesta, Esteban and Garrido, Aleix and Ruiz, José Enrique and Zhao, Jun and Klyne, Graham},
	editor = {Alani, Harith and Kagal, Lalana and Fokoue, Achille and Groth, Paul and Biemann, Chris and Parreira, Josiane Xavier and Aroyo, Lora and Noy, Natasha and Welty, Chris and Janowicz, Krzysztof},
	year = {2013},
	keywords = {Reliability Score, Research Object, Scholarly Article, Stability Score, Virtual Observatory},
	pages = {81--97},
	file = {Full Text PDF:files/1904/Gómez-Pérez et al. - 2013 - When History Matters - Assessing Reliability for t.pdf:application/pdf},
}

@inproceedings{euzenat_beyond_2022,
	address = {New York, NY, USA},
	series = {{WWW} '22},
	title = {Beyond {Reproduction}, {Experiments} want to be {Understood}},
	isbn = {978-1-4503-9130-6},
	url = {https://dl.acm.org/doi/10.1145/3487553.3524676},
	doi = {10.1145/3487553.3524676},
	abstract = {The content of experiments must be semantically described. This topic has already been largely covered. However, some neglected benefits of such an approach provide more arguments in favour of scientific knowledge graphs. Beyond being searchable through flat metadata, a knowledge graph of experiment descriptions may be able to provide answers to scientific and methodological questions. This includes identifying non experimented conditions or retrieving specific techniques used in experiments. In turn, this is useful for researchers as this information can be used for repurposing experiments, checking claimed results or performing meta-analyses.},
	urldate = {2023-03-19},
	booktitle = {Companion {Proceedings} of the {Web} {Conference} 2022},
	publisher = {Association for Computing Machinery},
	author = {Euzenat, Jérôme},
	month = aug,
	year = {2022},
	keywords = {semantic technologies, e-science, scientific knowledge graphs, semantic experiment description},
	pages = {774--778},
	file = {Full Text PDF:files/1906/Euzenat - 2022 - Beyond Reproduction, Experiments want to be Unders.pdf:application/pdf},
}

@inproceedings{antonetti_collezioni_2019,
	title = {Collezioni di calchi epigrafici: una nuova risorsa digitale},
	shorttitle = {Collezioni di calchi epigrafici},
	url = {https://shs.hal.science/halshs-02444625},
	doi = {10.30687/Axon/2532-6848/2019/02/004},
	abstract = {T},
	language = {it},
	urldate = {2023-03-20},
	author = {Antonetti, Claudia and Brunet, Michèle and Paganoni, Eloisa},
	month = jan,
	year = {2019},
	file = {Full Text PDF:files/1910/Antonetti et al. - 2019 - Collezioni di calchi epigrafici una nuova risorsa.pdf:application/pdf},
}

@article{prag_isicily_2019,
	title = {I.{Sicily}, {Open} {Scholarship}, and the {Epigraphic} {Landscape} of {Hellenistic}/{Roman} {Sicily}},
	volume = {44},
	url = {https://shs.hal.science/halshs-02444349},
	abstract = {This paper presents the development of the I.Sicily digital corpus of the inscriptions of ancient Sicily within the context of current debates about open scholarship. The evolution of the I.Sicily project is situated within the framework of Sicilian epigraphic publication and in turn within the framework of humanities publication practices. The approach of the I.Sicily project to open data practices, and the challenges which these pose, is examined through two case studies: the first offering a brief survey of Sicilian epigraphic culture in antiquity; the second considering the possibilities such datasets and corpora offer for collaborative and progressive research.},
	language = {en},
	urldate = {2023-03-20},
	journal = {KTÈMA Civilisations de l'Orient, de la Grèce et de Rome antiques},
	author = {Prag, Jonathan R. W.},
	year = {2019},
	pages = {107},
	file = {Full Text PDF:files/1912/Prag - 2019 - I.Sicily, Open Scholarship, and the Epigraphic Lan.pdf:application/pdf},
}

@book{prag_i_2021,
	title = {I. {Sicily} and {Crossreads}: a digital epigraphic corpus for ancient {Sicily}},
	isbn = {978-1-78925-591-1},
	shorttitle = {I. {Sicily} and {Crossreads}},
	url = {https://ora.ox.ac.uk/objects/uuid:12ed3928-dfc6-4c01-9d25-c5b21050b281},
	abstract = {This paper presents the I.Sicily and Crossreads projects, which aim to build and exploit a digital corpus of the epigraphic texts of ancient Sicily. The introduction summarises the history of epigraphic corpora for the island. In part two the core elements of the I.Sicily corpus project are outlined and briefly discussed. In part three, the primary areas of focus of the Crossreads project are summarised (historical linguistics, petrographic analysis, and palaeographic study).},
	language = {English},
	urldate = {2023-03-20},
	publisher = {Oxbow Books},
	author = {Prag, J. R. W.},
	year = {2021},
	file = {Full Text PDF:files/1914/Prag - 2021 - I. Sicily and Crossreads a digital epigraphic cor.pdf:application/pdf},
}

@article{spampinato_aspetti_2020,
	title = {Aspetti funzionali e implementativi del {Museo} epigrafico digitale {EpiCUM}},
	copyright = {Copyright (c) 2020},
	issn = {2532-8816},
	url = {https://umanisticadigitale.unibo.it/article/view/9973},
	doi = {10.6092/issn.2532-8816/9973},
	abstract = {This work describes the main development activities of the EpiCUM project with particular reference to the implementation and functional aspects of the results achieved within it. EpiCUM aims to present and make available with a single digital museum the whole epigraphic corpus of the civic museum Castello Ursino di Catania, codified in EpiDoc.
The project stems from the collaboration between the Institute of Cognitive Sciences and Technologies of the CNR and the Municipality of Catania and has gained the interest of the I.Sicily project and the involvement of the M.M. Lazarus of Catania with school-work alternation activities. The first phase of the project was mainly dedicated to the recognition of the epigraphs and to the preparation of the exhibition Voci di Pietra which proposes a selection of epigraphs according to innovative exposure methods through the intelligent use of technology and digital. The next phase focused on the analysis and coding in the open EpiDoc format of all the inscriptions of the civic museum and on the realization of the digital museum.
All information on epigraphs are encoded in EpiDoc within XML files and are easily accessible through the various sections of the digital museum in which they are presented in a simple and intuitive way, and visualized within epigraphic cards. The epigraphic cards provide access to the XML files containing the EpiDoc encodings. The epigraphic information can be appropriately queried through a section of the digital museum dedicated to searches. With this method of organizing epigraphic information in the digital museum, the whole epigraphic heritage of the civic museum of Catania can be used for various purposes, both for scholars in the sector, but also for all other types of possible users.
Notice that in order to facilitate the navigation through epigraphic information, it was decided to separately include also information about the religious sphere, the collections of provenance and the copy status of the epigraphs, encoding them within the XML files by means of a specially selected set of EpiDoc markup elements.},
	language = {it},
	number = {9},
	urldate = {2023-03-20},
	journal = {Umanistica Digitale},
	author = {Spampinato, Daria and Cristofaro, Salvatore},
	month = dec,
	year = {2020},
	note = {Number: 9},
	pages = {61--77},
	file = {Full Text PDF:files/1916/Spampinato e Cristofaro - 2020 - Aspetti funzionali e implementativi del Museo epig.pdf:application/pdf},
}

@article{orlandi_latin_2020,
	title = {Latin language and digital epigraphy : different approaches and multiple solutions},
	shorttitle = {Latin language and digital epigraphy},
	url = {https://www.torrossa.com/en/resources/an/4711584},
	doi = {10.19272/202013701002},
	abstract = {Purchase online the PDF of Latin language and digital epigraphy : different approaches and multiple solutions, Orlandi, Silvia - Fabrizio Serra - Article},
	language = {en},
	urldate = {2023-03-20},
	journal = {Latin language and digital epigraphy : different approaches and multiple solutions},
	author = {Orlandi, Silvia},
	year = {2020},
	note = {Publisher: Fabrizio Serra},
	pages = {11--25},
}

@misc{noauthor_data_2016,
	title = {Data and data categories in {I}.{Sicily}},
	url = {https://isicily.org/data-in-isicily/},
	abstract = {An overview of the data and methodology behind the content of I.Sicily},
	language = {en},
	urldate = {2023-03-20},
	journal = {I.Sicily},
	month = dec,
	year = {2016},
}

@article{liddel_attic_2022,
	title = {The {Attic} {Inscriptions}: {Education} {Project}},
	volume = {23},
	issn = {2058-6310},
	shorttitle = {The {Attic} {Inscriptions}},
	url = {https://www.cambridge.org/core/journals/journal-of-classics-teaching/article/attic-inscriptions-education-project/569AE3F28D545B82C353B8F662DA1EFA},
	doi = {10.1017/S2058631021000428},
	abstract = {In ‘Greek Inscriptions: insights and resources in the classroom and beyond’ (Liddel, 2017), I outlined some of the opportunities and perspectives that the study of inscriptions offers to learners getting familiar with the history and culture of ancient Greece at pre-university stage, and I considered the obstacles and opportunities that teachers and students face when trying to access them. That piece very much concentrated on inscriptions as a source for teachers and candidates of OCR's A-level Ancient History. In this essay I take a much broader approach to make a case for the relevance of ancient Greek inscriptions to pre-18 education, considering the ways in which they inform our understanding of Athenian society and contribute to the development of skills of analysis and evaluation of evidence. I highlight the growing significance of the Attic Inscriptions Online website, the Attic Inscriptions in UK Collections project, the newly-launched Attic Inscriptions: Education resource and the AIO YouTube channel to learners’ critical engagement with sources for the ancient Greek world.},
	language = {en},
	number = {45},
	urldate = {2023-03-20},
	journal = {Journal of Classics Teaching},
	author = {Liddel, Peter},
	year = {2022},
	note = {Publisher: Cambridge University Press},
	pages = {35--39},
	file = {Full Text PDF:files/1920/Liddel - 2022 - The Attic Inscriptions Education Project.pdf:application/pdf},
}

@inproceedings{jordanous_contemporary_nodate,
	address = {Montréal, Canada},
	title = {Contemporary transformation of ancient documents for recording and retrieving maximum information: when one form of markup is not enough},
	shorttitle = {Contemporary transformation of ancient documents for recording and retrieving maximum information},
	url = {http://www.balisage.net/Proceedings/vol8/html/Jordanous01/BalisageVol8-Jordanous01.html},
	doi = {10.4242/BalisageVol8.Jordanous01},
	abstract = {This paper considers what we can gain from enhancing TEI-encoded texts with RDF. We consider the use of Open Annotation Collaboration (OAC) annotations as part of our work for the future. To illustrate our approach, we take as a case study the Sharing Ancient Wisdoms (SAWS) project, which explores and analyses the tradition of wisdom literatures in ancient Greek, Arabic and other languages. It aims to publish its texts digitally in a manner that enables linking and comparisons within and between anthologies, their source texts, and the texts that draw upon them.},
	urldate = {2023-03-20},
	author = {Jordanous, Anna and Stanley, Alan and Tupman, Charlotte},
}

@article{orlandi_eagle_2014,
	title = {{EAGLE}: {Europeana} {Network} of {Ancient} {Greek} and {Latin} {Epigraphy}. {Making} the {Ancient} {Inscriptions} {Accessible}},
	copyright = {Copyright (c)},
	issn = {2283-7833},
	shorttitle = {{EAGLE}},
	url = {https://lexicon.cnr.it/ojs/index.php/LP/article/view/408},
	doi = {10.19283/lph-20142.408},
	abstract = {EAGLE is a project whose principal aim is to bring together the most prominent European institutions and archives in the field of Classical Latin and Greek epigraphy in order to provide a single free user-friendly portal to the inscriptions of the Ancient World. Financed by the European Commission, EAGLE was born to endow Europeana, the European digital library, with a comprehensive collection of unique historical sources. EAGLE will thus provide access to the majority of the surviving inscriptions of the ancient Greco-Roman world – a massive resource and a veritable pillar of European culture, made accessible for the first time to everyone, from the curious to the scholar.},
	language = {en},
	number = {2},
	urldate = {2023-03-20},
	journal = {Lexicon Philosophicum: International Journal for the History of Texts and Ideas},
	author = {Orlandi, Silvia and Giberti, Luca Marco Carlo and Santucci, Raffaella},
	month = mar,
	year = {2014},
	note = {Number: 2},
	keywords = {Classical Latin and Greek Inscriptions, Digital Humanities, Digital Library, EAGLE, Europeana},
	file = {Full Text PDF:files/1923/Orlandi et al. - 2014 - EAGLE Europeana Network of Ancient Greek and Lati.pdf:application/pdf},
}

@inproceedings{mannocci_europeana_2014,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {The {Europeana} {Network} of {Ancient} {Greek} and {Latin} {Epigraphy} {Data} {Infrastructure}},
	isbn = {978-3-319-13674-5},
	doi = {10.1007/978-3-319-13674-5_27},
	abstract = {Epigraphic archives, containing collections of editions about ancient Greek and Latin inscriptions, have been created in several European countries during the last couple of centuries. Today, the project EAGLE (Europeana network of Ancient Greek and Latin Epigraphy, a Best Practice Network partially funded by the European Commission) aims at providing a single access point for the content of about 15 epigraphic archives, totaling about 1,5M digital objects. This paper illustrates some of the challenges encountered and their solution for the realization of the EAGLE data infrastructure. The challenges mainly concern the harmonization, interoperability and service integration issues caused by the aggregation of metadata from heterogeneous archives (different data models and metadata schemas, and exchange formats). EAGLE has defined a common data model for epigraphic information, into which data models from different archives can be optimally mapped. The data infrastructure is based on the D-NET software toolkit, capable of dealing with data collection, mapping, cleaning, indexing, and access provisioning through web portals or standard access protocols.},
	language = {en},
	booktitle = {Metadata and {Semantics} {Research}},
	publisher = {Springer International Publishing},
	author = {Mannocci, Andrea and Casarosa, Vittore and Manghi, Paolo and Zoppi, Franco},
	editor = {Closs, Sissi and Studer, Rudi and Garoufallou, Emmanouel and Sicilia, Miguel-Angel},
	year = {2014},
	keywords = {Epigraphy, Aggregation System, Cleaning, D-NET, Data Harmonization, Data Infrastructure, Data Interoperability, Metadata Formats},
	pages = {286--300},
}

@book{liuzzo_networking_2014,
	title = {Networking {EAGLE} with {CIDOC} and {TEI}},
	abstract = {The Europeana network of Ancient Greek and Latin Epigraphy (EAGLE) brings together most repositories of ancient epigraphical documents and aims to provide scholars not just with a ”useful” research tool, but with a curated online edition which has high quality contents as well as high quality data. In this paper, the choices of the EAGLE BPN will be presented as a case of decisions about data driven by the community need for multiple approaches and the desire to enlarge the existing network. The EAGLE Best Practice Network chose multiplicity of editions, interactivity, engagement and multilingualism in order to offer a complete and critically
structured endpoint to the user. To encode inscriptions, EAGLE developed a metadata format that assessed the provider’s metadata structures and considered two sets of standards: TEI EpiDoc and CIDOC CRM. EpiDoc4 allows a full description of the text of inscriptions. CIDOC CRM enables a further full description which is instead oriented to consider inscriptions as objects, thus reflecting the different souls of Epigraphy, the philological and the Archaeological one, pushing the boundaries of filing and collecting in order to meet the deepest intellectual needs of research. The EAGLE BPN choice of the two standards grants full meaning and all possibilities to connect and link other data with external annotation or by alignment. Beside usefulness, the choice of complexity will be rewarding as a choice of semantic quality, but entails deeper changes of perspective.},
	author = {Liuzzo, Pietro and Rivero, Eydel and Vassallo, Valentina},
	month = oct,
	year = {2014},
}

@inproceedings{alvarez_relational_2011,
	address = {Berlin, Heidelberg},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {From {Relational} {Databases} to {Linked} {Data} in {Epigraphy}: {Hispania} {Epigraphica} {Online}},
	isbn = {978-3-642-24731-6},
	shorttitle = {From {Relational} {Databases} to {Linked} {Data} in {Epigraphy}},
	doi = {10.1007/978-3-642-24731-6_24},
	abstract = {Epigraphic databases store metadata and digital representations of inscriptions for information purposes, heritage conservation or scientific use. At present, there are several of such databases available, but our focus is on those that are part of the EAGLE consortium, which aims to make available the epigraphy from the ancient classical civilization. Right now, the EAGLE partners share a basic data schema and an agreement on workload and responsibilities, but each repository has it own storage structure, data identification system and even its different idea of what an epigraphic database is or should be. Any of these aspects may lead to redundancy and hampers search and linking. This paper describes a system implementation for epigraphic data sharing as linked data. Although the described system was tested on a specific database, i.e. Hispania Epigraphica Online, it could be easily tailored to other systems, enabling the advantage of semantic search on several disparate databases.},
	language = {en},
	booktitle = {Metadata and {Semantic} {Research}},
	publisher = {Springer},
	author = {Álvarez, Fernando-Luis and Gómez-Pantoja, Joaquín-L. and García-Barriocanal, Elena},
	editor = {García-Barriocanal, Elena and Cebeci, Zeynel and Okur, Mehmet C. and Öztürk, Aydın},
	year = {2011},
	keywords = {Semantic Web, Linked Data, Epigraphy},
	pages = {225--233},
}

@article{grieshaber_epigraphic_2019,
	title = {Epigraphic {Database} {Heidelberg} – {Data} {Reuse} {Options}},
	copyright = {info:eu-repo/semantics/openAccess},
	url = {https://archiv.ub.uni-heidelberg.de/volltextserver/26599/},
	doi = {10.11588/heidok.00026599},
	abstract = {The “Epigraphic Database Heidelberg” (EDH) is one of the longest running database projects in digital Latin epigraphy with a start as early as 1986. In 1997 the website of the “Epigraphic Database Heidelberg” has gone online: All inscriptions, images, bibliographic and geographic records can be searched and browsed online. In the last years a growing number of researchers asked for direct access to EDH data: Consequently an “Open Data Repository” has been added to the EDH website (https://edh-www.adw.uni-heidelberg.de/data) and improved continuously since then. Options for accessing data include simple CSV downloads, an API returning JSON responses, a SPARQL endpoint, an IIIF API and access via a Distributed Text Services API. This article describes the data in the EDH repository, the various ways of how users can reuse this data for their own research and when to choose which option.},
	language = {eng},
	urldate = {2023-03-20},
	author = {Grieshaber, Frank},
	year = {2019},
	note = {Place: Heidelberg},
	pages = {1--16},
	file = {Full Text PDF:files/1930/Grieshaber - 2019 - Epigraphic Database Heidelberg – Data Reuse Option.pdf:application/pdf;Snapshot:files/1931/26599.html:text/html},
}

@article{creamer_archiving_2021,
	title = {Archiving a {TEI} {Project} {FAIRly}},
	copyright = {For this publication a Creative Commons Attribution 4.0 International license has been granted by the author(s) who retain full copyright.},
	issn = {2162-5603},
	url = {https://journals.openedition.org/jtei/4324},
	doi = {10.4000/jtei.4324},
	abstract = {The Inscriptions of Israel/Palestine project is an online corpus of over four thousand inscriptions from Israel and Palestine, written in Hebrew, Greek, Latin, and Aramaic, dating roughly from the Persian Period to the Arab Conquest. The source files with inscription text and metadata are encoded using EpiDoc, a TEI customization widely used by epigraphers. As the project prepared to deposit its XML files in an institutional repository, it transformed them into a locally developed robust archival format. This paper evaluates these decisions against the FAIR metrics, using IIP as a test case. This allows us to suggest improvements for our own archival encoding as well as to see where EpiDoc and TEI enhance FAIRness and where they could provide more support. Finally, we suggest some ways to use FAIR metrics that are more amenable to TEI documents and corpora.},
	language = {en},
	number = {Issue 14},
	urldate = {2023-03-20},
	journal = {Journal of the Text Encoding Initiative},
	author = {Creamer, Andrew and Lembi, Gaia and Mylonas, Elli and Satlow, Michael},
	month = mar,
	year = {2021},
	note = {Number: Issue 14
Publisher: Text Encoding Initiative Consortium},
	keywords = {EpiDoc, digital epigraphy, FAIR},
	file = {Full Text PDF:files/1933/Creamer et al. - 2021 - Archiving a TEI Project FAIRly.pdf:application/pdf},
}

@article{coffee_agenda_2018,
	title = {An {Agenda} for the {Study} of {Intertextuality}},
	volume = {148},
	issn = {2575-7199},
	url = {https://muse.jhu.edu/pub/1/article/693654},
	doi = {10.1353/apa.2018.0008},
	abstract = {, summary:, The study of intertextuality has been a central pursuit of scholars of Greek and especially Latin literature. It promises to reveal the meaning of texts for original audiences, trace authorial influence, and illuminate an aspect of literary artistry. Yet inconsistent standards and the scattering of insights across publications have hindered progress. This article proposes restoring momentum toward the goals of intertextual study through an agenda of representing intertexts in a standard digital form susceptible to complex and systematic analysis.},
	number = {1},
	urldate = {2023-03-20},
	journal = {TAPA},
	author = {Coffee, Neil},
	year = {2018},
	note = {Publisher: Johns Hopkins University Press},
	pages = {205--223},
	file = {An Agenda for the Study of Intertextuality:files/1935/Coffee - 2018 - An Agenda for the Study of Intertextuality.pdf:application/pdf},
}

@incollection{de_santis_16_2018,
	title = {16 {Making} up for {Lost} {Time}: {Digital} {Epigraphy}, {Chronology}, and the {PeriodO} {Project}},
	isbn = {978-3-11-060720-8},
	shorttitle = {16 {Making} up for {Lost} {Time}},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110607208-017/html},
	abstract = {Digital epigraphy has made great strides toward interoperability and data integration over the last two decades, and Linked Data approaches are now taking advantage of the spatial information associated with inscriptions for new search and visualization tools. The ability to search across epigraphic collections by time, and especially by relative chronologies, lags behind. The PeriodO project has created a Linked Data gazetteer of structured period definitions that facilitates translation between absolute dates and relative chronologies, creating new possibilities for the interoperability of epigraphic collections and their connection with archaeological databases.},
	language = {en},
	urldate = {2023-03-20},
	booktitle = {Crossing {Experiences} in {Digital} {Epigraphy}},
	publisher = {De Gruyter},
	author = {Rabinowitz, Adam and Shaw, Ryan and Golden, Patrick},
	editor = {De Santis, Annamaria and Rossi, Irene},
	month = dec,
	year = {2018},
	doi = {10.1515/9783110607208-017},
	pages = {202--215},
	file = {Rabinowitz et al. - 2018 - 16 Making up for Lost Time Digital Epigraphy, Chr.pdf:files/1936/Rabinowitz et al. - 2018 - 16 Making up for Lost Time Digital Epigraphy, Chr.pdf:application/pdf},
}

@article{iversen_packard_2007,
	title = {The {Packard} {Humanities} {Institute} ({PHI}) {Greek} {Epigraphy} {Project} and the {Revolution} in {Greek} {Epigraphy}},
	volume = {2},
	issn = {1687-8280, 2213-8609},
	url = {https://brill.com/view/journals/abga/2/1/article-p51_7.xml},
	doi = {10.1163/22138609-00201007},
	abstract = {In this paper, the history, purpose and importance of the Packard Humanities Institute (PHI) Greek Epigraphy Project are discussed.},
	language = {en},
	number = {1},
	urldate = {2023-03-20},
	journal = {Abgadiyat},
	author = {Iversen, Paul A.},
	month = jan,
	year = {2007},
	pages = {51--55},
	file = {Iversen - 2007 - The Packard Humanities Institute (PHI) Greek Epigr.pdf:files/1940/Iversen - 2007 - The Packard Humanities Institute (PHI) Greek Epigr.pdf:application/pdf},
}

@inproceedings{isaksen_pelagios_2014,
	address = {New York, NY, USA},
	series = {{WebSci} '14},
	title = {Pelagios and the emerging graph of ancient world data},
	isbn = {978-1-4503-2622-3},
	url = {https://doi.org/10.1145/2615569.2615693},
	doi = {10.1145/2615569.2615693},
	abstract = {This paper discusses an emerging cloud of Linked Open Data in the humanities sometimes referred to as the Graph of Ancient World Data (GAWD). It provides historical background to the domain, before gong on to describe the open and decentralised characteristics which have partially characterised its development. This is done principally through the lens of Pelagios, a collaborative initiative led by the authors which connects online historical resources based on common references to places. The benefits and limitations of the approach are evaluated, in particular its low barrier to entry, open architecture and restricted scope. The paper concludes with a number of suggestion for encouraging the adoption of Linked Open Data within other humanities communities and beyond.},
	urldate = {2023-03-20},
	booktitle = {Proceedings of the 2014 {ACM} conference on {Web} science},
	publisher = {Association for Computing Machinery},
	author = {Isaksen, Leif and Simon, Rainer and Barker, Elton T.E. and de Soto Cañamares, Pau},
	month = jun,
	year = {2014},
	keywords = {geospatial, humanities, linked open data},
	pages = {197--201},
	file = {Versione accettata:files/1943/Isaksen et al. - 2014 - Pelagios and the emerging graph of ancient world d.pdf:application/pdf},
}

@article{ltd_publication_2020,
	title = {{PUBLICATION}, {TESTING} {AND} {VISUALIZATION} {WITH} {EFES}: {A} {TOOL} {FOR} {ALL} {STAGES} {OF} {THE} {EPIDOC} {XML} {EDITING} {PROCESS}},
	volume = {65},
	issn = {2559-6721, 2559-6721},
	shorttitle = {{PUBLICATION}, {TESTING} {AND} {VISUALIZATION} {WITH} {EFES}},
	url = {https://www.ceeol.com/search/article-detail?id=914513},
	abstract = {EpiDoc is a set of recommendations, schema and other tools for the encoding of ancient texts, especially inscriptions and papyri, in TEI XML, that is now used by upwards of a hundred projects around the world, and large numbers of scholars seek training in EpiDoc encoding every year. The EpiDoc Front-End Services tool (EFES) was designed to fill the important need for a publication solution for researchers and editors who have produced EpiDoc encoded texts but do not have access to digital humanities support or a well-funded IT service to produce a publication for them.This paper will discuss the use of EFES not only for final publication, but as a tool in the editing and publication workflow, by editors of inscriptions, papyri and similar texts including those on coins and seals. The edition visualisations, indexes and search interface produced by EFES are able to serve as part of the validation, correction and research apparatus for the author of an epigraphic corpus, iteratively improving the editions long before final publication. As we will argue, this research process is a key component of epigraphic and papyrological editing practice, and studying these needs will help us to further enhance the effectiveness of EFES as a tool.To this end we also plan to add three major functionalities to the EFES toolbox: (1) date visualisation and filter—building on the existing “date slider,” and inspired by partner projects such as Pelagios and Godot; (2) geographic visualization features, again building on Pelagios code, allowing the display of locations within a corpus or from a specific set of search results in a map; (3) export of information and metadata from the corpus as Linked Open Data, following the recommendations of projects such as the Linked Places format, SNAP, Chronontology and Epigraphy.info, to enable the semantic sharing of data within and beyond the field of classical and historical editions.Finally, we will discuss the kinds of collaboration that will be required to bring about desired enhancements to the EFES toolset, especially in this age of research-focussed, short-term funding. Embedding essential infrastructure work of this kind in research applications for specific research and publication projects will almost certainly need to be part of the solution.},
	language = {English},
	number = {1},
	urldate = {2023-03-20},
	journal = {Studia Universitatis Babeș-Bolyai - Digitalia},
	author = {Ltd, ICB-InterConsult Bulgaria},
	year = {2020},
	note = {Publisher: Studia Universitatis Babes-Bolyai},
	keywords = {Linked Open Data, Epigraphy, Ancient Texts, Digital Publication, Extensible Stylesheet Language Transformations, Papyrology, Text Encoding},
	pages = {17--35},
}

@inproceedings{vassallo_revealing_2013,
	title = {Revealing cross-disciplinary information through formal knowledge representation — {A} proposed {Metadata} for ancient {Cypriot} inscriptions},
	volume = {2},
	doi = {10.1109/DigitalHeritage.2013.6744732},
	abstract = {This paper presents recent developments in constructing a cross-disciplinary metadata for ancient Cypriot inscriptions, integrating information regarding the objects themselves and their digital “surrogates” (3D models, photographic documentation, digital texts, transliterations, etc.).},
	booktitle = {2013 {Digital} {Heritage} {International} {Congress} ({DigitalHeritage})},
	author = {Vassallo, V. and Christophorou, E. and Hermon, S. and Niccolucci, F.},
	month = oct,
	year = {2013},
	keywords = {Data models, Solid modeling, Europe, Three-dimensional displays, Documentation, Digital Humanities, digital epigraphy, ancient Cypriot inscriptions, Communities, cross-disciplinary metadata, Geology},
	pages = {79--82},
	file = {IEEE Xplore Abstract Record:files/1947/6744732.html:text/html;IEEE Xplore Full Text PDF:files/1946/Vassallo et al. - 2013 - Revealing cross-disciplinary information through f.pdf:application/pdf},
}

@article{felicetti_integrating_nodate,
	title = {Integrating {Terminological} {Tools} and {Semantic} {Archaeological} {Information}: the {ICCD} {RA} {Schema} and {Thesaurus}},
	abstract = {This paper describes the process of mapping, translation and publication in SKOS format of the RA Thesaurus, a terminological tool developed by the Italian Ministry of Cultural Heritage (MiBACT) as a part of the oﬃcial documentation used for the recording of archaeological ﬁnds. In particular, the RA Thesaurus is intended to provide uniﬁed and meaningful terminology for the description of archaeological objects according to the MiBACT oﬃcial cataloguing standards. After describing the thesaurus, the logic with which it was developed and its internal structure, we report the various phases of the conversion, both from a theoretical and implementation point of view, and the various technologies used for the publication of the thesaurus on the web. This work is a collaborative eﬀort between PIN and MiBACT carried out under the ARIADNE project.},
	language = {en},
	author = {Felicetti, Achille and Galluccio, Ilenia and Luddi, Cinzia and Mancinelli, Maria Letizia and Scarselli, Tiziana and Madonna, Antonio Davide},
	file = {Felicetti et al. - Integrating Terminological Tools and Semantic Arch.pdf:files/1948/Felicetti et al. - Integrating Terminological Tools and Semantic Arch.pdf:application/pdf},
}

@article{catalano_representing_2020,
	title = {Representing quantitative documentation of {3D} cultural heritage artefacts with {CIDOC} {CRMdig}},
	volume = {21},
	issn = {1432-1300},
	url = {https://doi.org/10.1007/s00799-020-00287-3},
	doi = {10.1007/s00799-020-00287-3},
	abstract = {In this paper, we will explore the theme of the documentation of 3D cultural heritage assets, not only as entire artefacts but also including the interesting features of the object from an archaeological perspective. Indeed, the goal is supporting archaeological research and curation, providing a different approach to enrich the documentation of digital resources and their components with corresponding measurements, combining semantic and geometric techniques. A documentation scheme based on CIDOC, where measurements on digital data have been included extending CIDOC CRMdig, is discussed. To annotate accurately the components and features of the artefacts, a controlled vocabulary named Cultural Heritage Artefact Partonomy (CHAP) has been defined and integrated into the scheme as a SKOS taxonomy to showcase the proposed methodology. CHAP concerns Coroplastic, which is the study of ancient terracotta figurines and in particular the Cypriot production. Two case studies have been considered: the terracotta statues from the port of Salamis and the small clay statuettes from the Ayia Irini sanctuary. Focussing both on the artefacts and their digital counterparts, the proposed methodology supports effectively typical operations within digital libraries and repositories (e.g. search, part-based annotation), and more specific objectives such as the archaeological interpretation and digitally assisted classification, as proved in a real archaeological scenario. The proposed approach is general and applies to different contexts, since it is able to support any archaeological research where the goal is an extensive digital documentation of tangible findings including quantitative attributes.},
	language = {en},
	number = {4},
	urldate = {2023-03-20},
	journal = {International Journal on Digital Libraries},
	author = {Catalano, Chiara Eva and Vassallo, Valentina and Hermon, Sorin and Spagnuolo, Michela},
	month = dec,
	year = {2020},
	keywords = {CIDOC CRM, 3D cultural heritage documentation, Cypriot Coroplastic, Quantitative data, SKOS vocabulary},
	pages = {359--373},
	file = {Full Text PDF:files/1951/Catalano et al. - 2020 - Representing quantitative documentation of 3D cult.pdf:application/pdf},
}

@article{antonetti_digital_2017,
	title = {Digital {Epigraphy} at the {Greek} {Epigraphy} {Laboratory}, {Ca}’ {Foscari} {University} of {Venice}},
	copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {2240-774X},
	url = {https://journals.openedition.org/historika/419},
	abstract = {This paper presents two important Projects of the Greek Epigraphy Laboratory, Ca' Foscari University of Venice: the Venice Squeeze Project and the AXON Project. The Venice Squeeze Project intends to set up an online collection of the squeezes of the Venetian Laboratory and to contribute to the recognition, enhancement, and preservation of archives of squeezes. The AXON Project - data-base and on-line journal - includes digital entries of a selection of Greek historical epigraphical documents: each entry gives a presentation of the inscription with philological elements, text and translation, commentary and bibliography.},
	language = {en},
	number = {7},
	urldate = {2023-03-20},
	journal = {Historika. Studi di storia greca e romana},
	author = {Antonetti, Claudia and Matijašić, Ivan and De Vido, Stefania and Mignosa, Valentina},
	month = dec,
	year = {2017},
	note = {Number: 7
Publisher: Celid Edizioni},
	pages = {491--502},
	file = {Full Text PDF:files/1953/Antonetti et al. - 2017 - Digital Epigraphy at the Greek Epigraphy Laborator.pdf:application/pdf},
}

@book{felle_off_2016,
	title = {Off the {Beaten} {Track}. {Epigraphy} at the {Borders}: {Proceedings} of 6th {EAGLE} {International} {Event} (24-25 {September} 2015, {Bari}, {Italy})},
	isbn = {978-1-78491-323-6},
	shorttitle = {Off the {Beaten} {Track}. {Epigraphy} at the {Borders}},
	abstract = {This volume contains the papers presented during the Meeting ‘Off the Beaten Track – Epigraphy at the Borders’, the sixth in a series of international events planned by the EAGLE, Europeana network of Ancient Greek and Latin Epigraphy international consortium.The Meeting was held on 24–25 September 2015, with the support of the Department of Classics and Late Antiquity Studies at the University of Bari Aldo Moro (Italy). During the event, the EAGLE Portal (http://www.eagle-network.eu) was officially launched and presented to the public for the first time. The event was intended to address the issues which arise in digitizing inscriptions characterised by ‘unusual’ features in comparison with the epigraphic norm. Here are collected contributions from several ongoing digital projects raising questions and proposing solutions regarding encoding inscriptions – from the Archaic period to the Middle Ages and beyond, even in languages other than Greek and Latin – which do not fall within those labelled as standard. The projects involved are the following: ILA – Iscrizioni Latine Arcaiche; The Ancient Graffiti Project; DASI – Digital Archive for the Study of pre-Islamic Arabian Inscriptions; EDB – Epigraphic Database Bari; EDV – Epigraphic Database Vernacular Inscriptions; AshLi – Ashmolean Latin Inscriptions Project.},
	language = {en},
	publisher = {Archaeopress Publishing Ltd},
	author = {Felle, Antonio E. and Rocco, Anita},
	month = mar,
	year = {2016},
	note = {Google-Books-ID: iRteEAAAQBAJ},
	keywords = {Social Science / Archaeology},
}

@article{erdas_gei_2019,
	title = {{GEI}. {Greek} {Economic} {Inscriptions} (online)},
	issn = {2532-6848},
	url = {https://edizionicafoscari.unive.it/riviste/axon/2019/2/gei-greek-economic-inscriptions-online-geisnsit/},
	doi = {10.30687/Axon/2532-6848/2019/02/008},
	abstract = {In recent years the attention of modern scholars to ancient Greek economy has received impetus from a series of newly published documents of undisputed significance. The results have been a deeply renewed examination of consolidated theoretical positions, and a detailed analysis of specific aspects of the economic life of the polis. Within this framework the GEI project aims at providing an online collection of epigraphic documents related to the economy of ancient Greece. Some of these documents, already known or newly discovered, have never been collected in a selection of this kind. The project covers a period from the archaic age to 1st century BC. The selected texts are representative of the different areas of ancient Greek economy, and are marked-up using the EpiDoc encoding conventions. For each document all technical information has been provided along with existing critical editions, bibliography, a critical apparatus, an English translation and a commentary.},
	language = {it},
	number = {2},
	urldate = {2023-03-20},
	journal = {Axon},
	author = {Erdas, Donatella and Magnetto, Anna},
	month = dec,
	year = {2019},
	pages = {JournalArticle\_2590},
	file = {Full text:files/1957/Erdas e Magnetto - 2019 - GEI. Greek Economic Inscriptions (online).pdf:application/pdf},
}

@misc{noauthor_x_nodate,
	title = {A {X} {O} {N}},
	url = {https://mizar.unive.it/axon/public/axon/pagine/schedaaxon},
	urldate = {2023-03-21},
	file = {A X O N:files/1959/schedaaxon.html:text/html},
}

@book{berman_placing_2016,
	title = {Placing {Names}: {Enriching} and {Integrating} {Gazetteers}},
	isbn = {978-0-253-02244-8},
	shorttitle = {Placing {Names}},
	url = {https://www.jstor.org/stable/j.ctt2005zq7},
	abstract = {Well before the innovation of maps, gazetteers served as the main geographic referencing system for hundreds of years. Consisting of a specialized index of place names, gazetteers traditionally linked descriptive elements with topographic features and coordinates. Placing Names is inspired by that tradition of discursive place-making and by contemporary approaches to digital data management that have revived the gazetteer and guided its development in recent decades. Adopted by researchers in the Digital Humanities and Spatial Sciences, gazetteers provide a way to model the kind of complex cultural, vernacular, and perspectival ideas of place that can be located in texts and expanded into an interconnected framework of naming history. This volume brings together leading and emergent scholars to examine the history of the gazetteer, its important role in geographic information science, and its use to further the reach and impact of spatial reasoning into the digital age.},
	urldate = {2023-03-23},
	publisher = {Indiana University Press},
	editor = {Berman, Merrick Lex and Mostern, Ruth and Southall, Humphrey},
	year = {2016},
	doi = {10.2307/j.ctt2005zq7},
}

@inproceedings{alvarez_sharing_2010-1,
	address = {Berlin, Heidelberg},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Sharing {Epigraphic} {Information} as {Linked} {Data}},
	isbn = {978-3-642-16552-8},
	doi = {10.1007/978-3-642-16552-8_21},
	abstract = {The diffusion of epigraphic data has evolved in the last years from printed catalogues to indexed digital databases shared through the Web. Recently, the open EpiDoc specifications have resulted in an XML-based schema for the interchange of ancient texts that uses XSLT to render typographic representations. However, these schemas and representation systems are still not providing a way to encode computational semantics and semantic relations between pieces of epigraphic data. This paper sketches an approach to bring these semantics into an EpiDoc based schema using the Ontology Web Language (OWL) and following the principles and methods of information sharing known as “linked data”. The paper describes the general principles of the OWL mapping of the EpiDoc schema and how epigraphic data can be shared in RDF format via dereferenceable URIs that can be used to build advanced search, visualization and analysis systems.},
	language = {en},
	booktitle = {Metadata and {Semantic} {Research}},
	publisher = {Springer},
	author = {Álvarez, Fernando-Luis and García-Barriocanal, Elena and Gómez-Pantoja, Joaquín-L.},
	editor = {Sánchez-Alonso, Salvador and Athanasiadis, Ioannis N.},
	year = {2010},
	keywords = {Semantic Web, EpiDoc, Epigraphy, linked data, OWL},
	pages = {222--234},
	file = {MTSR_Alcala_2010-libre.pdf:files/1964/MTSR_Alcala_2010-libre.pdf:application/pdf},
}

@inproceedings{vassallo_revealing_2013-1,
	title = {Revealing cross-disciplinary information through formal knowledge representation — {A} proposed {Metadata} for ancient {Cypriot} inscriptions},
	volume = {2},
	doi = {10.1109/DigitalHeritage.2013.6744732},
	abstract = {This paper presents recent developments in constructing a cross-disciplinary metadata for ancient Cypriot inscriptions, integrating information regarding the objects themselves and their digital “surrogates” (3D models, photographic documentation, digital texts, transliterations, etc.).},
	booktitle = {2013 {Digital} {Heritage} {International} {Congress} ({DigitalHeritage})},
	author = {Vassallo, V. and Christophorou, E. and Hermon, S. and Niccolucci, F.},
	month = oct,
	year = {2013},
	keywords = {Data models, Solid modeling, Europe, Three-dimensional displays, Documentation, Digital Humanities, digital epigraphy, ancient Cypriot inscriptions, Communities, cross-disciplinary metadata, Geology},
	pages = {79--82},
	file = {IEEE Xplore Abstract Record:files/1967/6744732.html:text/html;IEEE Xplore Full Text PDF:files/1966/Vassallo et al. - 2013 - Revealing cross-disciplinary information through f.pdf:application/pdf},
}

@book{orlandi_information_2014,
	title = {Information {Technologies} for {Epigraphy} and {Cultural} {Heritage}: {Proceedings} of the {First} {EAGLE} {International} {Conference}},
	isbn = {978-88-98533-42-8},
	shorttitle = {Information {Technologies} for {Epigraphy} and {Cultural} {Heritage}},
	abstract = {This peer-reviewed volume contains selected papers from the First EAGLE International Conference on Information Technologies for Epigraphy and Cultural Heritage, held in Paris between September 29 and October 1, 2014. Here are assembled for the first time in a unique volume contributions regarding all aspects of Digital Epigraphy: Models, Vocabularies, Translations, User Engagements, Image Analysis, 3D methodologies, and ongoing projects at the cutting edge of digital humanities. The scope of this book is not limited to Greek and Latin epigraphy; it provides an overview of projects related to all epigraphic inquiry and its related communities. This approach intends to furnish the reader with the broadest possible perspective of the discipline, while at the same time giving due attention to the specifics of unique issues.},
	language = {en},
	publisher = {Sapienza Università Editrice},
	author = {Orlandi, Silvia and Santucci, Raffaella and Casarosa, Vittore and Liuzzo, Pietro},
	month = sep,
	year = {2014},
	note = {Google-Books-ID: rVtwDwAAQBAJ},
	keywords = {Technology \& Engineering / Power Resources / Alternative \& Renewable},
}

@inproceedings{blanke_linked_2012,
	title = {Linked data for humanities research — {The} {SPQR} experiment},
	doi = {10.1109/DEST.2012.6227932},
	abstract = {Ancient texts represent a primary source for research in the classics. A substantial body of digital material has evolved enriching these texts. Unfortunately these data are often distributed across myriad locations, stored in diverse and incompatible formats and are either not available online or are made available only in isolation. This paper describes an investigation into using linked data principles and technologies to build bridges between these islands of data to deliver an integrated data landscape through which researchers can explore and so seek to understand this data. The evaluation revealed that researchers were of the opinion that the linked data representation, and its visualisation as graphs, offers an intuitive and usable means of exploring and understanding the data, exceeding the capabilities offered by current online portals to classics data.},
	booktitle = {2012 6th {IEEE} {International} {Conference} on {Digital} {Ecosystems} and {Technologies} ({DEST})},
	author = {Blanke, Tobias and Bodard, Gabriel and Bryant, Michael and Dunn, Stuart and Hedges, Mark and Jackson, Michael and Scott, David},
	month = jun,
	year = {2012},
	note = {ISSN: 2150-4946},
	keywords = {Semantics, Ontologies, Resource description framework, Linked Data, Encoding, XML, Digital Humanities, Browsers, Data Integration, Materials},
	pages = {1--6},
	file = {Versione inviata:files/1972/Blanke et al. - 2012 - Linked data for humanities research — The SPQR exp.pdf:application/pdf},
}

@article{gruber_role_nodate,
	title = {The {Role} of {Common} {Ontology} in {Achieving} {Sharable}, {Reusable} {Knowledge} {Bases}},
	abstract = {Although AI research and commercial system development depend on bodies of formally represented knowledge that are expensive and di cult to construct, current knowledge base design does not support the accumulation or reuse of such knowledge. This paper presents a strategy for building libraries of sharable, reusable knowledge in which common ontologies play a central role as a knowledge coupling construct. Ontologies are de ned as coherent sets of representational terms, together with textual and formal de nitions, that embody a set of representational design choices. Problems in the design of sharable ontologies are identi ed.},
	language = {en},
	author = {Gruber, Thomas R},
	file = {Gruber - The Role of Common Ontology in Achieving Sharable,.pdf:files/1973/Gruber - The Role of Common Ontology in Achieving Sharable,.pdf:application/pdf},
}

@article{oneill_digital_2022-1,
	title = {Digital cultural heritage standards: from silo to semantic web},
	volume = {37},
	issn = {1435-5655},
	shorttitle = {Digital cultural heritage standards},
	url = {https://doi.org/10.1007/s00146-021-01371-1},
	doi = {10.1007/s00146-021-01371-1},
	abstract = {This paper is a survey of standards being used in the domain of digital cultural heritage with focus on the Metadata Encoding and Transmission Standard (METS) created by the Library of Congress in the United States of America. The process of digitization of cultural heritage requires silo breaking in a number of areas—one area is that of academic disciplines to enable the performance of rich interdisciplinary work. This lays the foundation for the emancipation of the second form of silo which are the silos of knowledge, both traditional and born digital, held in individual institutions, such as galleries, libraries, archives and museums. Disciplinary silo breaking is the key to unlocking these institutional knowledge silos. Interdisciplinary teams, such as developers and librarians, work together to make the data accessible as open data on the “semantic web”. Description logic is the area of mathematics which underpins many ontology building applications today. Creating these ontologies requires a human–machine symbiosis. Currently in the cultural heritage domain, the institutions’ role is that of provider of this  open data to the national aggregator which in turn can make the data available to the trans-European aggregator known as Europeana. Current ingests to the aggregators are in the form of machine readable cataloguing metadata which is limited in the richness it provides to disparate object descriptions. METS can provide this richness.},
	language = {en},
	number = {3},
	urldate = {2023-03-23},
	journal = {AI \& SOCIETY},
	author = {O’Neill, Brenda and Stapleton, Larry},
	month = sep,
	year = {2022},
	keywords = {MARC, Metadata aggregators, METS metadata, Open-linked data, Semantic web, Silo},
	pages = {891--903},
	file = {Full Text PDF:files/1977/O’Neill e Stapleton - 2022 - Digital cultural heritage standards from silo to .pdf:application/pdf},
}

@inproceedings{carriero_arco_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{ArCo}: {The} {Italian} {Cultural} {Heritage} {Knowledge} {Graph}},
	isbn = {978-3-030-30796-7},
	shorttitle = {{ArCo}},
	doi = {10.1007/978-3-030-30796-7_3},
	abstract = {ArCo is the Italian Cultural Heritage knowledge graph, consisting of a network of seven vocabularies and 169 million triples about 820 thousand cultural entities. It is distributed jointly with a SPARQL endpoint, a software for converting catalogue records to RDF, and a rich suite of documentation material (testing, evaluation, how-to, examples, etc.). ArCo is based on the official General Catalogue of the Italian Ministry of Cultural Heritage and Activities (MiBAC) - and its associated encoding regulations - which collects and validates the catalogue records of (ideally) all Italian Cultural Heritage properties (excluding libraries and archives), contributed by CH administrators from all over Italy. We present its structure, design methods and tools, its growing community, and delineate its importance, quality, and impact.},
	language = {en},
	booktitle = {The {Semantic} {Web} – {ISWC} 2019},
	publisher = {Springer International Publishing},
	author = {Carriero, Valentina Anita and Gangemi, Aldo and Mancinelli, Maria Letizia and Marinucci, Ludovica and Nuzzolese, Andrea Giovanni and Presutti, Valentina and Veninata, Chiara},
	editor = {Ghidini, Chiara and Hartig, Olaf and Maleshkova, Maria and Svátek, Vojtěch and Cruz, Isabel and Hogan, Aidan and Song, Jie and Lefrançois, Maxime and Gandon, Fabien},
	year = {2019},
	pages = {36--52},
	file = {Full Text PDF:files/1982/Carriero et al. - 2019 - ArCo The Italian Cultural Heritage Knowledge Grap.pdf:application/pdf},
}

@inproceedings{presutti_role_2016,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Role} of {Ontology} {Design} {Patterns} in {Linked} {Data} {Projects}},
	isbn = {978-3-319-46397-1},
	doi = {10.1007/978-3-319-46397-1_9},
	abstract = {The contribution of this paper is twofold: (i) a UML stereotype for component diagrams that allows for representing ontologies as a set of interconnected Ontology Design Patterns, aimed at supporting the communication between domain experts and ontology engineers; (ii) an analysis of possible approaches to ontology reuse and the definition of four methods according to their impact on the sustainability and stability of the resulting ontologies and knowledge bases. To conceptually prove the effectiveness of our proposals, we present two real LOD projects.},
	language = {en},
	booktitle = {Conceptual {Modeling}},
	publisher = {Springer International Publishing},
	author = {Presutti, Valentina and Lodi, Giorgia and Nuzzolese, Andrea and Gangemi, Aldo and Peroni, Silvio and Asprino, Luigi},
	editor = {Comyn-Wattiau, Isabelle and Tanaka, Katsumi and Song, Il-Yeol and Yamamoto, Shuichiro and Saeki, Motoshi},
	year = {2016},
	keywords = {Ontology, Linked data, eXtreme Design, Ontology design patterns, Ontology reuse},
	pages = {113--121},
	file = {Full Text PDF:files/1984/Presutti et al. - 2016 - The Role of Ontology Design Patterns in Linked Dat.pdf:application/pdf},
}

@article{portales_digital_2018,
	title = {Digital {Cultural} {Heritage}},
	volume = {2},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2414-4088},
	url = {https://www.mdpi.com/2414-4088/2/3/58},
	doi = {10.3390/mti2030058},
	abstract = {n/a},
	language = {en},
	number = {3},
	urldate = {2023-03-24},
	journal = {Multimodal Technologies and Interaction},
	author = {Portalés, Cristina and Rodrigues, João M. F. and Rodrigues Gonçalves, Alexandra and Alba, Ester and Sebastián, Jorge},
	month = sep,
	year = {2018},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {n/a},
	pages = {58},
	file = {Full Text PDF:files/1986/Portalés et al. - 2018 - Digital Cultural Heritage.pdf:application/pdf},
}

@article{navarrete_digital_2013,
	title = {Digital cultural heritage},
	url = {https://www.elgaronline.com/display/edcoll/9780857930996/9780857930996.00023.xml},
	abstract = {"Chapter 12: Digital cultural heritage" published on 30 Jul 2013 by Edward Elgar Publishing.},
	language = {en\_US},
	urldate = {2023-03-24},
	journal = {Handbook on the Economics of Cultural Heritage},
	author = {Navarrete, Trilce},
	month = jul,
	year = {2013},
	note = {ISBN: 9780857931009
Publisher: Edward Elgar Publishing
Section: Handbook on the Economics of Cultural Heritage},
	pages = {251--271},
}

@article{owens_digital_2013,
	title = {Digital {Cultural} {Heritage} and the {Crowd}},
	volume = {56},
	issn = {2151-6952},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cura.12012},
	doi = {10.1111/cura.12012},
	abstract = {Libraries, archives, and museums have a long history of collaboration with members of the public. There is already considerable interest in extending this relationship, inviting members of the public, often referred to as “the crowd,” to tag and classify, transcribe, organize, and otherwise add value to digital cultural heritage collection content. In this essay, current discussions of crowdsourcing are connected with the mission and values of cultural heritage organizations and a framework is offered for thinking about distinct components of different kinds of projects that have been lumped together.},
	language = {en},
	number = {1},
	urldate = {2023-03-24},
	journal = {Curator: The Museum Journal},
	author = {Owens, Trevor},
	year = {2013},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cura.12012},
	pages = {121--130},
	file = {Full Text PDF:files/1989/Owens - 2013 - Digital Cultural Heritage and the Crowd.pdf:application/pdf},
}

@article{mason_digital_2021,
	title = {Digital {Cultural} {Heritage} {Design} {Practice}: {A} {Conceptual} {Framework}},
	volume = {24},
	issn = {1460-6925},
	shorttitle = {Digital {Cultural} {Heritage} {Design} {Practice}},
	url = {https://doi.org/10.1080/14606925.2021.1889738},
	doi = {10.1080/14606925.2021.1889738},
	abstract = {Human-Centred Design approaches in museums give rise to a new, digital cultural heritage design practice by refocusing design from the (digital) technology on to the (digitally-enhanced) visitor experience and requiring involvement in design from both designers and non-designers. This practice is foregrounded as central within a wider landscape of transformative museum design and innovation. The paper calls for a new research agenda that takes design practice as the unit of analysis and recognizes the uniqueness of each cultural heritage organization and its capacity to deploy digital media and technologies successfully in its own unique ways and as a matter of organizational fit. We outline this agenda through a conceptual framework for the analysis of digital cultural heritage design practice along the dimensions of activity, tool mediation, and knowledge production. The framework acknowledges that the design of digitally-enhanced visitor experiences is catalytically mediated by tools and constitutes powerful ways of knowing-in-designing.},
	number = {3},
	urldate = {2023-03-24},
	journal = {The Design Journal},
	author = {Mason, Marco and Vavoula, Giasemi},
	month = may,
	year = {2021},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14606925.2021.1889738},
	keywords = {Design as practice, digital cultural heritage, museums},
	pages = {405--424},
	file = {Versione accettata:files/1991/Mason e Vavoula - 2021 - Digital Cultural Heritage Design Practice A Conce.pdf:application/pdf},
}

@article{eschenfelder_nine_2018,
	title = {A nine dimensional framework for digital cultural heritage organizational sustainability: {A} content analysis of the {LIS} literature (2000–2015)},
	volume = {43},
	issn = {1468-4527},
	shorttitle = {A nine dimensional framework for digital cultural heritage organizational sustainability},
	url = {https://doi.org/10.1108/OIR-11-2017-0318},
	doi = {10.1108/OIR-11-2017-0318},
	abstract = {Purpose The purpose of this paper is to report on how library and information science (LIS) as a field operationalizes the concept of organizational sustainability for managing digital resources, projects and infrastructures such as digital libraries and repositories over time. It introduces a nine dimensional framework for organizational sustainability in the digital cultural heritage community. Design/methodology/approach Content analysis of publications from three LIS databases (2000–2015). Findings Comparing the articles to the nine dimension framework shows that most LIS articles discuss technology, financial or management dimensions. Fewer articles describe disaster planning, assessment or policy dimensions. Research limitations/implications Three LIS databases might not include all relevant journals, conferences, white papers and other materials. The data set also did not include books; library management textbooks might include useful material on organizational sustainability. Claims about the prevalence of themes are subject to methodological limits of content analysis. Practical implications Organizations that steward digital collections need to be clear about what they mean when they are referring to organizational sustainability so that they can make appropriate decisions for future-proofing their collections. The analysis would also suggest for a greater need to consider the full range of dimensions of organizational sustainability. Originality/value By introducing a new nine dimensional framework of organizational sustainability the authors hope to promote more and better conversations within the LIS community about organizational sustainability. The authors hope these conversations will lead to productive action and improvements in the arrangements of people and work necessary to keep digital projects and services going over time, given ongoing challenges.},
	number = {2},
	urldate = {2023-03-24},
	journal = {Online Information Review},
	author = {Eschenfelder, Kristin R. and Shankar, Kalpana and Williams, Rachel D. and Salo, Dorothea and Zhang, Mei and Langham, Allison},
	month = jan,
	year = {2018},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Sustainability, Content analysis, Data and digital repositories, Digital longevity},
	pages = {182--196},
	file = {Full Text PDF:files/1993/Eschenfelder et al. - 2018 - A nine dimensional framework for digital cultural .pdf:application/pdf},
}

@article{agosti_promoting_2018,
	title = {Promoting user engagement with digital cultural heritage collections},
	volume = {19},
	issn = {1432-1300},
	url = {https://doi.org/10.1007/s00799-018-0245-y},
	doi = {10.1007/s00799-018-0245-y},
	abstract = {In the context of cooperating in a project whose central aim has been the production of a corpus agnostic research environment supporting access to and exploitation of digital cultural heritage collections, we have worked towards promoting user engagement with the collections. The aim of this paper is to present the methods and the solutions that have been envisaged and implemented to engage a diversified range of users with digital collections. Innovative solutions to stimulate and enhance user engagement have been achieved through a sustained and broad-based involvement of different cohorts of users. In particular, we propose the use of narratives to support and guide users within the collection and present them the main available tools. In moving beyond the specialized, search-based and stereotyped norm, the environment that we have contributed to developing offers a new approach for accessing and interacting with cultural heritage collections. It shows the value of an adaptive interface that dynamically responds to support the user, whatever his or her level of experience with digital environments or familiarity with the content may be.},
	language = {en},
	number = {4},
	urldate = {2023-03-24},
	journal = {International Journal on Digital Libraries},
	author = {Agosti, Maristella and Orio, Nicola and Ponchia, Chiara},
	month = nov,
	year = {2018},
	keywords = {CULTURA project, Digital cultural heritage collections, Evaluation, Narratives, User engagement, User studies},
	pages = {353--366},
	file = {Full Text PDF:files/1995/Agosti et al. - 2018 - Promoting user engagement with digital cultural he.pdf:application/pdf},
}

@article{muenster_digital_2019,
	series = {International {Archives} of the {Photogrammetry}, {Remote} {Sensing} and {Spatial} {Information} {Sciences}},
	title = {Digital {Cultural} {Heritage} meets {Digital} {Humanities}},
	issn = {1682-1750},
	doi = {10.5194/isprs-archives-XLII-2-W15-813-2019},
	abstract = {Digital Cultural Heritage and Digital Humanities are, historically seen, in focus of different communities as well as approaching different research topics and - from an organizational point of view - departments. However, are they that different? The idea of this joint article involving digital humanists and heritage researchers is to examine communities, concepts and research applications as well as shared challenges. Beyond a collection of problem-centred essays this is intended to initiate a fruitful discussion about commonalities and differences between both scholarly fields as well as to assess to which extent they are two sides of the same medal},
	journal = {27Th Cipa International Symposium: Documenting The Past For A Better Future},
	editor = {Muenster, S. and Apollonio, F. I. and Bell, P. and Kuroczynski, P. and Di Lenardo, I. and Rinaudo, F. and Tamborrino, R.},
	year = {2019},
	note = {Meeting Name: 27th CIPA International Symposium on Documenting the Past for a Better Future
Place: Hannover
Publisher: INTL SOC PHOTOGRAMMETRY \& REMOTE SENSING-ISPRS},
	keywords = {Computer Science, digital humanities, digital cultural heritage, Archaeology, Architecture, Art, challenges, Computer Science, Information Systems, essay, Imaging Science \& Photographic Technology, information, Remote Sensing, topics},
	file = {Full text:files/1997/Muenster et al. - 2019 - Digital Cultural Heritage meets Digital Humanities.pdf:application/pdf},
}

@inproceedings{oomen_crowdsourcing_2011,
	address = {New York, NY, USA},
	series = {C\&amp;{T} '11},
	title = {Crowdsourcing in the cultural heritage domain: opportunities and challenges},
	isbn = {978-1-4503-0824-3},
	shorttitle = {Crowdsourcing in the cultural heritage domain},
	url = {https://dl.acm.org/doi/10.1145/2103354.2103373},
	doi = {10.1145/2103354.2103373},
	abstract = {Galleries, Libraries, Archives and Museums (short: GLAMs) around the globe are beginning to explore the potential of crowdsourcing, i. e. outsourcing specific activities to a community though an open call. In this paper, we propose a typology of these activities, based on an empirical study of a substantial amount of projects initiated by relevant cultural heritage institutions. We use the Digital Content Life Cycle model to study the relation between the different types of crowdsourcing and the core activities of heritage organizations. Finally, we focus on two critical challenges that will define the success of these collaborations between amateurs and professionals: (1) finding sufficient knowledgeable, and loyal users; (2) maintaining a reasonable level of quality. We thus show the path towards a more open, connected and smart cultural heritage: open (the data is open, shared and accessible), connected (the use of linked data allows for interoperable infrastructures, with users and providers getting more and more connected), and smart (the use of knowledge and web technologies allows us to provide interesting data to the right users, in the right context, anytime, anywhere -- both with involved users/consumers and providers). It leads to a future cultural heritage that is open, has intelligent infrastructures and has involved users, consumers and providers.},
	urldate = {2023-03-24},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Communities} and {Technologies}},
	publisher = {Association for Computing Machinery},
	author = {Oomen, Johan and Aroyo, Lora},
	month = jun,
	year = {2011},
	keywords = {heritage, metadata, crowdsourcing, lifecycle model, tagging},
	pages = {138--149},
	file = {Full Text PDF:files/1999/Oomen e Aroyo - 2011 - Crowdsourcing in the cultural heritage domain opp.pdf:application/pdf},
}

@article{dragoni_knowledge_2017,
	title = {A {Knowledge} {Management} {Architecture} for {Digital} {Cultural} {Heritage}},
	volume = {10},
	issn = {1556-4673},
	url = {https://dl.acm.org/doi/10.1145/3012289},
	doi = {10.1145/3012289},
	abstract = {The increasing demand of technological facilities for galleries, museums, and archives has led to the need for designing practical and effective solutions for managing the digital life cycle of cultural heritage collections. These facilities have to support users in addressing several challenges directly related to the creation, management, preservation, and visualization of digital collections. Such challenges include, for example, the support for a collaborative management of the produced information, their curation from a multilingual perspective to break the language barriers and make collections available to different stakeholders, and the development of services for exposing structured version of data both to users and machines. Platforms satisfying all of these requirements have to support curators activities and, at the same time, provide facilities for engaging the virtual consumers of the produced data. In this article, we propose a description of an abstract architecture for managing digital collections built on a set of components, services, and APIs able to address the challenges mentioned previously. An instantiation of this architecture is discussed, and we present a use case concerning the management of a digital archive of verbo-visual art. Lessons learned from this experience are reported to outline future activities.},
	number = {3},
	urldate = {2023-03-24},
	journal = {Journal on Computing and Cultural Heritage},
	author = {Dragoni, Mauro and Tonelli, Sara and Moretti, Giovanni},
	month = jul,
	year = {2017},
	keywords = {curation, digital heritage, Knowledge management, services, visualization},
	pages = {15:1--15:18},
	file = {Full Text PDF:files/2001/Dragoni et al. - 2017 - A Knowledge Management Architecture for Digital Cu.pdf:application/pdf},
}

@misc{httpsplusgooglecomunesco_concept_2019,
	title = {Concept of {Digital} {Heritage}},
	url = {https://en.unesco.org/themes/information-preservation/digital-heritage/concept-digital-heritage},
	language = {en},
	urldate = {2023-03-24},
	journal = {UNESCO},
	author = {https://plus.google.com/+UNESCO},
	month = mar,
	year = {2019},
	file = {Snapshot:files/2003/concept-digital-heritage.html:text/html},
}

@misc{noauthor_charter_nodate,
	title = {Charter on the {Preservation} of the {Digital} {Heritage} - {UNESCO} {Digital} {Library}},
	url = {https://unesdoc.unesco.org/ark:/48223/pf0000179529.page=2},
	urldate = {2023-03-24},
	file = {Charter on the Preservation of the Digital Heritage - UNESCO Digital Library:files/2005/pf0000179529.html:text/html},
}

@misc{noauthor_deployment_2022,
	title = {The deployment of a common {European} data space for cultural heritage {\textbar} {Shaping} {Europe}’s digital future},
	url = {https://digital-strategy.ec.europa.eu/en/news/deployment-common-european-data-space-cultural-heritage},
	abstract = {The service contract for the deployment of the common European data space for cultural heritage has been awarded to a consortium of 19 partners from 9 EU countries.},
	language = {en},
	urldate = {2023-03-24},
	month = oct,
	year = {2022},
	file = {Snapshot:files/2007/deployment-common-european-data-space-cultural-heritage.html:text/html},
}

@article{daquino_linked_2019,
	title = {Linked {Data} per le edizioni scientifiche digitali. {Il} workflow di pubblicazione dell’edizione semantica del quaderno di appunti di {Paolo} {Bufalini}},
	copyright = {Copyright (c) 2019},
	issn = {2532-8816},
	url = {https://umanisticadigitale.unibo.it/article/view/9091},
	doi = {10.6092/issn.2532-8816/9091},
	abstract = {Digital Scholarly Editions (DSE) are a powerful tool for disseminating cultural heritage. As long as Semantic Web technologies become a de facto standard for disseminating cultural heritage data, DSE are a missing bit that must be integrated in the LOD Cloud. Despite a number of standards are in place for exchanging data about encoded texts (XML/TEI, noSQL database, RESTful API), a number of key elements are missing, namely: (1) a comprehensive workflow for publishing DSE as knowledge graphs, (2) data models for identifying concepts and relationships characterising DSE, and (3) a cost-benefit analysis of the usage of such technologies. In this paper we present the proof-of-concept DSE of Paolo Bufalini's notebook so as to address, discuss, and evaluate aforementioned issues.},
	language = {it},
	number = {7},
	urldate = {2023-03-27},
	journal = {Umanistica Digitale},
	author = {Daquino, Marilena and Giovannetti, Francesca and Tomasi, Francesca},
	month = dec,
	year = {2019},
	note = {Number: 7},
	keywords = {Semantic publishing},
	file = {Full Text PDF:files/2009/Daquino et al. - 2019 - Linked Data per le edizioni scientifiche digitali..pdf:application/pdf},
}

@incollection{buzzoni_protocol_2016,
	edition = {1},
	series = {Theories and {Practices}},
	title = {A {Protocol} for {Scholarly} {Digital} {Editions}?: {The} {Italian} {Point} of {View}},
	volume = {4},
	isbn = {978-1-78374-238-7},
	shorttitle = {A {Protocol} for {Scholarly} {Digital} {Editions}?},
	url = {https://www.jstor.org/stable/j.ctt1fzhh6v.8},
	abstract = {This chapter discusses whether it is desirable to establish a \textit{protocol} that would provide, if not a standard, at least some guidance on how to structure the core elements that one should expect to find in a scholarly electronic edition.  A preliminary examination is thus needed to determine which features should be defined as fundamental. Though the debate on the issue is still intense, many scholars in the field of digital philology 1 now agree that there are at least five domains in which scholarly digital editions may offer important advantages over paper editions, namely:²  1. the possibility to present},
	urldate = {2023-03-27},
	booktitle = {Digital {Scholarly} {Editing}},
	publisher = {Open Book Publishers},
	author = {Buzzoni, Marina},
	editor = {Driscoll, Matthew James and Pierazzo, Elena},
	year = {2016},
	pages = {59--82},
	file = {JSTOR Full Text PDF:files/2011/Buzzoni - 2016 - A Protocol for Scholarly Digital Editions The It.pdf:application/pdf},
}

@article{calder_computational_2018,
	title = {Computational modelling for decision-making: where, why, what, who and how},
	volume = {5},
	shorttitle = {Computational modelling for decision-making},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rsos.172096},
	doi = {10.1098/rsos.172096},
	abstract = {In order to deal with an increasingly complex world, we need ever more sophisticated computational models that can help us make decisions wisely and understand the potential consequences of choices. But creating a model requires far more than just raw data and technical skills: it requires a close collaboration between model commissioners, developers, users and reviewers. Good modelling requires its users and commissioners to understand more about the whole process, including the different kinds of purpose a model can have and the different technical bases. This paper offers a guide to the process of commissioning, developing and deploying models across a wide range of domains from public policy to science and engineering. It provides two checklists to help potential modellers, commissioners and users ensure they have considered the most significant factors that will determine success. We conclude there is a need to reinforce modelling as a discipline, so that misconstruction is less likely; to increase understanding of modelling in all domains, so that the misuse of models is reduced; and to bring commissioners closer to modelling, so that the results are more useful.},
	number = {6},
	urldate = {2023-03-27},
	journal = {Royal Society Open Science},
	author = {Calder, Muffy and Craig, Claire and Culley, Dave and de Cani, Richard and Donnelly, Christl A. and Douglas, Rowan and Edmonds, Bruce and Gascoigne, Jonathon and Gilbert, Nigel and Hargrove, Caroline and Hinds, Derwen and Lane, David C. and Mitchell, Dervilla and Pavey, Giles and Robertson, David and Rosewell, Bridget and Sherwin, Spencer and Walport, Mark and Wilson, Alan},
	month = jun,
	year = {2018},
	note = {Publisher: Royal Society},
	keywords = {data, uncertainty, communication, complexity, decision-making, modelling},
	pages = {172096},
	file = {Full Text PDF:files/2013/Calder et al. - 2018 - Computational modelling for decision-making where.pdf:application/pdf},
}

@misc{tomasi_vespasiano_2020,
	title = {Vespasiano da {Bisticci}, {Lettere}. {Knowledge} {Base} 2020},
	copyright = {cc\_by\_4},
	url = {http://amsacta.unibo.it/6852},
	doi = {10.6092/UNIBO/AMSACTA/6852},
	abstract = {Edizione digitale semantica delle Lettere di Vespasiano da Bisticci, comprensiva di: dataset, applicazione, documentazione},
	urldate = {2023-03-28},
	publisher = {Alma Mater Studiorum - Università di Bologna},
	author = {Tomasi, Francesca and Daquino, Marilena and Barzaghi, Sebastian},
	year = {2020},
	note = {Medium: archive},
	keywords = {M-STO/08 Archivistica, bibliografia e biblioteconomia, PE6\_10 Web and information systems, database systems, information retrieval and digital libraries, data fusion, SH5\_11 Cultural heritage, cultural memory},
}

@misc{noauthor_epistolario_nodate,
	title = {Epistolario {De} {Gasperi}},
	url = {https://epistolariodegasperi.it/#/},
	urldate = {2023-03-28},
	file = {Epistolario De Gasperi:files/2167/epistolariodegasperi.it.html:text/html},
}

@book{ciotti_dallinformatica_2012,
	title = {Dall'{Informatica} umanistica alle culture digitali: {Atti} del convegno di studi ({Roma}, 27-28 {Ottobre} 2011) in memoria di {Giuseppe} {Gigliozzi}},
	isbn = {978-88-95814-82-7},
	shorttitle = {Dall'{Informatica} umanistica alle culture digitali},
	language = {it},
	publisher = {Sapienza Università Editrice},
	author = {Ciotti, Fabio and Crupi, Gianfranco},
	month = dec,
	year = {2012},
	note = {Google-Books-ID: A1mRDwAAQBAJ},
	keywords = {Computers / Digital Media / General},
}

@misc{noauthor_epistolario_nodate-1,
	title = {Epistolario {De} {Gasperi}: {National} {Edition} of {De} {Gasperi}’s {Letters} in {Digital} {Format}},
	url = {https://publicatt.unicatt.it/handle/10807/155838},
	urldate = {2023-03-28},
	file = {Epistolario De Gasperi\: National Edition of De Gasperi’s Letters in Digital Format:files/2171/155838.html:text/html},
}

@article{pollin_depcha_nodate,
	title = {{DEPCHA} and the {Bookkeeping} {Ontology}},
	abstract = {The Project ”Digital Edition Publishing Cooperative for Historical Accounts”, a Andrew W. Mellon funded cooperation of five US partners and the Centre for Information Modelling at Graz University, aims to link the knowledge domain of economic activities to historical accounting records. For this purpose the so-called Bookkeeping Ontology is developed. DEPCHA creates a publication hub for digital editions on the web. It converts multiple formats into RDF and publishes these in combination with the associated transcriptions. DEPCHA also allows the usage of retrieval and visualization functionalities, as well as interoperability and reuse of information in the sense of Linked Open Data.},
	language = {en},
	author = {Pollin, Christopher},
	file = {Pollin - DEPCHA and the Bookkeeping Ontology.pdf:files/2172/Pollin - DEPCHA and the Bookkeeping Ontology.pdf:application/pdf},
}

@article{del_turco_designing_2019,
	title = {Designing an advanced software tool for {Digital} {Scholarly} {Editions}: {The} inception and development of {EVT} ({Edition} {Visualization} {Technology})},
	volume = {12},
	issn = {1559-2936},
	shorttitle = {Designing an advanced software tool for {Digital} {Scholarly} {Editions}},
	url = {https://www.jstor.org/stable/26821538},
	abstract = {The increasing dissemination of Digital Scholarly Editions has highlighted not only the great potential of this method of publication, but also a good number of theoretical problems that affect both the DSEs as editorial products, and the impact of tools and methods of computer science on the methodology of textual criticism. On the one hand, the editions published so far are an evolution of the practice of ecdotics and represent not only a collection of interesting experiments, but also innovative and effective research tools. On the other hand, however, the limits within which an author of digital editions is forced to operate and the most appropriate strategies to minimize their impact have not yet been thoroughly investigated. The adoption of IT tools and methods, in fact, provides many answers to the requests of digital philologists, but the very nature of these tools imposes very strict modes of action, sometimes perceived as too rigid by the scholar. This article presents and describes a software tool that comes at the end of the process of creating a digital edition, to be used in that crucial phase when the edition is prepared for publication on the Web. The aim is not to show the more technical aspects of this tool, even if its fundamental characteristics will be introduced to better understand the terms of the issue, but to describe its genesis and development, and to highlight how visualization software represents a crucial element of the whole editorial process.},
	number = {2},
	urldate = {2023-03-28},
	journal = {Textual Cultures},
	author = {Del Turco, Roberto Rosselli},
	year = {2019},
	note = {Publisher: [Society for Textual Scholarship, Indiana University Press]},
	pages = {91--111},
	file = {JSTOR Full Text PDF:files/2175/Del Turco - 2019 - Designing an advanced software tool for Digital Sc.pdf:application/pdf},
}

@article{broyles_digital_2020,
	title = {Digital {Editions} and {Version} {Numbering}},
	volume = {14},
	issn = {1938-4122},
	url = {https://hcommons.org/deposits/item/hc:38103/},
	abstract = {Digital editions are easily modified after they are first published — a state of affairs that poses challenges both for long-term scholarly reference and for various forms of electronic distribution and analysis. This article argues that producers of digital editions should assign meaningful version numbers to their editions and update those version numbers with each change, allowing both humans and computers to know when resources have been modified and how significant the changes are. As an examination of versioning practices in the software industry reveals, version numbers are not neutral descriptors but social products intended for use in specific contexts, and the producers of digital editions must consider how version numbers will be used in developing numbering schemes. It may be beneficial to version different parts of an edition separately, and in particular to version the data objects or content of an edition independently from the environment in which it is displayed. The article concludes with a case study of the development of a versioning policy for the Piers Plowman Electronic Archive, and includes an appendix surveying how a selection of digital editions handle the problem of recording and communicating changes.},
	language = {en-US},
	number = {2},
	urldate = {2023-03-28},
	journal = {Digital Humanities Quarterly (DHQ)},
	author = {Broyles, Paul A.},
	year = {2020},
	note = {Publisher: Alliance of Digital Humanities Organizations},
	file = {Full Text PDF:files/2177/Broyles - 2020 - Digital Editions and Version Numbering.pdf:application/pdf},
}

@inproceedings{stringer_workflow_2009,
	title = {Workflow, {Responsibility} and {Quality} {Control} for {Digital} {Editions}: {A} {Case} {Study}},
	shorttitle = {Workflow, {Responsibility} and {Quality} {Control} for {Digital} {Editions}},
	url = {https://ore.exeter.ac.uk/repository/handle/10871/25194},
	abstract = {The modern digital edition of a literary work is most often a collaborative product, with many contributors participating in the process of production, from the planning and image capture phases through to the electronic presentation of the edition. Managing the production process, and marshalling all these forces into an efficient workflow presents a major challenge, which is often well understood for large scale projects, but is perhaps less well defined for individual Edition projects. 
In this paper I will present some suggestions for tools to ease this workflow, and some analysis of their effectiveness in use, notably within the AHRC‐funded project, “Citation and Allusion in the Ars Nova French Chanson and Motet”, towards the production of “Je chante ung chant”, an archive of late‐medieval lyrical poetry. Now in a pre‐production phase, this project has leant heavily on a number of tools to ensure consistency in a highly complex markup schema. Many of the tools examined are standard, open‐source products, and are commonly used in other areas of digital production, such as software development; I will address both their applicability to the domain of literary text production, and their suitability to a less technical audience such literary editors and reviewers and look at notable features to assist developers, designers, editors and project managers.},
	language = {en},
	urldate = {2023-03-28},
	publisher = {DRHA},
	author = {Stringer, G. B.},
	month = sep,
	year = {2009},
	note = {Accepted: 2017-01-13T10:22:39Z},
	file = {Full Text PDF:files/2179/Stringer - 2009 - Workflow, Responsibility and Quality Control for D.pdf:application/pdf},
}

@article{kuczera_digital_nodate,
	title = {Digital {Editions} beyond {XML} – {Graph}-based {Digital} {Editions}},
	abstract = {XML has been the de facto standard for digital editions for years, but its serious limitations include an inability to represent overlapping markup and the encoding of multiple annotation hierarchies. With emerging graph database technologies we have the opportunity to develop new approaches. In this paper the advantages and modelling principles of graph-based digital editions will be discussed.},
	language = {en},
	author = {Kuczera, Andreas},
	file = {Kuczera - Digital Editions beyond XML – Graph-based Digital .pdf:files/2180/Kuczera - Digital Editions beyond XML – Graph-based Digital .pdf:application/pdf},
}

@article{pollin_semantically_nodate,
	title = {Semantically {Enriched} {Historical} {Data}. {Drawing} on the {Example} of the {Digital} {Edition} of the ”{Urfehdebu}¨cher der {Stadt} {Basel}”},
	abstract = {Historical data is widely recognized as a rather complex type of data that contains records about multi-layered, context-sensitive entities and can often be represented as a graph. This paper describes the digital edition of the ”Urfehdebu¨cher der Stadt Basel” as an example of how semantic web technologies can oﬀer comprehensive tools in response to the challenges coming with historical data. It introduces the FEDORA Commons based GAMS-infrastructure, reports the workﬂow from XML/TEI1 encoded historical documents to semantically enriched data in form of XML/RDF data, and describes the speciﬁc data model for the resource. Finally, the paper discusses how the data can be used beyond a standard web interface with reading and search functionalities, for analysis with network visualisation functionalities.},
	language = {en},
	author = {Pollin, Christopher and Vogeler, Georg},
	file = {Pollin e Vogeler - Semantically Enriched Historical Data. Drawing on .pdf:files/2182/Pollin e Vogeler - Semantically Enriched Historical Data. Drawing on .pdf:application/pdf},
}

@article{schmidt_towards_2014,
	title = {Towards an {Interoperable} {Digital} {Scholarly} {Edition}},
	copyright = {TEI Consortium 2014 (Creative Commons Attribution-NoDerivs 3.0 Unported License)},
	issn = {2162-5603},
	url = {https://journals.openedition.org/jtei/979},
	doi = {10.4000/jtei.979},
	abstract = {Recent proposals for creating digital scholarly editions (DSEs) through the crowdsourcing of transcriptions and collaborative scholarship, for the establishment of national repositories of digital humanities data, and for the referencing, sharing, and storage of DSEs, have underlined the need for greater data interoperability. The TEI Guidelines have tried to establish standards for encoding transcriptions since 1988. However, because the choice of tags is guided by human interpretation, TEI-XML encoded files are in general not interoperable. One way to fix this problem may be to break down the current all-in-one approach to encoding so that DSEs can be specified instead by a bundle of separate resources that together offer greater interoperability: plain text versions, markup, annotations, and metadata. This would facilitate not only the development of more general software for handling DSEs, but also enable existing programs that already handle these kinds of data to function more efficiently.},
	language = {en},
	number = {Issue 7},
	urldate = {2023-03-28},
	journal = {Journal of the Text Encoding Initiative},
	author = {Schmidt, Desmond},
	month = nov,
	year = {2014},
	note = {Number: Issue 7
Publisher: Text Encoding Initiative Consortium},
	keywords = {interoperability, metadata, stand-off markup, annotation, digital scholarly editions},
	file = {Full Text PDF:files/2185/Schmidt - 2014 - Towards an Interoperable Digital Scholarly Edition.pdf:application/pdf},
}

@article{bonch-osmolovskaya_tolstoy_2019,
	title = {Tolstoy semanticized: {Constructing} a digital edition for knowledge discovery},
	volume = {59},
	issn = {1570-8268},
	shorttitle = {Tolstoy semanticized},
	url = {https://www.sciencedirect.com/science/article/pii/S1570826818300635},
	doi = {10.1016/j.websem.2018.12.001},
	abstract = {The paper presents the results of a project devoted to the creation of a digital edition of Leo Tolstoy’s complete works.1 Our primary source is the 90-volume critical print edition of Tolstoy’s oeuvre. We discuss the rationale for semantic markup of metadata for three classes of texts: works, letters and diaries. We extract information from the critical apparatus and supplement it with some new additional markups that enable visualizing the evolution of Tolstoy as a publicist. We show that the named entity index constitutes a valuable knowledge base, which can serve as a basis for generating a knowledge graph that is more detailed and systematic than the open linked databases like DBpedia.},
	language = {en},
	urldate = {2023-03-28},
	journal = {Journal of Web Semantics},
	author = {Bonch-Osmolovskaya, Anastasia and Skorinkin, Daniil and Pavlova, Irina and Kolbasov, Matvey and Orekhov, Boris},
	month = dec,
	year = {2019},
	keywords = {TEI, Digital edition, Leo Tolstoy, Semantic markup},
	pages = {100483},
	file = {ScienceDirect Snapshot:files/2187/S1570826818300635.html:text/html},
}

@article{de_smedt_fair_2020,
	title = {{FAIR} {Digital} {Objects} for {Science}: {From} {Data} {Pieces} to {Actionable} {Knowledge} {Units}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2304-6775},
	shorttitle = {{FAIR} {Digital} {Objects} for {Science}},
	url = {https://www.mdpi.com/2304-6775/8/2/21},
	doi = {10.3390/publications8020021},
	abstract = {Data science is facing the following major challenges: (1) developing scalable cross-disciplinary capabilities, (2) dealing with the increasing data volumes and their inherent complexity, (3) building tools that help to build trust, (4) creating mechanisms to efficiently operate in the domain of scientific assertions, (5) turning data into actionable knowledge units and (6) promoting data interoperability. As a way to overcome these challenges, we further develop the proposals by early Internet pioneers for Digital Objects as encapsulations of data and metadata made accessible by persistent identifiers. In the past decade, this concept was revisited by various groups within the Research Data Alliance and put in the context of the FAIR Guiding Principles for findable, accessible, interoperable and reusable data. The basic components of a FAIR Digital Object (FDO) as a self-contained, typed, machine-actionable data package are explained. A survey of use cases has indicated the growing interest of research communities in FDO solutions. We conclude that the FDO concept has the potential to act as the interoperable federative core of a hyperinfrastructure initiative such as the European Open Science Cloud (EOSC).},
	language = {en},
	number = {2},
	urldate = {2023-03-28},
	journal = {Publications},
	author = {De Smedt, Koenraad and Koureas, Dimitris and Wittenburg, Peter},
	month = jun,
	year = {2020},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {FAIR data, data infrastructure, data management, data science, digital object, EOSC, European Open Science Cloud, open science, persistent identifier, research infrastructure},
	pages = {21},
	file = {Full Text PDF:files/2189/De Smedt et al. - 2020 - FAIR Digital Objects for Science From Data Pieces.pdf:application/pdf},
}

@article{noauthor_e_2021,
	title = {E. {Spadini}, {F}. {Tomasi} e {G}. {Vogeler} (eds.), {Graph} {Data}-{Models} and {Semantic} {Web} {Technologies} in {Scholarly} {Digital} {Editing} ({A}.{S}. {Lip}- polis), p. 235 · {M}.{G}. {Tavoni}, {Storie} di libri e tecnologie: dall\&\#8217;avven- to della stampa al digitale ({P}. {Tin} ti), p. 241 · {P}. {Trovato}, {Sguardi} da un altro pianeta. {Nove} esercizi di \&\#64257;lologia ({R}. {Cupo}), p. 245},
	issn = {1825-5361},
	shorttitle = {E. {Spadini}, {F}. {Tomasi} e {G}. {Vogeler} (eds.), {Graph} {Data}-{Models} and {Semantic} {Web} {Technologies} in {Scholarly} {Digital} {Editing} ({A}.{S}. {Lip}- polis), p. 235 · {M}.{G}. {Tavoni}, {Storie} di libri e tecnologie},
	doi = {10.7385/103830},
	number = {1/2021},
	journal = {Ecdotica},
	year = {2021},
	note = {Context Object: ctx\_ver=Z39.88-2004\&rfr\_id=info\%3Asid\%2Fmulino.it\%3AeNabu\&rft\_val\_fmt=info\%3Aofi\%2Ffmt\%3Akev\%3Amtx\%3Ajournal\&rft.genre=article\&rft.atitle=E.\%20Spadini\%2C\%20F.\%20Tomasi\%20e\%20G.\%20Vogeler\%20\%28eds.\%29\%2C\%20Graph\%20Data-Models\%20and\%20Semantic\%20Web\%20Technologies\%20in\%20Scholarly\%20Digital\%20Editing\%20\%28A.S.\%20Lip-\%20polis\%29\%2C\%20p.\%20235\%20\%C2\%B7\%20M.G.\%20Tavoni\%2C\%20Storie\%20di\%20libri\%20e\%20tecnologie\%3A\%20dall\%26\%238217\%3Bavven-\%20to\%20della\%20stampa\%20al\%20digitale\%20\%28P.\%20Tin\%20ti\%29\%2C\%20p.\%20241\%20\%C2\%B7\%20P.\%20Trovato\%2C\%20Sguardi\%20da\%20un\%20altro\%20pianeta.\%20Nove\%20esercizi\%20di\%20\%26\%2364257\%3Blologia\%20\%28R.\%20Cupo\%29\%2C\%20p.\%20245\%20\&rft.title=Ecdotica\&rft.stitle=EC\&rft.issn=1825-5361\&rft.date=2021\&rft.issue=1\%2F2021\&rft\_id=info\%3Adoi\%2F10.7385\%2F103830},
}

@article{tomasi_l8217edizione_2012,
	title = {L\&\#8217;edizione digitale e la rappresentazione della conoscenza. {Un} esempio: {Vespasiano} da {Bisticci} e le sue lettere},
	issn = {1825-5361},
	shorttitle = {L\&\#8217;edizione digitale e la rappresentazione della conoscenza. {Un} esempio},
	doi = {10.7385/99154},
	number = {1/2012},
	journal = {Ecdotica},
	author = {Tomasi, Francesca},
	year = {2012},
}

@inproceedings{barbera_annotating_2013,
	address = {Berlin, Heidelberg},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Annotating {Digital} {Libraries} and {Electronic} {Editions} in a {Collaborative} and {Semantic} {Perspective}},
	isbn = {978-3-642-35834-0},
	doi = {10.1007/978-3-642-35834-0_7},
	abstract = {The distinction between digital libraries and electronic editions is becoming more and more subtle. The practice of annotation represents a point of convergence of two only apparently separated worlds. The aim of this paper is to present a model of collaborative semantic annotation of texts (SemLib project), suggesting a system that find in Semantic Web and Linked Data the solution technologies for enabling structured semantic annotation, also in the field of electronic editions in Digital Humanities domain. The main purpose of SemLib is to develop an application so to make easy for developers the integration of annotation software in digital libraries, which are different both for technical implementations and managed contents, and provide to users, indifferently from their cultural backgrounds, a simple system which could be used as a front-end. We present, for this purpose, a final example of semantic annotation in a specific context: a digital edition of a literary text and the issues that an annotation task involves.},
	language = {en},
	booktitle = {Digital {Libraries} and {Archives}},
	publisher = {Springer},
	author = {Barbera, Michele and Meschini, Federico and Morbidoni, Christian and Tomasi, Francesca},
	editor = {Agosti, Maristella and Esposito, Floriana and Ferilli, Stefano and Ferro, Nicola},
	year = {2013},
	keywords = {ontologies, Linked Data, TEI, RDF, Open Collaboration},
	pages = {45--56},
	file = {Versione inviata:files/2194/Barbera et al. - 2013 - Annotating Digital Libraries and Electronic Editio.pdf:application/pdf},
}

@article{winslow_ontologies_nodate,
	title = {Ontologies in the {Digital} {Repository}: {Metadata} {Integration}, {Knowledge} {Management} and {Ontology}-{Driven} {Applications}},
	abstract = {This paper illustrates how ontologies form an important foundation for the preservation, management, publication, and retrieval of humanities research data in the University of Graz’ institutional repository for the Humanities, the Geisteswissenschaftliches Asset Management System (GAMS). The GAMS is a Fedora Commons-based repository which hosts more than one hundred research projects from different scholarly domains that extensively employ semantic web technologies and ontologies in their implementation. Many projects expose their research data as RDF and use shared vocabularies for shared entities. Using representative examples from digital scholarly editions, digital collections, and language resources, we show how ontologies enrich the user experience at the levels of modelling, analysis, and integration. The use of shared ontologies by projects with similar data allows search and retrieval scenarios to function across equivalent datasets in different projects and the formalization of data through large datasets allows the comparison of larger bodies of information than were possible using traditional (analogue) humanities methods.},
	language = {en},
	author = {Winslow, Sean M and Schneider, Gerlinde and Bleier, Roman and Steiner, Christian and Pollin, Christopher and Vogeler, Georg},
	file = {Winslow et al. - Ontologies in the Digital Repository Metadata Int.pdf:files/2195/Winslow et al. - Ontologies in the Digital Repository Metadata Int.pdf:application/pdf},
}

@book{sikos_mastering_2015,
	address = {Berkeley, CA},
	title = {Mastering {Structured} {Data} on the {Semantic} {Web}},
	isbn = {978-1-4842-1050-5 978-1-4842-1049-9},
	url = {http://link.springer.com/10.1007/978-1-4842-1049-9},
	language = {en},
	urldate = {2023-03-28},
	publisher = {Apress},
	author = {Sikos, Leslie F.},
	year = {2015},
	doi = {10.1007/978-1-4842-1049-9},
}

@article{messaoudi_ontological_2018,
	title = {An ontological model for the reality-based {3D} annotation of heritage building conservation state},
	volume = {29},
	issn = {1296-2074},
	url = {https://www.sciencedirect.com/science/article/pii/S1296207417304508},
	doi = {10.1016/j.culher.2017.05.017},
	abstract = {The conservation and restoration of historical monuments require a diagnostic analysis carried out by a multidisciplinary team. The results of the diagnosis include data produced by different techniques and protocols, which are used by conservation scientists to assess the built heritage. Nowadays, together with the aforementioned data, a great deal of heterogeneous information is also available, including descriptive and contextual information, as well as 2D/3D geometrical restitution of the studied object. However, the integration of these diverse data into a unique information model capable of fully describing the building conservation state, as well as integrating future data, is still an open issue within the Cultural Heritage community. It is of paramount importance to correlate these data and spatialize them in order to provide scientists in charge of our heritage with a practical and easy means to explore the information used during their assessment, as well as a way to record their scientific observation and share them within their community of practice. In order to resolve this issue, we developed a correlation pipeline for the integration of the semantic, spatial and morphological dimension of a built heritage. The pipeline uses an ontological model for recording and integrating multidisciplinary observations of the conservation state into structural data spatialized into a semantic-aware 3D representation. The pipeline was successfully tested on the Saint Maurice church of Caromb in the south of France, integrating into a unique spatial representation information about material and alteration phenomena, providing users with a means to correlate, and more importantly retrieve several types of information.},
	language = {en},
	urldate = {2023-03-28},
	journal = {Journal of Cultural Heritage},
	author = {Messaoudi, Tommy and Véron, Philippe and Halin, Gilles and De Luca, Livio},
	month = jan,
	year = {2018},
	keywords = {Knowledge, Conservation, Ontology, Cultural heritage, Data management, Semantic annotation},
	pages = {100--112},
	file = {ScienceDirect Snapshot:files/2200/S1296207417304508.html:text/html;Versione inviata:files/2201/Messaoudi et al. - 2018 - An ontological model for the reality-based 3D anno.pdf:application/pdf},
}

@inproceedings{sikos_rich_2016,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Rich {Semantics} for {Interactive} {3D} {Models} of {Cultural} {Artifacts}},
	isbn = {978-3-319-49157-8},
	doi = {10.1007/978-3-319-49157-8_14},
	abstract = {The automated processing of 3D models of cultural artifacts can be significantly improved with formally defined high-level structured descriptors. Despite the large number of multimedia ontologies, however, the semantic enrichment of 3D models still has open issues. Many 3D ontologies are semi-structured only, cover a very narrow knowledge domain, do not provide comprehensive coverage for geometric primitives, or do not exploit the full expressivity of the implementation language. This paper presents the first attempt to transform the entire XML Schema-based vocabulary of the latest version of the X3D ISO standard (ISO/IEC 19775, 19776, and 19777) to OWL 2, complemented by fundamental concepts and roles of the 3D modeling industry not covered by X3D. The result of this effort is the most comprehensive formally grounded 3D multimedia ontology to date with standard alignment, which can be used for the representation, annotation, and efficient indexing and retrieval of 3D models.},
	language = {en},
	booktitle = {Metadata and {Semantics} {Research}},
	publisher = {Springer International Publishing},
	author = {Sikos, Leslie F.},
	editor = {Garoufallou, Emmanouel and Subirats Coll, Imma and Stellato, Armando and Greenberg, Jane},
	year = {2016},
	keywords = {Cultural heritage, 3D annotation, 3D model retrieval, Multimedia ontology, X3D},
	pages = {169--180},
}

@inproceedings{brutzman_x3d_2020,
	address = {New York, NY, USA},
	series = {{Web3D} '20},
	title = {{X3D} {Ontology} for {Querying} {3D} {Models} on the {Semantic} {Web}},
	isbn = {978-1-4503-8169-7},
	url = {https://dl.acm.org/doi/10.1145/3424616.3424715},
	doi = {10.1145/3424616.3424715},
	abstract = {The Semantic Web offers significant capabilities that transform the current Web into a global knowledge base including various cross-linked multimedia content with formal descriptions of its semantics understandable to humans and processable by computers. Content on the Semantic Web can be subject to reasoning and queries with standardized languages, methods and tools, which opens new opportunities for collaborative creation, use and exploration of web repositories. However, these opportunities have not been exploited so far by the available 3D formats and modeling tools, which limits the possibilities of search and reuse of 3D content as part of the Semantic Web. This work contributes a semantic development pipeline of the X3D Ontology, with corresponding conversion of X3D models into triple forms suitable for formal query. The ontology design reflects experience accompanying the development of the Extensible 3D (X3D) Graphics International Standard, in particular, the X3D Unified Object Model (X3DUOM). This approach combines semantic and syntactic elements of X3D models and metadata to support integration with the Semantic Web. The pipeline enables automatic generation of the X3D Ontology, thereby providing an up-to-date 3D representation with semantics during X3D specification development. By extending commonplace model conversions from other formats to X3D, the ontology presents the potential to enable integration of most forms of 3D content with the Semantic Web.},
	urldate = {2023-03-28},
	booktitle = {The 25th {International} {Conference} on {3D} {Web} {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Brutzman, Don and Flotyński, Jakub},
	month = nov,
	year = {2020},
	keywords = {Semantic Web, Semantic 3D, Web3D, X3D Ontology, X3DUOM},
	pages = {1--6},
	file = {Full Text PDF:files/2204/Brutzman e Flotyński - 2020 - X3D Ontology for Querying 3D Models on the Semanti.pdf:application/pdf},
}

@article{georgieva-trifonova_transforming_nodate,
	title = {Transforming {3D} {Models} to {Semantic} {Web} {Representation}},
	abstract = {The purpose of the present paper is to research a rule-based approach for transforming X3D (eXtensible 3D) models to RDF (Resource Description Framework). The transformation is performed by using the RDF Mapping Language (RML). Its advantages are summarized, which are mainly due to the fact that the rules created build a knowledge base. By applying SPARQL (SPARQL Protocol and RDF Query Language) queries to it, the possibility of explore in order to validate and improve the deﬁned RML rules themselves, is pointed out. An approach for reversing from the RDF triples to the original X3D in a unique way is considered, and the types of SPARQL queries needed for its implementation are systematized.},
	language = {en},
	author = {Georgieva-Trifonova, Tsvetanka and Galabov, Miroslav},
	file = {Georgieva-Trifonova e Galabov - Transforming 3D Models to Semantic Web Representat.pdf:files/2205/Georgieva-Trifonova e Galabov - Transforming 3D Models to Semantic Web Representat.pdf:application/pdf},
}

@inproceedings{flotynski_semantic_2019,
	title = {The {Semantic} {Web3d}: {Towards} {Comprehensive} {Representation} of 3d {Content} on the {Semantic} {Web}},
	shorttitle = {The {Semantic} {Web3d}},
	doi = {10.1109/IC3D48390.2019.8975906},
	abstract = {One of the main obstacles for wide dissemination of immersive virtual and augmented reality environments on the Web is the lack of integration between 3D technologies and web technologies, which are increasingly focused on collaboration, annotation and semantics. This gap can be filled by combining VR and AR with the Semantic Web, which is a significant trend in the development of theWeb. The use of the Semantic Web may improve creation, representation, indexing, searching and processing of 3D web content by linking the content with formal and expressive descriptions of its meaning. Although several semantic approaches have been developed for 3D content, they are not explicitly linked to the available well-established 3D technologies, cover a limited set of 3D components and properties, and do not combine domain-specific and 3D-specific semantics. In this paper, we present the main motivations, concepts and development of the Semantic Web3D approach. It enables semantic ontology-based representation of 3D content built upon the Extensible 3D (X3D) standard. The approach can integrate the Semantic Web with interactive 3D technologies within different domains, thereby serving as a step towards building the next generation of the Web that incorporates semantic 3D contents.},
	booktitle = {2019 {International} {Conference} on {3D} {Immersion} ({IC3D})},
	author = {Flotyński, Jakub and Brutzman, Don and Hamza-Lup, Felix G. and Malamos, Athanasios and Polys, Nicholas and Sikos, Leslie F. and Walczak, Krzysztof},
	month = dec,
	year = {2019},
	note = {ISSN: 2379-1780},
	keywords = {ontologies, Semantic Web, X3D, Web3D, knowledge bases, virtual reality},
	pages = {1--9},
	file = {IEEE Xplore Abstract Record:files/2208/8975906.html:text/html},
}

@article{homburg_metadata_2021,
	title = {Metadata schema and ontology for capturing and processing of {3D} cultural heritage objects},
	volume = {9},
	issn = {2050-7445},
	url = {https://doi.org/10.1186/s40494-021-00561-w},
	doi = {10.1186/s40494-021-00561-w},
	abstract = {Motivated by the increased use of 3D acquisition of objects by cultural heritage institutions, we were investigating ontologies and metadata schemes for the acquisition process to provide details about the 3D capturing, which can be combined with preexisting ontologies describing an object. Therefore we divided the 3D capturing workflow into common steps starting with the object being placed in front of a 3D scanner to preparation and publication of the 3D datasets and/or derived images. While the proposed ontology is well defined on a coarse level of detail for very different techniques, e.g. Stucture from Motion and LiDAR we elaborated the metadata scheme in very fine detail for 3D scanners available at our institutions. This includes practical experiments with measurement data from past and current projects including datasets published at Zenodo as guiding examples and the source code for their computation. Additionally, the free and Open Source GigaMesh Software Framework’s analysis and processing methods have been extended to provide metadata about the 3D processing steps like mesh cleaning as well as 2D image generation. Finally, we discuss the current limitations and give an outlook about future extensions.},
	number = {1},
	urldate = {2023-03-29},
	journal = {Heritage Science},
	author = {Homburg, Timo and Cramer, Anja and Raddatz, Laura and Mara, Hubert},
	month = jul,
	year = {2021},
	keywords = {Ontologies, Metadata, Semantic web, 3D scanning, Data quality},
	pages = {91},
	file = {Full Text PDF:files/2210/Homburg et al. - 2021 - Metadata schema and ontology for capturing and pro.pdf:application/pdf;Snapshot:files/2211/s40494-021-00561-w.html:text/html},
}

@inproceedings{dandrea_carare_2013,
	title = {{CARARE} 2.0: {A} metadata schema for {3D} cultural objects},
	volume = {2},
	shorttitle = {{CARARE} 2.0},
	doi = {10.1109/DigitalHeritage.2013.6744745},
	abstract = {One of the features of the digital data is that they cannot be understood without information about their meaning and the ways they have been created. 3D ICONS, a project funded by the European Commission, has brought together partners expert in 3D digitization of the archaeological and architectural heritage to contribute content to Europeana. The project has had as one of its main objectives the quality control of 3D data and establishing a metadata schema to support the provenance and paradata required for quality assurance of 3D models. This paper describes provenance in the CRMdig schema, the paradata principles of the London Charter and how provenance and paradata could be relevant for the new strategy of Europeana. The schema, which builds on earlier work in the CARARE project, aims to foster the adoption of a clearer approach to describing the features of cultural object, the techniques and the methodologies chosen for the digitization and the motivation behind the creation of a digital object. Complete knowledge of the digital resource allows for more efficient reuse and increased usability of the resources on-line.},
	booktitle = {2013 {Digital} {Heritage} {International} {Congress} ({DigitalHeritage})},
	author = {D'Andrea, Andrea and Fernie, Kate},
	month = oct,
	year = {2013},
	keywords = {Cultural differences, Data models, Solid modeling, Europe, Three-dimensional displays, Metadata, Provenance, Europeana, Materials, 3D Objects, 3D-ICONS, CARARE, EDM, Organizations, Paradata},
	pages = {137--143},
	file = {IEEE Xplore Abstract Record:files/2214/6744745.html:text/html;IEEE Xplore Full Text PDF:files/2213/D'Andrea e Fernie - 2013 - CARARE 2.0 A metadata schema for 3D cultural obje.pdf:application/pdf},
}

@techreport{corns_3d-icons_2013,
	title = {{3D}-{ICONS}: {D7}.3-{Guidelines} and {Case} {Studies}},
	shorttitle = {{3D}-{ICONS}},
	url = {https://zenodo.org/record/1311797},
	abstract = {The structure of this publication has been created with two distinct sections Guidelines:  Documentation of the digitisation, modelling and online access pipeline for the creation of online 3D models of cultural heritage objects. Case Studies:  28 examples of 3D content creation by the 3D-ICONS partners across a range of monuments, architectural features and artefacts.},
	urldate = {2023-03-29},
	institution = {Zenodo},
	author = {Corns, Anthony},
	month = nov,
	year = {2013},
	doi = {10.5281/zenodo.1311797},
	file = {Zenodo Full Text PDF:files/2217/Corns - 2013 - 3D-ICONS D7.3-Guidelines and Case Studies.pdf:application/pdf},
}

@article{mi_metadata_2018,
	title = {Metadata {Schema} to {Facilitate} {Linked} {Data} for {3D} {Digital} {Models} of {Cultural} {Heritage} {Collections}: {A} {University} of {South} {Florida} {Libraries} {Case} {Study}},
	volume = {56},
	issn = {0163-9374},
	shorttitle = {Metadata {Schema} to {Facilitate} {Linked} {Data} for {3D} {Digital} {Models} of {Cultural} {Heritage} {Collections}},
	url = {https://doi.org/10.1080/01639374.2017.1388894},
	doi = {10.1080/01639374.2017.1388894},
	abstract = {The University of South Florida Libraries house and provide access to a collection of cultural heritage and 3D digital models. In an effort to provide greater access to these collections, a linked data project has been implemented. A metadata schema for the 3D cultural heritage objects which uses linked data is an excellent way to share these collections with other repositories, thus gaining global exposure and access to these valuable resources. This article will share the process of building the 3D cultural heritage metadata model as well as an assessment of the model and recommendations for future linked data projects.},
	number = {2-3},
	urldate = {2023-03-29},
	journal = {Cataloging \& Classification Quarterly},
	author = {Mi, Xiying and Pollock, Bonita M.},
	month = feb,
	year = {2018},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/01639374.2017.1388894},
	keywords = {metadata, 3D digital models, cultural heritage collections, Dublin Core, Europeana Data Model, Linked open data},
	pages = {273--286},
}

@article{dandrea_3d-icons_nodate-2,
	title = {{3D}-{ICONS} {METADATA} {SCHEMA} {FOR} {3D} {OBJECTS}},
	language = {en},
	journal = {A. D},
	author = {D’Andrea, Andrea and Fernie, Kate},
	file = {D’Andrea e Fernie - 3D-ICONS METADATA SCHEMA FOR 3D OBJECTS.pdf:files/2219/D’Andrea e Fernie - 3D-ICONS METADATA SCHEMA FOR 3D OBJECTS.pdf:application/pdf},
}

@article{felicetti_metadata_2011,
	title = {Metadata and {Tools} for {Integration} and {Preservation} of {Cultural} {Heritage} {3D} {Information}},
	volume = {6},
	copyright = {Copyright (c) 2015 Achille Felicetti, Matteo Lorenzini},
	issn = {1802-2669},
	url = {https://ojs.cvut.cz/ojs/index.php/gi/article/view/gi.6.16},
	doi = {10.14311/gi.6.16},
	abstract = {In this paper we investigate many of the various storage, portability and interoperability issues arising among archaeologists and cultural heritage people when dealing with 3D technologies. On the one side, the available digital repositories look often unable to guarantee affordable features in the management of 3D models and their metadata; on the other side the nature of most of the available data format for 3D encoding seem to be not satisfactory for the necessary portability required nowadays by 3D information across different systems. We propose a set of possible solutions to show how integration can be achieved through the use of well known and wide accepted standards for data encoding and data storage. Using a set of 3D models acquired during various archaeological campaigns and a number of open source tools, we have implemented a straightforward encoding process to generate meaningful semantic data and metadata. We will also present the interoperability process carried out to integrate the encoded 3D models and the geographic features produced by the archaeologists. Finally we will report the preliminary (rather encouraging) development of a semantic enabled and persistent digital repository, where 3D models (but also any kind of digital data and metadata) can easily be stored, retrieved and shared with the content of other digital archives.},
	language = {en},
	urldate = {2023-03-29},
	journal = {Geoinformatics FCE CTU},
	author = {Felicetti, Achille and Lorenzini, Matteo},
	month = dec,
	year = {2011},
	keywords = {ontologies, metadata, CIDOC-CRM, 3D, digital repositories, open source},
	pages = {118--124},
	file = {Full Text PDF:files/2222/Felicetti e Lorenzini - 2011 - Metadata and Tools for Integration and Preservatio.pdf:application/pdf},
}

@article{mi_linked_nodate,
	title = {Linked {Metadata} for {3D} {Models}: from {Dublin} {Core} to {Europeana} {Data} {Model}},
	language = {en},
	author = {Mi, Xiying and Pollock, Bonita and Bernardy, Richard},
	file = {Mi et al. - Linked Metadata for 3D Models from Dublin Core to.pdf:files/2223/Mi et al. - Linked Metadata for 3D Models from Dublin Core to.pdf:application/pdf},
}

@article{budin_creating_2012,
	title = {Creating {Lexical} {Resources} in {TEI} {P5}: {A} {Schema} for {Multi}-purpose {Digital} {Dictionaries}},
	issn = {2162-5603},
	shorttitle = {Creating {Lexical} {Resources} in {TEI} {P5}},
	url = {http://journals.openedition.org/jtei/522},
	doi = {10.4000/jtei.522},
	language = {en},
	number = {Issue 3},
	urldate = {2023-03-29},
	journal = {Journal of the Text Encoding Initiative},
	author = {Budin, Gerhard and Majewski, Stefan and Mörth, Karlheinz},
	month = nov,
	year = {2012},
	file = {Budin et al. - 2012 - Creating Lexical Resources in TEI P5 A Schema for.pdf:files/2225/Budin et al. - 2012 - Creating Lexical Resources in TEI P5 A Schema for.pdf:application/pdf},
}

@article{tomasi_francesca_dipartimento_di_filologia_classica_e_italianistica_alma_mater_studiorum_universita_di_bologna_vespasiano_2013,
	title = {Vespasiano da {Bisticci}, {Lettere}},
	url = {http://vespasianodabisticciletters.unibo.it},
	doi = {10.6092/UNIBO/VESPASIANODABISTICCILETTERS},
	abstract = {Il poster vuole presentare il progetto di edizione, in corso, ‘Gustave Roud, Œuvres complètes’ dell’Università di Losanna (Centre de recherche sur les lettres romandes). In particolare, ci si concentrerà sulle scelte tecniche e sull’utilizzo dell’infrastruttura software ‘Knora’ (RDF, OWL, RESTful API).},
	urldate = {2023-03-29},
	author = {Tomasi, Francesca; Dipartimento Di Filologia Classica E Italianistica, Alma Mater Studiorum, Università Di Bologna},
	year = {2013},
	note = {Publisher: Alma Mater Studiorum, Università  di Bologna. CRR-MM},
	file = {Tomasi, Francesca\; Dipartimento Di Filologia Classica E Italianistica, Alma Mater Studiorum, Università Di Bologna - 2013 - Vespasiano da Bisticci, Lettere.pdf:files/2227/Tomasi, Francesca\; Dipartimento Di Filologia Classica E Italianistica, Alma Mater Studiorum, Università Di Bologna - 2013 - Vespasiano da Bisticci, Lettere.pdf:application/pdf},
}

@article{vogeler_assertive_2019,
	title = {The ‘assertive edition’},
	volume = {1},
	issn = {2524-7840},
	url = {https://doi.org/10.1007/s42803-019-00025-5},
	doi = {10.1007/s42803-019-00025-5},
	abstract = {The paper describes the special interest among historians in scholarly editing and the resulting editorial practice in contrast to the methods applied by pure philological textual criticism. The interest in historical ‘facts’ suggests methods the goal of which is to create formal representations of the information conveyed by the text in structured databases. This can be achieved with RDF representations of statements extracted from the text, by automatic information extraction methods, or by hand. The paper suggests the use of embedded RDF representations in TEI markup, following the practice in several recent projects, and it concludes with a proposal for a definition of the ‘assertive edition’.},
	language = {en},
	number = {2},
	urldate = {2023-03-29},
	journal = {International Journal of Digital Humanities},
	author = {Vogeler, Georg},
	month = jul,
	year = {2019},
	keywords = {Semantic web, Critial edition, Digital scholarly edition, Historical documents, History, RDF (Resource Description Framework), TEI (Text Encoding Initiative)},
	pages = {309--322},
	file = {Full Text PDF:files/2230/Vogeler - 2019 - The ‘assertive edition’.pdf:application/pdf},
}

@inproceedings{lasolle_assisting_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Assisting the {RDF} {Annotation} of a {Digital} {Humanities} {Corpus} {Using} {Case}-{Based} {Reasoning}},
	isbn = {978-3-030-62466-8},
	doi = {10.1007/978-3-030-62466-8_38},
	abstract = {The Henri Poincaré correspondence is a corpus composed of around 2100 letters which is a rich source of information for historians of science. Semantic Web technologies provide a way to structure and publish data related to this kind of corpus. However, Semantic Web data editing is a process which often requires human intervention and may seem tedious for the user. This article introduces , an editor which aims at facilitating annotation of documents. This tool uses case-based reasoning (cbr) to provide suggestions for the user which are related to the current document annotation process. These suggestions are found and ranked by considering the annotation context related to the resource currently being edited and by looking for similar resources already annotated in the database. Several methods and combinations of methods are presented here, as well as the evaluation associated with each of them.},
	language = {en},
	booktitle = {The {Semantic} {Web} – {ISWC} 2020},
	publisher = {Springer International Publishing},
	author = {Lasolle, Nicolas and Bruneau, Olivier and Lieber, Jean and Nauer, Emmanuel and Pavlova, Siyana},
	editor = {Pan, Jeff Z. and Tamma, Valentina and d’Amato, Claudia and Janowicz, Krzysztof and Fu, Bo and Polleres, Axel and Seneviratne, Oshani and Kagal, Lalana},
	year = {2020},
	keywords = {Semantic Web, Digital humanities, Case-based reasoning, Content annotation, History of science, RDF(S), Scientific correspondence, SPARQL query transformation},
	pages = {617--633},
	file = {Full Text PDF:files/2234/Lasolle et al. - 2020 - Assisting the RDF Annotation of a Digital Humaniti.pdf:application/pdf},
}

@inproceedings{morbidoni_curating_2015,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Curating a {Document} {Collection} via {Crowdsourcing} with {Pundit} 2.0},
	isbn = {978-3-319-25639-9},
	doi = {10.1007/978-3-319-25639-9_20},
	abstract = {Pundit 2.0 is a semantic web annotation system that supports users in creating structured data on top of web pages. Annotations in Pundit are RDF triples that users build starting from web page elements, as text or images. Annotations can be made public and developers can access and combine them into RDF knowledge graphs, while authorship of each triple is always retrievable. In this demo we showcase Pundit 2.0 and demonstrate how it can be used to enhance a digital library, by providing a data crowdsourcing platform. Pundit enables users to annotate different kind of entities and to contribute to the collaborative creation of a knowledge graph. This, in turn, refines in real-time the exploration functionalities of the library’s faceted search, providing an immediate added value out of the annotation effort. Ad-hoc configurations can be used to drive specific visualisations, like the timeline-map shown in this demo.},
	language = {en},
	booktitle = {The {Semantic} {Web}: {ESWC} 2015 {Satellite} {Events}},
	publisher = {Springer International Publishing},
	author = {Morbidoni, Christian and Piccioli, Alessio},
	editor = {Gandon, Fabien and Guéret, Christophe and Villata, Serena and Breslin, John and Faron-Zucker, Catherine and Zimmermann, Antoine},
	year = {2015},
	keywords = {Digital humanities, Linked data, Semantic annotation, Faceted browsing, Pundit},
	pages = {102--106},
	file = {Full Text PDF:files/2236/Morbidoni e Piccioli - 2015 - Curating a Document Collection via Crowdsourcing w.pdf:application/pdf},
}

@misc{noauthor_shapes_2017,
	title = {Shapes {Constraint} {Language} ({SHACL})},
	url = {https://www.w3.org/TR/shacl/},
	language = {en},
	urldate = {2023-03-29},
	month = jul,
	year = {2017},
	file = {Snapshot:files/2283/shacl.html:text/html},
}

@article{boochs_towards_2014,
	title = {Towards {A} {Knowledge} {Model} {Bridging} {Technologies} {And} {Applications} {In} {Cultural} {Heritage} {Documentation}},
	volume = {II-5},
	issn = {2194-9050},
	url = {https://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/II-5/81/2014/},
	doi = {10.5194/isprsannals-II-5-81-2014},
	abstract = {Abstract. This paper documents the formulation of an international, interdisciplinary study, on a concerted European level, to prepare an innovative, reliable, independent and global knowledge base facilitating the use of today’s and future optical measuring techniques for the documentation of cultural heritage. Cultural heritage professionals, color engineers and scientists share similar goals for the documentation, curation, long-term preservation and representation of cultural heritage artifacts. Their focus is on accuracy in the digital capture and remediation of artefacts through a range of temporal, spatial and technical constraints. A shared vocabulary to interrogate these shared concerns will transform mutual understanding and facilitate an agreed movement forward in cultural heritage documentation here proposed in the work of the COST Action Color and Space in Cultural Heritage (COSCH). The goal is a model that captures the shared concerns of professionals for a standards-based solution with an organic Linked Data model. The knowledge representation proposed here invokes a GUI interface for non-expert users of capture technologies, facilitates, and formulates their engagement with key questions for the field.},
	language = {en},
	urldate = {2023-03-29},
	journal = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Boochs, F. and Trémeau, A. and Murphy, O. and Gerke, M. and Lerma, J.L. and Karmacharya, A. and Karaszewski, M.},
	month = may,
	year = {2014},
	pages = {81--88},
	file = {Full text:files/2307/Boochs et al. - 2014 - Towards A Knowledge Model Bridging Technologies An.pdf:application/pdf},
}

@article{franzini_digital_2019,
	title = {Digital {Editions} of {Text}: {Surveying} {User} {Requirements} in the {Digital} {Humanities}},
	volume = {12},
	issn = {1556-4673, 1556-4711},
	shorttitle = {Digital {Editions} of {Text}},
	url = {https://dl.acm.org/doi/10.1145/3230671},
	doi = {10.1145/3230671},
	abstract = {This article presents the findings of a web survey designed to better understand the expectations and use of digital editions of texts. The survey, modelled upon a detailed analysis of 242 projects, recorded 218 complete responses, shedding light on user requirements of digital editions. Specifically, the survey indicates that issues of data reuse, licensing, image availability, and comprehensive documentation are the most requested features of digital editions, although ones which seldom are provided. This analysis feeds into previous studies on good practice in building Digital Humanities resources and puts forward practical recommendations for both creators and funders of digital editions in an effort to promote a stronger consideration of user needs. This survey will be of interest to those who produce digital editions of texts, including developers and engineers, and will also be of interest to those who commission and fund these projects, such as universities, libraries, and archives, whose documentary collections are often showcased in digital editions.},
	language = {en},
	number = {1},
	urldate = {2023-03-30},
	journal = {Journal on Computing and Cultural Heritage},
	author = {Franzini, Greta and Terras, Melissa and Mahony, Simon},
	month = feb,
	year = {2019},
	pages = {1--23},
	file = {Versione accettata:files/2451/Franzini et al. - 2019 - Digital Editions of Text Surveying User Requireme.pdf:application/pdf},
}

@article{franzini_catalogue_2017,
	title = {Catalogue of {Digital} {Editions}: {A} web application to browse, curate and analyse digital editions},
	shorttitle = {Catalogue of {Digital} {Editions}},
	url = {http://rgdoi.net/10.13140/RG.2.2.25323.64803},
	doi = {10.13140/RG.2.2.25323.64803},
	urldate = {2023-03-30},
	author = {Franzini, Greta and Andorfer, Peter},
	year = {2017},
	note = {Publisher: Unpublished},
}

@incollection{driscoll_9_2016,
	title = {9. {A} {Catalogue} of {Digital} {Editions}},
	isbn = {978-1-78374-238-7 978-1-78374-239-4 978-1-78374-240-0 978-1-78374-241-7 978-1-78374-242-4},
	url = {http://www.openbookpublishers.com/product/483},
	urldate = {2023-03-30},
	booktitle = {Digital {Scholarly} {Editing}: {Theories} and {Practices}},
	publisher = {Open Book Publishers},
	author = {Franzini, Greta and Terras, Melissa and Mahony, Simon},
	editor = {Driscoll, Matthew James and Pierazzo, Elena},
	month = aug,
	year = {2016},
	doi = {10.11647/OBP.0095.09},
	pages = {161--182},
	file = {Full text:files/2452/Franzini et al. - 2016 - 9. A Catalogue of Digital Editions.pdf:application/pdf},
}

@article{gualandi_what_2022,
	title = {What do we mean by “data”? {A} proposed classification of data types in the arts and humanities},
	volume = {ahead-of-print},
	issn = {0022-0418},
	shorttitle = {What do we mean by “data”?},
	url = {https://doi.org/10.1108/JD-07-2022-0146},
	doi = {10.1108/JD-07-2022-0146},
	abstract = {Purpose This article describes the interviews the authors conducted in late 2021 with 19 researchers at the Department of Classical Philology and Italian Studies at the University of Bologna. The main purpose was to shed light on the definition of the word “data” in the humanities domain, as far as FAIR data management practices are concerned, and on what researchers think of the term. Design/methodology/approach The authors invited one researcher for each of the official disciplinary areas represented within the department and all 19 accepted to participate in the study. Participants were then divided into five main research areas: philology and literary criticism, language and linguistics, history of art, computer science and archival studies. The interviews were transcribed and analysed using a grounded theory approach. Findings A list of 13 research data types has been compiled thanks to the information collected from participants. The term “data” does not emerge as especially problematic, although a good deal of confusion remains. Looking at current research management practices, methodologies and teamwork appear more central than previously reported. Originality/value Our findings confirm that “data” within the FAIR framework should include all types of inputs and outputs humanities research work with, including publications. Also, the participants of this study appear ready for a discussion around making their research data FAIR: they do not find the terminology particularly problematic, while they rely on precise and recognised methodologies, as well as on sharing and collaboration with colleagues.},
	number = {ahead-of-print},
	urldate = {2023-03-31},
	journal = {Journal of Documentation},
	author = {Gualandi, Bianca and Pareschi, Luca and Peroni, Silvio},
	month = jan,
	year = {2022},
	keywords = {FAIR principles, Grounded theory approach, Humanities, Research data management, Survey},
	file = {Full Text PDF:files/2481/Gualandi et al. - 2022 - What do we mean by “data” A proposed classificati.pdf:application/pdf},
}

@inproceedings{sartini_marriage_2021,
	address = {New York, NY, USA},
	series = {K-{CAP} '21},
	title = {Marriage is a {Peach} and a {Chalice}: {Modelling} {Cultural} {Symbolism} on the {Semantic} {Web}},
	isbn = {978-1-4503-8457-5},
	shorttitle = {Marriage is a {Peach} and a {Chalice}},
	url = {https://dl.acm.org/doi/10.1145/3460210.3493552},
	doi = {10.1145/3460210.3493552},
	abstract = {In this work, we fill the gap in the Semantic Web in the context of Cultural Symbolism. Building upon earlier work in {\textbackslash}citesartini\_towards\_2021, we introduce the Simulation Ontology, an ontology that models the background knowledge of symbolic meanings, developed by combining the concepts taken from the authoritative theory of Simulacra and Simulations of Jean Baudrillard with symbolic structures and content taken from "Symbolism: a Comprehensive Dictionary'' by Steven Olderr. We re-engineered the symbolic knowledge already present in heterogeneous resources by converting it into our ontology schema to create HyperReal, the first knowledge graph completely dedicated to cultural symbolism. A first experiment run on the knowledge graph is presented to show the potential of quantitative research on symbolism.},
	urldate = {2023-04-04},
	booktitle = {Proceedings of the 11th on {Knowledge} {Capture} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Sartini, Bruno and van Erp, Marieke and Gangemi, Aldo},
	month = dec,
	year = {2021},
	keywords = {ontology, semantic web, knowledge graph, linked data, symbolism},
	pages = {201--208},
	file = {Full Text PDF:files/2615/Sartini et al. - 2021 - Marriage is a Peach and a Chalice Modelling Cultu.pdf:application/pdf},
}

@article{sartini_towards_nodate,
	title = {Towards the unchaining of symbolism from knowledge graphs: how symbolic relationships can link cultures.},
	abstract = {The aim of the work here proposed is to address the lack of information concerning symbolic meaning in linked open data of the Cultural Heritage domain. Moreover, it is emphasized how this issue limits the interconnections between cultures and cultural heritage items. A review of the current semantic databases and their methods to encode symbolism is presented. Then, an empirical experiment is conducted by describing the symbolism of 15 elements depicted in a CH item using a prototype ontology. The symbolism of those elements has been expanded by including information from a renowned source, and a knowledge base has been created which includes their potential symbolic meaning according to different cultures. This KB has later been matched to a dataset of 3197 paintings, belonging to various genres, extracted from Wikidata. An initial quantitative and qualitative analysis of the results of the matching is presented to demonstrate the potential of a linked data-based semantic representation of symbolism.},
	language = {en},
	author = {Sartini, Bruno and Gangemi, Aldo},
	file = {Sartini e Gangemi - Towards the unchaining of symbolism from knowledge.pdf:files/2616/Sartini e Gangemi - Towards the unchaining of symbolism from knowledge.pdf:application/pdf},
}

@article{dhuy_evolution_2016,
	title = {The {Evolution} of {Myths}},
	volume = {315},
	issn = {0036-8733},
	url = {https://www.jstor.org/stable/26047253},
	number = {6},
	urldate = {2023-04-04},
	journal = {Scientific American},
	author = {d’Huy, Julien},
	year = {2016},
	note = {Publisher: Scientific American, a division of Nature America, Inc.},
	pages = {62--69},
	file = {JSTOR Full Text PDF:files/2619/d’Huy - 2016 - The Evolution of Myths.pdf:application/pdf},
}

@article{doja_computational_2021,
	title = {Computational challenges to test and revitalize {Claude} {Lévi}-{Strauss} transformational methodology},
	volume = {8},
	issn = {2053-9517},
	url = {https://doi.org/10.1177/20539517211037862},
	doi = {10.1177/20539517211037862},
	abstract = {The ambition and proposal for data modeling of myths presented in this paper is to link contemporary technical affordances to some canonical projects developed in structural anthropology. To articulate the theoretical promise and innovation of this proposal, we present a discrete-event system specification modeling and simulation approach in order to perform a generative analysis and a dynamic visualization of selected narratives, aimed at validating and revitalizing the transformational and morphodynamic theory and methodology proposed by Claude Lévi-Strauss in his structural analysis of myth. After an analysis of Lévi-Strauss?s transformational methodology, we describe in detail how discrete-event system specification models are implemented and developed in the framework of a DEVSimPy software environment. The validation of the method involves a discrete-event system specification simulation based on the extension of discrete-event system specification models dedicated to provide a dynamic Google Earth visualization of the selected myth. Future work around the discrete-event system specification formalism in anthropology is described as well as future applications regarding the impact of computational models (discrete-event system specification formalism, Bayesian inferences, and object-oriented features) to new contemporary anthropological domains.},
	number = {2},
	urldate = {2023-04-04},
	journal = {Big Data \& Society},
	author = {Doja, Albert and Capocchi, Laurent and Santucci, Jean-François},
	month = jul,
	year = {2021},
	note = {Publisher: SAGE Publications Ltd},
	pages = {20539517211037862},
	file = {SAGE PDF Full Text:files/2621/Doja et al. - 2021 - Computational challenges to test and revitalize Cl.pdf:application/pdf},
}

@article{leavitt_mytheme_2010,
	title = {Mytheme and {Motif}: {Lévi}-{Strauss} and {Wagner}},
	volume = {30},
	issn = {1911-0146, 1918-512X},
	shorttitle = {Mytheme and {Motif}},
	url = {https://www.erudit.org/en/journals/is/1900-v1-n1-is1522422/1003501ar/abstract/},
	doi = {10.7202/1003501ar},
	abstract = {Starting with Claude Lévi-Strauss’s evaluation of Richard Wagner as “the undeniable father of the structural analysis of myth,” this paper compares Lévi-Strauss’s myth analysis with Wagner’s myth construction, arguing that each illuminates, clarifies, and potentially enriches the other.},
	language = {en},
	number = {1},
	urldate = {2023-04-04},
	journal = {Intersections: Canadian Journal of Music / Intersections : revue canadienne de musique},
	author = {Leavitt, John},
	year = {2010},
	note = {Publisher: Canadian University Music Society / Société de musique des universités canadiennes},
	pages = {95--116},
	file = {Full text:files/2623/Leavitt - 2010 - Mytheme and Motif Lévi-Strauss and Wagner.pdf:application/pdf},
}

@article{mohnike_narrating_2020,
	title = {Narrating the {North}. {Towards} a theory of mythemes of social knowledge in cultural circulation},
	url = {https://hal.science/hal-03020605},
	abstract = {When studying the history of geographical imaginations of the North, scholars often note that in spite of the wealth of cultural, artistic and societal contexts that are analysed, the same sets of elements representing the North can be found in constantly evolving combinations. In order to understand the sign system that is the North in social knowledge, the present article argues that we should change perspective and start by observing the smallest parts of the system, describing their nature and their ability to connect with other units of discourse. I propose to call these smallest units of discourse ‘mythemes of social knowledge’, and the laws that determine the possibilities to combine mythemes at a certain moment in time their ‘discursive grammar’. This approach allows us to understand the perceived stability not as a historical fact per se, but as an effect of family resemblance between mythemes changing through use and cultural circulation, and it permits to trace the history and geography of these transformations. In spite of the apparent simplicity of the approach, it proves to be quite complex as soon as we want to describe the changing repertoire of mythemes of the North in cultural circulation because of the number of sources and mythemes that should be considered. It requires data management that goes beyond traditional pen-and-paper analysis. It demands the use of relational databases, best informed by digital text retrieval with tools still to be developed. The last part of the article investigates the challenges and possible solutions for the sketched problem and presents first experimental results. It also shows that digital analysis not only allows us to handle the apparent complexity, but also helps to avoid the arbitrary definitions of individual mythemes because it forces us to work in a counterintuitive fashion, by objectivizing intuitive knowledge.},
	language = {en},
	urldate = {2023-04-04},
	journal = {Deshima. Revue d'histoire globale des Pays du Nord},
	author = {Mohnike, Thomas},
	month = nov,
	year = {2020},
	file = {Full Text PDF:files/2625/Mohnike - 2020 - Narrating the North. Towards a theory of mythemes .pdf:application/pdf},
}

@incollection{mcdowell_expressive_2002,
	title = {From {Expressive} {Language} to {Mythemes}: {Meaning} in {Mythic} {Narratives}},
	isbn = {978-0-253-34158-7},
	shorttitle = {From {Expressive} {Language} to {Mythemes}},
	url = {https://scholarworks.iu.edu/dspace/handle/2022/25261},
	abstract = {It is no secret that there are many ways of thinking about myth, or that 
myths have multiple layers and levels of meanmg. These certainties provoke 
a number of uncertainties when we attempt to define myth or interpret 
its meaning. In this essay I will have relatively little to say about the 
problem of defining myth, but will rather occupy myself which interpretive 
strategies rooted in the study of language. If we can agree that myth can or 
must be a story, and that stories are necessarily composed of narrative discourse, 
then we are well on the way toward recognizing the importance of 
language as one parameter for assessing the meaning of myth. But our 
quest will deliver us into some curious paradoxes, when we learn that scholarly 
programs originating in the study of language can arrive at very different 
places, and that the very notion of story may be deleted altogether from 
the enterprise.},
	language = {en},
	urldate = {2023-04-04},
	publisher = {Indiana University Press},
	author = {McDowell, John H.},
	year = {2002},
	note = {Accepted: 2020-03-05T20:30:44Z},
	file = {Full Text PDF:files/2628/McDowell - 2002 - From Expressive Language to Mythemes Meaning in M.pdf:application/pdf},
}

@article{monaco_wood_2018,
	title = {{WOOD} {IN} {CULTURAL} {HERITAGE} {PROPERTIES} {AND} {CONSERVATION} {OF} {HISTORICAL} {WOODEN} {ARTEFACTS}},
	abstract = {Wood is one of the most used materials in the human history for the production of artistic works, evidence that reflects not only the availability of wood but also its natural aesthetic qualities. The investigation of wooden artefacts supplies an interesting reference framework for better understanding the technical construction skills of the past and provides concurrently information on the significance of the artefacts, on their values and also on the historical period during which they probably were created. Changes in the structure of the wood can help conservators to know the characteristics of the past storage spaces, giving so indication for better understanding the conservation state evolution during time and to plan the optimal maintenance activities. Anamnesis and diagnosis are indispensable phases in wood restoration and conservation: they should become routine activities. The main aim of this approach is to choose the best intervention as possible in order to allow maintaining the cultural values of the artefact and, at the same time, preserving, valorising and transmitting it to the future generations. This paper provides a short review of case studies based on scientific investigation of wood artworks in order to increase their knowledge through objective data.},
	language = {en},
	journal = {European Journal of Science and Theology},
	author = {Monaco, Angela Lo and Balletti, Federica and Pelosi, Claudia},
	year = {2018},
	file = {Monaco et al. - 2018 - WOOD IN CULTURAL HERITAGE PROPERTIES AND CONSERVAT.pdf:files/2629/Monaco et al. - 2018 - WOOD IN CULTURAL HERITAGE PROPERTIES AND CONSERVAT.pdf:application/pdf},
}

@article{uzun_multidisciplinary_2018,
	title = {A multidisciplinary study to reveal the historical value of wooden structures and to develop a conservation approach: {Dere} and {Karlı} {Mosques} in {Samsun}, {Turkey}},
	volume = {32},
	issn = {1296-2074},
	shorttitle = {A multidisciplinary study to reveal the historical value of wooden structures and to develop a conservation approach},
	url = {https://www.sciencedirect.com/science/article/pii/S1296207417305198},
	doi = {10.1016/j.culher.2018.01.010},
	abstract = {Wood is one of the oldest traditional construction materials used for religious and civil architecture in the Black Sea Region of Turkey. Samsun, located in the central Black Sea Region, has qualified examples of wooden mosques in rural areas. In the scope of this paper, two wooden mosques (Dere and Karlı), located in rural areas of Kavak district (Samsun), were studied in detail with an interdisciplinary study. We aimed to emphasize the historical value of both mosques by determining their building dates, defining their conservation problems and offering proper conservation approach principles. While the Dere Mosque was registered as immovable cultural heritage by Samsun Regional Council of Conservation, Karlı Mosque has not yet been registered. However, both mosques have similar conservation problems, caused particularly by improper management such as unqualified interventions, abandonment, neglect and fire risk. For the sustainability of wooden religious heritage, it is important to reveal the historical value of the mosques and to develop detailed conservation proposals. We believe that this research will guide the quality refurbishment of wooden structures with similar conservation problems in the region and stimulate the protection of wooden heritage.},
	language = {en},
	urldate = {2023-04-04},
	journal = {Journal of Cultural Heritage},
	author = {Uzun, Zeynep and Köse, Coşkun and Köse, Nesibe},
	month = jul,
	year = {2018},
	keywords = {Black Sea region, Conservation problems, Dendrochronology, Traditional buildings, Wooden mosques},
	pages = {60--72},
	file = {ScienceDirect Full Text PDF:files/2632/Uzun et al. - 2018 - A multidisciplinary study to reveal the historical.pdf:application/pdf;ScienceDirect Snapshot:files/2633/S1296207417305198.html:text/html},
}

@article{zmeu_risk_2022,
	title = {Risk analysis of biodeterioration in contemporary art collections: the poly-material challenge},
	volume = {58},
	issn = {1296-2074},
	shorttitle = {Risk analysis of biodeterioration in contemporary art collections},
	url = {https://www.sciencedirect.com/science/article/pii/S1296207422001534},
	doi = {10.1016/j.culher.2022.09.014},
	abstract = {Biodeterioration is one of the most common alteration factors affecting cultural heritage, and its appearance responds to numerous factors. Awareness of the risk it poses to heritage material and the study of its development is essential. With the mass production evolution of widely accessible materials, the criteria for choosing the constituents of a work of art no longer respond to traditional premises, associating the conservation of these new materials with the flawed expectation of longevity and stable resistance to biological attack. This work aims to update the contemporary preventive conservation practice through the review of the biodeterioration risk of indoor poly-material artworks. It also means analyzing the potential incidence of biological agents deteriorating contemporary materials stored in art collections, characterized by their industrial origin, and frequently used in the pieces produced in the current art scene. Due to their characteristic agglomeration of components, the artistic object is subjected to complicated surveillance and problematic biological control and eradication, which can often be contraindicated for some constituents. The study encompasses four main points that make up the risk review analysis sequence: a brief art history exposition to understand poly-material creative values; a general definition of terms surrounding biodeterioration; a selection of most used contemporary materials and a study of their biodeterioration risks; and the basic preventive conservation considerations regarding biological attacks. The review concludes with a critical analysis of the complicated issue of preventive treatment compatibility, as well as a proposed model of action and consideration towards heritage pieces endangered or affected by biological attacks.},
	language = {en},
	urldate = {2023-04-04},
	journal = {Journal of Cultural Heritage},
	author = {Zmeu, C. Nadine and Bosch-Roig, Pilar},
	month = nov,
	year = {2022},
	keywords = {art collections, artistic materials, biodeterioration, contemporary art, polimaterialism, preventive conservation},
	pages = {33--48},
	file = {ScienceDirect Full Text PDF:files/2635/Zmeu e Bosch-Roig - 2022 - Risk analysis of biodeterioration in contemporary .pdf:application/pdf;ScienceDirect Snapshot:files/2636/S1296207422001534.html:text/html},
}

@article{aven_ontological_2011,
	title = {On the ontological status of the concept of risk},
	volume = {49},
	issn = {0925-7535},
	url = {https://www.sciencedirect.com/science/article/pii/S0925753511000981},
	doi = {10.1016/j.ssci.2011.04.015},
	abstract = {In this paper we review a set of frequently used risk definitions and analyze their ontological status, i.e. to what extent risk exists in itself independent of any specific assessor. According to some prevailing risk perspectives in the social sciences, risk exists as objective states of the world, but for other common risk perspectives the status of risk is not as clear, for example if risk is viewed as uncertainty about and severity of the consequences of an activity with respect to something that humans value. The principal aim of this paper is to contribute to a clarification of the issue in order to strengthen the foundations of the meaning of risk.},
	language = {en},
	number = {8},
	urldate = {2023-04-04},
	journal = {Safety Science},
	author = {Aven, Terje and Renn, Ortwin and Rosa, Eugene A.},
	month = oct,
	year = {2011},
	keywords = {Ontology, Objectivity, Risk, Subjectivity, Uncertainties},
	pages = {1074--1079},
	file = {ScienceDirect Full Text PDF:files/2640/Aven et al. - 2011 - On the ontological status of the concept of risk.pdf:application/pdf;ScienceDirect Snapshot:files/2641/S0925753511000981.html:text/html},
}

@inproceedings{sales_common_2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Common} {Ontology} of {Value} and {Risk}},
	isbn = {978-3-030-00847-5},
	doi = {10.1007/978-3-030-00847-5_11},
	abstract = {Risk analysis is traditionally accepted as a complex and critical activity in various contexts, such as strategic planning and software development. Given its complexity, several modeling approaches have been proposed to help analysts in representing and analyzing risks. Naturally, having a clear understanding of the nature of risk is fundamental for such an activity. Yet, risk is still a heavily overloaded and conceptually unclear notion, despite the wide number of efforts to properly characterize it, including a series of international standards. In this paper, we address this issue by means of an in-depth ontological analysis of the notion of risk. In particular, this analysis shows a surprising and important result, namely, that the notion of risk is irreducibly intertwined with the notion of value and, more specifically, that risk assessment is a particular case of value ascription. As a result, we propose a concrete artifact, namely, the Common Ontology of Value and Risk, which we employ to harmonize different conceptions of risk existing in the literature.},
	language = {en},
	booktitle = {Conceptual {Modeling}},
	publisher = {Springer International Publishing},
	author = {Sales, Tiago Prince and Baião, Fernanda and Guizzardi, Giancarlo and Almeida, João Paulo A. and Guarino, Nicola and Mylopoulos, John},
	editor = {Trujillo, Juan C. and Davis, Karen C. and Du, Xiaoyong and Li, Zhanhuai and Ling, Tok Wang and Li, Guoliang and Lee, Mong Li},
	year = {2018},
	keywords = {Risk, Enterprise modeling, OntoUML, Risk modeling, Value},
	pages = {121--135},
	file = {Full Text PDF:files/2643/Sales et al. - 2018 - The Common Ontology of Value and Risk.pdf:application/pdf},
}

@inproceedings{ahmed_towards_2007,
	title = {Towards an {Ontology}-based {Risk} {Assessment} in {Collaborative} {Environment} {Using} the {SemanticLIFE}},
	doi = {10.1109/ARES.2007.152},
	abstract = {The rise in interconnectivity in the last few years has made computer systems and networks more vulnerable to threats as they are accessed by an ever increasing number of users. Nowadays organizations are lacking proper security measures and means to calculate risk assessment for their assets. Legacy systems in organizations are facing different kind of risks like viruses, bugs and system failure causing damages to hardware and software resulting in data loss. The ultimate challenge in many organizations is to assess their risk factors for their computers and networks. There is no way to completely overcome the threat that an organization might have. The goal is to calculate risks, so that problems resulting from them could be minimized and to fill the gap between business entities (like a project, a role) and organization infrastructure using semantic Web technologies. SemanticLIFE is a personal information management system which gathers the user interaction events and correlates those by using ontologies. In this paper the ontology-based risk assessment in the context of the organizational security, a fundamental issue for planners and decision makers in the IT field, is explored using SemanticLIFE tool},
	booktitle = {The {Second} {International} {Conference} on {Availability}, {Reliability} and {Security} ({ARES}'07)},
	author = {Ahmed, Mansoor and Anjomshoaa, Amin and Nguyen, Tho Manh and Tjoa, A Min},
	month = apr,
	year = {2007},
	keywords = {Ontologies, Semantic Web, Risk management, Collaboration, Computer bugs, Computer networks, Computer viruses, Data security, Hardware, Information management},
	pages = {400--407},
	file = {IEEE Xplore Abstract Record:files/2646/4159829.html:text/html;IEEE Xplore Full Text PDF:files/2645/Ahmed et al. - 2007 - Towards an Ontology-based Risk Assessment in Colla.pdf:application/pdf},
}

@article{ebrahimipour_ontology_2010,
	title = {An ontology approach to support {FMEA} studies},
	volume = {37},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417409005715},
	doi = {10.1016/j.eswa.2009.06.033},
	abstract = {FMEA (Failure Modes and Effects Analysis) is a method to analyze potential reliability problems in the development cycle of the project, making it easier to take actions to overcome such issues, thus enhancing the reliability through design. FMEA is used to identify actions to mitigate the analyzed potential failure modes and their effect on the operations. Anticipating these failure modes, being the central step in the analysis, needs to be carried on extensively, in order to prepare a list of maximum potential failure modes. However, the information stored in risk assessment tools is in the form of textual natural language descriptions that limit computer-based extraction of knowledge for the reuse of the FMEA analyses in other designs or during plant operation. To overcome the limitations of text-based descriptions, FMEA ontology has been proposed that provides a basic set of standard concepts and terms. The development of the ontology uses an upper ontology based on ISO-15926, which defines general-purpose terms and act as a foundation for more specific domains. The ontology is developed so that engineers can build new concepts from the basic set of concepts. This paper evaluates the proposed ontology by means of use cases that measure the performance in finding relevant information used and produced during the safety analyses. In particular, the extraction of knowledge is performed using JTP (an object oriented Modular Reasoning System) that is used for querying the ontology.},
	language = {en},
	number = {1},
	urldate = {2023-04-04},
	journal = {Expert Systems with Applications},
	author = {Ebrahimipour, V. and Rezaie, K. and Shokravi, S.},
	month = jan,
	year = {2010},
	keywords = {OWL, XML, RDF, FMEA, Protégé},
	pages = {671--677},
	file = {ScienceDirect Full Text PDF:files/2648/Ebrahimipour et al. - 2010 - An ontology approach to support FMEA studies.pdf:application/pdf;ScienceDirect Snapshot:files/2649/S0957417409005715.html:text/html},
}

@article{scheuer_towards_2013,
	title = {Towards a flood risk assessment ontology – {Knowledge} integration into a multi-criteria risk assessment approach},
	volume = {37},
	issn = {0198-9715},
	url = {https://www.sciencedirect.com/science/article/pii/S0198971512000762},
	doi = {10.1016/j.compenvurbsys.2012.07.007},
	abstract = {Flood risk management must rely on a proper and encompassing flood risk assessment, which possibly reflects the individual characteristics of all elements at risk of being flooded. In addition to prevalent expert knowledge, such an approach must also rely on local knowledge. In this context, stakeholder preferences for risk assessment indicators and assessment deliverables hold great importance but are often neglected. This paper proposes to put this body of information into operation in form of a knowledge base, thereby making it accessible and reusable in multi-criteria risk assessment. Selected use cases discuss the advantages of such a semantically enhanced assessment approach.},
	language = {en},
	urldate = {2023-04-04},
	journal = {Computers, Environment and Urban Systems},
	author = {Scheuer, Sebastian and Haase, Dagmar and Meyer, Volker},
	month = jan,
	year = {2013},
	keywords = {Knowledge, Ontology, Flood risk assessment, Risk mapping, Stakeholder},
	pages = {82--94},
	file = {ScienceDirect Snapshot:files/2651/S0198971512000762.html:text/html},
}

@article{zotti_microfungal_2008,
	title = {Microfungal biodeterioration of historic paper: {Preliminary} {FTIR} and microbiological analyses},
	volume = {62},
	issn = {0964-8305},
	shorttitle = {Microfungal biodeterioration of historic paper},
	url = {https://www.sciencedirect.com/science/article/pii/S0964830508000103},
	doi = {10.1016/j.ibiod.2008.01.005},
	abstract = {Paper is subjected to numerous biodeterioration processes, which may cause the irreversible degradation of important documents and works of art. Many chemical and physical factors can affect these processes and their behaviour, and fungi seem to play a key role in biodeteriorating paper materials. This study is mainly aimed at verifying the presence of fungi in biodeteriorated 18th century etchings, and characterizing the paper surface by means of Fourier transform infrared (FTIR) spectroscopy and fluorescence under UV radiation. The laboratory tests highlight the presence of fungal entities from all the samples investigated. Specifically, 14 species were identified; three of them were never isolated from paper until now. Furthermore, the data gathered do not confirm the theory according to which there is a correspondence between fluorescence of the stains under UV radiation and the vitality of microfungi. Finally, possible correlations among paper composition (as determined by FTIR), mode of conservation and fungal attack are presented and discussed.},
	language = {en},
	number = {2},
	urldate = {2023-04-04},
	journal = {International Biodeterioration \& Biodegradation},
	author = {Zotti, M. and Ferroni, A. and Calvini, P.},
	month = sep,
	year = {2008},
	keywords = {Archaeometry, Foxing, Fungi, Moulds, Paper biodeterioration, Paper composition},
	pages = {186--194},
	file = {ScienceDirect Snapshot:files/2653/S0964830508000103.html:text/html},
}

@article{chen_non-destructive_2023,
	title = {Non-destructive preservation state estimation of waterlogged archaeological wooden artifacts},
	volume = {285},
	issn = {1386-1425},
	url = {https://www.sciencedirect.com/science/article/pii/S138614252200988X},
	doi = {10.1016/j.saa.2022.121840},
	abstract = {Non-destructive preservation state estimation is an essential prerequisite for the preservation and conservation of waterlogged archaeological wooden artifacts. Herein, Near Infrared (NIR) spectroscopy coupled with orthogonal partial least squares discriminant analysis (OPLS-DA) were applied to assess sixty-four waterlogged archaeological woods collected from seven excavation sites in the period range of 2900 BCE-1912 CE, aiming at developing a non-destructive, accurate and rapid preservation state estimation methodology. The role of non-decayed recent wood of relevant species on preservation state estimation was studied in prior, showing the use of non-decayed recent wood could not improve the predictive ability. Besides, the high variability in terms of chemical structure between archaeological softwoods and archaeological hardwoods did affect the preservation state estimation. Thus, a simple OPLS-DA model of non-destructively distinguishing archaeological hardwoods from softwoods, R2Xcum of 0.659, R2Ycum of 0.836 and Q2cum of 0.763, was established to avoid and overcome destructive approach for wood identification. Then, the well-defined three grouped separations of slightly-decayed, moderately-decayed and severely-decayed waterlogged archaeological woods were revealed in OPLS-DA models, providing R2Xcum of 0.793, R2Ycum of 0.738, Q2cum of 0.680, and R2Xcum of 0.780, R2Ycum of 0.901, Q2cum of 0.870, for waterlogged archaeological hardwoods and waterlogged archaeological softwoods respectively. Potential predictive wood spectral bands were screened and tentatively identified as hydroxyls of crystalline cellulose, acetyl groups of hemicelluloses, C-H bands of lignin, which guaranteed the elimination of non-structural compounds, such as water and inorganic components interference. Furthermore, the developed NIR methodology was validated by an extensively used destructive method consisting of anatomical characteristics, maximum water content and basic density analyses. The results indicated that NIR coupled to chemometrics could non-destructively and accurately predict the preservation states of waterlogged archaeological wooden artifacts and avoid the interference of water and inorganic deposits.},
	language = {en},
	urldate = {2023-04-04},
	journal = {Spectrochimica Acta Part A: Molecular and Biomolecular Spectroscopy},
	author = {Chen, Jiabao and Liu, Shoujia and Yin, Lijuan and Cao, Huimin and Xi, Guanglan and Zhang, Zhiguo and Liu, Jian'an and Luo, Rupeng and Han, Liuyang and Yin, Yafang and Guo, Juan},
	month = jan,
	year = {2023},
	keywords = {Hardwood, NIR, Non-destructive, Preservation state, Softwood, Waterlogged archaeological wood},
	pages = {121840},
}

@article{waters_emerging_2022,
	title = {The emerging digital infrastructure for research in the humanities},
	issn = {1432-1300},
	url = {https://doi.org/10.1007/s00799-022-00332-3},
	doi = {10.1007/s00799-022-00332-3},
	abstract = {This article advances the thesis that three decades of investments by national and international funders, combined with those of scholars, technologists, librarians, archivists, and their institutions, have resulted in a digital infrastructure in the humanities that is now capable of supporting end-to-end research workflows. The article refers to key developments in the epigraphy and paleography of the premodern period. It draws primarily on work in classical studies but also highlights related work in the adjacent disciplines of Egyptology, ancient Near East studies, and medieval studies. The argument makes a case that much has been achieved but it does not declare “mission accomplished.” The capabilities of the infrastructure remain unevenly distributed within and across disciplines, institutions, and regions. Moreover, the components, including the links between steps in the workflow, are generally far from user-friendly and seamless in operation. Because further refinements and additional capacities are still much needed, the article concludes with a discussion of key priorities for future work.},
	language = {en},
	urldate = {2023-04-13},
	journal = {International Journal on Digital Libraries},
	author = {Waters, Donald J.},
	month = oct,
	year = {2022},
	keywords = {Research infrastructure, Humanities, Classical studies, Premodern studies, Research workflow, Scholarly communications},
	file = {Full Text PDF:files/2979/Waters - 2022 - The emerging digital infrastructure for research i.pdf:application/pdf},
}

@article{shaw_conceptual_nodate,
	title = {Conceptual modeling as language design},
	volume = {n/a},
	issn = {2330-1643},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.24739},
	doi = {10.1002/asi.24739},
	abstract = {Conceptual modeling is a broad practice encompassing knowledge organization, domain modeling, and knowledge representation. It is best understood not as a scientific process of discovery, but as a constructive process of language design. This constructive process involves both explicating differences of meaning implicit in some discursive tradition and revising those differences to improve that tradition. Understood this way, conceptual modeling can serve as the basis for a paradigm of information research and practice that does not reproduce fundamental asymmetries between researchers and the people they study, or between practitioners and the people they serve. Progress within this paradigm will involve combining methods from what have up to now been different traditions or modes of conceptual modeling. It will require paying closer attention to the historical and structural dimensions of discursive traditions and reimagining the function of critique.},
	language = {en},
	number = {n/a},
	urldate = {2023-04-14},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Shaw, Ryan},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.24739},
	file = {Full Text PDF:files/3006/Shaw - Conceptual modeling as language design.pdf:application/pdf;Snapshot:files/3007/asi.html:text/html},
}

@incollection{moraitou_knowledge_2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Knowledge {Management} {Using} {Ontology} on the {Domain} of {Artworks} {Conservation}},
	isbn = {978-3-319-75826-8},
	url = {https://doi.org/10.1007/978-3-319-75826-8_5},
	abstract = {Conservation is an integral process of collections management aiming to preserve cultural heritage objects in the best possible condition. Object conservation procedures require detailed and accurate documentation in textual or visual records which provide valuable information for the future researcher, curator or conservator. Furthermore, conservation requires the awareness of cultural, historical and scientific information from sources both internal and external which in turn influence the ways in which conservators must approach their work. This integration of different information forms the body of knowledge, relevant to thoughtful decisions on treatment and care of cultural heritage objects. Taking into consideration the diversity of conservation information and associated information sources, the integration cannot be regarded as a trivial task. Therefore, knowledge organization, especially in a concepts level, is necessary. To this end this work presents a domain ontology known as the Conservation Reasoning (CORE) ontology aiming to address the specific requirements of the conservation sector.},
	language = {en},
	urldate = {2023-04-15},
	booktitle = {Digital {Cultural} {Heritage}: {Final} {Conference} of the {Marie} {Skłodowska}-{Curie} {Initial} {Training} {Network} for {Digital} {Cultural} {Heritage}, {ITN}-{DCH} 2017, {Olimje}, {Slovenia}, {May} 23–25, 2017, {Revised} {Selected} {Papers}},
	publisher = {Springer International Publishing},
	author = {Moraitou, Efthymia and Kavakli, Evangelia},
	editor = {Ioannides, Marinos},
	year = {2018},
	doi = {10.1007/978-3-319-75826-8_5},
	keywords = {Semantics, Ontology, Knowledge management, Artworks conservation},
	pages = {50--62},
	file = {Full Text PDF:files/3209/Moraitou e Kavakli - 2018 - Knowledge Management Using Ontology on the Domain .pdf:application/pdf},
}

@article{moraitou_semantic_2019,
	title = {Semantic {Bridging} of {Cultural} {Heritage} {Disciplines} and {Tasks}},
	volume = {2},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2571-9408},
	url = {https://www.mdpi.com/2571-9408/2/1/40},
	doi = {10.3390/heritage2010040},
	abstract = {The Cultural Heritage (CH) domain encompasses a wide range of different disciplines, serving the study, interpretation, curation, and preservation of objects, collections, archives, sites, and the dissemination of related knowledge. In this context, stakeholders generate, retrieve, and share a vast amount of diverse information. Therefore, information interoperability has been considered a crucial task, especially in terms of semantics. In this way, the CIDOC CRM (International Committee for Documentation Conceptual Reference Model) has been widely used as an underlying model that offers interoperability between CH domain metadata standards and ontologies. To the best of our knowledge, an overall review of mapping, merging, and extending this core ontology, as well as an aggregate table which classifies and correlates those ontologies and standards, has not yet been presented. Our study conducts an aggregate review of relevant published efforts and outlines the various associations between them, encapsulating the CIDOC CRM and its specialized models, as well. This work aims to further clarify the field and scope of the different works, identify their methods, and highlight the semantic overlap, or differences, between them.},
	language = {en},
	number = {1},
	urldate = {2023-04-15},
	journal = {Heritage},
	author = {Moraitou, Efthymia and Aliprantis, John and Christodoulou, Yannis and Teneketzis, Alexandros and Caridakis, George},
	month = mar,
	year = {2019},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {CIDOC CRM, aggregation table, mapping and extending, merging, overview},
	pages = {611--630},
	file = {Full Text PDF:files/3211/Moraitou et al. - 2019 - Semantic Bridging of Cultural Heritage Disciplines.pdf:application/pdf},
}

@article{moraitou_semantic_2023,
	title = {Semantic models and services for conservation and restoration of cultural heritage: {A} comprehensive survey},
	volume = {14},
	issn = {1570-0844},
	shorttitle = {Semantic models and services for conservation and restoration of cultural heritage},
	url = {https://content.iospress.com/articles/semantic-web/sw223105},
	doi = {10.3233/SW-223105},
	abstract = {Over the last decade, the Cultural Heritage (CH) domain has gradually adopted Semantic Web (SW) technologies for organizing information and for tackling interoperability issues. Several semantic models have been proposed which accommodate essential a},
	language = {en},
	number = {2},
	urldate = {2023-04-15},
	journal = {Semantic Web},
	author = {Moraitou, Efthymia and Christodoulou, Yannis and Caridakis, George},
	month = jan,
	year = {2023},
	note = {Publisher: IOS Press},
	pages = {261--291},
	file = {Full Text PDF:files/3213/Moraitou et al. - 2023 - Semantic models and services for conservation and .pdf:application/pdf},
}

@article{cacciotti_monument_2013,
	title = {{MONUMENT} {DAMAGE} {INFORMATION} {SYSTEM} ({MONDIS}): {AN} {ONTOLOGICAL} {APPROACH} {TO} {CULTURAL} {HERITAGE} {DOCUMENTATION}},
	volume = {II-5/W1},
	issn = {2194-9050},
	shorttitle = {{MONUMENT} {DAMAGE} {INFORMATION} {SYSTEM} ({MONDIS})},
	url = {https://isprs-annals.copernicus.org/articles/II-5-W1/55/2013/},
	doi = {10.5194/isprsannals-II-5-W1-55-2013},
	abstract = {Deriving from the complex nature of cultural heritage conservation it is the need for enhancing a systematic but flexible organization of expert knowledge in the field. Such organization should address comprehensively the interrelations and complementariness among the different factors that come into play in the understanding of diagnostic and intervention problems. The purpose of MONDIS is to endorse this kind of organization. The approach consists in applying an ontological representation to the field of heritage conservation in order to establish an appropriate processing of data. The system allows replicating in a computer readable form the basic dependence among factors influencing the description, diagnosis and intervention of damages to immovable objects. More specifically MONDIS allows to input and search entries concerning object description, structural evolution, location characteristics and risk, component, material properties, surveys and measurements, damage typology, damage triggering events and possible interventions. The system supports searching features typical of standard databases, as it allows for the digitalization of a wide range of information including professional reports, books, articles and scientific papers. It also allows for computer aided retrieval of information tailored to user´s requirements. The foreseen outputs will include a web user interface and a mobile application for visual inspection purposes.},
	language = {en},
	urldate = {2023-04-15},
	journal = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Cacciotti, R. and Valach, J. and Kuneš, P. and Čerňanský, M. and Blaško, M. and Křemen, P.},
	month = jul,
	year = {2013},
	pages = {55--60},
	file = {Cacciotti et al. - 2013 - MONUMENT DAMAGE INFORMATION SYSTEM (MONDIS) AN ON.pdf:files/3216/Cacciotti et al. - 2013 - MONUMENT DAMAGE INFORMATION SYSTEM (MONDIS) AN ON.pdf:application/pdf},
}

@article{hellmund_implementing_2019,
	title = {Implementing the {HERACLES} {Ontology}},
	abstract = {Environmental factors, worsened by the increasing climate change impact, represent significant threats to European Cultural Heritage (CH) assets. In Europe, the huge number and diversity of CH assets, together with the different climatological sub-regions aspects, as well as the different adaptation policies to climate change adopted (or to be adopted) by the different nations, generate a very complex scenario. This paper will present a multidisciplinary methodology that will bridge the gap between two different worlds: the CH stakeholders and the scientific/technological experts. Since protecting cultural heritage assets and increasing their resilience against effects caused by the climate change is a multidisciplinary task, experts from many domains need to work together to meet their conservation goals. In this paper we introduce the HERACLES Ontology, which structures data and explicitly links adjacent data. Furthermore the implementation of the HERACLES Ontology within the HERACLES Knowledge Base is described. Use cases and benefits of the application are given. The ontology comprises the following topics: Cultural Heritage Assets, Stakeholders and Roles, Climate and Weather Effects, Risk Management, Conservation Actions, Materials, Sensors, Models and Observations, Standard Operation Procedures/Workflows and Damages.},
	language = {en},
	author = {Hellmund, Tobias and Hertweck, Philipp and Moßgraber, Jürgen and Hilbring, Désirée and Pouli, Paraskevi and Padeletti, Guiseppina},
	year = {2019},
	file = {Hellmund et al. - 2019 - Implementing the HERACLES Ontology.pdf:files/3220/Hellmund et al. - 2019 - Implementing the HERACLES Ontology.pdf:application/pdf},
}

@article{rebec_old_2022,
	title = {Old buildings need new ideas: {Holistic} integration of conservation-restoration process data using {Heritage} {Building} {Information} {Modelling}},
	volume = {55},
	issn = {1296-2074},
	shorttitle = {Old buildings need new ideas},
	url = {https://www.sciencedirect.com/science/article/pii/S1296207422000292},
	doi = {10.1016/j.culher.2022.02.005},
	abstract = {The preservation of cultural heritage and the renovation, restoration and remodelling processes could benefit greatly from Building Information Modelling (BIM) workflows being established. Currently, experts are involved with fractionated workflows, where a lot of data are missing, become lost or are duplicated by different stakeholders. All the resulting confusion severely impacts on the preservation of heritage as well as the efficiency of its restoring/remodelling/revitalizing from the point of view of current needs. Heritage information is usually conveyed through conservation-restoration plans and guidelines In this research, a new methodology for managing the information holistically integrated into the BIM is proposed. The workflow is showcased on a demo-case building that is protected as cultural heritage. Consequently, the conservation plan becomes more accessible, not only for stakeholders in heritage, but also stakeholders responsible for the renovation, such as architects and contractors. This can result in an improved understanding of the heritage and a better revitalization.},
	language = {en},
	urldate = {2023-04-16},
	journal = {Journal of Cultural Heritage},
	author = {Rebec, Katja Malovrh and Deanovič, Boris and Oostwegel, Laurens},
	month = may,
	year = {2022},
	keywords = {Conservation plan, Digitisation, Heritage Building Information Modelling (HBIM), Revitalization},
	pages = {30--42},
	file = {ScienceDirect Full Text PDF:files/3223/Rebec et al. - 2022 - Old buildings need new ideas Holistic integration.pdf:application/pdf;ScienceDirect Snapshot:files/3224/S1296207422000292.html:text/html},
}

@article{acierno_architectural_2017-1,
	title = {Architectural heritage knowledge modelling: {An} ontology-based framework for conservation process},
	volume = {24},
	issn = {1296-2074},
	shorttitle = {Architectural heritage knowledge modelling},
	url = {https://www.sciencedirect.com/science/article/pii/S129620741630262X},
	doi = {10.1016/j.culher.2016.09.010},
	abstract = {This paper presents an ontology-based model to support the representation and management of information and knowledge during investigation activities for the conservation of architectural heritage. Despite the significant impact of information and communications technology (ICT) on architectural heritage, current approaches to its use in this context are often conceived only to provide flexible and reusable tools and methodologies, thus proposing oversimplified procedures that are ultimately insufficient for a truly accurate conservation project. A few experiences recently have focused much attention on the specifics of conservation. Although they have generally been concerned with the specific activities and knowledge domains related to conservation processes (such as cataloguing or monument damage), the importance of dealing with them in an integrated way is often neglected. Hence, each step of the process – such as the preliminary phase of knowledge acquisition, the summaries, which facilitate the assessment of value, diagnostics, design, the construction phase, and maintenance – is treated in isolation from all the other activities. This lack of synergy often compromises the final result. In order to deal with the complexity of representing historical architecture, and its conservation process, this proposed model defines four main knowledge domains (artefact – lifecycle – architectural heritage investigation process – actors), in which all the knowledge related to each artefact is formalized through semantic networks, in terms of entities, properties and relationships. Specific reasoning and inference rules allow checking of the model for coherence, in order to reduce information discrepancies, inconsistencies and errors. The proposed model offers a high level of accuracy in its capacity for description and, at the same time, a broad versatility within representation modelling, allowing such a reliable representation of multiple issues that eventually it may be required for every historical building, depending on its features and state of conservation. Moreover, the versatility of the model provides a suitable representation even for the different nature of the investigation activities results – whether analytical or hermeneutical. Finally, the knowledgebase has been connected with a building information modelling environment, providing an effective integration between geometrical and non-geometrical information.},
	language = {en},
	urldate = {2023-04-16},
	journal = {Journal of Cultural Heritage},
	author = {Acierno, Marta and Cursi, Stefano and Simeone, Davide and Fiorani, Donatella},
	month = mar,
	year = {2017},
	keywords = {Ontologies, Architectural heritage, Building information modelling, Investigation and conservation process, Knowledge modelling},
	pages = {124--133},
	file = {Full text:files/3226/Acierno et al. - 2017 - Architectural heritage knowledge modelling An ont.pdf:application/pdf;ScienceDirect Snapshot:files/3227/S129620741630262X.html:text/html},
}

@article{acierno_architectural_2017-2,
	title = {Architectural heritage knowledge modelling: {An} ontology-based framework for conservation process},
	volume = {24},
	issn = {1296-2074},
	shorttitle = {Architectural heritage knowledge modelling},
	url = {https://www.sciencedirect.com/science/article/pii/S129620741630262X},
	doi = {10.1016/j.culher.2016.09.010},
	abstract = {This paper presents an ontology-based model to support the representation and management of information and knowledge during investigation activities for the conservation of architectural heritage. Despite the significant impact of information and communications technology (ICT) on architectural heritage, current approaches to its use in this context are often conceived only to provide flexible and reusable tools and methodologies, thus proposing oversimplified procedures that are ultimately insufficient for a truly accurate conservation project. A few experiences recently have focused much attention on the specifics of conservation. Although they have generally been concerned with the specific activities and knowledge domains related to conservation processes (such as cataloguing or monument damage), the importance of dealing with them in an integrated way is often neglected. Hence, each step of the process – such as the preliminary phase of knowledge acquisition, the summaries, which facilitate the assessment of value, diagnostics, design, the construction phase, and maintenance – is treated in isolation from all the other activities. This lack of synergy often compromises the final result. In order to deal with the complexity of representing historical architecture, and its conservation process, this proposed model defines four main knowledge domains (artefact – lifecycle – architectural heritage investigation process – actors), in which all the knowledge related to each artefact is formalized through semantic networks, in terms of entities, properties and relationships. Specific reasoning and inference rules allow checking of the model for coherence, in order to reduce information discrepancies, inconsistencies and errors. The proposed model offers a high level of accuracy in its capacity for description and, at the same time, a broad versatility within representation modelling, allowing such a reliable representation of multiple issues that eventually it may be required for every historical building, depending on its features and state of conservation. Moreover, the versatility of the model provides a suitable representation even for the different nature of the investigation activities results – whether analytical or hermeneutical. Finally, the knowledgebase has been connected with a building information modelling environment, providing an effective integration between geometrical and non-geometrical information.},
	language = {en},
	urldate = {2023-04-16},
	journal = {Journal of Cultural Heritage},
	author = {Acierno, Marta and Cursi, Stefano and Simeone, Davide and Fiorani, Donatella},
	month = mar,
	year = {2017},
	keywords = {Ontologies, Architectural heritage, Building information modelling, Investigation and conservation process, Knowledge modelling},
	pages = {124--133},
	file = {Full text:files/3231/Acierno et al. - 2017 - Architectural heritage knowledge modelling An ont.pdf:application/pdf;ScienceDirect Snapshot:files/3232/S129620741630262X.html:text/html},
}

@article{guerra_de_oliveira_optimizing_2022,
	title = {Optimizing {H}-{BIM} {Workflow} for {Interventions} on {Historical} {Building} {Elements}},
	volume = {14},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2071-1050},
	url = {https://www.mdpi.com/2071-1050/14/15/9703},
	doi = {10.3390/su14159703},
	abstract = {Intervention projects for historical buildings depend on the quality of multidisciplinary data sets; their collection, structure, and semantics. Building information model (BIM) based workflows for historical buildings accumulate some of the data sets in a shared information model that contains the building’s geometry assemblies with associated attributes (such as material). A BIM model of any building can be a source of data for different engineering assessments, for example, solar and wind exposure and seismic vulnerability, but for historic buildings it is particularly important for interventions like conservation, rehabilitation, and improvements such as refurbishment and retrofitting. When the BIM model is abstracted to a semantic model, enabling the use of semantic technologies such as reasoning and querying, semantic links can be established to other historical contexts. The semantic technologies help historic building experts to aggregate data into meaningful form. Ontologies provide them with an accurate knowledge representation of the concepts, relationships, and rules related to the historic building. In the paper, we are proposing an improved workflow for the transformation of a heritage BIM model to a semantic model. In the BIM part the workflow demonstrates how the fully parametric modelling of historical building components is relevant, for example, in terms of reusability and adaptation to a different context. In the semantic model part, ontology reuse, reasoning, and querying mechanisms are applied to validate the usability of the proposed workflow. The presented work will improve knowledge-sharing and reuse among stakeholders involved in historic building projects.},
	language = {en},
	number = {15},
	urldate = {2023-04-16},
	journal = {Sustainability},
	author = {Guerra de Oliveira, Sara and Biancardo, Salvatore Antonio and Tibaut, Andrej},
	month = jan,
	year = {2022},
	note = {Number: 15
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {semantic model, SPARQL, algorithmic design, Erlangen CRM/OWL, heritage building information modelling (H-BIM), ifcOWL},
	pages = {9703},
	file = {Full Text PDF:files/3242/Guerra de Oliveira et al. - 2022 - Optimizing H-BIM Workflow for Interventions on His.pdf:application/pdf},
}

@article{de_santo_ontology_2016,
	title = {An {Ontology} to {Support} {Non}-{Invasive} {Diagnosis} of {Heritage} {Metals}},
	url = {https://aisel.aisnet.org/mcis2016/32},
	journal = {MCIS 2016 Proceedings},
	author = {De Santo, Alessio and Vonlanthen, Yann and Rosselet, Antoine and Degrigny, Christian and Gaspoz, Cédric},
	month = jan,
	year = {2016},
	file = {"An Ontology to Support Non-Invasive Diagnosis of Heritage Metals" by Alessio De Santo, Yann Vonlanthen et al.:files/3426/32.html:text/html},
}

@article{quattrini_knowledge-based_2017-1,
	title = {Knowledge-based data enrichment for {HBIM}: {Exploring} high-quality models using the semantic-web},
	volume = {28},
	issn = {1296-2074},
	shorttitle = {Knowledge-based data enrichment for {HBIM}},
	url = {https://www.sciencedirect.com/science/article/pii/S1296207417300754},
	doi = {10.1016/j.culher.2017.05.004},
	abstract = {In the last decade, the paradigm Historical Building Information Modeling (HBIM) was investigated to exploit the possibilities offered by the application of BIM to historical buildings. In the Cultural Heritage domain, the BIM-oriented approach can produce 3D models that are data collector populated by both geometrical and non-geometrical information related to various themes: historical documents, monitoring data, structural information, conservation or restoration state and so on. The realization of a 3D model fully interoperable and rich in its informative content could represent a very important change towards a more efficient management of the historical real estate. The work presented in these pages outlines a novel approach to solve this interoperability issue, by developing and testing a workflow that exploits the advantages of BIM platforms and Semantic-Web technologies, enabling the user to query a repository composed of semantically structured and rich HBIM data. The presented pipeline follows four main steps: (i) the first step consists on modeling an ontology with the main information needs for the domain of interest, providing a data structure that can be leveraged to inform the data-enrichment phase and, later, to meaningfully query the data. (ii) Afterwards, the data enrichment was performed, by creating a set of shared parameters reflecting the properties in our domain ontology. (iii) To structure data in a machine-readable format, a data conversion was needed to represent the domain (ontology) and analyze data of specific buildings respectively; this step is mandatory to reuse the analysis data together with the 3D model, providing the end-user with a querying tool. (iv) As a final step in our workflow, we developed a demonstrative data exploration web application based on the faceted browsing paradigm and allowing to exploit both structured metadata and 3D visualization. This research demonstrates how is possible to represent a huge amount of specialized information models with appropriate LOD and Grade in BIM environment and then guarantee a complete interoperability with IFC/RDF format. Relying on semantically structured data (ontologies) and on the Linked Data stack appears a valid approach for addressing existing information system issues in the CH domain and constitutes a step forward in the management of repositories and web libraries devoted to historical buildings.},
	language = {en},
	urldate = {2023-04-17},
	journal = {Journal of Cultural Heritage},
	author = {Quattrini, Ramona and Pierdicca, Roberto and Morbidoni, Christian},
	month = nov,
	year = {2017},
	keywords = {Data Standardization, Interoperability, Ontologies, Representation workflow, Shared parameters, Taxonomies},
	pages = {129--139},
	file = {ScienceDirect Full Text PDF:files/3430/Quattrini et al. - 2017 - Knowledge-based data enrichment for HBIM Explorin.pdf:application/pdf;ScienceDirect Snapshot:files/3431/S1296207417300754.html:text/html},
}

@article{cursi_linking_2022-1,
	title = {Linking external knowledge to heritage {BIM}},
	volume = {141},
	issn = {0926-5805},
	url = {https://www.sciencedirect.com/science/article/pii/S092658052200317X},
	doi = {10.1016/j.autcon.2022.104444},
	abstract = {The application of the Building Information Modelling (BIM) process to Built Heritage (HBIM) is a growing practice in processes and activities aimed at the investigation, documentation, and conservation of architectural heritage. However, it still raises some questions, such as the compatibility between the formalisation of information in the BIM model; and what limitations are inherent in current software implementations to establish a connection with external resources. On this basis, this paper aims at reviewing which methods are currently experimented to improve the level of semantic enrichment and to extend the knowledge representation domain offered today by the most common BIM authoring tools in an HBIM process. The analysis distinguishes two approaches that differ in the role played by external databases and the objectives pursued. Conclusions were drawn highlighting common needs for overcoming technical and conceptual limitations imposed by the use of proprietary BIM authoring tools, and differences in application perspectives and effectiveness.},
	language = {en},
	urldate = {2023-04-17},
	journal = {Automation in Construction},
	author = {Cursi, Stefano and Martinelli, Letizia and Paraciani, Nicolò and Calcerano, Filippo and Gigliarelli, Elena},
	month = sep,
	year = {2022},
	keywords = {BIM, Built heritage, HBIM, Interoperability, Ontologies, Database design, Semantic-enrichment},
	pages = {104444},
	file = {ScienceDirect Full Text PDF:files/3433/Cursi et al. - 2022 - Linking external knowledge to heritage BIM.pdf:application/pdf;ScienceDirect Snapshot:files/3434/S092658052200317X.html:text/html},
}

@inproceedings{blasko_monument_2012,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Monument {Damage} {Ontology}},
	isbn = {978-3-642-34234-9},
	doi = {10.1007/978-3-642-34234-9_22},
	abstract = {Capturing knowledge about damages and failures of culture heritage objects is a complex task because of term ambiguity, knowledge incompleteness and variety. To tackle this complexity, the paper introduces a semantic web ontology that aims at modeling monument damage knowledge with significant contextual information, including monument identification, damage identification, risk assessment, damage diagnosis and remedial measures. The developed ontology is being tested in the MONDIS project as a background knowledge for custom software tools for management of damage failure knowledge. During the course of the project it becomes a common model for linked-data-compliant knowledge-based system serving different stakeholders to model/retrieve/compare different cases of damage and successful interventions.},
	language = {en},
	booktitle = {Progress in {Cultural} {Heritage} {Preservation}},
	publisher = {Springer},
	author = {Blaško, Miroslav and Cacciotti, Riccardo and Křemen, Petr and Kouba, Zdeněk},
	editor = {Ioannides, Marinos and Fritsch, Dieter and Leissner, Johanna and Davies, Rob and Remondino, Fabio and Caffo, Rossella},
	year = {2012},
	keywords = {ontology, semantic web, damage, monument},
	pages = {221--230},
	file = {Full Text PDF:files/3482/Blaško et al. - 2012 - Monument Damage Ontology.pdf:application/pdf},
}

@inproceedings{moraitou_supporting_2022,
	title = {Supporting conservation and restoration through digital media modeling and exploitation - the example of the {Acropolis} of {Ancient} {Tiryns}},
	doi = {10.1109/SMAP56125.2022.9942216},
	abstract = {Open laboratories (OpenLabs) in Cultural Heritage (CH) institutions constitute an effective practice for providing visibility of all the processes that take place “behind the scenes”, as well as for the promotion of documentation data, which the specialists of the domain collect and produce. However, a simple “presentation” of processes, or the absence of necessary further explanation and communication with the specialists, may be problematic in terms of what visitors eventually see and understand. The exploitation of digital media and their efficient management and interlinking to meaningful data and knowledge may contribute significantly to the dissemination of publicly available information and the support of OpenLabs. Considering all the above, the CAnTi (Conservation of Ancient Tiryns) research project aims to design and implement virtual and augmented reality interactive applications that will visualize the conservation and restoration (CnR) data of the Acropolis of Ancient Tiryns. The digital content of the applications will be modeled using Semantic Web (SW) technologies, providing cultural visitors with access to insight documentation data and media produced by CnR scientists. The applications will constitute a part of the OpenLab activities that will be carried out on the archaeological site, enhancing the visitors’ experience regarding the CnR of the site’s current practices and past.},
	booktitle = {2022 17th {International} {Workshop} on {Semantic} and {Social} {Media} {Adaptation} \& {Personalization} ({SMAP})},
	author = {Moraitou, Efthymia and Konstantakis, Markos and Chrysanthi, Angeliki and Christodoulou, Yannis and Pavlidis, George and Caridakis, George},
	month = nov,
	year = {2022},
	keywords = {Semantics, Data models, cultural heritage, conservation, Documentation, Semantic Web, Media, Data visualization, digital applications, Laboratories, openlabs, restoration data, semantic modeling},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:files/3593/9942216.html:text/html;IEEE Xplore Full Text PDF:files/3592/Moraitou et al. - 2022 - Supporting conservation and restoration through di.pdf:application/pdf},
}

@article{peroni_interfacing_2017,
	series = {Industry and {In}-use {Applications} of {Semantic} {Technologies}},
	title = {Interfacing fast-fashion design industries with {Semantic} {Web} technologies: {The} case of {Imperial} {Fashion}},
	volume = {44},
	issn = {1570-8268},
	shorttitle = {Interfacing fast-fashion design industries with {Semantic} {Web} technologies},
	url = {https://www.sciencedirect.com/science/article/pii/S1570826817300288},
	doi = {10.1016/j.websem.2017.06.001},
	abstract = {With the advent of the fourth industrial revolution, several enterprises worldwide have started to evolve their production processes with new automation and data exchange policies by means of the adoption of emergent technologies, i.e. knowledge graphs, sensor networks, big data, and cloud computing. While several domains have been already involved in this revolution, other parties, such as the fast-fashion industries, have started to move the first steps in that direction since few months. In this article we describe the first outcomes of a project, i.e. Refactoring Imperial Selling Data (RISED), which aims at using Semantic Web technologies so as to simplify the management and the enrichment of a huge set of data that are continuously collected by Imperial Fashion, one of the most important fast-fashion companies in Italy. In particular, we introduce the process adopted for the development of a unifying model (i.e. an OWL 2 DL ontology) for the description of all the Imperial Fashion data and we propose some mechanisms for converting the original data stored in existing databases according to the new ontology. Finally, we introduce some prototypical visual tools that use the converted data for addressing some of the questions that have been raised by Imperial Fashion employees during several informal meetings we had about the project RISED.},
	language = {en},
	urldate = {2023-04-17},
	journal = {Journal of Web Semantics},
	author = {Peroni, Silvio and Vitali, Fabio},
	month = may,
	year = {2017},
	keywords = {Ontology, Semantic Web, OWL, Data conversion, Data reengineering, Data visualisation, Fast-fashion design},
	pages = {37--53},
	file = {ScienceDirect Full Text PDF:files/3605/Peroni e Vitali - 2017 - Interfacing fast-fashion design industries with Se.pdf:application/pdf;ScienceDirect Snapshot:files/3606/S1570826817300288.html:text/html},
}

@misc{noauthor_viaduct_nodate,
	title = {Viaduct},
	url = {http://www.viaduct-diadrasis.net/},
	urldate = {2023-04-17},
	file = {Viaduct:files/3636/www.viaduct-diadrasis.net.html:text/html},
}

@article{messaoudi_ontological_2018-1,
	title = {An ontological model for the reality-based {3D} annotation of heritage building conservation state},
	volume = {29},
	url = {https://hal.science/hal-01982887},
	doi = {10.1016/j.culher.2017.05.017},
	abstract = {The conservation and restoration of historical monuments require a diagnostic analysis carried out by amultidisciplinary team. The results of the diagnosis include data produced by different techniques andprotocols, which are used by conservation scientists to assess the built heritage. Nowadays, together withthe aforementioned data, a great deal of heterogeneous information is also available, including descriptiveand contextual information, as well as 2D/3D geometrical restitution of the studied object. However, theintegration of these diverse data into a unique information model capable of fully describing the buildingconservation state, as well as integrating future data, is still an open issue within the Cultural Heritagecommunity. It is of paramount importance to correlate these data and spatialize them in order to providescientists in charge of our heritage with a practical and easy means to explore the information usedduring their assessment, as well as a way to record their scientific observation and share them withintheir community of practice. In order to resolve this issue, we developed a correlation pipeline for theintegration of the semantic, spatial and morphological dimension of a built heritage. The pipeline uses anontological model for recording and integrating multidisciplinary observations of the conservation stateinto structural data spatialized into a semantic-aware 3D representation. The pipeline was successfullytested on the Saint Maurice church of Caromb in the south of France, integrating into a unique spatialrepresentation information about material and alteration phenomena, providing users with a means tocorrelate, and more importantly retrieve several types of information.},
	language = {en},
	urldate = {2023-04-21},
	journal = {Journal of Cultural Heritage},
	author = {Messaoudi, Tommy and Véron, Philippe and Halin, Gilles and Luca, Livio de},
	year = {2018},
	pages = {100},
	file = {Full Text PDF:files/3743/Messaoudi et al. - 2018 - An ontological model for the reality-based 3D anno.pdf:application/pdf},
}

@article{gillam_terminology_2005,
	title = {Terminology and the construction of ontology},
	volume = {11},
	issn = {0929-9971, 1569-9994},
	url = {https://www.jbe-platform.com/content/journals/10.1075/term.11.1.04gil},
	doi = {10.1075/term.11.1.04gil},
	abstract = {This paper discusses a method for corpus-driven ontology design: extracting conceptual hierarchies from arbitrary domain-specific collections of texts. These hierarchies can form the basis for a concept-oriented (onomasiological) terminology collection, and hence may be used as the basis for developing knowledge-based systems using ontology editors. This reference to ontology is explored in the context of collections of terms. The method presented is a hybrid of statistical and linguistic techniques, employing statistical techniques initially to elicit a conceptual hierarchy, which is then augmented through linguistic analysis. The result of such an extraction may be useful in information retrieval, knowledge management, or in the discipline of terminology science itself.},
	language = {en},
	number = {1},
	urldate = {2023-04-21},
	journal = {Terminology. International Journal of Theoretical and Applied Issues in Specialized Communication},
	author = {Gillam, Lee and Tariq, Mariam and Ahmad, Khurshid},
	month = jan,
	year = {2005},
	note = {Publisher: John Benjamins},
	pages = {55--81},
	file = {Snapshot:files/3745/term.11.1.html:text/html},
}

@article{hackman_documentation_1987,
	title = {The {Documentation} {Strategy} {Process}: {A} {Model} and a {Case} {Study}},
	volume = {50},
	issn = {0360-9081},
	shorttitle = {The {Documentation} {Strategy} {Process}},
	url = {https://doi.org/10.17723/aarc.50.1.uxr6766121033766},
	doi = {10.17723/aarc.50.1.uxr6766121033766},
	abstract = {How might the archival community strengthen its ability to analyze documentation needs and address these needs more efficiently? Is there a general approach to analysis and action that can help guide such work? This article describes a model addressing these goals and provides a case study illustrating the model at work.First the authors outline the case for broad, ongoing analysis of the adequacy of archival documentation and for coordinated action to improve the identification, retention, and treatment of records of enduring value. In the second section, Hackman presents an analytic model for an Archival Documentation Strategy Process, describing the development, refinement, and implementation of documentation strategies. The model suggests broader analysis, increased communication and coordination, and more active use of a range of sources of influence to shape archival selection policies and programs. As the archival community evaluates the feasibility and potential effectiveness of documentation strategies, it may be especially useful to consider a case study of an institution that has already employed many aspects of the model. In the third section, Warnow-Blewett reviews the motivations that led the American Institute of Physics to design an initial documentation strategy in the 1960s and outlines the refinement, extension, and effectiveness of that strategy during the past twentyfive years. In the closing section the authors outline some of the implications of the documentation strategy process for established archival theory and practice, and call for discussion and testing in other areas of documentation.},
	number = {1},
	urldate = {2023-04-23},
	journal = {The American Archivist},
	author = {Hackman, Larry and Warnow-Blewett, Joan},
	month = jan,
	year = {1987},
	pages = {12--47},
	file = {Full Text PDF:files/3773/Hackman e Warnow-Blewett - 1987 - The Documentation Strategy Process A Model and a .pdf:application/pdf;Snapshot:files/3772/The-Documentation-Strategy-Process-A-Model-and-a.html:text/html},
}

@article{buckland_what_1997,
	title = {What is a “document”?},
	volume = {48},
	issn = {1097-4571},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-4571%28199709%2948%3A9%3C804%3A%3AAID-ASI5%3E3.0.CO%3B2-V},
	doi = {10.1002/(SICI)1097-4571(199709)48:9<804::AID-ASI5>3.0.CO;2-V},
	abstract = {Ordinarily the word “document” denotes a textual record. Increasingly sophisticated attempts to provide access to the rapidly growing quantity of available documents raised questions about what should be considered a “document.” The answer is important for any definition of the scope of Information Science. Paul Otlet and others developed a functional view of “document” and discussed whether, for example, sculpture, museum objects, and live animals, could be considered “documents.” Suzanne Briet equated “document” with organized physical evidence. These ideas appear to resemble notions of “material culture” in cultural anthropology and “object-as-sign” in semiotics. Others, especially in the U.S.A. (e.g., Jesse Shera and Louis Shores) took a narrower view. New digital technology renews old questions and also old confusions between medium, message, and meaning. © 1997 John Wiley \& Sons, Inc.},
	language = {en},
	number = {9},
	urldate = {2023-04-23},
	journal = {Journal of the American Society for Information Science},
	author = {Buckland, Michael K.},
	year = {1997},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291097-4571\%28199709\%2948\%3A9\%3C804\%3A\%3AAID-ASI5\%3E3.0.CO\%3B2-V},
	pages = {804--809},
	file = {Snapshot:files/3775/(SICI)1097-4571(199709)489804AID-ASI53.0.html:text/html},
}

@incollection{lund_document_2015,
	edition = {3},
	title = {Document {Theory}},
	isbn = {978-0-203-75763-5},
	abstract = {This entry provides an overview about the historical development of theoretical reflections on documents and formulation of document theories. Starting out with its Latin predecessor documentum and the use of the conception in the European state bureaucracy from the seventeenth century, the first interest for document theory was a professional one and can be observed at the beginning of the twentieth century, closely connected with names like Paul Otlet and Suzanne Briet. While the notion of document and documentation was well established around 1930, it was replaced by the notion of information after World War II, at least in the Anglophone community. Nevertheless, at the same time a new kind of document theory was emerging, a critical one connected to names like Michel Foucault, Harold Garfinkel, and Dorothy E. Smith. While the “professional” document theory developed by Otlet and others was focused on the knowledge more or less inherent in the documents and to make documents about something, then the general document theory developed by critical social scientists such as Foucault is much more about what the documents are and do. Since the 1990s, there has been a growing interest for the notion of document and documentation also inside Library and Information Science (LIS) again, connected to names like Michael Buckland, Ronald Day, and Bernd Frohmann. Together with a growing interest in digital documents, document theorists in North America, Scandinavia, and France are emphasizing the complexity in document theory and a need of a complementary approach to document theory connecting physical, social, and cultural dimensions in how documents are and do.},
	booktitle = {Encyclopedia of {Library} and {Information} {Sciences}},
	publisher = {CRC Press},
	author = {Lund, Niels Windfeld and Skare, Roswitha},
	year = {2015},
	note = {Num Pages: 8},
}

@article{rayward_visions_1994,
	title = {Visions of {Xanadu}: {Paul} {Otlet} (1868–1944) and hypertext},
	volume = {45},
	issn = {1097-4571},
	shorttitle = {Visions of {Xanadu}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-4571%28199405%2945%3A4%3C235%3A%3AAID-ASI2%3E3.0.CO%3B2-Y},
	doi = {10.1002/(SICI)1097-4571(199405)45:4<235::AID-ASI2>3.0.CO;2-Y},
	abstract = {The work of the Belgian internationalist and documentalist, Paul Otlet (1868–1944), and his colleagues in Brussels, forms an important and neglected part of the history of information science. They developed a complex of organizations that are similar in important respects functionally to contemporary hypertext7sol;hypermedia systems. These organizations effectively provided for the integration of bibliographic, image, and textual databases. Chunks of text on cards or separate sheets were created according to “the monographic principle” and their physical organization managed by the Universal Decimal Classification, created by the Belgians from Melvil Dewey's Decimal Classification. This article, discusses Otlet's concept of the Office of Documentation and, as examples of an approach to actual hypertext systems, several special Offices of Documentation set up in the International Office of Bibliography. In his Traité de Documentation of 1934, one of the first systematic treatises on what today we would call information science, Otlet speculated imaginatively about telecommunications, text-voice conversion, and what is needed in computer workstations, though of course he does not use this terminology. By assessing how the intellectual paradigm of nineteenth century positivism shaped Otlet's thinking, this study suggests how, despite its apparent contemporaneity, what he proposed was in fact conceptually different from the hypertext systems that have been developed or speculated about today. Such as analysis paradoxically also suggests the irony that a “deconstructionist” reading of accounts of these systems might find embedded in them the positivist approach to knowledge that the system designers would seem on the face of it explicitly to have repudiated. © 1994 John Wiley \& Sons, Inc.},
	language = {en},
	number = {4},
	urldate = {2023-04-23},
	journal = {Journal of the American Society for Information Science},
	author = {Rayward, W. Boyd},
	year = {1994},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291097-4571\%28199405\%2945\%3A4\%3C235\%3A\%3AAID-ASI2\%3E3.0.CO\%3B2-Y},
	pages = {235--250},
	file = {Snapshot:files/3778/(SICI)1097-4571(199405)454235AID-ASI23.0.html:text/html},
}

@article{otlet_international_1990,
	title = {International {Organisation} and {Dissemination} of {Knowledge}: {Selected} {Essays} of {Paul} {Otlet}},
	copyright = {Copyright 1990 International Federation of Documentation.},
	shorttitle = {International {Organisation} and {Dissemination} of {Knowledge}},
	url = {https://hdl.handle.net/2142/4004},
	abstract = {These translations of a selection of Paul Otlet's writings have been a long time in
preparation. Now put down, now taken up again over a period of ten years or so in Chicago,
London and Sydney, they are dispatched at last to Amsterdam with relief. They follow an
earlier biographical and institutional study of Otlet and the International Institute of
Bibliography (now FID, the International Federation for Information and Documentation).  The publication of that work left me with a troubled sense of more that needed to be done, of an obligation incurred but not yet discharged. It has always seemed to me that, though not entirely neglected, Otlet's contributions to our understanding of bibliography, documentation and what is now called information storage and retrieval, sometimes information science, and
the technical and institutional arrangements needed to maximise their social utility, have not had the attention in the English-speaking world that is their due. It is my hope that the availability of this selection of papers in English, both in themselves and because of the attention that the act of publication can engender, will encourage a renewal of interest in Otlet's thinking about and work for the international organisation and dissemination of knowledge. (From the preface)},
	language = {en},
	urldate = {2023-04-23},
	author = {Otlet, Paul},
	year = {1990},
	note = {Publisher: Elsevier for the International Federation of Documentation},
	file = {Full Text PDF:files/3780/Otlet - 1990 - International Organisation and Dissemination of Kn.pdf:application/pdf},
}

@article{buckland_what_nodate,
	title = {What is a "digital document"?},
	abstract = {The question "What is a digital document?" is seen as a special case of the question "What is a document?" Ordinarily the word "document" denotes a textual record. Early this century, attempts to provide access to the rapidly growing quantity of available documents raised questions about which should be considered a "document". Paul Otlet and others developed a functional view of "document" and discussed whether, for example, sculpture, museum objects, and live animals, could be considered to be "documents". Suzanne Briet equated "document" with organized physical evidence. These ideas resemble notions of "material culture" in cultural anthropology and "object-as-sign" in semiotics. Others, especially in the USA (e.g. Jesse Shera and Louis Shores) took a narrower view. Old confusions between medium, message, and meaning are renewed with digital technology because technological definitions of "document" become even less realistic when everything is in bits.},
	language = {en},
	author = {Buckland, Michael},
	file = {Buckland - What is a digital document.pdf:files/3781/Buckland - What is a digital document.pdf:application/pdf},
}

@article{le_deuff_paul_2019,
	title = {Paul {Otlet} and the {Ultimate} {Prospect} of {Documentation}},
	volume = {6},
	issn = {2473-215X},
	url = {https://ideaexchange.uakron.edu/docam/vol6/iss1/14},
	doi = {10.35492/docam/6/1/9},
	number = {1},
	journal = {Proceedings from the Document Academy},
	author = {Le Deuff, Olivier and Perret, Arthur},
	month = dec,
	year = {2019},
	file = {"Paul Otlet and the ultimate prospect of documentation" by Olivier Le Deuff and Arthur Perret:files/3785/14.html:text/html;Full text:files/3784/Le Deuff e Perret - 2019 - Paul Otlet and the Ultimate Prospect of Documentat.pdf:application/pdf},
}

@article{rayward_origins_1997,
	title = {The origins of information science and the {International} {Institute} of {Bibliography}/{International} {Federation} for {Information} and {Documentation} ({FID})},
	volume = {48},
	issn = {1097-4571},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-4571%28199704%2948%3A4%3C289%3A%3AAID-ASI2%3E3.0.CO%3B2-S},
	doi = {10.1002/(SICI)1097-4571(199704)48:4<289::AID-ASI2>3.0.CO;2-S},
	abstract = {This article suggests that the ideas and practices embraced by the term “documentation,” introduced by Paul Otlet and his colleagues to describe the work of the International Institute of Bibliography (later FID) that they set up in Brussels in 1895, constituted a new “discursive formation,” to echo Foucault. While today's special terminology of information science was not then in use, this should not obscure the fact that key concepts for information science as we now understand this field of study and research—and the technical systems and professional activities in which it is anchored—were implicit in and operationalized by what was created within the International Institute of Bibliography in 1895 and the decades that followed. The ideas and practices to be discussed would today be rubricated as information technology, information retrieval, search strategies, information centers, fee-based information services, linked data bases, database management software, scholarly communication networks, multimedia and hypertext, even the modern, diffuse notion of “information” itself. The article argues that important aspects of the origins of information science, as we now know it in the U.S. and elsewhere in the English-speaking world, were contained within or became an extension of the discursive formation that we have labeled “documentation.” © 1997 John Wiley \& Sons, Inc.},
	language = {en},
	number = {4},
	urldate = {2023-04-23},
	journal = {Journal of the American Society for Information Science},
	author = {Rayward, W. Boyd},
	year = {1997},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291097-4571\%28199704\%2948\%3A4\%3C289\%3A\%3AAID-ASI2\%3E3.0.CO\%3B2-S},
	pages = {289--300},
	file = {Snapshot:files/3787/(SICI)1097-4571(199704)484289AID-ASI23.0.html:text/html},
}

@article{rayward_paul_2007,
	title = {Paul {Otlet}, documentation and classification},
	volume = {43},
	doi = {10.1002/meet.1450430173},
	journal = {Proceedings of the American Society for Information Science and Technology},
	author = {Rayward, Boyd and Furner, Jonathan and La Barre, Kathryn and Rayward, W. and Warner, Julian},
	month = oct,
	year = {2007},
	pages = {1--6},
	file = {Full Text PDF:files/3790/Rayward et al. - 2007 - Paul Otlet, documentation and classification.pdf:application/pdf},
}

@article{buckland_centenary_1995,
	title = {The centenary of “{Madame} {Documentation}”: {Suzanne} {Briet}, 1894–1989},
	volume = {46},
	issn = {1097-4571},
	shorttitle = {The centenary of “{Madame} {Documentation}”},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-4571%28199504%2946%3A3%3C235%3A%3AAID-ASI7%3E3.0.CO%3B2-J},
	doi = {10.1002/(SICI)1097-4571(199504)46:3<235::AID-ASI7>3.0.CO;2-J},
	abstract = {This is a biographical account of Suzanne Briet, 1894–1989, librarian, documentalist, historian, organizer, and feminist. One of the first few women appointed as librarian at the Bibliothèque Nationale, Paris, Briet was a leader in the development of Documentation in the 1930s and until she retired in 1954. Her manifesto on the nature of Documentation, Qu'est-ce que la documentation? (Paris, 1951), remains significant for information science theory. © 1995 John Wiley \& Sons, Inc.},
	language = {en},
	number = {3},
	urldate = {2023-04-23},
	journal = {Journal of the American Society for Information Science},
	author = {Buckland, Michael K.},
	year = {1995},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291097-4571\%28199504\%2946\%3A3\%3C235\%3A\%3AAID-ASI7\%3E3.0.CO\%3B2-J},
	pages = {235--237},
	file = {Snapshot:files/3792/(SICI)1097-4571(199504)463235AID-ASI73.0.html:text/html},
}

@book{briet_what_2006,
	title = {What is {Documentation}?: {English} {Translation} of the {Classic} {French} {Text}},
	isbn = {978-0-8108-5109-2},
	shorttitle = {What is {Documentation}?},
	abstract = {Born in Paris in 1894, Suzanne Briet was active nationally and internationally in the development of what was then known as Documentation but would now be called Information Management or Information Science. In 1931, she participated in founding the Union Française des Organismes de Documentation (UFOD), the French analogue of the American Documentation Institute now called the American Society for Information Science and Technology. She was a leader in developing professional education for this new specialty and designed a plan for what would have been the first school of Documentation / Information Science worldwide, had it been established. In 1951, when a school of information science was finally established, Briet was the founding Director of Studies. She became Vice President of the International Federation for Documentation (FID) and acquired the nickname "Madame Documentation." What is Documentation? relates this fascinating story and includes the first English translation of Briet's remarkable manifesto on the nature of documentation, Qu'est-ce que la documentation? (Paris: EDIT, 1951). A pamphlet of 48 pages, Part I sought to push the boundaries of the field beyond texts to include any material form of evidence ("Is a living animal a document?" she asked). Part II argued that a new and distinct profession was emerging. Part III urged the societal need for new and active documentary services. This tract remains significant due to its continuing relevance towards understanding the nature, scope, and societal impacts of documents and documentation. Briet's modernist perspective, combined with semiotics, deserves attention now because it offers a sturdy and insightful alternative to the scientific, positivist view that has so dominated information science and which is increasingly questioned.},
	language = {en},
	publisher = {Scarecrow Press},
	author = {Briet, Suzanne},
	year = {2006},
	note = {Google-Books-ID: 2yMQZJWeL2IC},
}

@article{lund_document_2008,
	title = {Document, documentation, and the {Document} {Academy}: introduction},
	volume = {8},
	issn = {1573-7519},
	shorttitle = {Document, documentation, and the {Document} {Academy}},
	url = {https://doi.org/10.1007/s10502-009-9076-3},
	doi = {10.1007/s10502-009-9076-3},
	abstract = {A series of efforts starting in the late nineteenth century to manage the increase in documents came to be knows as “documentation.” Leaders included Paul Otlet and Suzanne Briet. The concern was with access to evidence and the meaning of “document” was broadened to include any sign preserved to represent phenomena. Legal deposit, when extended to new modern media, required new techniques and led to a new program in documentation at the University of Tromsø, Norway, in 1996. Niels Lund, Michael Buckland, and others collaborated in forming the Document Academy and organized a series of conferences.},
	language = {en},
	number = {3},
	urldate = {2023-04-23},
	journal = {Archival Science},
	author = {Lund, Niels Windfeld and Buckland, Michael},
	month = sep,
	year = {2008},
	keywords = {Documentation, Document, Document Academy, University of Tromsø},
	pages = {161--164},
	file = {Full Text PDF:files/3796/Lund e Buckland - 2008 - Document, documentation, and the Document Academy.pdf:application/pdf},
}

@article{buckland_boyd_2013,
	title = {Boyd {Rayward}, {Documentation}, and {Information} {Science}},
	volume = {62},
	issn = {1559-0682},
	url = {https://muse.jhu.edu/pub/1/article/540515},
	doi = {10.1353/lib.2013.0038},
	abstract = {W. Boyd Rayward is best known as the biographer of Paul Otlet and as a historian of documentation, but he has also always been concerned with contemporary services and with the nature of information science. Less well known and certainly less well documented is his exceptional indirect influence through correspondence, encouragement, conferences, and the building of informal networks. We provide an informal account of some of Rayward’s influence during the past twenty-five years in building a more complete and historically informed understanding of information science.},
	number = {2},
	urldate = {2023-04-23},
	journal = {Library Trends},
	author = {Buckland, Michael K. and Lund, Niels W.},
	year = {2013},
	note = {Publisher: Johns Hopkins University Press},
	pages = {302--310},
	file = {Versione inviata:files/3798/Buckland e Lund - 2013 - Boyd Rayward, Documentation, and Information Scien.pdf:application/pdf},
}

@article{buckland_documentality_2014,
	title = {Documentality {Beyond} {Documents}},
	volume = {97},
	url = {https://www.pdcnet.org/pdc/bvdb.nsf/purchase?openform&fp=monist&id=monist_2014_0097_0002_0179_0186},
	doi = {10.5840/monist201497212},
	language = {en},
	number = {2},
	urldate = {2023-04-23},
	journal = {The Monist},
	author = {Buckland, Michael},
	month = apr,
	year = {2014},
	pages = {179--186},
	file = {Versione inviata:files/3800/Buckland - 2014 - Documentality Beyond Documents.pdf:application/pdf},
}

@article{maack_lady_2004,
	title = {The {Lady} and the {Antelope}: {Suzanne} {Briet}'s {Contribution} to the {French} {Documentation} {Movement}},
	copyright = {Copyright owned by Board of Trustees of the University of Illinois. 2004.},
	issn = {0024-2594},
	shorttitle = {The {Lady} and the {Antelope}},
	url = {https://hdl.handle.net/2142/1704},
	abstract = {During her thirty years at the Bibliothèque Nationale (BN), Suzanne Briet
(1894–1989) made important theoretical, organizational, and institutional
contributions to the documentation movement in France. This article attempts
to place her documentation work within the context of the far-reaching
reform of French libraries, with special attention to the transformation
of the BN. Like her colleagues in special libraries, Briet embraced modernity
and science. Because of her strong orientation toward humanistic
scholarship, however, she viewed documentation service and bibliographic
orientation as an enhancement rather than a rejection of the scholarly
traditions of the national library. This article will focus on her efforts to
integrate the innovative ideas of the documentation movement into the
practice of librarianship at the Bibliothèque Nationale.},
	language = {en},
	urldate = {2023-04-23},
	author = {Maack, Mary Niles},
	year = {2004},
	note = {Publisher: Graduate School of Library and Information Science. University of Illinois at Urbana-Champaign.},
	file = {Full Text PDF:files/3802/Maack - 2004 - The Lady and the Antelope Suzanne Briet's Contrib.pdf:application/pdf},
}

@article{buckland_before_2017,
	title = {Before the {Antelope}: {Robert} {Pagès} on {Documents}},
	volume = {4},
	issn = {2473-215X},
	shorttitle = {Before the {Antelope}},
	url = {https://ideaexchange.uakron.edu/docam/vol4/iss2/6},
	doi = {10.35492/docam/4/2/6},
	number = {2},
	journal = {Proceedings from the Document Academy},
	author = {Buckland, Michael},
	month = dec,
	year = {2017},
	file = {"Before the Antelope" by Michael K. Buckland:files/3805/6.html:text/html;Full text:files/3804/Buckland - 2017 - Before the Antelope Robert Pagès on Documents.pdf:application/pdf},
}

@book{buckland_document_2015,
	title = {Document {Theory}: {An} {Introduction}.},
	isbn = {978-953-331-080-0},
	shorttitle = {Document {Theory}},
	url = {https://escholarship.org/uc/item/87s642x7},
	abstract = {Writing, printing, telecommunications, and copying enabled the rise of the “information society” (more accurately “document society”) characterized by the division of labor. Document (verb) means to make evident. A document (noun) is something from which you learn, especially a text. Documents have a phenomenological aspect; employ cultural codes; form media types; and use physical media. The management of documents led to a more inclusive definition, including Briet’s antelope. Documents have technical, social, and mental aspects. Factual assertions require context. Documents are used to shape our lives and culture. Conventionally documents are made as documents; but objects can also be made into documents; or simply regarded as documents. New forms of document require new forms of bibliography. Current trends lead to the recording, the representation, and the analysis of everything, simultaneously.},
	language = {en},
	urldate = {2023-04-23},
	author = {Buckland, M. K.},
	year = {2015},
	file = {Full Text PDF:files/3807/Buckland - 2015 - Document Theory An Introduction..pdf:application/pdf},
}

@article{gorichanaz_understanding_2017,
	title = {Understanding {Art}-{Making} as {Documentation}},
	volume = {36},
	issn = {0730-7187},
	url = {https://www.journals.uchicago.edu/doi/abs/10.1086/694239},
	doi = {10.1086/694239},
	abstract = {Typically, arts information professionals are concerned with the documentation of artwork. As a provocation, this conceptual article explores how art-making itself can be considered a form of documentation and finished artworks as documents in their own right. In this view, art works as evidence in referencing something else, within a broader system, and under scrutiny it exposes how it references. Some implications of this perspective are discussed, springing from a historical discussion of document epistemology, research on the information behavior of artists, and the philosophy of Nelson Goodman. This discussion provides a framework for conceptualizing artistic information behavior along the entire information chain. Framing art-making in terms of information science in this way may help arts information professionals assist artists, as well as provide grounds for deeper co-understandings between artists and information scientists. Once information scientists consider art as a kind of document, one can begin to see that even non-artistic documents perhaps never were as “objective” or “factual” as they may have seemed.},
	number = {2},
	urldate = {2023-04-23},
	journal = {Art Documentation: Journal of the Art Libraries Society of North America},
	author = {Gorichanaz, Tim},
	month = sep,
	year = {2017},
	note = {Publisher: The University of Chicago Press},
	pages = {191--203},
	file = {Versione inviata:files/3809/Gorichanaz - 2017 - Understanding Art-Making as Documentation.pdf:application/pdf},
}

@article{day_totality_2001,
	title = {Totality and representation: {A} history of knowledge management through {European} documentation, critical modernity, and post-{Fordism}},
	volume = {52},
	issn = {1532-2890},
	shorttitle = {Totality and representation},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.1125},
	doi = {10.1002/asi.1125},
	abstract = {This article presents European documentalist, critical modernist, and Autonomous Marxist influenced post-Fordist views regarding the management of knowledge in mid- and late twentieth century Western modernity and postmodernity, and the complex theoretical and ideological debates, especially concerning issues of language and community. The introduction and use for corporate, governmental, and social purposes of powerful information and communication technologies created conceptual and political tensions and theoretical debates. In this article, knowledge management, including the specific recent approach known as “Knowledge Management,” is discussed as a social, cultural, political, and organizational issue, including the problematic feasibility of capturing and representing knowledge that is “tacit,” “invisible,” and is imperfectly representable. “Social capital” and “affective labor” are discussed as elements of “tacit” knowledge. Views of writers in the European documentalist, critical modernist, and Italian Autonomous Marxist influenced post-Fordist traditions, such as Otlet, Briet, Heidegger, Benjamin, Marazzi, and Negri, are discussed.1},
	language = {en},
	number = {9},
	urldate = {2023-04-23},
	journal = {Journal of the American Society for Information Science and Technology},
	author = {Day, Ronald E.},
	year = {2001},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.1125},
	pages = {725--735},
	file = {Snapshot:files/3811/asi.html:text/html},
}

@book{packer_communication_2013,
	title = {Communication {Matters}: {Materialist} {Approaches} to {Media}, {Mobility} and {Networks}},
	isbn = {978-1-136-58960-7},
	shorttitle = {Communication {Matters}},
	abstract = {Communication has often been understood as a realm of immaterial, insubstantial phenomena—images, messages, thoughts, languages, cultures, and ideologies—mediating our embodied experience of the concrete world. Communication Matters challenges this view, assembling leading scholars in the fields of Communication, Rhetoric, and English to focus on the materiality of communication. Building on the work of materialist theorists such as Gilles Deleuze, Michel Foucault, Friedrich Kittler, and Henri Lefebvre, the essays collected here examine the materiality of discourse itself and the constitutive force of communication in the production of the real.      Communication Matters presents original work that rethinks communication as material and situates materialist approaches to communication within the broader "materiality turn" emerging in the humanities and social sciences. This collection will be of interest to researchers and postgraduate students in Media, Communication Studies, and Rhetoric. The book includes images of the digital media installations of Francesca Talenti, Professor, Department of Communication Studies, University of North Carolina at Chapel Hill.},
	language = {en},
	publisher = {Routledge},
	author = {Packer, Jeremy and Wiley, Stephen B. Crofts},
	month = jun,
	year = {2013},
	note = {Google-Books-ID: flmBKnX4u9MC},
	keywords = {Social Science / Media Studies},
}

@article{jones_reconsidering_2019,
	title = {Reconsidering data in learning analytics: opportunities for critical research using a documentation studies framework},
	volume = {44},
	issn = {1743-9884},
	shorttitle = {Reconsidering data in learning analytics},
	url = {https://doi.org/10.1080/17439884.2018.1556216},
	doi = {10.1080/17439884.2018.1556216},
	abstract = {In this article, we argue that the contributions of documentation studies can provide a useful framework for analyzing the datafication of students due to emerging learning analytics (LA) practices. Specifically, the concepts of individuals being ‘made into’ data and how that data is ‘considered as’ can help to frame vital questions concerning the use of student data in LA. More specifically, approaches informed by documentation studies will enable researchers to address the sociotechnical processes underlying how students are constructed into data, and ways data about students are considered and understood. We draw on these concepts to identify and describe three areas for future research in LA. With the description of each area, we provide a brief analysis of current practices in American higher education, highlighting how documentation studies enables deeper analytical digging.},
	number = {1},
	urldate = {2023-04-23},
	journal = {Learning, Media and Technology},
	author = {Jones, Kyle M. L. and McCoy, Chase},
	month = jan,
	year = {2019},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/17439884.2018.1556216},
	keywords = {critical data studies, documentation studies, educational data mining, Learning analytics},
	pages = {52--63},
	file = {Versione inviata:files/3815/Jones e McCoy - 2019 - Reconsidering data in learning analytics opportun.pdf:application/pdf},
}

@article{tourney_caging_2003,
	title = {Caging {Virtual} {Antelopes}: {Suzanne} {Briet}’s {Definition} of {Documents} in the {Context} of {The} {Digital} {Age}},
	volume = {3},
	issn = {1573-7519},
	shorttitle = {Caging {Virtual} {Antelopes}},
	url = {https://doi.org/10.1007/s10502-004-4038-2},
	doi = {10.1007/s10502-004-4038-2},
	language = {en},
	number = {3},
	urldate = {2023-04-23},
	journal = {Archival Science},
	author = {Tourney, Michele M.},
	month = sep,
	year = {2003},
	keywords = {Cultural Heritage},
	pages = {291--311},
	file = {Full Text PDF:files/3817/Tourney - 2003 - Caging Virtual Antelopes Suzanne Briet’s Definiti.pdf:application/pdf},
}

@article{grenersen_landscapes_2016,
	title = {Landscapes as documents: {The} relationship between traditional {Sámi} terminology and the concepts of document and documentation},
	volume = {72},
	issn = {0022-0418},
	shorttitle = {Landscapes as documents},
	url = {https://doi.org/10.1108/JD-01-2016-0010},
	doi = {10.1108/JD-01-2016-0010},
	abstract = {Purpose The purpose of this paper is to discuss the following questions: what is the origin of the concepts of documents and documentation? Are there a need for these concepts in every culture? Who gives the terms for their definitions, and what are the consequences of different terminology? Design/methodology/approach The authors use interdisciplinary methodology, combining document and information theory and Sámi linguistics. The aim of this paper is to discuss documentation from the perspective of the Sámi, with some examples from other indigenous groups. Findings Oral accounts, legends, traditional songs and traces in the landscape are seen as documents and documentation in Sámi and other indigenous cultures. The paper presents different theories in order to interpret and understand the specific information content in indigenous forms of documentation. Practical implications Indigenous ways of documentation have been accepted as valid proof of ownership or the right to extensive use of land resources. When no written records exist, oral testimonies and the landscape itself can be seen as documenting traditional use and has been accepted as evidence in high courts in Norway and Canada. The authors have also seen that the rich Sámi snow terminology is used as concepts in different fields of natural sciences. Originality/value The Sámi understanding of the concepts of document and documentation contributes to the traditional information and documentation disciplines by introducing ways of seeing natural phenomenon as fundamental forms of information.},
	number = {6},
	urldate = {2023-04-23},
	journal = {Journal of Documentation},
	author = {Grenersen, Geir and Kemi, Kjell and Nilsen, Steinar},
	month = jan,
	year = {2016},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Documentation, Document terminology, Document theory, Documents, Fundamental forms of information, Indigenous documentation, Information science and documentation, Sámi},
	pages = {1181--1196},
	file = {Full Text PDF:files/3819/Grenersen et al. - 2016 - Landscapes as documents The relationship between .pdf:application/pdf},
}

@article{gourlay_surveillance_2022,
	title = {Surveillance and {Datafication} in {Higher} {Education}: {Documentation} of the {Human}},
	issn = {2524-4868},
	shorttitle = {Surveillance and {Datafication} in {Higher} {Education}},
	url = {https://doi.org/10.1007/s42438-022-00352-x},
	doi = {10.1007/s42438-022-00352-x},
	language = {en},
	urldate = {2023-04-23},
	journal = {Postdigital Science and Education},
	author = {Gourlay, Lesley},
	month = oct,
	year = {2022},
	keywords = {Algorithms, Learning analytics, Datafication, Publication metrics, Sociotechnical imaginaries, Surveillance},
	file = {Full Text PDF:files/3821/Gourlay - 2022 - Surveillance and Datafication in Higher Education.pdf:application/pdf},
}

@book{noauthor_essentials_2008,
	title = {Essentials of {Language} {Documentation}},
	isbn = {978-3-11-019773-0},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110197730/html},
	abstract = {Language documentation is a rapidly emerging new field in linguistics which is concerned with the methods, tools and theoretical underpinnings for compiling a representative and lasting multipurpose record of a natural language. This volume presents in-depth introductions to major aspects of language documentation, including overviews on fieldwork ethics and data processing, guidelines for the basic annotation of digitally-stored multimedia corpora and a discussion on how to build and maintain a language archive. It combines theoretical and practical considerations and makes specific suggestions for the most common problems encountered in language documentation. Key features textbook introduction to Language Documentation considers all common problems},
	language = {en},
	urldate = {2023-04-23},
	publisher = {De Gruyter Mouton},
	month = aug,
	year = {2008},
	doi = {10.1515/9783110197730},
	note = {Publication Title: Essentials of Language Documentation},
	keywords = {fieldwork, Language documentation},
}

@article{hermon_metadata_2012,
	title = {A {Metadata} {Schema} for {Cultural} {Heritage} {Documentation}},
	url = {https://www.torrossa.com/en/resources/an/2497325},
	doi = {10.1400/187333},
	abstract = {Purchase online the PDF of A Metadata Schema for Cultural Heritage Documentation, Hermon, Sorin,Niccolucci, Franco,Ronzino, Paola - Firenze University Press - Chapter},
	language = {en},
	urldate = {2023-04-23},
	journal = {A Metadata Schema for Cultural Heritage Documentation},
	author = {Hermon, Sorin},
	year = {2012},
	note = {Publisher: Firenze University Press},
	pages = {36--41},
}

@article{latham_museum_2012,
	title = {Museum object as document: {Using} {Buckland}'s information concepts to understand museum experiences},
	volume = {68},
	issn = {0022-0418},
	shorttitle = {Museum object as document},
	url = {https://doi.org/10.1108/00220411211200329},
	doi = {10.1108/00220411211200329},
	abstract = {Purpose – The purpose of this article is to understand the meaning of museum objects from an information perspective. Links are made from Buckland's conceptual information framework as a semiotic to museum object as “document” and finally to user experience of these museum “documents”. The aim is to provide a new lens through which museum studies researchers can understand museum objects and for LIS researchers to accept museum objects as another form of document to be studied. Design/methodology/approach – A conceptual and comparative analysis of Buckland's information typology as a semiotic. Outcome of analysis forms a model of understanding the museum object as a “document” that is accessed by users on a continuum of experience. Findings – Michael Buckland's information typology is insightful and useful for a broad understanding of what all heritage institutions have in common: the physical object. Buckland helps us see the museum as an information system, the museum object as a document, and the multidimensional use of the concept information and its semiotic ramifications. Originality/value – Buckland's typology is important to an understanding of the museum system and museum object in both LIS and museum studies. The concept of “document” opens up a broader perspective, which creates, rather than limits understandings of the human relationship with information. This expanded concept of “document” as sign/semiotic helps us understand user experience in ways not previously explored in the convergence of museums and information studies, from the practical to the theoretical. In this inclusive sense, Buckland's concept of document is a unifying theoretical concept for museums, libraries, and archives.},
	number = {1},
	urldate = {2023-04-24},
	journal = {Journal of Documentation},
	author = {Latham, Kiersten F.},
	month = jan,
	year = {2012},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Museums, Document, Document handling, Michael Buckland, Museum objects, Reader response, Semiotics},
	pages = {45--71},
	file = {Snapshot:files/3825/html.html:text/html},
}

@article{allen-robertson_critically_2018,
	title = {Critically assessing digital documents: materiality and the interpretative role of software},
	volume = {21},
	issn = {1369-118X},
	shorttitle = {Critically assessing digital documents},
	url = {https://doi.org/10.1080/1369118X.2017.1351575},
	doi = {10.1080/1369118X.2017.1351575},
	abstract = {As a contribution to the ongoing tradition of critically assessing documents for research, this paper aims to highlight materiality as a key factor in the co-shaping of knowledge derived from digital documents. The paper first builds upon prior debates in document studies with work from the fields of Science and Technology Studies, and Communication Studies, to establish the role of document materiality in the interpretative process. By first establishing digital documents’ material reality as electrical signal, the paper then discusses the interpretative role of software, in both the representation of that signal for human interpretation and the production of the document through software tools. Finally, the paper considers the implications for persistence and access to digital documents posed by their material reality and the private archival contexts in which they often reside.},
	number = {11},
	urldate = {2023-04-24},
	journal = {Information, Communication \& Society},
	author = {Allen-Robertson, James},
	month = nov,
	year = {2018},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/1369118X.2017.1351575},
	keywords = {critical assessment, Digital document, materiality, software},
	pages = {1732--1746},
	file = {Full Text PDF:files/3827/Allen-Robertson - 2018 - Critically assessing digital documents materialit.pdf:application/pdf},
}

@incollection{lund_document_2018,
	edition = {4},
	title = {Document {Theory}},
	isbn = {978-1-315-11614-3},
	abstract = {This entry provides an overview about the historical development of theoretical reflections on documents and formulation of document theories. Starting out with its Latin predecessor documentum and the use of the conception in the European state bureaucracy from the seventeenth century, the first interest for document theory was a professional one and can be observed at the beginning of the twentieth century, closely connected with names like Paul Otlet and Suzanne Briet. While the notion of document and documentation was well established around 1930, it was replaced by the notion of information after World War II, at least in the Anglophone community. Nevertheless, at the same time, a new kind of document theory was emerging, a critical one connected to names like Michel Foucault, Harold Garfinkel, and Dorothy E. Smith. While the “professional” document theory developed by Otlet and others was focused on the knowledge more or less inherent in the documents and to make documents about something, then the general document theory developed by critical social scientists such as Foucault is much more about what the documents are and do. Since the 1990s, there has been a growing interest in general in the notion of document and documentation as well as inside Library and Information Science (LIS). Together with a growing interest in digital documents, document theorists around the world are emphasizing the complexity in document theory and a need of a complementary approach to document theory connecting physical, social, and cultural dimensions in how documents are and do.},
	booktitle = {Encyclopedia of {Library} and {Information} {Sciences}},
	publisher = {CRC Press},
	author = {Lund, Niels Windfeld and Skare, Roswitha},
	year = {2018},
	note = {Num Pages: 9},
}

@article{berryman_art_2018,
	title = {Art as document: on conceptual art and documentation},
	volume = {74},
	issn = {0022-0418},
	shorttitle = {Art as document},
	url = {https://doi.org/10.1108/JD-01-2018-0010},
	doi = {10.1108/JD-01-2018-0010},
	abstract = {Purpose The purpose of this paper is to bring the work of Seth Siegelaub (1941–2013) to the attention of document studies. Siegelaub was a pioneer of the conceptual art movement in New York in the 1960s, active as an Art Dealer, Curator and Publisher. He is remembered by art history for his exhibition catalogues, which provided a material base for intangible works of art. Design/methodology/approach This paper uses a comparative approach to examine the documents of conceptual art, especially the exhibition catalogues produced by Siegelaub between 1968 and 1972. Drawing on literature from document theory and art history and criticism, it examines several of Siegelaub’s key exhibition catalogues and books. Findings Siegelaub’s theories of information have much in common with the documentalist tradition. Siegelaub’s work is important, not just for its potential to contribute to the literature of document theory. It also provides a point of dialogue between art history and information studies. Originality/value To date, the common ground between art and documentation has been explored almost exclusively from the perspective of art history. This paper is among the first to examine conceptual art from the perspective of document theory. It demonstrates potential for cross-disciplinary collaboration.},
	number = {6},
	urldate = {2023-04-24},
	journal = {Journal of Documentation},
	author = {Berryman, Jim},
	month = jan,
	year = {2018},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Documentation, Art theory, Conceptual art, Document analysis, Exhibition catalogues, Primary information, Seth Siegelaub},
	pages = {1149--1161},
	file = {Full Text PDF:files/3830/Berryman - 2018 - Art as document on conceptual art and documentati.pdf:application/pdf},
}

@article{nord_ishi_2020,
	title = {Ishi, {Briet}'s {Antelope}, and the {Documentality} of {Human} {Documents}},
	volume = {7},
	issn = {2473-215X},
	url = {https://ideaexchange.uakron.edu/docam/vol7/iss1/8},
	doi = {10.35492/docam/7/1/8},
	number = {1},
	journal = {Proceedings from the Document Academy},
	author = {Nord, Martin},
	month = dec,
	year = {2020},
	file = {"Ishi, Briet's Antelope, and the Documentality of Human Documents" by Martin I. Nord:files/3832/8.html:text/html},
}

@book{mendes_francophone_2017,
	title = {The francophone development of the concept of document: the works of {Paul} {Otlet}, {Suzanne} {Briet}, {Jean} {Meyriat} and {Roger} {T}. {Pédauque}},
	shorttitle = {The francophone development of the concept of document},
	abstract = {The paper follows the premise that the analysis of francophone literature on document theory and Documentation Science can provide Knowledge Organization and Library and Information Science with relevant foundations to the design of knowledge organisation systems and structures, as well as to knowledge dissemination and mediation. Thus, the paper seeks to analyse the concept of document in the literature of francophone authors as a mean to understand its conceptual developments within modernity and its transition to postmodernity. The paper explores the works of Paul Otlet, Suzanne Briet, Jean Meyriat, and Roger T. Pédauque from the perspective of critical-hermeneutics and taking into consideration the historical and sociocultural contexts the concepts were developed within. After considering each author’s conception of the notion of document, the paper discusses in which manner the modern and the postmodern frameworks influenced the concept of document, and highlights how these frameworks influenced non-francophone nations to turn their attention to document theory and Documentation Science.},
	author = {Mendes, Luciana},
	month = jul,
	year = {2017},
	file = {Full Text PDF:files/3835/Mendes - 2017 - The francophone development of the concept of docu.pdf:application/pdf},
}

@article{kosciejew_material-documentary_2017,
	title = {A {Material}-{Documentary} {Literacy}: {Documents}, {Practices}, and the {Materialization} of {Information}},
	volume = {2017},
	issn = {0026-5667},
	shorttitle = {A {Material}-{Documentary} {Literacy}},
	url = {https://doi.org/10.1215/00265667-3787426},
	doi = {10.1215/00265667-3787426},
	abstract = {The document is one of the oldest material objects of all recorded civilizations, one upon which we are, in many ways, still dependent today. Documentation — that is, documents and their associated practices, institutions, and histories — plays an important role in helping to materialize information, transforming it from something seemingly intangible into something tangible. Indeed, one of the main effects of documentation is information's materialization. This article contributes to new materialism by introducing a documentary approach to analyzing and understanding information's materiality. The article calls for a more materialist reorientation in the library and information science (LIS) field, specifically, and for considerations of information generally, by drawing attention to the important role played by documentation in the materialization of information. This reorientation also serves as a response to Ann-Sophie Lehmann's call for greater material literacy to help us better learn and understand more about our material surroundings. Lehmann argues that we need to have more awareness of and appreciation for the basic materials of our daily life and world. She explains that to uncover the richness of the material world, including how it affects us and its implications for our lives, we need to know what it is made of; in other words, what actually makes up the objects and things that we need and use? Documentation science complements and supports Lehmann's call for material literacy by drawing attention to documents and our practices with them. It explores how documents relate to the material world and vice versa. One places a specific document, or documents, at the center of observation, study, and analysis and thereby develops documentary dialogues about and for it, uses the document to better illuminate its context, and integrates the document in teaching and researching information.},
	number = {88},
	urldate = {2023-04-24},
	journal = {the minnesota review},
	author = {Kosciejew, Marc},
	month = may,
	year = {2017},
	pages = {96--111},
	file = {Snapshot:files/3837/A-Material-Documentary-LiteracyDocuments-Practices.html:text/html},
}

@article{day_living_2021,
	title = {“{Living} {Document}”: {From} {Documents} to {Documentality}, from {Mimesis} to {Performative} {Indexicality}},
	volume = {8},
	issn = {2473-215X},
	shorttitle = {“{Living} {Document}”},
	url = {https://ideaexchange.uakron.edu/docam/vol8/iss2/15},
	doi = {10.35492/docam/8/2/15},
	number = {2},
	journal = {Proceedings from the Document Academy},
	author = {Day, Ronald},
	month = dec,
	year = {2021},
	file = {Full text:files/3839/Day - 2021 - “Living Document” From Documents to Documentality.pdf:application/pdf},
}

@article{f_latham_experiencing_2014,
	title = {Experiencing documents},
	volume = {70},
	issn = {0022-0418},
	url = {https://doi.org/10.1108/JD-01-2013-0013},
	doi = {10.1108/JD-01-2013-0013},
	abstract = {Purpose The purpose of this paper is to invite further consideration of how people experience documents. By offering a model from Reader Response theory – Louise Rosenblatt's Transactional Theory of Reading – as well as examples from research on numinous experiences with museum objects, the author hopes to open further avenues of information behavior studies about people and documents. The goal is to incorporate more aspects of lived experience and the aesthetic into practice with and research of documents. Design/methodology/approach Theoretical scope includes Louise Rosenblatt's Transactional Theory of Reading, John Dewey's concepts of transaction and experience and lived experience concepts/methods derived from phenomenology. Findings Rosenblatt's Transactional Theory explicates the continuum of reader response, from the efferent to the aesthetic, stating that the act of “reading” (experience) involves a transaction between the reader (person) and the text (document). Each transaction is a unique experience in which the reader and text continuously act and are acted upon by each other. This theory of reading translates well into the realm of investigating the lived experience of documents and in that context, a concrete example and suggested strategies for future study are provided. Originality/value This paper provides a holistic approach to understanding lived experience with documents and introduces the concept of person-document transaction. It inserts the wider notion of document into a more specific theory of reading, expanding its use beyond the borders of text, print and literature. By providing an example of real document experiences and applying Rosenblatt's continuum, the value of this paper is in opening new avenues for information behavior inquiries.},
	number = {4},
	urldate = {2023-04-24},
	journal = {Journal of Documentation},
	author = {F. Latham, Kiersten},
	month = jan,
	year = {2014},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Museums, Documents, Reader response, John Dewey, Numinous, Rosenblatt, Transactions},
	pages = {544--561},
	file = {Full Text PDF:files/3841/F. Latham - 2014 - Experiencing documents.pdf:application/pdf},
}

@article{cashion_cataloging_2016,
	title = {Cataloging {Medieval} {Manuscripts}, from {Beasts} to {Bytes}},
	volume = {5},
	issn = {2162-9552},
	url = {https://muse.jhu.edu/pub/1/article/646702},
	doi = {10.1353/dph.2016.0009},
	abstract = {, This article investigates the history of cataloging medieval manuscripts in order to determine a paradigm for digital catalogs of the present. Inspired by the work of Suzanne Briet (1894–1989), it argues in favor of a culturally informed “documentation” that considers not only the complexity of medieval manuscripts as information objects, but also anticipates the diverse interests of users who depend on digital images and supporting metadata to access manuscripts as primary sources for research. Presented here is a faceted metadata structure that considers the premodern manuscript as physical, textual, historical, as well as digital information. This approach is built upon various traditions for cataloging medieval manuscripts, from Cassiodorus in the sixth century to the electronic databases and digital catalogs of the present.},
	number = {2},
	urldate = {2023-04-24},
	journal = {Digital Philology: A Journal of Medieval Cultures},
	author = {Cashion, Debra Taylor},
	year = {2016},
	note = {Publisher: Johns Hopkins University Press},
	pages = {135--159},
	file = {Cataloging Medieval Manuscripts, from Beasts to Bytes:files/3843/Cashion - 2016 - Cataloging Medieval Manuscripts, from Beasts to By.pdf:application/pdf},
}

@article{basden_towards_2004,
	title = {Towards a philosophical understanding of documentation: a {Dooyeweerdian} framework},
	volume = {60},
	issn = {0022-0418},
	shorttitle = {Towards a philosophical understanding of documentation},
	url = {https://doi.org/10.1108/00220410410548135},
	doi = {10.1108/00220410410548135},
	abstract = {Documents as we encounter them in everyday life are complex and diverse things, whether on paper, computer disk or on the World Wide Web. They play many roles vis‐à‐vis human beings, and the humans engaged with them have diverse responsibilities that are not always easy to fulfil. Added to this is the issue of how a document or literary work can change and yet retain its identity, as found in maintenance, drafting and versioning of documents. This paper explores how the meaning‐oriented philosophy of Herman Dooyeweerd may be used to understand the complex nature of documents, to throw light on the roles, responsibilities and culture surrounding them, and to tackle issues of identity and change.},
	number = {4},
	urldate = {2023-04-24},
	journal = {Journal of Documentation},
	author = {Basden, A. and Burke, M.E.},
	month = jan,
	year = {2004},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Knowledge management, Change management, Document management, Philosophy},
	pages = {352--370},
	file = {Full Text PDF:files/3845/Basden e Burke - 2004 - Towards a philosophical understanding of documenta.pdf:application/pdf},
}

@misc{trace_phenomenology_2017,
	type = {text},
	title = {Phenomenology, experience, and the essence of documents as objects},
	copyright = {http://creativecommons.org/licenses/by-nd-nc/1.0/},
	url = {https://informationr.net/ir/22-1/colis/colis1630.html},
	abstract = {Introduction. The descriptive phenomenology of Edmund Husserl studies the structure of consciousness, experience, and meaning. This paper looks at how the phenomenological approach can be put to use by information science researchers interested in the study of documents and document work. It particular, the paper explores how phenomenology can expand both our understanding of the document as object and the document as experienced. Analysis. Phenomenology provides us with an ontology of real and ideal objects in which we can situate our understanding of the document as an object in the world to which our consciousness is attuned. This includes understanding the document as a real object situated in time and space, understanding the essence that is born by that document (that which makes it an instance of a particular object type), and understanding the document as it is experienced in consciousness (how we are conscious of documents as they are brought before our minds). Conclusion. Taking a phenomenological perspective, this paper moves the discussion in document studies from one focused on how people are affected by objects in the world to one that explores how people have a sense of such objects in the world.},
	language = {en},
	urldate = {2023-04-24},
	author = {Trace, Ciaran B.},
	month = mar,
	year = {2017},
	note = {Publisher: University of Borås},
	file = {Snapshot:files/3847/colis1630.html:text/html},
}

@article{umerle_rethinking_2017,
	title = {Rethinking the {Potential} of {Documentation} of {Culture} as a {Data} {Gathering} {Practice}},
	volume = {4},
	issn = {2473-215X},
	url = {https://ideaexchange.uakron.edu/docam/vol4/iss2/15},
	doi = {10.35492/docam/4/2/15},
	number = {2},
	journal = {Proceedings from the Document Academy},
	author = {Umerle, Tomasz},
	month = dec,
	year = {2017},
	file = {"Documentation of Culture" by Tomasz Umerle:files/3850/15.html:text/html;Full text:files/3849/Umerle - 2017 - Rethinking the Potential of Documentation of Cultu.pdf:application/pdf},
}

@article{day_documents_2022,
	title = {Documents and the {Malady} of {Truth}},
	volume = {9},
	issn = {2473-215X},
	url = {https://ideaexchange.uakron.edu/docam/vol9/iss2/11},
	doi = {10.35492/docam/9/2/11},
	number = {2},
	journal = {Proceedings from the Document Academy},
	author = {Day, Ronald},
	month = dec,
	year = {2022},
	file = {"Documents and the Malady of Truth" by Ronald E. Day:files/3853/11.html:text/html;Full text:files/3852/Day - 2022 - Documents and the Malady of Truth.pdf:application/pdf},
}

@article{vasilakis_common_nodate,
	title = {A common ontology for multi-dimensional shapes},
	abstract = {In recent years, digital shapes have become more and more widespread and have been made available in a plethora of online repositories. A systematic and formal approach for capturing and representing shape-related information is needed to facilitate its reuse and enable the demonstration of useful cross-domain usage scenarios. In this paper we present an ontology for digital shapes, called the Common Shape Ontology (CSO). We discuss the rationale, the requirements and the scope of this ontology, we present in detail its structure and describe the most relevant choices related to its development. Finally, we show how the CSO conceptualization is used in domain-specific application scenarios.},
	language = {en},
	author = {Vasilakis, George and Garcia-Rojas, Alejandra and Papaleo, Laura and Catalano, Chiara E and Robbiano, Francesco and Spagnuolo, Michela and Vavalis, Manolis and Pitikakis, Marios},
	file = {Vasilakis et al. - A common ontology for multi-dimensional shapes.pdf:files/3894/Vasilakis et al. - A common ontology for multi-dimensional shapes.pdf:application/pdf},
}

@article{calandra_effect_2019,
	title = {The effect of numerical aperture on quantitative use-wear studies and its implication on reproducibility},
	volume = {9},
	copyright = {2019 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-019-42713-w},
	doi = {10.1038/s41598-019-42713-w},
	abstract = {Many archeologists are skeptical about the capabilities of use-wear analysis to infer on the function of archeological tools, mainly because the method is seen as subjective, not standardized and not reproducible. Quantitative methods in particular have been developed and applied to address these issues. However, the importance of equipment, acquisition and analysis settings remains underestimated. One of those settings, the numerical aperture of the objective, has the potential to be one of the major factors leading to reproducibility issues. Here, experimental flint and quartzite tools were imaged using laser-scanning confocal microscopy with two objectives having the same magnification but different numerical apertures. The results demonstrate that 3D surface texture ISO 25178 parameters differ significantly when the same surface is measured with objectives having different numerical apertures. It is, however, unknown whether this property would blur or mask information related to use of the tools. Other acquisition and analyses settings are also discussed. We argue that to move use-wear analysis toward standardization, repeatability and reproducibility, the first step is to report all acquisition and analysis settings. This will allow the reproduction of use-wear studies, as well as tracing the differences between studies to given settings.},
	language = {en},
	number = {1},
	urldate = {2023-04-26},
	journal = {Scientific Reports},
	author = {Calandra, Ivan and Schunk, Lisa and Bob, Konstantin and Gneisinger, Walter and Pedergnana, Antonella and Paixao, Eduardo and Hildebrandt, Andreas and Marreiros, Joao},
	month = apr,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Archaeology},
	pages = {6313},
	file = {Full Text PDF:files/3900/Calandra et al. - 2019 - The effect of numerical aperture on quantitative u.pdf:application/pdf},
}

@misc{daneshmand_3d_2018,
	title = {{3D} {Scanning}: {A} {Comprehensive} {Survey}},
	shorttitle = {{3D} {Scanning}},
	url = {http://arxiv.org/abs/1801.08863},
	doi = {10.48550/arXiv.1801.08863},
	abstract = {This paper provides an overview of 3D scanning methodologies and technologies proposed in the existing scientific and industrial literature. Throughout the paper, various types of the related techniques are reviewed, which consist, mainly, of close-range, aerial, structure-from-motion and terrestrial photogrammetry, and mobile, terrestrial and airborne laser scanning, as well as time-of-flight, structured-light and phase-comparison methods, along with comparative and combinational studies, the latter being intended to help make a clearer distinction on the relevance and reliability of the possible choices. Moreover, outlier detection and surface fitting procedures are discussed concisely, which are necessary post-processing stages.},
	urldate = {2023-04-26},
	publisher = {arXiv},
	author = {Daneshmand, Morteza and Helmi, Ahmed and Avots, Egils and Noroozi, Fatemeh and Alisinanoglu, Fatih and Arslan, Hasan Sait and Gorbova, Jelena and Haamer, Rain Eric and Ozcinar, Cagri and Anbarjafari, Gholamreza},
	month = jan,
	year = {2018},
	note = {arXiv:1801.08863 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics},
	file = {arXiv Fulltext PDF:files/3903/Daneshmand et al. - 2018 - 3D Scanning A Comprehensive Survey.pdf:application/pdf;arXiv.org Snapshot:files/3904/1801.html:text/html},
}

@article{zaytseva_controlled_2020,
	title = {Controlled {Vocabularies} and {SKOS}},
	url = {https://campus.dariah.eu/en/resource/posts/controlled-vocabularies-and-skos},
	abstract = {Thesauri, taxonomies and other forms of controlled vocabularies represent a conceptual backbone of the research, playing an ever-increasing role in various aspects of the data management process. These resources are indispensable to determine common understanding allowing to systematically categorize and enrich research data in a consistent manner, as well as foster the data interoperability and integration among projects and web applications.},
	language = {en},
	urldate = {2023-04-28},
	journal = {DARIAH-Campus},
	author = {Zaytseva, Ksenia},
	month = mar,
	year = {2020},
	note = {Publisher: DARIAH-Campus},
	file = {Snapshot:files/3906/controlled-vocabularies-and-skos.html:text/html},
}

@article{cox_ten_2021,
	title = {Ten simple rules for making a vocabulary {FAIR}},
	volume = {17},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1009041},
	doi = {10.1371/journal.pcbi.1009041},
	abstract = {We present ten simple rules that support converting a legacy vocabulary—a list of terms available in a print-based glossary or in a table not accessible using web standards—into a FAIR vocabulary. Various pathways may be followed to publish the FAIR vocabulary, but we emphasise particularly the goal of providing a globally unique resolvable identifier for each term or concept. A standard representation of the concept should be returned when the individual web identifier is resolved, using SKOS or OWL serialised in an RDF-based representation for machine-interchange and in a web-page for human consumption. Guidelines for vocabulary and term metadata are provided, as well as development and maintenance considerations. The rules are arranged as a stepwise recipe for creating a FAIR vocabulary based on the legacy vocabulary. By following these rules you can achieve the outcome of converting a legacy vocabulary into a standalone FAIR vocabulary, which can be used for unambiguous data annotation. In turn, this increases data interoperability and enables data integration.},
	language = {en},
	number = {6},
	urldate = {2023-04-28},
	journal = {PLOS Computational Biology},
	author = {Cox, Simon J. D. and Gonzalez-Beltran, Alejandra N. and Magagna, Barbara and Marinescu, Maria-Cristina},
	editor = {Markel, Scott},
	month = jun,
	year = {2021},
	pages = {e1009041},
	file = {Cox et al. - 2021 - Ten simple rules for making a vocabulary FAIR.pdf:files/3907/Cox et al. - 2021 - Ten simple rules for making a vocabulary FAIR.pdf:application/pdf},
}

@article{herbort_introduction_2011,
	title = {An introduction to image-based {3D} surface reconstruction and a survey of photometric stereo methods},
	volume = {2},
	doi = {10.1007/3DRes.03(2011)4},
	abstract = {This paper provides an introduction to photometric methods for image-based 3D shape reconstruction and a survey of photometric
stereo techniques. We begin with taxonomy of active and passive shape acquisition techniques. Then we describe the methodical
background of photometric 3D reconstruction, define the canonical setting of photometric stereo (Lambertian surface reflectance,
parallel incident light, known illumination direction, known surface albedo, absence of cast shadows), discuss the 3D reconstruction
of surfaces from local gradients, summarize the concept of the bidirectional reflectance distribution function (BRDF), and
outline several important empirically and physically motivated reflectance models. We provide a detailed treatment of several
generalizations of the canonical setting of photometric stereo, namely non-distant light sources, unknown illumination directions,
and, in some detail, non-Lambertian surface reflectance functions. An important special case is purely specular reflections,
where an extended light source allows capturing a surface that consists of perfectly specular surface patches. Linear combinations
of purely Lambertian and purely specular reflectance components are favorably used for reconstructing smooth surfaces and
also human skin. Nonuniform surface reflectance properties are estimated based on a simultaneous 3D reconstruction and determination
of the locally variable parameters of the reflectance function based on a multitude of images. Assuming faceted surfaces,
the effective resolution of the 3D reconstruction result can be increased to some extent beyond that of the underlying images.
Other approaches separate specular and diffuse reflectance components based on polarization data or color information. The
specular reflections can be used additionally to estimate the direction from which the surface is illuminated. Finally, we
describe methods to combine photometric 3D reconstruction techniques with active and passive triangulation-based approaches.

Keywords3D surface reconstruction–shape analysis–survey–Photometric Stereo},
	journal = {3D Res},
	author = {Herbort, Steffen and Wöhler, Christian},
	month = sep,
	year = {2011},
	pages = {1--17},
	file = {Full Text PDF:files/3910/Herbort e Wöhler - 2011 - An introduction to image-based 3D surface reconstr.pdf:application/pdf},
}

@inproceedings{oomen_television_2013,
	title = {Television heritage linked and visualized: {The} {EUscreen} virtual exhibitions and the {Linked} {Open} {Data} pilot},
	volume = {2},
	shorttitle = {Television heritage linked and visualized},
	doi = {10.1109/DigitalHeritage.2013.6744788},
	abstract = {The EUscreenXL initiative represents the European television archives. It acts as a domain aggregator for Europeana, Europe's digital library, which provides access to over 20 million digitized cultural objects. The main motivation for the EUscreenXL initiative is to aggregate a comprehensive amount of professional audiovisual content and make it accessible through Europeana. EUscreenXL builds on the EUscreen project, which provided unified access to a representative collection of television articles, and in this way allowed students, scholars and the general public to study the history of television in its wider context. This paper gives an overview of related projects that work on bringing audiovisual heritage online. It furthermore explores the EUscreen activities related to [1] novel ways of presenting curated content in virtual exhibitions and [2] publishing EUscreen metadata as Linked Open Data. Regarding the latter, it is demonstrated how available metadata can be enriched and visualized using a timeline interface.},
	booktitle = {2013 {Digital} {Heritage} {International} {Congress} ({DigitalHeritage})},
	author = {Oomen, Johan and Verbruggen, Erwin and Tzouvaras, Vassilis and Hyyppä, Kati},
	month = oct,
	year = {2013},
	keywords = {Cultural differences, Interoperability, Europe, Visualization, Linked Open Data, Media, TV, Europeana, Data visualization, Films, Linked Media, Metadata Interoperability, TV on the Web},
	pages = {393--396},
	file = {IEEE Xplore Abstract Record:files/3918/6744788.html:text/html;IEEE Xplore Full Text PDF:files/3917/Oomen et al. - 2013 - Television heritage linked and visualized The EUs.pdf:application/pdf},
}

@article{nishanbaev_web_2021,
	title = {A {Web} {GIS}-{Based} {Integration} of {3D} {Digital} {Models} with {Linked} {Open} {Data} for {Cultural} {Heritage} {Exploration}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2220-9964},
	url = {https://www.mdpi.com/2220-9964/10/10/684},
	doi = {10.3390/ijgi10100684},
	abstract = {In recent years, considerable efforts have been made by cultural heritage institutions across the globe to digitise cultural heritage sites, artifacts, historical maps, etc. for digital preservation and online representation. On the other hand, ample research projects and studies have been published that demonstrate the great capabilities of web-geographic information systems (web-GIS) for the dissemination and online representation of cultural heritage data. However, cultural heritage data and the associated metadata produced by many cultural heritage institutions are heterogeneous. To make this heterogeneous data more interoperable and structured, an ever-growing number of cultural heritage institutions are adopting linked data principles. Although the cultural heritage domain has already started implementing linked open data concepts to the cultural heritage data, there are not many research articles that present an easy-to-implement, free, and open-source-based web-GIS architecture that integrates 3D digital cultural heritage models with cloud computing and linked open data. Furthermore, the integration of web-GIS technologies with 3D web-based visualisation and linked open data may offer new dimensions of interaction and exploration of digital cultural heritage. To demonstrate the high potential of integration of these technologies, this study presents a novel cloud architecture that attempts to enhance digital cultural heritage exploration by integrating 3D digital cultural heritage models with linked open data from DBpedia and GeoNames platforms using web-GIS technologies. More specifically, a digital interactive map, 3D digital cultural heritage models, and linked open data from DBpedia and GeoNames platforms were integrated into a cloud-based web-GIS architecture. Thus, the users of the architecture can easily interact with the digital map, visualise 3D digital cultural heritage models, and explore linked open data from GeoNames and DBpedia platforms, which offer additional information and context related to the selected cultural heritage site as well as external web resources. The architecture was validated by applying it to specific case studies of Australian cultural heritage and seeking expert feedback on the system, its benefits, and scope for improvement in the near future.},
	language = {en},
	number = {10},
	urldate = {2023-05-08},
	journal = {ISPRS International Journal of Geo-Information},
	author = {Nishanbaev, Ikrom and Champion, Erik and McMeekin, David A.},
	month = oct,
	year = {2021},
	note = {Number: 10
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {cultural heritage, digital humanities, 3D visualisation, the geospatial semantic web, the semantic web, web-GIS},
	pages = {684},
	file = {Full Text PDF:files/3920/Nishanbaev et al. - 2021 - A Web GIS-Based Integration of 3D Digital Models w.pdf:application/pdf},
}

@incollection{liuzzo_storytelling_2017,
	address = {Cham},
	title = {Storytelling and {Digital} {Epigraphy}-{Based} {Narratives} in {Linked} {Open} {Data}},
	isbn = {978-3-319-49607-8},
	url = {https://doi.org/10.1007/978-3-319-49607-8_20},
	abstract = {Carefully curated digital collections, structured with rich metadata sets and accessible via search engines and APIs, are not enough for users anymore. Multimedia narratives on the web and other digital “wayfindings” help a wider audience access the content of digital collections and also familiarize them with the research products that are published online. Digital humanists, then, face a twofold challenge: how to create scientific-oriented resources that serve the need of both scholars and general users and how to introduce nonspecialists to the digital collections produced by academics. The case of epigraphy is interesting, as there are already several examples of how niche content can be introduced to a wider public using multiple tools. This chapter illustrates the effort made by the Europeana network of Ancient Greek and Latin Epigraphy (EAGLE) in both integrating the largest collections of digitized inscriptions in Europe in a single database and providing users with tools for research, interaction, and fact finding. In particular, we will focus on the web-based storytelling tools that help users build engaging multimedia narrative based on inscriptions and ancient monuments and on a virtual exhibition that showcases some of the most spectacular items in the EAGLE collection.},
	language = {en},
	urldate = {2023-05-08},
	booktitle = {Mixed {Reality} and {Gamification} for {Cultural} {Heritage}},
	publisher = {Springer International Publishing},
	author = {Liuzzo, Pietro and Mambrini, Francesco and Franck, Philipp},
	editor = {Ioannides, Marinos and Magnenat-Thalmann, Nadia and Papagiannakis, George},
	year = {2017},
	doi = {10.1007/978-3-319-49607-8_20},
	keywords = {Linked open data, Digital epigraphy, Digital storytelling, Virtual exhibitions},
	pages = {507--523},
}

@article{monaco_linked_2022,
	title = {Linked open data in authoring virtual exhibitions},
	volume = {53},
	issn = {1296-2074},
	url = {https://www.sciencedirect.com/science/article/pii/S1296207421001667},
	doi = {10.1016/j.culher.2021.11.002},
	abstract = {In the last years, virtual exhibitions have been widely adopted to enhance traditional museums and enable active interaction with culture without posing any physical constraints. Nevertheless, people interested in cultural heritage still behave as visitors. To fully engage them, we propose to let cultural heritage lovers play the role of exhibition curators. In authoring virtual exhibitions, users have to perform a data selection phase that poses several challenges, including finding data sources and extracting data of interest. We aim to take advantage of data published as Knowledge Graphs in the Linked Open Data format. Users can query geographically distributed artworks thanks to their linking nature, manipulate heterogeneous data, and easily customise their exhibitions by exploiting the wide range of available cultural heritage knowledge graphs. However, the complexity of linked open data query languages (such as SPARQL) threatens their exploitation. Consequently, we need to mask SPARQL technical challenges and guide users in naturally posing questions to unlock the potentialities of linked open data to a broader audience. We propose a virtual exhibition authoring tool that guides users from knowledge graphs querying to the automatic generation of virtual experiences. The Knowledge Graph query phase relies on ELODIE, a natural language interface to scaffold users in retrieving data of interest without asking for technical skills in query languages. We introduce our prototype by describing its operating mechanism and by detailing its components. We present a Van Gogh’s experience as a use case by collecting all the artist’s artworks published on DBpedia (a well-known and general purpose knowledge graph) and organise them in a virtual reality-based virtual exhibition. Finally, we conclude by overviewing advantages and technical challenges posed by linked open data in designing and developing knowledge graph exploitation tools.},
	language = {en},
	urldate = {2023-05-08},
	journal = {Journal of Cultural Heritage},
	author = {Monaco, Daniele and Pellegrino, Maria Angela and Scarano, Vittorio and Vicidomini, Luca},
	month = jan,
	year = {2022},
	keywords = {Linked open data, Virtual exhibitions, Knowledge graph, Natural language interface, Query builder, Virtual reality},
	pages = {127--142},
	file = {ScienceDirect Full Text PDF:files/3923/Monaco et al. - 2022 - Linked open data in authoring virtual exhibitions.pdf:application/pdf;ScienceDirect Snapshot:files/3924/S1296207421001667.html:text/html},
}

@inproceedings{rinaldi_approach_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {An {Approach} {Based} on {Linked} {Open} {Data} and {Augmented} {Reality} for {Cultural} {Heritage} {Content}-{Based} {Information} {Retrieval}},
	isbn = {978-3-031-10450-3},
	doi = {10.1007/978-3-031-10450-3_8},
	abstract = {Nowadays, many technologies are changing our way of life, including those related to extended reality. One of the most interesting is Augmented Reality (AR). Today, even if this technology seems to be discovered yet, it is widely applied in several contexts, including the fruition and conservation of cultural heritage. Such spread is mainly offered by the new and more powerful mobile devices, allowing museums and art exhibitions to use AR to offer new experiences to visitors. In this paper, we present an augmented reality mobile system based on content-based image analysis techniques and Linked Open Data to improve the user knowledge about cultural heritage. We use different image analysis techniques, and we present several experimental results to show the performance of our system.},
	language = {en},
	booktitle = {Computational {Science} and {Its} {Applications} – {ICCSA} 2022},
	publisher = {Springer International Publishing},
	author = {Rinaldi, Antonio M. and Russo, Cristiano and Tommasino, Cristian},
	editor = {Gervasi, Osvaldo and Murgante, Beniamino and Hendrix, Eligius M. T. and Taniar, David and Apduhan, Bernady O.},
	year = {2022},
	pages = {99--112},
	file = {Full Text PDF:files/3926/Rinaldi et al. - 2022 - An Approach Based on Linked Open Data and Augmente.pdf:application/pdf},
}

@article{alexiev_museum_2018,
	title = {Museum {Linked} {Open} {Data}: {Ontologies}, {Datasets}, {Projects}},
	issn = {1314-4006, 2535-0366},
	shorttitle = {Museum {Linked} {Open} {Data}},
	url = {https://www.ceeol.com/search/article-detail?id=701509},
	abstract = {The Galleries, Libraries, Archives and Museums (GLAM) sector deals with complex and varied data. Integrating that data, especially across institutions, has always been a challenge. Semantic data integration is the best approach to deal with such challenges. Linked Open Data (LOD) enable large-scale Digital Hu-manities (DH) research, collaboration and aggregation, allowing DH researchers to make connections between (and make sense of) the multitude of digitized Cul-tural Heritage (CH) available on the web. An upsurge of interest in semtech and LOD has swept the CH and DH communities. An active Linked Open Data for Libraries, Archives and Museums (LODLAM) community exists, CH data is published as LOD, and international collaborations have emerged. The value of LOD is especially high in the GLAM sector, since culture by its very nature is cross-border and interlinked. We present interesting LODLAM projects, datasets, and ontologies, as well as Ontotext\&\#39;s experience in this domain. An extended version of this paper is available. It has 77 pages, 67 figures, de-tailed info about CH content and XML standards, Wikidata and global authority control.},
	language = {English},
	number = {VIII},
	urldate = {2023-05-08},
	journal = {Digital Presentation and Preservation of Cultural and Scientific Heritage},
	author = {Alexiev, Vladimir},
	year = {2018},
	note = {Publisher: Институт по математика и информатика - Българска академия на науките},
	keywords = {CIDOC CRM, semantic technologies, LODLAM, museum data},
	pages = {19--50},
}

@article{sartini_multivocal_nodate,
	title = {Multivocal {Exhibition}: a user-centric application to explore symbolic interpretations of artefacts from different cultural perspectives⋆},
	language = {en},
	author = {Sartini, Bruno and Nesterov, Andrei and Libbi, Claudia and Brate, Ryan and Alam, Sarah Binta and Daniil, Savvina},
	file = {Sartini et al. - Multivocal Exhibition a user-centric application .pdf:files/3928/Sartini et al. - Multivocal Exhibition a user-centric application .pdf:application/pdf},
}

@incollection{simou_enriching_2017,
	address = {Cham},
	title = {Enriching and {Publishing} {Cultural} {Heritage} as {Linked} {Open} {Data}},
	isbn = {978-3-319-49607-8},
	url = {https://doi.org/10.1007/978-3-319-49607-8_7},
	abstract = {In the last decade, a lot of effort has been put by the cultural community around the world into digitization and aggregation activities. The main outcome of these was the development of portals like Europeana, DPLA, DigitalNZ, and National Library of Australia, which are collecting and providing access to the public digitized cultural assets from Europe, America, New Zealand, and Australia, respectively. Their main objective, however, is not only to bring the public closer to culture but also to efficiently represent information about cultural objects that will make them useful to various target groups like teachers, students, and developers by also permitting their creative reuse. The best practice for fulfilling this requirement is the publication of such information according to the Linked Open Data (LOD) principles. In this chapter, we present the tools developed and the methodology adopted through the participation of our group in aggregation activities for enriching and publishing cultural heritage as Linked Open Data.},
	language = {en},
	urldate = {2023-05-08},
	booktitle = {Mixed {Reality} and {Gamification} for {Cultural} {Heritage}},
	publisher = {Springer International Publishing},
	author = {Simou, Nikolaos and Chortaras, Alexandros and Stamou, Giorgos and Kollias, Stefanos},
	editor = {Ioannides, Marinos and Magnenat-Thalmann, Nadia and Papagiannakis, George},
	year = {2017},
	doi = {10.1007/978-3-319-49607-8_7},
	keywords = {Linked Open Data, Europeana, Aggregation, Enrichment, Metadata interoperability, Semantic alignment},
	pages = {201--223},
}

@article{pasqual_linked_2022-2,
	title = {Linked open data per la valorizzazione di collezioni culturali: il dataset {mythLOD}},
	volume = {62},
	copyright = {Copyright (c) 2022 Valentina Pasqual, Francesca Tomasi},
	issn = {2239-6152},
	shorttitle = {Linked open data per la valorizzazione di collezioni culturali},
	url = {https://aibstudi.aib.it/article/view/13301},
	doi = {10.2426/aibstudi-13301},
	abstract = {The formal representation of cultural metadata has always been a challenge, considering the heterogeneity of cultural objects and especially when dealing with experts’ interpretation over them.This paper presents an overview of the mythLOD dataset production as the Mythologiae digital collection revalorisation into linked open data format. The research aims then to explore Mythologiae data leveraging semantic web potentialities, focusing over the formal representation of experts’ analysis when associating visual artworks (and their interpretations) to literary sources.The workflow of the project consisted of data model definition, data cleaning and entity linking, conversion (from tabular data to graph) and testing activity (domain experts review over competency questions and two designed on-purpose data visualizations). The result is the mythLOD platform, which present the dataset and the detailed documentation of the research. Additionally, the platform hosts the two data visualization spaces which have been implemented – the online catalogue and the storytelling experiment over Aeneid – as a user friendly testing unit for the dataset and an additional tool for documenting the project and exploring the collection.},
	language = {it},
	number = {1},
	urldate = {2023-05-08},
	journal = {AIB studi},
	author = {Pasqual, Valentina and Tomasi, Francesca},
	month = may,
	year = {2022},
	note = {Number: 1},
	keywords = {semantic web, Linked Open Data, citazioni canoniche, collezione semantica, ermeneutica digitale, Mythologiae, workflow},
	pages = {149--168},
	file = {Full Text PDF:files/3932/Pasqual e Tomasi - 2022 - Linked open data per la valorizzazione di collezio.pdf:application/pdf},
}

@article{zaporozhtseva_mythologemes_2016,
	title = {Mythologemes and mythemes: {Semiotic} markers of myth in contemporary mass culture},
	issn = {1406-4278},
	shorttitle = {Mythologemes and mythemes},
	url = {https://www.ceeol.com/search/article-detail?id=705935},
	abstract = {This paper focuses on the scrutiny of structural units of myth within mass cultural discourse. The author reviews studies of the mytho logeme and mytheme in semiotics and also relevant research in other fields concerning the announced research object. The main aim of the paper is to distinguish inner semiotic markers of myth and to examine their application to mass cultural narratives. Drawing on the analysis of previous theoretical research and case studies, the author compares the two structural units and makes an attempt to formulate specifi cations towards existing definitions. Particular examples of mythemes and mythologemes in mass culture discourse are regarded within this paper. The author points out the mytheme of Transformation, the mytheme of Backtracking, the mythologeme of Childhood (Golden Age), the mythologeme of Arma geddon (Flood), and the mythologeme of World Tree.},
	language = {English},
	number = {16},
	urldate = {2023-05-08},
	journal = {Tartu Semiotics Library},
	author = {Zaporozhtseva, Lyudmyla},
	year = {2016},
	note = {Publisher: Tartu \&\#220;likooli Kirjastus},
	keywords = {cultural narratives, cultural universals, mass culture, mytheme, mythologeme},
	pages = {27--48},
}

@article{zaporozhtseva_mythologemes_2016-1,
	title = {Mythologemes and mythemes: {Semiotic} markers of myth in contemporary mass culture},
	issn = {1406-4278},
	shorttitle = {Mythologemes and mythemes},
	url = {https://www.ceeol.com/search/article-detail?id=705935},
	abstract = {This paper focuses on the scrutiny of structural units of myth within mass cultural discourse. The author reviews studies of the mytho logeme and mytheme in semiotics and also relevant research in other fields concerning the announced research object. The main aim of the paper is to distinguish inner semiotic markers of myth and to examine their application to mass cultural narratives. Drawing on the analysis of previous theoretical research and case studies, the author compares the two structural units and makes an attempt to formulate specifi cations towards existing definitions. Particular examples of mythemes and mythologemes in mass culture discourse are regarded within this paper. The author points out the mytheme of Transformation, the mytheme of Backtracking, the mythologeme of Childhood (Golden Age), the mythologeme of Arma geddon (Flood), and the mythologeme of World Tree.},
	language = {English},
	number = {16},
	urldate = {2023-05-08},
	journal = {Tartu Semiotics Library},
	author = {Zaporozhtseva, Lyudmyla},
	year = {2016},
	note = {Publisher: Tartu \&\#220;likooli Kirjastus},
	keywords = {cultural narratives, cultural universals, mass culture, mytheme, mythologeme},
	pages = {27--48},
}

@article{peinado_description_nodate,
	title = {A {Description} {Logic} {Ontology} for {Fairy} {Tale} {Generation}},
	abstract = {The combination of resources like Ontologies and an inference formalism such as Description Logics has proved very useful for generating semantically correct texts. However the possibilities of applying such combinations to obtain results in practical situations is restricted by the availability of ontological resources for the domains under consideration. This paper presents work on the development of an OWL ontology based on Propp’s Morphology of the Folk Tale oriented towards automatic story generation. The ontology is designed so that it allows measurement of the semantical distance between narrative functions. We explain how to use this resource to generate creative and meaningful stories.},
	language = {en},
	author = {Peinado, Federico and Gervas, Pablo and Dıaz-Agudo, Belen},
	file = {Peinado et al. - A Description Logic Ontology for Fairy Tale Genera.pdf:files/3935/Peinado et al. - A Description Logic Ontology for Fairy Tale Genera.pdf:application/pdf},
}

@article{marcelloni_valentina_nodate,
	title = {Valentina {Bartalesi} {Lenzi}},
	language = {en},
	author = {Marcelloni, Francesco and Meghini, Dott Carlo and Niccolucci, Franco and Doerr, Dott Martin and Luise, Marco},
	file = {Marcelloni et al. - Valentina Bartalesi Lenzi.pdf:files/3937/Marcelloni et al. - Valentina Bartalesi Lenzi.pdf:application/pdf},
}

@article{doerr_cidoc_2003,
	title = {The {CIDOC} {Conceptual} {Reference} {Module}: {An} {Ontological} {Approach} to {Semantic} {Interoperability} of {Metadata}},
	volume = {24},
	copyright = {Copyright (c)},
	issn = {2371-9621},
	shorttitle = {The {CIDOC} {Conceptual} {Reference} {Module}},
	url = {https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/1720},
	doi = {10.1609/aimag.v24i3.1720},
	abstract = {This article presents the methodology that has been successfully used over the past seven years by an interdisciplinary team to create the International Committee for Documentation of the International Council of Museums (CIDOC) CONCEPTUAL REFERENCE MODEL (CRM), a high-level ontology to enable information integration for cultural heritage data and their correlation with library and archive information. The CIDOC CRM is now in the process to become an International Organization for Standardization (ISO) standard. This article justifies in detail the methodology and design by functional requirements and gives examples of its contents. The CIDOC CRM analyzes the common conceptualizations behind data and metadata structures to support data transformation, mediation, and merging. It is argued that such ontologies are propertycentric, in contrast to terminological systems, and should be built with different methodologies. It is demonstrated that ontological and epistemological arguments are equally important for an effective design, in particular when dealing with knowledge from the past in any domain. It is assumed that the presented methodology and the upper level of the ontology are applicable in a far wider domain.},
	language = {en},
	number = {3},
	urldate = {2023-05-12},
	journal = {AI Magazine},
	author = {Doerr, Martin},
	month = sep,
	year = {2003},
	note = {Number: 3},
	pages = {75--75},
	file = {Full Text PDF:files/3940/Doerr - 2003 - The CIDOC Conceptual Reference Module An Ontologi.pdf:application/pdf},
}

@article{doerr_crmdig_nodate,
	title = {{CRMdig}: {A} generic digital provenance model for scientiﬁc observation},
	abstract = {The systematic large-scale production of digital scientiﬁc objects, the diversity of the processes involved and the complexity of describing historical relationships among them, imposes the need for an innovative knowledge management system capable to handle all the semantic information in order to monitor, manage and document the origins and derivation of products in a ﬂexible manner. We have implemented CRMdig, an extension of the CIDOC-CRM ontology, which is able to capture the modeling and the query requirements regarding the provenance of digital objects for e-science. CRMdig is particularly rich in describing the physical circumstances of scientiﬁc observation resulting in digital data.},
	language = {en},
	author = {Doerr, Martin and Theodoridou, Maria},
	file = {Doerr e Theodoridou - CRMdig A generic digital provenance model for sci.pdf:files/3941/Doerr e Theodoridou - CRMdig A generic digital provenance model for sci.pdf:application/pdf},
}

@article{gabellone_digital_2022,
	title = {Digital {Twin}: a new perspective for cultural heritage management and fruition},
	volume = {11},
	copyright = {Copyright (c) 2022 ACTA IMEKO},
	issn = {2221-870X},
	shorttitle = {Digital {Twin}},
	url = {https://acta.imeko.org/index.php/acta-imeko/article/view/IMEKO-ACTA-11%20%282022%29-01-05},
	doi = {10.21014/acta_imeko.v11i1.1085},
	abstract = {This paper describes the example of an interesting distance visit approach carried out during the COVID-19 emergency, applied to an underground oil-mill in the town of Gallipoli (Puglia, Italy). The limitations of access for people with disabilities and the complete closure of Italian museums during the emergency have suggested the development of an immersive platform, in the broader perspective of using the output in accordance to digital twin perspectives. Then a tool to support an innovative visit method has been realized: a virtual visit assisted by a real remote guide, hereinafter referred to as “Live-Guided Tour” with e-learning functionality. All this has been made possible starting from a three-dimensional model of an underground oil-mill, from which we extracted the stereoscopic scenes. The stereoscopy is very important for the overall success of the project, because this aspect influences the level of interest, the immersion and the ability to generate emotion and wonder. To the best of Author’s knowledge, this is the only system available today for a shared virtual visit for an inaccessible context, which implements many features of a VR visit in a multi-user and multi-platform environment.},
	language = {en},
	number = {1},
	urldate = {2023-05-12},
	journal = {Acta IMEKO},
	author = {Gabellone, Francesco},
	month = mar,
	year = {2022},
	note = {Number: 1},
	pages = {7 pp.--7 pp.},
	file = {Full Text PDF:files/3944/Gabellone - 2022 - Digital Twin a new perspective for cultural herit.pdf:application/pdf},
}

@article{niccolucci_heritage_2023-1,
	title = {The {Heritage} {Digital} {Twin}: a bicycle made for two. {The} integration of digital methodologies into cultural heritage research},
	volume = {3},
	issn = {2732-5121},
	shorttitle = {The {Heritage} {Digital} {Twin}},
	url = {https://open-research-europe.ec.europa.eu/articles/3-64/v1},
	doi = {10.12688/openreseurope.15496.1},
	abstract = {The paper concerns the definition of a novel ontology for cultural heritage based on the concept of digital twin. The ontology, called Heritage Digital Twin ontology, is a compatible extension of the well-known CIDOC CRM ISO standard for cultural heritage documentation and incorporates all the different documentation systems presently in use for cultural heritage documentation. In the authors’ view, it supports documentation interoperability at a higher level than the ones currently in use and enables effective cooperation among different users.},
	language = {en},
	urldate = {2023-05-12},
	journal = {Open Research Europe},
	author = {Niccolucci, Franco and Markhoff, Béatrice and Theodoridou, Maria and Felicetti, Achille and Hermon, Sorin},
	month = apr,
	year = {2023},
	pages = {64},
	file = {Full Text PDF:files/3946/Niccolucci et al. - 2023 - The Heritage Digital Twin a bicycle made for two..pdf:application/pdf},
}

@article{vanderhorn_digital_2021,
	title = {Digital {Twin}: {Generalization}, characterization and implementation},
	volume = {145},
	issn = {0167-9236},
	shorttitle = {Digital {Twin}},
	url = {https://www.sciencedirect.com/science/article/pii/S0167923621000348},
	doi = {10.1016/j.dss.2021.113524},
	abstract = {Digital Twin is one of the promising digital technologies being developed at present to support digital transformation and decision making in multiple industries. While the concept of a Digital Twin is nearly 20 years old, it continues to evolve as it expands to new industries and use cases. This has resulted in a continually increasing variety of definitions that threatens to dilute the concept and lead to ineffective implementations of the technology. There is a need for a consolidated and generalized definition, with clearly established characteristics to distinguish what constitutes a Digital Twin and what does not. This paper reviews 46 Digital Twin definitions given in the literature over the past ten years to propose a generalized definition that encompasses the breadth of options available and provides a detailed characterization which includes criteria to distinguish the Digital Twin from other digital technologies. Next, a process and considerations for the implementation of Digital Twins is presented through a case study. Digital Twin future needs and opportunities are also outlined.},
	language = {en},
	urldate = {2023-05-13},
	journal = {Decision Support Systems},
	author = {VanDerHorn, Eric and Mahadevan, Sankaran},
	month = jun,
	year = {2021},
	keywords = {Decision making, Digital Twin, Information fusion, Model updating, Virtual representation},
	pages = {113524},
	file = {ScienceDirect Snapshot:files/4010/S0167923621000348.html:text/html},
}

@article{niccolucci_populating_2022,
	title = {Populating the {Data} {Space} for {Cultural} {Heritage} with {Heritage} {Digital} {Twins}},
	volume = {7},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2306-5729},
	url = {https://www.mdpi.com/2306-5729/7/8/105},
	doi = {10.3390/data7080105},
	abstract = {The present paper concerns the design of the semantic infrastructure of the data space for cultural heritage as envisaged by the European Commission in its recent documents. Due to the complexity of the cultural heritage data and of their intrinsic inter-relationships, it is necessary to introduce a novel ontology, yet compliant with existing standards and interoperable with previous platforms used in this context as Europeana. The data space organization must be tailored to the methods and the theory of cultural heritage, briefly summarized in the introduction. The new ontology is based on the Digital Twin concept, i.e., the digital counterpart of cultural heritage assets incorporating all the digital information pertaining to them. This creates a Knowledge Base on the cultural heritage data space. The paper outlines the main features of the proposed Heritage Digital Twin ontology and provides some examples of its application. Future work will include completing the ontology in all its details and testing it in other real cases and with the various sectors of the cultural heritage community.},
	language = {en},
	number = {8},
	urldate = {2023-05-13},
	journal = {Data},
	author = {Niccolucci, Franco and Felicetti, Achille and Hermon, Sorin},
	month = aug,
	year = {2022},
	note = {Number: 8
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {digital twin, cultural heritage data space, cultural heritage semantics},
	pages = {105},
	file = {Full Text PDF:files/4012/Niccolucci et al. - 2022 - Populating the Data Space for Cultural Heritage wi.pdf:application/pdf},
}

@article{cosovic_application_nodate,
	title = {Application of the digital twin concept in cultural heritage},
	abstract = {Cultural heritage has benefited for years from the availability of technology in the domain of digitalization; hence digital heritage emerged. Researchers in the cultural heritage domain have used tools and digital techniques as way to preserve historical and religious buildings so that they are everlasting in time. These are mostly viewed as autonomous attempts, rarely organized. One of the digital tools that arose from the field of product life cycle management is the digital twin, which is defined as digital representation of physical product. There is an ongoing debate whether cultural heritage can be fully viewed in terms of digital twin and if the application of the digital twin concept can be sustainable in the management of the cultural heritage environment. This paper aims to address the role of the digital twin within the cultural heritage domain and if it can be used to recreate certain phenomena or environmental situation resulting in reducing deterioration over time. This is important since heritage sites and historical buildings must be preserved for future generations.},
	language = {en},
	author = {Ćosović, Marijana and Maksimović, Mirjana},
	file = {Ćosović e Maksimović - Application of the digital twin concept in cultura.pdf:files/4013/Ćosović e Maksimović - Application of the digital twin concept in cultura.pdf:application/pdf},
}

@incollection{dore_historic_2015,
	title = {Historic {Building} {Information} {Modelling} ({HBIM})},
	copyright = {Access limited to members},
	isbn = {978-1-4666-8379-2},
	url = {https://www.igi-global.com/chapter/historic-building-information-modelling-hbim/www.igi-global.com/chapter/historic-building-information-modelling-hbim/133415},
	abstract = {Historic Building Information Modelling (HBIM) is a new approach for modelling historic buildings which develops full Building Information Models (BIMs) from remotely sensed data. HBIM consists of a novel library of reusable parametric objects, based on historic architectural data and a system for m...},
	language = {en},
	urldate = {2023-05-13},
	booktitle = {Handbook of {Research} on {Emerging} {Digital} {Tools} for {Architectural} {Surveying}, {Modeling}, and {Representation}},
	publisher = {IGI Global},
	author = {Dore, Conor and Murphy, Maurice},
	year = {2015},
	doi = {10.4018/978-1-4666-8379-2.ch007},
	pages = {233--273},
}

@article{jouan_digital_2019-1,
	title = {{DIGITAL} {TWIN}: {A} {HBIM}-{BASED} {METHODOLOGY} {TO} {SUPPORT} {PREVENTIVE} {CONSERVATION} {OF} {HISTORIC} {ASSETS} {THROUGH} {HERITAGE} {SIGNIFICANCE} {AWARENESS}},
	volume = {XLII-2},
	copyright = {© Author(s) 2019. This work is distributed under the Creative Commons Attribution 4.0 License.},
	issn = {1682-1750},
	shorttitle = {{DIGITAL} {TWIN}},
	url = {https://orbi.uliege.be/handle/2268/239023},
	doi = {10.5194/isprs-archives-XLII-2-W15-609-2019},
	abstract = {Historic Building Information Modeling (HBIM), Digital Twin (DT), Heritage documentation, preventive conservation. 
 
Abstract. During preliminary phases of conservation projects, a considerable amount of heterogeneous datasets are produced, gathered, analysed and interpreted. Abundant researches have gradually proven that Historic Building Information Modelling (HBIM) is a relevant alternative for the collaborative management of information related to existing structures. Apart from the obvious benefits of HBIM for information exchange among stakeholders during conservation project, the potential of such processes to support preservation strategies should not be neglected. Moreover, the recent developments of HBIM web-interfaces illustrate the need for additional investigation in strengthening the relationships between the digital model and the real-world to better support preventive conservation of heritage places. Besides, values-based approaches for the elaboration of conservation strategies have been gradually adopted in the last decades, both in academic and professional sector. In this paper, we propose a comprehensive methodology to structure and integrate the cultural significance of tangible and intangible elements into HBIM models to be further taken into account in the analysis and simulation of data. This article suggests the application of Digital Twin (DT) principles to support site managers in the preventive conservation of their assets. Based on the analysis and simulations of data captured by onsite sensors, threats to the site integrity and corresponding preventive solution can be predicted in the DT environment. The integration and structuration of Heritage Values in HBIM models allow further evaluation process to estimate the impact of each suggested interventions on the conservation of features of significance.},
	language = {English},
	number = {2019},
	urldate = {2023-05-13},
	journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Jouan, Pierre-André and Hallot, Pierre},
	month = aug,
	year = {2019},
	note = {Publisher: Copernicus, Goettingen, Germany},
	file = {Full Text PDF:files/4017/Jouan e Hallot - 2019 - DIGITAL TWIN A HBIM-BASED METHODOLOGY TO SUPPORT .pdf:application/pdf},
}

@article{jouan_digital_2020,
	title = {Digital {Twin}: {Research} {Framework} to {Support} {Preventive} {Conservation} {Policies}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2220-9964},
	shorttitle = {Digital {Twin}},
	url = {https://www.mdpi.com/2220-9964/9/4/228},
	doi = {10.3390/ijgi9040228},
	abstract = {Preventive strategies for the conservation of heritage sites have gradually been preferred to curative approaches because of their ability to maintain their significance. Furthermore, most experts now agree that conservation management of heritage places based on a common understanding of their cultural values is essential to address all the particularities of their contexts. Recently, significant research has demonstrated the potential of Heritage Building Information Modelling (HBIM) for the collaborative data management in conjunction with conservation projects. The recent development of HBIM web platforms illustrates the value of strengthening the link between the digital model and the physical realm of heritage assets. This paper advocates the application of Digital Twin’s (DT) principles, using HBIM models as a digital replica, to support the preventive conservation of heritage places. Based on an extensive literature review, a comprehensive framework that integrates the DT into the management plan process for the preventive conservation of built heritage is proposed. Several recommendations for its implementation are finally discussed, such as the identification of tangible features of significance, the threats associated with their integrity and the corresponding mitigation strategies, with particular emphasis on the value assessment process. The result is a data model for structuring information on preventive conservation strategies. This framework provides the basis for future implementation and demonstrates the need for a DT approach in this context.},
	language = {en},
	number = {4},
	urldate = {2023-05-13},
	journal = {ISPRS International Journal of Geo-Information},
	author = {Jouan, Pierre and Hallot, Pierre},
	month = apr,
	year = {2020},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {HBIM, preventive conservation, Digital Twin, heritage documentation, risk management},
	pages = {228},
	file = {Full Text PDF:files/4019/Jouan e Hallot - 2020 - Digital Twin Research Framework to Support Preven.pdf:application/pdf},
}

@article{gros_faceting_2023,
	title = {Faceting the post-disaster built heritage reconstruction process within the digital twin framework for {Notre}-{Dame} de {Paris}},
	volume = {13},
	copyright = {2023 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-023-32504-9},
	doi = {10.1038/s41598-023-32504-9},
	abstract = {April 15th, 2019: Notre-Dame Cathedral in Paris was burning, the spire collapsed on the nave, vaults crumbled and most of the timber roof was gone. In the post-disaster context, the authenticity and the monitoring of the archaeological remains are crucial for their potential reuse during reconstruction. This paper analyzes the collapsed transverse arch from the nave of Notre-Dame as a case study of reconstruction, using the digital twin framework. We propose four facets for the digital twin experiment—physical anastylosis, reverse engineering, spatio-temporal tracking of assets, and operational research—that are described in detail, while being assembled to support a hybrid reconstruction hypothesis. The digital twin can realize the parallel unfolding of physical-native and digital-native processes, while acquiring and storing heterogeneous information as semantically structured data. The results demonstrate that the proposed modeling method facilitates the formalization and validation of the reconstruction problem and increases solutions performances. As result, we present a digital twin framework application ranging from acquisition to data processing that informs a successful hybrid reconstruction hypothesis.},
	language = {en},
	number = {1},
	urldate = {2023-05-13},
	journal = {Scientific Reports},
	author = {Gros, Antoine and Guillem, Anaïs and De Luca, Livio and Baillieul, Élise and Duvocelle, Benoit and Malavergne, Olivier and Leroux, Lise and Zimmer, Thierry},
	month = apr,
	year = {2023},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Applied mathematics, Engineering, Information technology},
	pages = {5981},
	file = {Full Text PDF:files/4021/Gros et al. - 2023 - Faceting the post-disaster built heritage reconstr.pdf:application/pdf},
}

@article{kritzinger_digital_2018,
	series = {16th {IFAC} {Symposium} on {Information} {Control} {Problems} in {Manufacturing} {INCOM} 2018},
	title = {Digital {Twin} in manufacturing: {A} categorical literature review and classification},
	volume = {51},
	issn = {2405-8963},
	shorttitle = {Digital {Twin} in manufacturing},
	url = {https://www.sciencedirect.com/science/article/pii/S2405896318316021},
	doi = {10.1016/j.ifacol.2018.08.474},
	abstract = {The Digital Twin (DT) is commonly known as a key enabler for the digital transformation, however, in literature is no common understanding concerning this term. It is used slightly different over the disparate disciplines. The aim of this paper is to provide a categorical literature review of the DT in manufacturing and to classify existing publication according to their level of integration of the DT. Therefore, it is distinct between Digital Model (DM), Digital Shadow (DS) and Digital Twin. The results are showing, that literature concerning the highest development stage, the DT, is scarce, whilst there is more literature about DM and DS.},
	language = {en},
	number = {11},
	urldate = {2023-05-13},
	journal = {IFAC-PapersOnLine},
	author = {Kritzinger, Werner and Karner, Matthias and Traar, Georg and Henjes, Jan and Sihn, Wilfried},
	month = jan,
	year = {2018},
	keywords = {Digital Twin, Digital Model, Digital Shadow, Literature Review, Manufacturing, Production},
	pages = {1016--1022},
	file = {ScienceDirect Full Text PDF:files/4023/Kritzinger et al. - 2018 - Digital Twin in manufacturing A categorical liter.pdf:application/pdf;ScienceDirect Snapshot:files/4024/S2405896318316021.html:text/html},
}

@article{jouan_digital_2020-1,
	title = {Digital {Twin}: {Research} {Framework} to {Support} {Preventive} {Conservation} {Policies}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2220-9964},
	shorttitle = {Digital {Twin}},
	url = {https://www.mdpi.com/2220-9964/9/4/228},
	doi = {10.3390/ijgi9040228},
	abstract = {Preventive strategies for the conservation of heritage sites have gradually been preferred to curative approaches because of their ability to maintain their significance. Furthermore, most experts now agree that conservation management of heritage places based on a common understanding of their cultural values is essential to address all the particularities of their contexts. Recently, significant research has demonstrated the potential of Heritage Building Information Modelling (HBIM) for the collaborative data management in conjunction with conservation projects. The recent development of HBIM web platforms illustrates the value of strengthening the link between the digital model and the physical realm of heritage assets. This paper advocates the application of Digital Twin’s (DT) principles, using HBIM models as a digital replica, to support the preventive conservation of heritage places. Based on an extensive literature review, a comprehensive framework that integrates the DT into the management plan process for the preventive conservation of built heritage is proposed. Several recommendations for its implementation are finally discussed, such as the identification of tangible features of significance, the threats associated with their integrity and the corresponding mitigation strategies, with particular emphasis on the value assessment process. The result is a data model for structuring information on preventive conservation strategies. This framework provides the basis for future implementation and demonstrates the need for a DT approach in this context.},
	language = {en},
	number = {4},
	urldate = {2023-05-13},
	journal = {ISPRS International Journal of Geo-Information},
	author = {Jouan, Pierre and Hallot, Pierre},
	month = apr,
	year = {2020},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {HBIM, preventive conservation, Digital Twin, heritage documentation, risk management},
	pages = {228},
	file = {Full Text PDF:files/4026/Jouan e Hallot - 2020 - Digital Twin Research Framework to Support Preven.pdf:application/pdf},
}

@article{tao_digital_2018,
	title = {Digital twin-driven product design, manufacturing and service with big data},
	volume = {94},
	issn = {1433-3015},
	url = {https://doi.org/10.1007/s00170-017-0233-1},
	doi = {10.1007/s00170-017-0233-1},
	abstract = {Nowadays, along with the application of new-generation information technologies in industry and manufacturing, the big data-driven manufacturing era is coming. However, although various big data in the entire product lifecycle, including product design, manufacturing, and service, can be obtained, it can be found that the current research on product lifecycle data mainly focuses on physical products rather than virtual models. Besides, due to the lack of convergence between product physical and virtual space, the data in product lifecycle is isolated, fragmented, and stagnant, which is useless for manufacturing enterprises. These problems lead to low level of efficiency, intelligence, sustainability in product design, manufacturing, and service phases. However, physical product data, virtual product data, and connected data that tie physical and virtual product are needed to support product design, manufacturing, and service. Therefore, how to generate and use converged cyber-physical data to better serve product lifecycle, so as to drive product design, manufacturing, and service to be more efficient, smart, and sustainable, is emphasized and investigated based on our previous study on big data in product lifecycle management. In this paper, a new method for product design, manufacturing, and service driven by digital twin is proposed. The detailed application methods and frameworks of digital twin-driven product design, manufacturing, and service are investigated. Furthermore, three cases are given to illustrate the future applications of digital twin in the three phases of a product respectively.},
	language = {en},
	number = {9},
	urldate = {2023-05-13},
	journal = {The International Journal of Advanced Manufacturing Technology},
	author = {Tao, Fei and Cheng, Jiangfeng and Qi, Qinglin and Zhang, Meng and Zhang, He and Sui, Fangyuan},
	month = feb,
	year = {2018},
	keywords = {Big data, Manufacturing, Cyber and physical convergence, Design, Digital twin, Product lifecycle, Service},
	pages = {3563--3576},
	file = {Full Text PDF:files/4028/Tao et al. - 2018 - Digital twin-driven product design, manufacturing .pdf:application/pdf},
}

@article{cimino_harmonising_2021,
	title = {Harmonising and integrating the {Digital} {Twins} multiverse: {A} paradigm and a toolset proposal},
	volume = {132},
	issn = {0166-3615},
	shorttitle = {Harmonising and integrating the {Digital} {Twins} multiverse},
	url = {https://www.sciencedirect.com/science/article/pii/S0166361521001081},
	doi = {10.1016/j.compind.2021.103501},
	abstract = {Digital Twins are of paramount relevance in the Industry 4.0 framework. However, the idea of Digital Twin has many different interpretations. These are tied to the intended use of a Digital Twin, thus to the viewpoint of the involved professionals (process designers, control specialists, managers, and so on). The said interpretations are often highly incompatible with one another, since they can involve as heterogeneous entities as a CAD drawing and a neural network. A convergence of Digital Twin interpretations is desirable, to take full profit of the contained knowledge. In this research we argue that this desired convergence cannot be found at the same abstraction level of the available Digital Twin interpretations, and calls for a higher one. We consequently propose a paradigm – that we name Digital Multiverse – to comprehend the major Digital Twin interpretations not only in the sense of data integration, which is the goal of promising complementary ideas like that of Asset Administration Shell, but also by establishing and enforcing consistency rules that involve both data and models. We also show some examples to support the usefulness and viability of our proposal.},
	language = {en},
	urldate = {2023-05-13},
	journal = {Computers in Industry},
	author = {Cimino, Chiara and Ferretti, Gianni and Leva, Alberto},
	month = nov,
	year = {2021},
	keywords = {Digital Twin, Advanced manufacturing, Cyber-Physical systems, Industry 4.0, Lifetime asset management},
	pages = {103501},
	file = {ScienceDirect Snapshot:files/4030/S0166361521001081.html:text/html},
}

@article{errandonea_digital_2020,
	title = {Digital {Twin} for maintenance: {A} literature review},
	volume = {123},
	issn = {0166-3615},
	shorttitle = {Digital {Twin} for maintenance},
	url = {https://www.sciencedirect.com/science/article/pii/S0166361520305509},
	doi = {10.1016/j.compind.2020.103316},
	abstract = {In recent years, Digital Twins (DT) have been implemented in different industrial sectors, in several applications areas such as design, production, manufacturing, and maintenance. In particular, maintenance is one of the most researched applications, as the impact of the execution of maintenance task may have a great impact in the business of the companies. For example, in sector such as energy or manufacturing, a maintenance activity can cause the shutdown of an entire production line, or in the case of a wind turbine inspection, may face the safety of an operator to measure a simple indicator. Hence, the application of more intelligent maintenance strategies can offer huge benefits. In this context, this paper focuses on the review of DT applications for maintenance, as no previous work has been found with this aim. For instance, both “Digital Twin” and “maintenance” concepts and strategies are described in detail, and then a literature review is carried out where these two concepts are involved. In addition to identifying and analyzing how DTs are currently being applied for maintenance, this paper also highlights future research lines and open issues.},
	language = {en},
	urldate = {2023-05-13},
	journal = {Computers in Industry},
	author = {Errandonea, Itxaro and Beltrán, Sergio and Arrizabalaga, Saioa},
	month = dec,
	year = {2020},
	keywords = {Digital twin, Decision support systems, Information system, Knowledge support system, Smart maintenance},
	pages = {103316},
	file = {ScienceDirect Snapshot:files/4032/S0166361520305509.html:text/html},
}

@article{semeraro_digital_2021,
	title = {Digital twin paradigm: {A} systematic literature review},
	volume = {130},
	issn = {0166-3615},
	shorttitle = {Digital twin paradigm},
	url = {https://www.sciencedirect.com/science/article/pii/S0166361521000762},
	doi = {10.1016/j.compind.2021.103469},
	abstract = {Manufacturing enterprises are facing the need to align themselves to the new information technologies (IT) and respond to the new challenges of variable market demand. One of the key enablers of this IT revolution toward Smart Manufacturing is the digital twin (DT). It embeds a “virtual” image of the reality constantly synchronized with the real operating scenario to provide sound information (knowledge model) to reality interpretation model to draw sound decisions. The paper aims at providing an up-to date picture of the main DT components, their features and interaction problems. The paper aims at clearly tracing the ongoing research and technical challenges in conceiving and building DTs as well, according to different application domains and related technologies. To this purpose, the main questions answered here are: ‘What is a Digital Twin?’; ‘Where is appropriate to use a Digital Twin?’; ‘When has a Digital Twin to be developed?’; ‘Why should a Digital Twin be used?’; ‘How to design and implement a Digital Twin?’; ‘What are the main challenges of implementing a Digital Twin?’. This study tries to answer to the previous questions funding on a wide systematic literature review of scientific research, tools, and technicalities in different application domains.},
	language = {en},
	urldate = {2023-05-13},
	journal = {Computers in Industry},
	author = {Semeraro, Concetta and Lezoche, Mario and Panetto, Hervé and Dassisti, Michele},
	month = sep,
	year = {2021},
	keywords = {Digital twin, Industry 4.0, Cyber-physical systems, Predictive manufacturing},
	pages = {103469},
	file = {ScienceDirect Snapshot:files/4037/S0166361521000762.html:text/html;Versione accettata:files/4038/Semeraro et al. - 2021 - Digital twin paradigm A systematic literature rev.pdf:application/pdf},
}

@article{tao_digital_2022,
	title = {Digital twin modeling},
	volume = {64},
	issn = {0278-6125},
	url = {https://www.sciencedirect.com/science/article/pii/S0278612522001108},
	doi = {10.1016/j.jmsy.2022.06.015},
	abstract = {The digital twin is an emerging and vital technology for digital transformation and intelligent upgrade. Driven by data and model, the digital twin can perform monitoring, simulation, prediction, optimization, and so on. Specifically, the digital twin modeling is the core for accurate portrayal of the physical entity, which enables the digital twin to deliver the functional services and satisfy the application requirements. Therefore, this paper provides systematic research of current studies on the digital twin modeling. Since the digital twin model is a faithful reflection of the digital twin modeling performance, a comprehensive and insightful analysis of digital twin models is given first from the perspective of the application field, hierarchy, discipline, dimension, universality, and functionality. Based on the analysis of digital twin models, current studies on the digital twin modeling are classified and analyzed according to the six modeling aspects within the digital twin modeling theoretical system proposed in our previous work. Meanwhile, enabling technologies and tools for the digital twin modeling are investigated and summarized. Finally, observations and future research recommendations are presented.},
	language = {en},
	urldate = {2023-05-13},
	journal = {Journal of Manufacturing Systems},
	author = {Tao, Fei and Xiao, Bin and Qi, Qinglin and Cheng, Jiangfeng and Ji, Ping},
	month = jul,
	year = {2022},
	keywords = {Digital twin, Digital twin model, Digital twin modeling, Enabling technologies, Enabling tools},
	pages = {372--389},
	file = {ScienceDirect Snapshot:files/4040/S0278612522001108.html:text/html},
}

@article{jones_characterising_2020,
	title = {Characterising the {Digital} {Twin}: {A} systematic literature review},
	volume = {29},
	issn = {1755-5817},
	shorttitle = {Characterising the {Digital} {Twin}},
	url = {https://www.sciencedirect.com/science/article/pii/S1755581720300110},
	doi = {10.1016/j.cirpj.2020.02.002},
	abstract = {While there has been a recent growth of interest in the Digital Twin, a variety of definitions employed across industry and academia remain. There is a need to consolidate research such to maintain a common understanding of the topic and ensure future research efforts are to be based on solid foundations. Through a systematic literature review and a thematic analysis of 92 Digital Twin publications from the last ten years, this paper provides a characterisation of the Digital Twin, identification of gaps in knowledge, and required areas of future research. In characterising the Digital Twin, the state of the concept, key terminology, and associated processes are identified, discussed, and consolidated to produce 13 characteristics (Physical Entity/Twin; Virtual Entity/Twin; Physical Environment; Virtual Environment; State; Realisation; Metrology; Twinning; Twinning Rate; Physical-to-Virtual Connection/Twinning; Virtual-to-Physical Connection/Twinning; Physical Processes; and Virtual Processes) and a complete framework of the Digital Twin and its process of operation. Following this characterisation, seven knowledge gaps and topics for future research focus are identified: Perceived Benefits; Digital Twin across the Product Life-Cycle; Use-Cases; Technical Implementations; Levels of Fidelity; Data Ownership; and Integration between Virtual Entities; each of which are required to realise the Digital Twin.},
	language = {en},
	urldate = {2023-05-13},
	journal = {CIRP Journal of Manufacturing Science and Technology},
	author = {Jones, David and Snider, Chris and Nassehi, Aydin and Yon, Jason and Hicks, Ben},
	month = may,
	year = {2020},
	keywords = {Digital Twin, Virtual Twin},
	pages = {36--52},
	file = {Full text:files/4042/Jones et al. - 2020 - Characterising the Digital Twin A systematic lite.pdf:application/pdf;ScienceDirect Snapshot:files/4043/S1755581720300110.html:text/html},
}

@article{qi_enabling_2021,
	series = {Digital {Twin} towards {Smart} {Manufacturing} and {Industry} 4.0},
	title = {Enabling technologies and tools for digital twin},
	volume = {58},
	issn = {0278-6125},
	url = {https://www.sciencedirect.com/science/article/pii/S027861251930086X},
	doi = {10.1016/j.jmsy.2019.10.001},
	abstract = {Digital twin is revolutionizing industry. Fired by sensor updates and history data, the sophisticated models can mirror almost every facet of a product, process or service. In the future, everything in the physical world would be replicated in the digital space through digital twin technology. As a cutting-edge technology, digital twin has received a lot of attention. However, digital twin is far from realizing their potential, which is a complex system and long-drawn process. Researchers must model all the different parts of the objects or systems. Varied types of data needed to be collected and merged. Many researchers and participators in engineering are not clear which technologies and tools should be used. 5-dimension digital twin model provides reference guidance for understanding and implementing digital twin. From the perspective of 5-dimension digital twin model, this paper tries to investigate and summarize the frequently-used enabling technologies and tools for digital twin to provide technologies and tools references for the applications of digital twin in the future.},
	language = {en},
	urldate = {2023-05-13},
	journal = {Journal of Manufacturing Systems},
	author = {Qi, Qinglin and Tao, Fei and Hu, Tianliang and Anwer, Nabil and Liu, Ang and Wei, Yongli and Wang, Lihui and Nee, A. Y. C.},
	month = jan,
	year = {2021},
	keywords = {Digital twin, Enabling technologies, Enabling tools, Five-dimension model},
	pages = {3--21},
	file = {ScienceDirect Snapshot:files/4045/S027861251930086X.html:text/html},
}

@article{declerck_towards_nodate,
	title = {Towards a {Linked} {Data} {Access} to {Folktales} classified by {Thompson}’s {Motifs} and {Aarne}-{Thompson}-{Uther}’s {Types}},
	language = {en},
	author = {Declerck, Thierry and Ko, Antónia},
	file = {Declerck e Ko - Towards a Linked Data Access to Folktales classifi.pdf:files/4046/Declerck e Ko - Towards a Linked Data Access to Folktales classifi.pdf:application/pdf},
}

@incollection{declerck_towards_2012,
	address = {Berlin, Heidelberg},
	title = {Towards {Linked} {Language} {Data} for {Digital} {Humanities}},
	isbn = {978-3-642-28249-2},
	url = {https://doi.org/10.1007/978-3-642-28249-2_11},
	abstract = {We investigate the extension of classification schemes in the Humanities into semantic data repositories, the benefits of which could be the automation of so far manually conducted processes, such as detecting motifs in folktale texts. In parallel, we propose linguistic analysis of the textual labels used in these repositories. The resulting resource, which we propose to publish in the Linked Open Data (LOD) framework, will explicitly interlink domain knowledge and linguistically enriched language data, which can be used for knowledge-driven content analysis of literary works.},
	language = {en},
	urldate = {2023-05-13},
	booktitle = {Linked {Data} in {Linguistics}: {Representing} and {Connecting} {Language} {Data} and {Language} {Metadata}},
	publisher = {Springer},
	author = {Declerck, Thierry and Lendvai, Piroska and Mörth, Karlheinz and Budin, Gerhard and Váradi, Tamás},
	editor = {Chiarcos, Christian and Nordhoff, Sebastian and Hellmann, Sebastian},
	year = {2012},
	doi = {10.1007/978-3-642-28249-2_11},
	keywords = {Linguistic Information, Link Open Data, Literary Work, Machine Translation, Semantic Annotation},
	pages = {109--116},
}

@article{declerck_multilingual_nodate,
	title = {Multilingual and {Semantic} {Extension} of {Folktale} {Catalogues}},
	abstract = {We address the multilingual and semantic upgrades of two digital catalogues of motifs and types in folk-literature: the Thompson’s Motif-Index of Folk-Literature (TMI) and the Aarne-Thompson-Uther classification system (ATU). The methods convert, translate, and represent their digitized content in terms of various (so far often implicit) structural and linguistic components. The results will enable (i) utilizing these resources for semi-automatic analysis and indexing of texts of relevant genres, in a multilingual setting, and (ii) pre-processing the data, for analysing motif sequences in folktale plots. We plan to publish the resulting data, which can be made available in the Linked Open Data (LOD) framework.},
	language = {en},
	author = {Declerck, Thierry and Lendvai, Piroska and Darányi, Sándor},
	file = {Declerck et al. - Multilingual and Semantic Extension of Folktale Ca.pdf:files/4050/Declerck et al. - Multilingual and Semantic Extension of Folktale Ca.pdf:application/pdf},
}

@inproceedings{declerck_linguistic_2011,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Linguistic and {Semantic} {Representation} of the {Thompson}’s {Motif}-{Index} of {Folk}-{Literature}},
	isbn = {978-3-642-24469-8},
	doi = {10.1007/978-3-642-24469-8_17},
	abstract = {We present on-going work on the linguistic and semantic processing of the labels of the Thompson’s Motif-Index of Folk-Literature, which has been proposed by Stith Thompson for the classification of narrative elements in folk-literature. We automatically extracted the labels of an on-line version of the Index, and wrote specialised grammars for providing for a multi-layer linguistic annotation of them. We are currently working on enriching the linguistically annotated labels with semantic classes and relations, allowing for a better access to the content of the Index. With this resource, we expect to be able to semi-automatically annotate digitised literary works at the sub-document level by means of automatically comparing the annotated Index with the results of text processing tools applied to those works, and so contribute to a better inter-textual interlinking and understanding of related works in the folk-literature, offering a new way of semantically accessing digital libraries.},
	language = {en},
	booktitle = {Research and {Advanced} {Technology} for {Digital} {Libraries}},
	publisher = {Springer},
	author = {Declerck, Thierry and Lendvai, Piroska},
	editor = {Gradmann, Stefan and Borri, Francesca and Meghini, Carlo and Schuldt, Heiko},
	year = {2011},
	keywords = {Cultural Heritage, Digital Library, Semantic Annotation, Language Technology, Word Form},
	pages = {151--158},
	file = {Full Text PDF:files/4053/Declerck e Lendvai - 2011 - Linguistic and Semantic Representation of the Thom.pdf:application/pdf},
}

@article{koleva_ontology-based_nodate,
	title = {Ontology-based {Recognition} of {Folktale} {Characters}},
	language = {en},
	author = {Koleva, Nikolina and Declerck, Thierry},
	file = {Koleva e Declerck - Ontology-based Recognition of Folktale Characters.pdf:files/4054/Koleva e Declerck - Ontology-based Recognition of Folktale Characters.pdf:application/pdf},
}

@misc{crawford_research_nodate,
	title = {Research {Guides}: {Library} {Research} {Guide} for {Folklore} and {Mythology}: {Tale}-{Type} and {Motif} {Indices}},
	copyright = {Copyright Harvard Library 2023},
	shorttitle = {Research {Guides}},
	url = {https://guides.library.harvard.edu/folk_and_myth/indices},
	abstract = {Research Guides: Library Research Guide for Folklore and Mythology: Tale-Type and Motif Indices},
	language = {en},
	urldate = {2023-05-13},
	author = {Crawford, Ramona},
	file = {Snapshot:files/4057/indices.html:text/html},
}

@article{cosovic_application_nodate-1,
	title = {Application of the digital twin concept in cultural heritage},
	abstract = {Cultural heritage has benefited for years from the availability of technology in the domain of digitalization; hence digital heritage emerged. Researchers in the cultural heritage domain have used tools and digital techniques as way to preserve historical and religious buildings so that they are everlasting in time. These are mostly viewed as autonomous attempts, rarely organized. One of the digital tools that arose from the field of product life cycle management is the digital twin, which is defined as digital representation of physical product. There is an ongoing debate whether cultural heritage can be fully viewed in terms of digital twin and if the application of the digital twin concept can be sustainable in the management of the cultural heritage environment. This paper aims to address the role of the digital twin within the cultural heritage domain and if it can be used to recreate certain phenomena or environmental situation resulting in reducing deterioration over time. This is important since heritage sites and historical buildings must be preserved for future generations.},
	language = {en},
	author = {Ćosović, Marijana and Maksimović, Mirjana},
	file = {Ćosović e Maksimović - Application of the digital twin concept in cultura.pdf:files/4058/Ćosović e Maksimović - Application of the digital twin concept in cultura.pdf:application/pdf},
}

@article{noauthor_no_nodate,
	title = {[{No} title found]},
	issn = {0128-178X},
	abstract = {Museum is one of the educational centre for people to gain knowledge. Varieties of communication modes have been used to deliver the information to museum visitors. The advent of technology has brought to the usage of mobile technology in museum, thus ensure visitor’s meaningful experiences. Further, the integration of mobile technology in museum has facilitated visitor’s understanding of information about artefacts in the museum. In addressing this issue, the present study focused on factors that might influence museum visitors' usage of mobile application based on the Technology Acceptance Model (TAM). Data for the study were collected through fifty-five responses from a survey questionnaire. All the museum visitors were asked to use their own mobile devices in order to access digital information provided in the museum. Findings show that perceived usefulness and perceived ease of use have directly influenced towards the actual use of mobile technology. The relationship between constructs is stronger mediated by attitude. Thus, museum visitors’ attitude has played an important role in determining the actual use of the mobile application.},
	language = {en},
	journal = {Journal of Tourism, Hospitality and Environment Management},
	file = {[No title found].pdf:files/4060/[No title found].pdf:application/pdf},
}

@inproceedings{nizar_examining_2018,
	title = {{EXAMINING} {THE} {MUSEUM} {VISITORS} {USE} {OF} {MOBILE} {TECHNOLOGY} {THROUGH} {TECHNOLOGY} {ACCEPTANCE} {MODEL} ({TAM})},
	url = {https://www.semanticscholar.org/paper/EXAMINING-THE-MUSEUM-VISITORS-USE-OF-MOBILE-THROUGH-Nizar-Rahmat/f52eee2751f082f069f40ab49314b229723ee19e},
	abstract = {Museum is one of the educational centre for people to gain knowledge. Varieties of communication modes have been used to deliver the information to museum visitors. The advent of technology has brought to the usage of mobile technology in museum, thus ensure visitor’s meaningful experiences. Further, the integration of mobile technology in museum has facilitated visitor’s understanding of information about artefacts in the museum. In addressing this issue, the present study focused on factors that might influence museum visitors' usage of mobile application based on the Technology Acceptance Model (TAM). Data for the study were collected through fifty-five responses from a survey questionnaire. All the museum visitors were asked to use their own mobile devices in order to access digital information provided in the museum. Findings show that perceived usefulness and perceived ease of use have directly influenced towards the actual use of mobile technology. The relationship between constructs is stronger mediated by attitude. Thus, museum visitors’ attitude has played an important role in determining the actual use of the mobile application.},
	urldate = {2023-05-14},
	author = {Nizar, N. and Rahmat, M.},
	year = {2018},
	file = {Full Text PDF:files/4064/Nizar e Rahmat - 2018 - EXAMINING THE MUSEUM VISITORS USE OF MOBILE TECHNO.pdf:application/pdf},
}

@incollection{hogan_resource_2020,
	address = {Cham},
	title = {Resource {Description} {Framework}},
	isbn = {978-3-030-51580-5},
	url = {https://doi.org/10.1007/978-3-030-51580-5_3},
	abstract = {This chapter provides a detailed primer for the Resource Description Framework (RDF 1.1) standard, proposed as a common data model for publishing and exchanging structured data on the Web. We first motivate the need for a data model like RDF. We then describe the types of terms used in RDF: the basic building blocks of the framework. We discuss how these terms can be combined to make coherent statements in the form of RDF triples, and how triples form graphs and datasets. Thereafter we discuss the RDF vocabulary: a built-in set of terms used for modelling more complex data, such as complex relations and ordered lists. Finally, we give an overview of the different syntaxes by which RDF can be serialised and communicated.},
	language = {en},
	urldate = {2023-05-14},
	booktitle = {The {Web} of {Data}},
	publisher = {Springer International Publishing},
	author = {Hogan, Aidan},
	editor = {Hogan, Aidan},
	year = {2020},
	doi = {10.1007/978-3-030-51580-5_3},
	pages = {59--109},
}

@article{styles_semantic_nodate,
	title = {Semantic {Marc}, {MARC21} and the {Semantic} {Web}},
	abstract = {The MARC standard for exchanging bibliographic data has been in use for several decades and is used by major libraries worldwide. This paper discusses the possibilities of representing the most prevalent form of MARC, MARC21, as RDF for the Semantic Web, and aims to understand the tradeoffs, if any, resulting from transforming the data. Critically our approach goes beyond a simple transliteration of the MARC21 record syntax to develop rich semantic descriptions of the varied things which may be described using bibliographic records. We present an algorithmic approach for consistently generating URIs from textual data, discuss the algorithmic matching of author names and suggest how RDF generated from MARC records may be linked to other data sources on the Web.},
	language = {en},
	author = {Styles, Rob and Ayers, Danny and Shabir, Nadeem},
	file = {Styles et al. - Semantic Marc, MARC21 and the Semantic Web.pdf:files/4066/Styles et al. - Semantic Marc, MARC21 and the Semantic Web.pdf:application/pdf},
}

@inproceedings{styles_semantic_2008,
	title = {Semantic {Marc}, {MARC21} and {The} {Semantic} {Web}},
	url = {https://www.semanticscholar.org/paper/Semantic-Marc%2C-MARC21-and-The-Semantic-Web-Styles-Ayers/a6f6e6fc91f2dd513ff844d912d65f366bca4c0c},
	abstract = {The MARC standard for exchanging bibliographic data has been in use for several decades and is used by major libraries worldwide. This paper discusses the possibilities of representing the most prevalent form of MARC, MARC21, as RDF for the Semantic Web, and aims to understand the tradeoffs, if any, resulting from transforming the data. Critically our approach goes beyond a simple transliteration of the MARC21 record syntax to develop rich semantic descriptions of the varied things which may be described using bibliographic records. We present an algorithmic approach for consistently generating URIs from textual data, discuss the algorithmic matching of author names and suggest how RDF generated from MARC records may be linked to other data sources on the Web.},
	urldate = {2023-05-20},
	author = {Styles, Rob and Ayers, Danny and Shabir, N.},
	year = {2008},
	file = {Full Text PDF:files/4071/Styles et al. - 2008 - Semantic Marc, MARC21 and The Semantic Web.pdf:application/pdf},
}

@article{kumar_exposing_2013,
	title = {Exposing {MARC} 21 {Format} for {Bibliographic} {Data} {As} {Linked} {Data} {With} {Provenance}},
	volume = {13},
	issn = {1938-6389},
	url = {https://doi.org/10.1080/19386389.2013.826076},
	doi = {10.1080/19386389.2013.826076},
	abstract = {The library community has been using the MARC 21 standard to exchange library data for decades and all the information processed seems to be successful. However, due to the proliferation of tools and technologies, people started anticipating the data to be easily available for their use. But this is only possible by standardizing the data representation formats and sharing data on the Web. The MARC 21 standard has no possibility of distributing library metadata outside the library community. Besides, these standards focus only on data representation and storage, which causes the semantics of data to be hidden for machines. This paper presents an approach on transitioning the MARC 21 Format for Bibliographic Data into RDF triple representation based on the linked data principles. The linked data principles proposed by Sir Tim Berners-Lee state how the data alone can be shared and linked with each other regardless of the documents they are enclosed in and formulating the web as a Web of Data. Further, an automatic generation of the provenance information of the library metadata is considered.},
	number = {2-3},
	urldate = {2023-05-20},
	journal = {Journal of Library Metadata},
	author = {Kumar, Sharma and Ujjal, Marjit and Utpal, Biswas},
	month = jul,
	year = {2013},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/19386389.2013.826076},
	keywords = {Semantic Web, linked data, MARC 21, provenance},
	pages = {212--229},
}

@article{force_unescopersist_2016,
	title = {The {UNESCO}/{PERSIST} {Guidelines} for the selection of digital heritage for long-term preservation},
	url = {https://repository.ifla.org/handle/123456789/1218},
	abstract = {The UNESCO PERSIST Project, an initiative of UNESCO, ICA, IFLA and other partners, for enhancing the sustainability of digital heritage, has launched the UNESCO/PERSIST Guidelines for the selection of digital heritage for long-term preservation in 2016. 
The Guidelines provide an overarching starting point for heritage institutions when drafting their own policies on the selection of digital heritage for long-term sustainable digital preservation. 
PERSIST Digital Heritage Selection Guidelines​​​The Guidelines target institutions, professionals and administrators on every level and in every region of the world in order to review existing material for selection, highlight important issues, and offer guidance when drafting institutional policies, they were written by a team of seven authors from the library, archives, and museums community.},
	language = {en},
	urldate = {2023-05-24},
	author = {Force, UNESCO/PERSIST Content Task and Choy, Sarah CC and Crofts, Nicholas and Fisher, Robert and Lek Choh, Ngian and Nickel, Susanne and Oury, Clément and Ślaska, Katarzyna},
	month = may,
	year = {2016},
	note = {Accepted: 2021-08-22T17:48:35Z},
	file = {Full Text PDF:files/4074/Force et al. - 2016 - The UNESCOPERSIST Guidelines for the selection of.pdf:application/pdf},
}

@misc{httpsplusgooglecomunesco_digital_2019,
	title = {Digital {Heritage}},
	url = {https://en.unesco.org/themes/information-preservation/digital-heritage},
	language = {en},
	urldate = {2023-05-24},
	journal = {UNESCO},
	author = {https://plus.google.com/+UNESCO},
	month = mar,
	year = {2019},
	file = {Snapshot:files/4076/digital-heritage.html:text/html},
}

@misc{httpsplusgooglecomunesco_digital_2019-1,
	title = {Digital {Heritage}: {Background}},
	shorttitle = {Digital {Heritage}},
	url = {https://en.unesco.org/themes/information-preservation/digital-heritage/background},
	language = {en},
	urldate = {2023-05-24},
	journal = {UNESCO},
	author = {https://plus.google.com/+UNESCO},
	month = apr,
	year = {2019},
	file = {Snapshot:files/4078/background.html:text/html},
}

@misc{httpsplusgooglecomunesco_concept_2019-1,
	title = {Concept of {Digital} {Heritage}},
	url = {https://en.unesco.org/themes/information-preservation/digital-heritage/concept-digital-heritage},
	language = {en},
	urldate = {2023-05-24},
	journal = {UNESCO},
	author = {https://plus.google.com/+UNESCO},
	month = mar,
	year = {2019},
	file = {Snapshot:files/4080/concept-digital-heritage.html:text/html},
}

@misc{noauthor_digital_2023,
	title = {Digital heritage},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Digital_heritage&oldid=1140332226},
	abstract = {Digital heritage is the use of digital media in the service of understanding and preserving cultural or natural heritage.The Charter on the Preservation of Digital Heritage of UNESCO defines digital heritage as embracing "cultural, educational, scientific and administrative resources, as well as technical, legal, medical and other kinds of information created digitally, or converted into digital form from existing analogue resources".The digitization of both cultural heritage and Natural heritage serves to enable the permanent access of current and future generations to culturally important objects ranging from literature and paintings to flora, fauna, or habitats. It is also used in the preservation and access of objects with enduring or significant historical, scientific, or cultural value including buildings, archeological sites, and natural phenomena. The main idea is the transformation of a material object into a virtual copy.  It should not be confused with digital humanities, which uses digitizing technology to specifically help with research. There have been several debates concerning the efficiency of the process of digitizing heritage. Some of the drawbacks refer to the deterioration and technological obsolescence due to the lack of funding for archival materials and underdeveloped policies that would regulate such a process. Another main social debate has taken place around the restricted accessibility due to the digital divide that exists around the world. Nevertheless, new technologies enable easy, instant and cross boarder access to the digitized work. Many of these technologies include spatial and surveying technology to gain aerial or 3D images.
Digital heritage is also used to monitor cultural heritage sites over years to help with preservation, maintenance, and sustainable tourism.  It aims to observe any changes, diseases, or deterioration that may occur on objects.},
	language = {en},
	urldate = {2023-05-24},
	journal = {Wikipedia},
	month = feb,
	year = {2023},
	note = {Page Version ID: 1140332226},
	file = {Snapshot:files/4082/Digital_heritage.html:text/html},
}

@article{bonacchi_digital_2019,
	title = {Digital heritage research re-theorised: ontologies and epistemologies in a world of big data},
	volume = {25},
	issn = {1352-7258},
	shorttitle = {Digital heritage research re-theorised},
	url = {https://doi.org/10.1080/13527258.2019.1578989},
	doi = {10.1080/13527258.2019.1578989},
	abstract = {This article provides the first theoretical treatment of the ontologies and epistemologies of digital heritage research at the time of the interconnected and social web, based on extensive empirical and analytical investigation. We draw on observations and concepts developed while conducting the first study of public experiences of the past that utilised big data – over 1.4 million Facebook posts, comments and replies – to revisit or generate new theory from the ground up. We expect that this will help scholars from a range of fields in the humanities, social and computing sciences who are interested in undertaking digital heritage research to understand the deeper implications of their work, the complexities and limitations of the knowledge they create, and its value in exposing the processes via which heritage is made and assessed.},
	number = {12},
	urldate = {2023-05-24},
	journal = {International Journal of Heritage Studies},
	author = {Bonacchi, Chiara and Krzyzanska, Marta},
	month = dec,
	year = {2019},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/13527258.2019.1578989},
	keywords = {ontologies, Digital heritage, activism, big data, epistemology},
	pages = {1235--1247},
	file = {Versione accettata:files/4084/Bonacchi e Krzyzanska - 2019 - Digital heritage research re-theorised ontologies.pdf:application/pdf},
}

@article{bonacchi_heritage_2018,
	title = {The heritage of {Brexit}: {Roles} of the past in the construction of political           identities through social media},
	volume = {18},
	issn = {1469-6053},
	shorttitle = {The heritage of {Brexit}},
	url = {https://doi.org/10.1177/1469605318759713},
	doi = {10.1177/1469605318759713},
	abstract = {This article assesses the role of the pre-modern past in the construction of political identities relating to the UK’s membership in the European Union by examining how materials and ideas from Iron Age to Early Medieval Britain and Europe were leveraged by those who discussed the topic of Brexit in over 1.4 million messages published in dedicated Facebook pages. Through a combination of data-intensive and qualitative investigations of textual data, we identify the ‘heritages’ invoked in support of pro- or anti-Brexit sentiments. We show how these heritages are centred around myths of origins, resistance and collapse that incorporate tensions and binary divisions. We highlight the strong influence of past expert practices in shaping such deeply entrenched dualistic thinking and reflect over the longue durée agency of heritage expertise. This is the first systematic study of public perceptions and experience of the past in contemporary society undertaken through digital heritage research fuelled by big data. As such, the article contributes novel methodological approaches and substantially advances theory in cultural heritage studies. It is also the first published work to analyse the role of heritage in the construction of political identities in relation to Brexit via extensive social research.},
	language = {en},
	number = {2},
	urldate = {2023-05-24},
	journal = {Journal of Social Archaeology},
	author = {Bonacchi, Chiara and Altaweel, Mark and Krzyzanska, Marta},
	month = jun,
	year = {2018},
	note = {Publisher: SAGE Publications},
	pages = {174--192},
	file = {SAGE PDF Full Text:files/4086/Bonacchi et al. - 2018 - The heritage of Brexit Roles of the past in the c.pdf:application/pdf},
}

@article{marwick_world_2021,
	title = {World {Heritage} sites on {Wikipedia}: {Cultural} heritage activism in a context of constrained agency},
	volume = {8},
	issn = {2053-9517},
	shorttitle = {World {Heritage} sites on {Wikipedia}},
	url = {https://doi.org/10.1177/20539517211017304},
	doi = {10.1177/20539517211017304},
	abstract = {UNESCO World Heritage sites are places of outstanding significance and often key sources of information that influence how people interact with the past today. The process of inscription on the UNESCO list is complicated and intersects with political and commercial controversies. But how well are these controversies known to the public? Wikipedia pages on these sites offer a unique dataset for insights into public understanding of heritage controversies. The unique technicity of Wikipedia, with its bot ecosystem and editing mechanics, shapes how knowledge about cultural heritage is constructed and how controversies are negotiated and communicated. In this article, we investigate the patterns of production, consumption, and spatial and temporal distributions of Wikipedia pages for World Heritage cultural sites. We find that Wikipedia provides a distinctive context for investigating how people experience and relate to the past in the present. The agency of participants is highly constrained, but distinctive, behind-the-scenes expressions of cultural heritage activism are evident. Concerns about state-like actors, violence and destruction, deal-making, etc. in the World Heritage inscription process are present, but rare on Wikipedia’s World Heritage pages. Instead, hyper-local and process issues dominate controversies on Wikipedia. We describe how this kind of research, drawing on Big Data and data science methods, contributes to digital heritage studies and also reveals its limitations.},
	language = {en},
	number = {1},
	urldate = {2023-05-24},
	journal = {Big Data \& Society},
	author = {Marwick, Ben and Smith, Prema},
	month = jan,
	year = {2021},
	note = {Publisher: SAGE Publications Ltd},
	pages = {20539517211017304},
	file = {SAGE PDF Full Text:files/4088/Marwick e Smith - 2021 - World Heritage sites on Wikipedia Cultural herita.pdf:application/pdf},
}

@article{sullivan_cultural_nodate,
	title = {Cultural {Heritage} \& {New} {Media}: {A} {Future} for the {Past}, 15 {J}. {Marshall} {Rev}. {Intell}. {Prop}. {L}. 604 (2016)},
	language = {en},
	journal = {NEW MEDIA},
	author = {Sullivan, Ann Marie},
	file = {Sullivan - Cultural Heritage & New Media A Future for the Pa.pdf:files/4089/Sullivan - Cultural Heritage & New Media A Future for the Pa.pdf:application/pdf},
}

@misc{noauthor_charter_nodate-1,
	title = {Charter on the {Preservation} of {Digital} {Heritage} {\textbar} {UNESCO}},
	url = {https://www.unesco.org/en/legal-affairs/charter-preservation-digital-heritage},
	language = {en},
	urldate = {2023-05-24},
	file = {Snapshot:files/4094/charter-preservation-digital-heritage.html:text/html},
}

@incollection{wang_digital_2020,
	address = {Singapore},
	title = {Digital {Heritage}},
	isbn = {978-981-329-915-3},
	url = {https://doi.org/10.1007/978-981-32-9915-3_17},
	abstract = {Natural and cultural heritage, the common wealth of human beings, are keys to human understanding of the evolution of our planet and social development. The protection and conservation of natural and cultural heritage is the common responsibility of all mankind. Spatial information technology provides a new applied theory and tool for the protection and utilization of natural and cultural heritage. This chapter is divided into four parts. The first part elaborates the connotation of digital heritage, the differences and connections between digital heritage and physical heritage, the technology of digital heritage formation and the research objectives and content of digital heritage. Parts 2 and 3 discuss the contents and methods of digital natural heritage and cultural heritage, respectively, and some practical case studies. In the fourth part, the future development trends of digital heritage research in protection and utilization are described, as well as six research directions that deserve attention.},
	language = {en},
	urldate = {2023-05-24},
	booktitle = {Manual of {Digital} {Earth}},
	publisher = {Springer},
	author = {Wang, Xinyuan and Lasaponara, Rosa and Luo, Lei and Chen, Fulong and Wan, Hong and Yang, Ruixia and Zhen, Jing},
	editor = {Guo, Huadong and Goodchild, Michael F. and Annoni, Alessandro},
	year = {2020},
	doi = {10.1007/978-981-32-9915-3_17},
	keywords = {Digital heritage, Archaeology, Case study, Heritage conservation, Remote sensing, Spatial information technology},
	pages = {565--591},
	file = {Full Text PDF:files/4093/Wang et al. - 2020 - Digital Heritage.pdf:application/pdf},
}

@article{munster_digital_2019,
	title = {Digital {Heritage} as a {Scholarly} {Field}—{Topics}, {Researchers}, and {Perspectives} from a {Bibliometric} {Point} of {View}},
	volume = {12},
	issn = {1556-4673},
	url = {https://dl.acm.org/doi/10.1145/3310012},
	doi = {10.1145/3310012},
	abstract = {Digital heritage comprises a broad variety of approaches and topics and involves researchers from multiple disciplines. Against this background, this article presents a four-stage investigation on standards, publications, disciplinary cultures, as well as scholars in the field of digital heritage and particularly tangible objects as monuments and sites, carried out in 2016 and 2017. It includes results of (1) the inquiry of nearly 4,000 publications from major conferences, (2) a workshop-based survey involving 44 researchers, (3) 15 qualitative interviews, as well as (4) two online surveys with 1,000 and 700 participants, respectively. As an overall finding, the community is driven by researchers from European countries, especially Italy, with a background in humanities. Cross-national co-authorships are promoted by cultural and spatial closeness and—probably due to funding policy—EU membership. A discourse is primarily driven by technologies, and the most common keywords refer to the technologies used. Most prominent research areas are data acquisition and management, visualization, and analysis. Recent topics are, for instance, unmanned airborne vehicle (UAV)-based 3D surveying technologies, augmented and virtual reality visualization, metadata and paradata standards for documentation, and virtual museums. Since a lack of money is named as the biggest obstacle nowadays, competency and human resources are most frequently named as demand. An epistemic culture in the scholarly field of digital heritage is closer to engineering than to humanities. Moreover, conference series are most relevant for a scientific discourse, and especially EU projects set pace as most important research endeavors.},
	number = {3},
	urldate = {2023-05-24},
	journal = {Journal on Computing and Cultural Heritage},
	author = {Münster, Sander},
	month = jul,
	year = {2019},
	keywords = {topics, Digital Heritage, scholarly field, survey},
	pages = {22:1--22:27},
	file = {Full Text PDF:files/4096/Münster - 2019 - Digital Heritage as a Scholarly Field—Topics, Rese.pdf:application/pdf},
}

@article{ryan_natural_2014,
	title = {Natural {Heritage} {Conservation} and {Eco}-{Digital} {Poiesis}: {A} {Western} {Australian} {Example}},
	volume = {153},
	issn = {1329-878X},
	shorttitle = {Natural {Heritage} {Conservation} and {Eco}-{Digital} {Poiesis}},
	url = {https://doi.org/10.1177/1329878X1415300111},
	doi = {10.1177/1329878X1415300111},
	abstract = {A city of biodiversity, Perth in Western Australia faces significant environmental challenges. As species and habitats vanish, so too can their biocultural heritage. To address biological and cultural decline, FloraCultures is a digital conservation initiative that uses archival, ethnographic and design approaches to conserve and promote Perth's ‘botanical heritage’. This article examines the project's conceptual foundations in terms of nature/culture, tangible/intangible and thinking/making dualisms, as well as some of the practical strategies used to address these dualisms. To articulate biocultural heritage, I have had to rethink categorical oppositions through ecopoiesis – the making of interactive digital objects as informed by ecological discourses. The repository being developed will incorporate cultural materials (texts, visual art, interview recordings, music and video) not conventionally associated with environmental conservation. Key community-building approaches, such as focus groups and crowdsourcing, discussed later in the article, provide digitally based interventions into biocultural heritage loss that reflect the ecopoietic basis of FloraCultures.},
	language = {en},
	number = {1},
	urldate = {2023-05-24},
	journal = {Media International Australia},
	author = {Ryan, John Charles},
	month = nov,
	year = {2014},
	note = {Publisher: SAGE Publications Ltd},
	pages = {88--97},
}

@article{liu_building_2005,
	title = {Building {Digital} {Heritage} with {Teamwork} {Empowerment}},
	volume = {24},
	copyright = {Copyright (c) 2015  Information Technology and Libraries},
	issn = {2163-5226},
	url = {https://ejournals.bc.edu/index.php/ital/article/view/3374},
	doi = {10.6017/ital.v24i3.3374},
	abstract = {Building digital heritage requires substantial resources in materials, expertise, tools, and cost. Government and university projects are limited in the time and space they can devote to covering even a small part of the world’s heritage. The preservation coverage problem is most serious in areas where sources of intellectual and cultural heritage may diminish or disappear over time. A central notion that helps resolve these issues is to make it easier for digital technology to reach sources of valuable heritage. The authors propose an approach to exploit noninstitutional resources for wider participation and inclusion in digital-heritage endeavors. The approach attempts to copy the techniques of institutional digital-heritage work while bringing together noninstitutional resources and providing standard practice.},
	language = {en},
	number = {3},
	urldate = {2023-05-24},
	journal = {Information Technology and Libraries},
	author = {Liu, Jyi-Shane and Tseng, Mu-Hsi and Huang, Tze-Kai},
	month = sep,
	year = {2005},
	note = {Number: 3},
	pages = {130--140},
	file = {Full Text PDF:files/4099/Liu et al. - 2005 - Building Digital Heritage with Teamwork Empowermen.pdf:application/pdf},
}

@article{king_experiencing_2016,
	title = {Experiencing the {Digital} {World}: {The} {Cultural} {Value} of {Digital} {Engagement} with {Heritage}},
	volume = {9},
	issn = {2159-032X},
	shorttitle = {Experiencing the {Digital} {World}},
	url = {https://doi.org/10.1080/2159032X.2016.1246156},
	doi = {10.1080/2159032X.2016.1246156},
	abstract = {Since the late 1990s the potential of the digital world for generating new ways of engaging with heritage, broadly defined, has been a key focus of academic work and cultural practice. At times, the emphasis has been on how the internet can provide a “shop window” for the sector, and how this might be translated into physical visits to sites. Elsewhere, scholars have argued that the digital sphere can provide a dynamic space for two-way engagement with heritage culture, aimed at providing a complementary experience to physical visits through a range of phenomena (e.g. user-generated content, online communities, crowdsourcing projects). Questions have also been raised about how to measure the value of this activity and what we mean by value in this context. We bring together literature on digital engagement, interactivity and participation within heritage, case studies of current practice, and a survey of heritage professionals to focus on six key areas: 1. Financial resources2. Relative value of the digital experience3. The location of culture value4. Cultural value and time5. Enhanced value through participation6. Cultural value, space, and placeWe present strategies that heritage organizations of different scales might consider incorporating into new digital resources, while also suggesting further areas for research. Primarily, we suggest that there is substantial untapped potential to better understand the experience of end users by harnessing the vast amount of data that is available within heritage institutions, but which organizations frequently do not have the resources to exploit.},
	number = {1},
	urldate = {2023-05-24},
	journal = {Heritage \& Society},
	author = {King, Laura and Stark, James F. and Cooke, Paul},
	month = jan,
	year = {2016},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/2159032X.2016.1246156},
	keywords = {heritage, museums, cultural value, digital, engagement, resource management},
	pages = {76--101},
	file = {Full Text PDF:files/4101/King et al. - 2016 - Experiencing the Digital World The Cultural Value.pdf:application/pdf},
}

@article{champion_3d_2019,
	title = {{3D} {Digital} {Heritage} {Models} as {Sustainable} {Scholarly} {Resources}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2071-1050},
	url = {https://www.mdpi.com/2071-1050/11/8/2425},
	doi = {10.3390/su11082425},
	abstract = {If virtual heritage is the application of virtual reality to cultural heritage, then one might assume that virtual heritage (and 3D digital heritage in general) successfully communicates the need to preserve the cultural significance of physical artefacts and intangible heritage. However, digital heritage models are seldom seen outside of conference presentations, one-off museum exhibitions, or digital reconstructions used in films and television programs. To understand why, we surveyed 1483 digital heritage papers published in 14 recent proceedings. Only 264 explicitly mentioned 3D models and related assets; 19 contained links, but none of these links worked. This is clearly not sustainable, neither for scholarly activity nor as a way to engage the public in heritage preservation. To encourage more sustainable research practices, 3D models must be actively promoted as scholarly resources. In this paper, we also recommend ways researchers could better sustain these 3D models and assets both as digital cultural artefacts and as tools to help the public explore the vital but often overlooked relationship between built heritage and the natural world.},
	language = {en},
	number = {8},
	urldate = {2023-05-24},
	journal = {Sustainability},
	author = {Champion, Erik and Rahaman, Hafizur},
	month = jan,
	year = {2019},
	note = {Number: 8
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {3D model, ecosystem, infrastructure, virtual heritage},
	pages = {2425},
	file = {Full Text PDF:files/4103/Champion e Rahaman - 2019 - 3D Digital Heritage Models as Sustainable Scholarl.pdf:application/pdf},
}

@article{rahaman_interpreting_2011,
	title = {Interpreting {Digital} {Heritage}: {A} {Conceptual} {Model} with {End}-{Users}' {Perspective}},
	volume = {9},
	issn = {1478-0771},
	shorttitle = {Interpreting {Digital} {Heritage}},
	url = {https://doi.org/10.1260/1478-0771.9.1.99},
	doi = {10.1260/1478-0771.9.1.99},
	abstract = {Present virtual heritage projects are mostly focused either on ‘process’ or ‘product’ but rarely consider ‘users’ (end-users' perception of the content) with project contents predominantly developed with an ‘ocular-centric’ tendency. There is no significant interpretation method or principle for interpreting digital heritage like other disciplines such as archaeology. This paper argues that, for better interpretation and experience of a digital heritage site, a comprehensive interpretation method is required, which should address end-users with various background, overcome the linearity in narrative level and subjectiveness in content creation. This paper also argues that instead of predetermined instructional sequences or descriptive interpretation, the interaction setting can be participatory and contributive, where the end-users and environment may engage in ‘dialogic-interaction’. In terms of methodology, ‘Interpretation’ is first conceptualized by assimilating definitions from various heritage scholars and interpretation organizations. Notions of interpretation-practice and level of interaction are identified from reviewing some online digital heritage projects. By identifying weaknesses, this paper finally proposes a conceptual model for developing a comprehensive interpretation method for future digital heritage projects.},
	language = {en},
	number = {1},
	urldate = {2023-05-24},
	journal = {International Journal of Architectural Computing},
	author = {Rahaman, Hafizur and Tan, Beng-Kiang},
	month = mar,
	year = {2011},
	note = {Publisher: SAGE Publications},
	pages = {99--113},
}

@article{schorlemer_unesco_2020,
	title = {{UNESCO} and the {Challenge} of {Preserving} the {Digital} {Cultural} {Heritage}},
	volume = {2020},
	issn = {2450-050X},
	url = {https://www.ejournals.eu/SAACLR/2020/2-2020/art/18632/},
	doi = {10.4467/2450050XSNR.20.010.13013},
	abstract = {UNESCO and the Challenge of Preserving the Digital Cultural Heritage},
	language = {pl},
	number = {2/2020 (6)},
	urldate = {2023-05-24},
	journal = {Santander Art and Culture Law Review},
	author = {Schorlemer, Sabine von},
	month = dec,
	year = {2020},
	note = {Number: 2/2020 (6)
Publisher: Portal Czasopism Naukowych Ejournals.eu},
	pages = {33--64},
	file = {Full Text PDF:files/4106/Schorlemer - 2020 - UNESCO and the Challenge of Preserving the Digital.pdf:application/pdf},
}

@incollection{silberman_chasing_2007,
	title = {{CHASING} {THE} {UNICORN}?: {The} quest for “essence” in digital heritage},
	isbn = {978-0-203-93788-4},
	shorttitle = {{CHASING} {THE} {UNICORN}?},
	abstract = {This book is assembled with a conﬁdent, if not always fully examined,
assumption: namely, that the digital media – according to the announcement of the theme of the conference – have “the capacity to become
a tool to capture both the tangible and intangible essence of both the
cultural heritage and the society that created or used the sites” (New
Heritage Conference 2006). Even the most enthusiastic promoters of the
new cultural technologies admit that there are still a number of unresolved
problems. The technology itself has to be developed, democratized, and
made more widely accessible. Visualization alone should not be the primary goal. The profundity of the interpretation needs improving, as does
the permanence of the data storage media. But since we all agree that we
are at the very beginning of the process, there is faith that conferences
like this one and other digital heritage initiatives will eventually overcome
the existing obstacles “to capture the complexity of cultural heritage and
the related social, political, and economic issues surrounding the sites or
artefacts.”},
	booktitle = {New {Heritage}},
	publisher = {Routledge},
	author = {SILBERMAN, NEIL},
	year = {2007},
	note = {Num Pages: 11},
}

@article{purkis_making_2017,
	title = {Making digital heritage about people’s life stories},
	volume = {23},
	issn = {1352-7258},
	url = {https://doi.org/10.1080/13527258.2016.1190392},
	doi = {10.1080/13527258.2016.1190392},
	abstract = {Actively creating new digital heritage content about people’s life histories is part of the democratisation of heritage engagement with the public. The approach of documenting unofficial histories is supported by a growing literature. Unofficial stories contribute new perspectives on the heritage identity of a region. The case study of the ‘Local People’ exhibition, curated by the author in 2013 in the North West of Ireland, is used to discuss the methodology of a digital curatorial process, www.localpeopleireland.com. This article argues that gathering and presenting unofficial histories of individuals' life experiences, can disrupt official narratives of The Troubles and challenge a regional identity based on conflict and division. The making of digital history is analysed as a curatorial process, rather than the ease of use of technology. The methods used included: filmed interviews, new portrait photography and the digitisation of family photograph albums. A virtual exhibition was produced and new digital historical sources were created that transform intangible heritage by crystallising people’s voices and images into ‘tangible’ digital objects. ‘Local People’ utilised Facebook https://www.facebook.com/localpeopleproject/?fref=ts and Vimeo https://vimeo.com/album/2518991. It is argued that the digital space provides a ‘virtual contact zone’ in which diverse, unofficial and personal narratives can be presented together.},
	number = {5},
	urldate = {2023-05-24},
	journal = {International Journal of Heritage Studies},
	author = {Purkis, Harriet},
	month = may,
	year = {2017},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/13527258.2016.1190392},
	keywords = {Digital heritage, curation, local, people, virtual exhibition},
	pages = {434--444},
}

@article{paliokas_gamified_2020,
	title = {A {Gamified} {Augmented} {Reality} {Application} for {Digital} {Heritage} and {Tourism}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/10/21/7868},
	doi = {10.3390/app10217868},
	abstract = {Although Augmented Reality (AR) technology has entered many market and knowledge domains such as games and leisure activities, it remains rather limited in digital heritage. After studying the potentiality of using modern AR elements in a museum context, this paper proposes the use of additional game and educational elements in the core AR application in order to enhance the overall on-the-spot museum visitor’s experience. An agile AR application design methodology was followed by taking into account the needs of small-to-medium sized real-world museums. Moreover, a heuristic evaluation protocol was applied by a group of experts in order to test the proof-of-concept AR application, in which some novel elements were proposed such as the AR quiz game. The main findings indicate that enhanced AR experiences in museum settings can make a nice fit with the user environment, physical and perceptual abilities, known metaphors, and user position and motion in 3D space. Moreover, AR services can be provided under a minimum distraction and physical effort. As a conclusion, AR technologies are mature enough to be standardized for museum usage, while the audience seems to be ready to take advantage of the related enhanced museum experiences to maximize both user satisfaction and learning outcomes.},
	language = {en},
	number = {21},
	urldate = {2023-05-24},
	journal = {Applied Sciences},
	author = {Paliokas, Ioannis and Patenidis, Athanasios T. and Mitsopoulou, Eirini E. and Tsita, Christina and Pehlivanides, George and Karyati, Elli and Tsafaras, Spyros and Stathopoulos, Evangelos A. and Kokkalas, Alexandros and Diplaris, Sotiris and Meditskos, Georgios and Vrochidis, Stefanos and Tasiopoulou, Eleana and Riggas, Christodoulos and Votis, Konstantinos and Kompatsiaris, Ioannis and Tzovaras, Dimitrios},
	month = jan,
	year = {2020},
	note = {Number: 21
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {museums, digital heritage, augmented reality, games, usability evaluation},
	pages = {7868},
	file = {Full Text PDF:files/4110/Paliokas et al. - 2020 - A Gamified Augmented Reality Application for Digit.pdf:application/pdf},
}

@article{were_digital_2014,
	title = {Digital {Heritage}, {Knowledge} {Networks}, and {Source} {Communities}: {Understanding} {Digital} {Objects} in a {Melanesian} {Society}},
	volume = {37},
	issn = {1548-1379},
	shorttitle = {Digital {Heritage}, {Knowledge} {Networks}, and {Source} {Communities}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/muan.12058},
	doi = {10.1111/muan.12058},
	abstract = {This article investigates digital heritage technologies from a Melanesian perspective. It explores—in the context of New Ireland, Papua New Guinea—the types of values placed on digital surrogates as a means to engage critically with recent debates on “digital” or “virtual” repatriation. It raises the question as to whether digital knowledge resources such as 3D digital objects are really seen as secondary or “second best” to the original or whether digital technologies reproduce, in new form, an economy of objects that sustains knowledge and revival practices. As a way to address this, the Mobile Museum pilot project was launched in January 2012 to help support the Nalik people of New Ireland reconnecting with and researching their cultural heritage in Queensland museums. This article demonstrates, in contrast to recent calls for an ideological return to the status of the museum object as put forward by Conn (2010), how ethnographic objects should be understood in terms of their performativity, mobility, and virtuality, which render them operative far beyond the physical realms of museum institutions. [digital heritage, digital repatriation, ethnographic collections, cultural revitalization, Melanesia]},
	language = {en},
	number = {2},
	urldate = {2023-05-24},
	journal = {Museum Anthropology},
	author = {Were, Graeme},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/muan.12058},
	pages = {133--143},
	file = {Full Text PDF:files/4114/Were - 2014 - Digital Heritage, Knowledge Networks, and Source C.pdf:application/pdf;Snapshot:files/4115/muan.html:text/html},
}

@article{he_digital_2017,
	title = {“{DIGITAL} {HERITAGE}” {THEORY} {AND} {INNOVATIVE} {PRACTICE}},
	volume = {XLII-2-W5},
	issn = {1682-1750},
	url = {https://isprs-archives.copernicus.org/articles/XLII-2-W5/335/2017/isprs-archives-XLII-2-W5-335-2017.html},
	doi = {10.5194/isprs-archives-XLII-2-W5-335-2017},
	abstract = {“Digital heritage”, as defined in this paper, is the integration of cultural heritage with digitization technology (“cultural heritage + digitization”), and of digital knowledge with research. It includes not only the three conventional aspects of cultural heritage digitization—digital collection and documentation, digital research and information management, digital presentation and interpretation—but also the creation and innovative use/application of the digital content (cultural heritage intellectual property/IP, experiential education, cultural tourism, film and media). Through analysis of two case studies, the Palazzo Valentini in Rome, Italy, and the Old Summer Palace (Yuanmingyuan) in Beijing, China, the paper assesses the concept of “digital heritage” and proposes a conceptual framework to capture recent developments and future prospects with regard to the industry.},
	language = {English},
	urldate = {2023-05-24},
	journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {He, Y. and Ma, Y. H. and Zhang, X. R.},
	month = aug,
	year = {2017},
	note = {Conference Name: ICOMOS/ISPRS International Scientific Committee on Heritage Documentation (CIPA) {\textless}br{\textgreater} 26th International CIPA Symposium \&ndash; Digital Workflows for Heritage Conservation (Volume XLII-2/W5) - 28 August\&ndash;1 September 2017, Ottawa, Canada
Publisher: Copernicus GmbH},
	keywords = {cultural heritage, Digital heritage, “Digital Yuanmingyuan”, digitization, innovative practice},
	pages = {335--342},
	file = {Full Text PDF:files/4117/He et al. - 2017 - “DIGITAL HERITAGE” THEORY AND INNOVATIVE PRACTICE.pdf:application/pdf},
}

@misc{noauthor_amphiboly_nodate,
	title = {Amphiboly of {Digital} {Heritage}},
	url = {https://ieeexplore.ieee.org/abstract/document/7419582/},
	abstract = {Digital Heritage is twofold in nature. There is rigid and actual heritage value as well as the freedom of digitality. Fusing the two adds a new layer to the authenticity issue prevalent in heritage studies. Within the context of our research of Kashgar, we confront three sub-layers to discuss authenticity. They are dichotomies between self-other (identity), topophilia-topophobia (place) and unilateral-plural perceptions (time). Our research interrogates these in relation to the people of Kashgar via digital applications. The approach taken is led by a Research through Design (RtD) approach which focuses on immediate user experiences through game design methods. The game is to produce feedback and data for understanding how creative digital media applications can enforce contestation for a plural and rich outcome instead of unilateral which contemporary digital media applications prevalently fall victim of.},
	language = {en-US},
	urldate = {2023-05-24},
	file = {Snapshot:files/4119/7419582.html:text/html},
}

@article{pietroni_virtual_2021,
	title = {Virtual {Restoration} and {Virtual} {Reconstruction} in {Cultural} {Heritage}: {Terminology}, {Methodologies}, {Visual} {Representation} {Techniques} and {Cognitive} {Models}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2078-2489},
	shorttitle = {Virtual {Restoration} and {Virtual} {Reconstruction} in {Cultural} {Heritage}},
	url = {https://www.mdpi.com/2078-2489/12/4/167},
	doi = {10.3390/info12040167},
	abstract = {Today, the practice of making digital replicas of artworks and restoring and recontextualizing them within artificial simulations is widespread in the virtual heritage domain. Virtual reconstructions have achieved results of great realistic and aesthetic impact. Alongside the practice, a growing methodological awareness has developed of the extent to which, and how, it is permissible to virtually operate in the field of restoration, avoid a false sense of reality, and preserve the reliability of the original content. However, there is not yet a full sharing of meanings in virtual restoration and reconstruction domains. Therefore, this article aims to clarify and define concepts, functions, fields of application, and methodologies. The goal of virtual heritage is not only producing digital replicas. In the absence of materiality, what emerges as a fundamental value are the interaction processes, the semantic values that can be attributed to the model itself. The cognitive process originates from this interaction. The theoretical discussion is supported by exemplar case studies carried out by the authors over almost twenty years. Finally, the concepts of uniqueness and authenticity need to be again pondered in light of the digital era. Indeed, real and virtual should be considered as a continuum, as they exchange information favoring new processes of interaction and critical thinking.},
	language = {en},
	number = {4},
	urldate = {2023-05-24},
	journal = {Information},
	author = {Pietroni, Eva and Ferdani, Daniele},
	month = apr,
	year = {2021},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {virtual museum, authenticity, virtual heritage, cognitive processes in cultural heritage, interaction, reliability, virtual reconstruction, virtual restoration},
	pages = {167},
	file = {Full Text PDF:files/4121/Pietroni e Ferdani - 2021 - Virtual Restoration and Virtual Reconstruction in .pdf:application/pdf},
}

@article{munster_digital_2021,
	title = {Digital topics on cultural heritage investigated: how can data-driven and data-guided methods support to identify current topics and trends in digital heritage?},
	volume = {5},
	issn = {2662-6802},
	shorttitle = {Digital topics on cultural heritage investigated},
	url = {https://doi.org/10.1186/s43238-021-00045-7},
	doi = {10.1186/s43238-021-00045-7},
	abstract = {In research and policies, the identification of trends as well as emerging topics and topics in decline is an important source of information for both academic and innovation management. Since at present policy analysis mostly employs qualitative research methods, the following article presents and assesses different approaches – trend analysis based on questionnaires, quantitative bibliometric surveys, the use of computer-linguistic approaches and machine learning and qualitative investigations. Against this backdrop, this article examines digital applications in cultural heritage and, in particular, built heritage via various investigative frameworks to identify topics of relevance and trendlines, mainly for European Union (EU)-based research and policies. Furthermore, this article exemplifies and assesses the specific opportunities and limitations of the different methodical approaches against the backdrop of data-driven vs. data-guided analytical frameworks. As its major findings, our study shows that both research and policies related to digital applications for cultural heritage are mainly driven by the availability of new technologies. Since policies focus on meta-topics such as digitisation, openness or automation, the research descriptors are more granular. In general, data-driven approaches are promising for identifying topics and trendlines and even predicting the development of near future trends. Conversely, qualitative approaches are able to answer “why” questions with regard to whether topics are emerging due to disruptive innovations or due to new terminologies or whether topics are becoming obsolete because they are common knowledge, as is the case for the term “internet”.},
	language = {en},
	number = {1},
	urldate = {2023-05-24},
	journal = {Built Heritage},
	author = {Münster, Sander and Utescher, Ronja and Ulutas Aydogan, Selda},
	month = dec,
	year = {2021},
	keywords = {NLP, Digital heritage, Survey, Bibliometrics, Policies, Qualitative assessment, Research topics},
	pages = {25},
	file = {Full Text PDF:files/4123/Münster et al. - 2021 - Digital topics on cultural heritage investigated .pdf:application/pdf},
}

@book{cazzaro_shared_2023,
	title = {A shared terminology for hypothetical {3D} digital reconstructions in the field of {Cultural} {Heritage}},
	abstract = {Working in synergy with experts coming not only from different fields (computer scientists, archaeologists, historians...), but also from different countries, thus speaking a variety of languages, is very often essential in the field of digital 3D reconstructions for cultural heritage, for heuristic rather than entertainment purposes. This inevitably leads to the comparison of different methods and workflows, each of which is based on its own terminology. Therefore, comparing the terms that are used, following their evolution and, to some extent, attempting to standardise them is a prerequisite for making the reconstruction as objective and reproducible as possible, qualities that are of prime importance especially when the goal is the publication of results in online platforms, so that they are accessible and comprehensible to a wide audience of interested users. Terminology is only one of the open problems in the field of digital 3D reconstructions, which, as is well known, also faces issues related, for instance, to different software and file formats, or even to data storage and to the platforms used to share them. These problems, however, can hardly be tackled without a shared terminology and methodology, which should be the basis of any 3D digital reconstruction used to disseminate (and potentially enrich with new discoveries) cultural heritage, especially when it comes to hypothetical reconstructions of artefacts that have been destroyed or have never been built. In this case, the dialogue between experts is a central element and it is therefore clear why, first of all, it is necessary to agree on the terms that are used. This study aims to analyse some of the most frequent ones in this sense, especially those relating to the certainty and reliability of a reconstruction, whose data model becomes a social and cultural object that we cannot ignore.},
	author = {Cazzaro, Irene},
	month = feb,
	year = {2023},
	file = {Full Text PDF:files/4126/Cazzaro - 2023 - A shared terminology for hypothetical 3D digital r.pdf:application/pdf},
}

@incollection{sayers_relationships_2018,
	address = {New York : Routledge, Taylor \& Francis Group, 2018.},
	edition = {1},
	title = {Relationships, {Not} {Records}},
	isbn = {978-1-315-73047-9},
	url = {https://www.taylorfrancis.com/books/9781317549093/chapters/10.4324/9781315730479-42},
	language = {en},
	urldate = {2023-05-24},
	booktitle = {The {Routledge} {Companion} to {Media} {Studies} and {Digital} {Humanities}},
	publisher = {Routledge},
	author = {Christen, Kimberly},
	editor = {Sayers, Jentery},
	month = may,
	year = {2018},
	doi = {10.4324/9781315730479-42},
	pages = {403--412},
	file = {Christen - 2018 - Relationships, Not Records.pdf:files/4130/Christen - 2018 - Relationships, Not Records.pdf:application/pdf},
}

@article{borrego_measuring_2020,
	title = {Measuring the {Impact} of {Digital} {Heritage} {Collections} {Using} {Google} {Scholar}},
	volume = {39},
	copyright = {Copyright (c) 2020 Ángel Borrego},
	issn = {2163-5226},
	url = {https://ejournals.bc.edu/index.php/ital/article/view/12053},
	doi = {10.6017/ital.v39i2.12053},
	abstract = {This study aimed to measure the impact of digital heritage collections by analysing the citations received in scholarly outputs. Google Scholar was used to retrieve the scholarly outputs citing Memòria Digital de Catalunya (MDC), a cooperative, open-access repository containing digitized collections related to Catalonia and its heritage. The number of documents citing MDC has grown steadily since the creation of the repository in 2006. Most citing documents are scholarly outputs in the form of articles, proceedings and monographs, and academic theses and dissertations. Citing documents mainly pertain to the humanities and the social sciences and are in local languages. The most cited MDC collection contains digitized ancient Catalan periodicals. The study shows that Google Scholar is a suitable tool for providing evidence of the scholarly impact of digital heritage collections. Google Scholar indexes the full-text of documents, facilitating the retrieval of citations inserted in the text or in sections that are not the final list of references. It also indexes document types, such as theses and dissertations, which contain a significant share of the citations to digital heritage collections.},
	language = {en},
	number = {2},
	urldate = {2023-05-24},
	journal = {Information Technology and Libraries},
	author = {Borrego, Ángel},
	month = jun,
	year = {2020},
	note = {Number: 2},
	file = {Full Text PDF:files/4133/Borrego - 2020 - Measuring the Impact of Digital Heritage Collectio.pdf:application/pdf},
}

@article{cook_digital_2019,
	title = {Digital {Heritage} as {Collaborative} {Process}: {Fostering} {Partnerships}, {Engagement} and {Inclusivity}},
	volume = {3},
	copyright = {Copyright (c) 2019 Katherine Cook, Genevieve Hill},
	issn = {2574-1748},
	shorttitle = {Digital {Heritage} as {Collaborative} {Process}},
	url = {https://scholarworks.iu.edu/journals/index.php/sdh/article/view/25297},
	doi = {10.14434/sdh.v3i1.25297},
	abstract = {This paper examines the importance of the process of collaboration and community engagement in developing and applying digital heritage resources. It draws on case studies from the authors’ experiences building partnerships between a university’s anthropology undergraduate program and a provincial museum to teach community-engaged applied digital heritage. The process of creating and using digital technologies in heritage environments were transformative for not only students but also professional archaeologists and communities, highlighting the meaningful engagement and understandings that are developed through collaborative making. However, it also highlighted the challenges facing these types of collaborations, including academic and heritage structures, digital preservation/management, and ethics and inclusivity in digitization projects.},
	language = {en},
	number = {1},
	urldate = {2023-05-24},
	journal = {Studies in Digital Heritage},
	author = {Cook, Katherine and Hill, Genevieve},
	month = aug,
	year = {2019},
	note = {Number: 1},
	keywords = {Higher Education},
	pages = {83--99},
	file = {Full Text PDF:files/4135/Cook e Hill - 2019 - Digital Heritage as Collaborative Process Fosteri.pdf:application/pdf},
}

@incollection{van_der_werf_documentary_2020,
	address = {Cham},
	series = {Heritage {Studies}},
	title = {Documentary {Heritage} in the {Digital} {Age}: {Born} {Digital}, {Being} {Digital}, {Dying} {Digital}},
	isbn = {978-3-030-18441-4},
	shorttitle = {Documentary {Heritage} in the {Digital} {Age}},
	url = {https://doi.org/10.1007/978-3-030-18441-4_12},
	abstract = {With connectivity spreading across the globe, online culture is becoming globally predominant, and the expanding digital universe is turning into the most powerful human memory-recording machine of all time. Never before in history was there a chance to capture our lives – from the ordinary to the extraordinary – so completely and accurately. Never was there a time when documentary heritage could reflect such a rich, high-fidelity memory of the peoples of the world. Drawing on earlier essays about digital preservation and the nature of digital heritage, the authors argue that preserving an externalised, high-fidelity digital memory is feasible and that it will give future generations the liberty to decide what is of value to them, instead of us doing that and introducing bias in the digital heritage. They observe that much in the digital universe is transient because it is not taken care of intentionally. For too long has the need for a digital memory in this space been ignored – both the ability to keep digital information for short-term memory purposes and the commitment to safeguard digital legacy in the longer term. With examples of digital archiving initiatives, such as the Internet archive, the Twitter archive and e-government archives, the authors point to some of the weaknesses and propose to fully archive digital live ecosystems in real time, as cultural monuments.},
	language = {en},
	urldate = {2023-05-24},
	booktitle = {The {UNESCO} {Memory} of the {World} {Programme}: {Key} {Aspects} and {Recent} {Developments}},
	publisher = {Springer International Publishing},
	author = {van der Werf, Titia and van der Werf, Bram},
	editor = {Edmondson, Ray and Jordan, Lothar and Prodan, Anca Claudia},
	year = {2020},
	doi = {10.1007/978-3-030-18441-4_12},
	keywords = {Digital heritage, High-fidelity memory, Internet archive, Online culture, Selection, Twitter archive},
	pages = {175--189},
}

@incollection{jordan_terminology_2020,
	address = {Cham},
	series = {Heritage {Studies}},
	title = {Terminology and {Criteria} of the {UNESCO} {Memory} of the {World} {Programme}: {New} {Findings} and {Proposals} for {Research}},
	isbn = {978-3-030-18441-4},
	shorttitle = {Terminology and {Criteria} of the {UNESCO} {Memory} of the {World} {Programme}},
	url = {https://doi.org/10.1007/978-3-030-18441-4_20},
	abstract = {The chapter addresses questions of terminology and criteria of the UNESCO Memory of the World Programme (MoW) in the context of other UNESCO heritage programmes. It starts with reflecting shortly the term “heritage” and its derivations. The following sub-chapter presents novelties on the prehistory of MoW, namely on the introduction of its name, and on early relations between MoW and World Cultural and Natural Heritage. Finally, the chapter makes proposals for future research concentrating on the critical, contextual and comparative analysis of key terms and criteria of MoW and other heritage programmes. It proposes to put such research into the framework of comparative conceptual history and links such considerations to similar projects in the early years of UNESCO. To substantiate the need for such future research, the article chooses examples from the Guidelines (2002, see Edmondson, Memory of the World: general guidelines to safeguard documentary heritage [Doc. No: CII-95/WS-11rev], UNESCO, Paris, 2002) and the (Draft) Guidelines (2017, see MoW Guidelines Review Group, UNESCO Memory of the World Programme. General guidelines, approved text December, UNESCO, Paris, 2017) as basic texts.},
	language = {en},
	urldate = {2023-05-24},
	booktitle = {The {UNESCO} {Memory} of the {World} {Programme}: {Key} {Aspects} and {Recent} {Developments}},
	publisher = {Springer International Publishing},
	author = {Jordan, Lothar},
	editor = {Edmondson, Ray and Jordan, Lothar and Prodan, Anca Claudia},
	year = {2020},
	doi = {10.1007/978-3-030-18441-4_20},
	keywords = {Access, Conceptual history, Criteria, Heritage, Terminology},
	pages = {293--308},
}

@article{barzaghi_development_2020,
	title = {Development of an ontology for modelling medieval manuscripts: the case of {Progetto} {IRNERIO}},
	shorttitle = {Development of an ontology for modelling medieval manuscripts},
	number = {9},
	journal = {Umanistica Digitale},
	author = {Barzaghi, Sebastian and Palmirani, Monica and Peroni, Silvio},
	year = {2020},
	pages = {117--140},
}

@misc{noauthor_edizione_nodate,
	title = {‪{Edizione} nazionale delle opere di {Aldo} {Moro}‬},
	url = {https://scholar.google.it/citations?view_op=view_citation&hl=en&user=qyPA9IgAAAAJ&authuser=1&citation_for_view=qyPA9IgAAAAJ:9yKSN-GCB0IC},
	abstract = {‪S Barzaghi, F Paolucci, F Tomasi, F Vitali, A Gangemi…, 2021‬},
	urldate = {2023-05-24},
	file = {Snapshot:files/4141/citations.html:text/html},
}

@misc{noauthor_national_nodate,
	title = {‪{National} {Edition} of {Aldo} {Moro}'s works ({RDF} {Dataset})‬},
	url = {https://scholar.google.it/citations?view_op=view_citation&hl=en&user=qyPA9IgAAAAJ&authuser=1&citation_for_view=qyPA9IgAAAAJ:d1gkVwhDpl0C},
	abstract = {‪S Barzaghi, 2021‬},
	urldate = {2023-05-24},
	file = {Snapshot:files/4143/citations.html:text/html},
}

@misc{noauthor_vespasiano_nodate,
	title = {‪{Vespasiano} da {Bisticci}, {Lettere}. {Knowledge} {Base} 2020‬},
	url = {https://scholar.google.it/citations?view_op=view_citation&hl=en&user=qyPA9IgAAAAJ&authuser=1&citation_for_view=qyPA9IgAAAAJ:u-x6o8ySG0sC},
	abstract = {‪F Tomasi, M Daquino, S Barzaghi, 2020‬},
	urldate = {2023-05-24},
	file = {Snapshot:files/4145/citations.html:text/html},
}

@article{barzaghi_protocol_2021,
	title = {Protocol of the competitive audit for designing and developing the {National} {Edition} of {Aldo} {Moro}'s works},
	url = {https://www.protocols.io/view/protocol-of-the-competitive-audit-for-designing-an-bxbipike},
	abstract = {This work aims to define a series of reference models that would serve as a guide to the design and development of the National Edition of Aldo Moro's works. These models ha...},
	language = {en},
	urldate = {2023-05-24},
	author = {Barzaghi, Sebastian},
	month = aug,
	year = {2021},
	file = {Full Text PDF:files/4147/Barzaghi - 2021 - Protocol of the competitive audit for designing an.pdf:application/pdf},
}

@article{barzaghi_modellazione_2021,
	title = {La modellazione dei dati nell'{Edizione} {Nazionale} delle {Opere} di {Aldo} {Moro}},
	url = {https://zenodo.org/record/5144961},
	doi = {10.5281/zenodo.5144961},
	abstract = {L’Edizione nazionale delle opere di Aldo Moro è un’edizione critica, filologicamente avvertita e annotata, dei testi editi ed inediti dello statista, che punta non solo a fornire un prodotto culturale universalmente fruibile dai cittadini, ma anche a realizzare un nuovo standard per la ricerca nazionale e internazionale sulla comunicazione politica. L'Edizione è realizzata interamente su piattaforma digitale ed è interrogabile in modo selettivo secondo molteplici criteri differenti basati su elementi intertestuali e contestuali delle opere, individuati dai ricercatori che ne hanno curato l’annotazione e la metadatazione. L’obiettivo di questo documento è quello di descrivere il processo di modellazione dei dati dell’Edizione. In particolare, questo documento si concentra sulla presentazione dei modelli principalmente utilizzati per descrivere le informazioni testuali, contestuali, e bibliografiche delle opere. Sebbene si tratti di un processo di modellazione basato sulle particolari necessità informative del Comitato Scientifico e della comunità scientifica interessata alla vita e all’operato di Aldo Moro, altri individui possono beneficiare di questo documento, che definisce un esempio di modellazione concettuale facilmente replicabile anche in altri contesti accademici e progettuali.},
	language = {en},
	urldate = {2023-05-24},
	author = {Barzaghi, Sebastian},
	month = jul,
	year = {2021},
	file = {Full Text PDF:files/4154/Barzaghi - 2021 - La modellazione dei dati nell'Edizione Nazionale d.pdf:application/pdf},
}

@article{barzaghi_competitive_2021,
	title = {Competitive audit for designing and developing the {National} {Edition} of {Aldo} {Moro}'s works},
	url = {https://zenodo.org/record/5184721},
	doi = {10.5281/zenodo.5184721},
	abstract = {This work aims to define a series of reference models that would serve as a guide to the design and development of the National Edition of Aldo Moro's works. These models have been defined through a benchmarking process that is organized as follows: content analysis on a sample of 30 digital editions, evaluated on the basis of certain criteria defined in [Sahle 2014]; processing of the data gathered as a result of the content analysis, so as to extract the relevant information, and visualize it; review of the data processing results and consideration of the models that can be used as reference. The digital editions that meet the quality criteria taken into consideration are equipped with the following characteristics: their audience is composed of both domain experts and generic users; their documentation is rich and accurate; their content is described by a complete set of metadata; they and their single parts are citable and uniquely identifiable; their data model is geared towards interoperability and interlinking between its contents and the relevant resources already existing on the Web; they use visualization and storytelling tools so as to convey information intuitively; their information architecture is well-structured and easily navigated; their data and contents can be downloaded in many different formats; they take advantage of Open Source software and tools; finally, their contents are open and accessible to anyone.},
	language = {en},
	urldate = {2023-05-24},
	author = {Barzaghi, Sebastian},
	month = may,
	year = {2021},
	file = {Snapshot:files/4152/5184721.html:text/html},
}

@article{auddino_conformita_2019,
	title = {Conformità all'{Open} {Access} delle riviste pubblicate dall'{Università} di {Bologna}},
	url = {https://zenodo.org/record/3344898},
	doi = {10.5281/zenodo.3344898},
	abstract = {Questo documento presenta un'analisi delle 39 riviste scientifiche online, dichiarate Open Access, a disposizione attraverso la piattaforma gestita dal servizio AlmaDL Journals dell'Università di Bologna, al fine di verificarne la compatibilità con la Open Definition.},
	language = {en},
	urldate = {2023-05-24},
	author = {Auddino, Alessandra and Barzaghi, Sebastian and Bernabè, Anna and Cavestri, Daniele and Foschi, Alessandra and Franchi, Caterina and Heibi, Ivan and Mangialardo, Francesca and Mariani, Fabio and Peroni, Silvio and Spinaci, Gianmarco},
	month = jul,
	year = {2019},
}

@article{cavestri_protocollo_2019,
	title = {Protocollo di {Conformità} di {Riviste} {Scientifiche} all {Open} {Access}},
	url = {https://www.protocols.io/view/protocollo-di-conformit-di-riviste-scientifiche-al-5aag2ae},
	abstract = {Questo protocollo è stato utilizzato per indagare la legittimità della definizione “Open Access Scientific Journals” indicata per le riviste curate dai Dipartimenti e dai...},
	language = {en},
	urldate = {2023-05-24},
	author = {Cavestri, Daniele and Mangialardo, Francesca and Barzaghi, Sebastian and Peroni, Silvio},
	month = jul,
	year = {2019},
	file = {Full Text PDF:files/4156/Cavestri et al. - 2019 - Protocollo di Conformità di Riviste Scientifiche a.pdf:application/pdf},
}

@misc{barzaghi_national_2021,
	title = {National {Edition} of {Aldo} {Moro}'s works ({RDF} {Dataset})},
	url = {https://zenodo.org/record/5592157},
	doi = {10.5281/zenodo.5592157},
	abstract = {A Turtle file that contains structural, intertextual and contextual data about the National Edition of Aldo Moro's works.},
	urldate = {2023-05-24},
	publisher = {Zenodo},
	author = {Barzaghi, Sebastian},
	month = oct,
	year = {2021},
	keywords = {semantic web, digital humanities, digital edition, national edition of aldo moro's works, rdf, turtle},
	file = {Zenodo Snapshot:files/4158/5592157.html:text/html},
}

@misc{barzaghi_source_2021,
	title = {Source code for processing the {National} {Edition} of {Aldo} {Moro}'s works data},
	url = {https://zenodo.org/record/5592470},
	abstract = {A series of Python scripts that have been used to process the documents in the National Edition of Aldo Moro's works.  In particular, the scripts are: recast.py, for refactoring the documents code, correcting possible errors, normalizing and finalizing resource URIs, and so on; TEIfy.py, for generating TEI documents from the HTML code. The TEI structure imitates the source code as closely as possible, and in addition integrates bibliographic metadata in the document header as well; PDFfy.py, for generating PDF documents from the HTML code. The PDF pagination and visualization is regulated by a CSS stylesheet (stylesheet.css); generate.py, for converting metadata into semantic statements collected in a knowledge base and organized on the basis of the standards defined in the data modelling phase; align.py, for integrating document markup in the knowledge base; main.py, for gathering and managing the functions defined in the other scripts; utils.py, for choosing which script to run and in which local directory. To start the program, run `python main.py` in the command prompt, then select the function you want to run and the directory you intend to use. You will either need a `config.json` file containing some variables in order to make it work (such as your local paths and names of the directories), or write them directly into the code as variables.},
	urldate = {2023-05-24},
	publisher = {Zenodo},
	author = {Barzaghi, Sebastian},
	month = oct,
	year = {2021},
	doi = {10.5281/zenodo.5592470},
	note = {Language: eng},
	keywords = {semantic web, digital humanities, digital edition, national edition of aldo moro's works, data cleaning, data wrangling, python},
	file = {Zenodo Snapshot:files/4160/5592470.html:text/html},
}

@misc{barzaghi_source_2021-1,
	title = {Source code for {PDF} conversion of introductory essays in the {National} {Edition} of {Aldo} {Moro}'s works},
	url = {https://zenodo.org/record/5707527},
	abstract = {A Python script used to convert introductions and historical-critical notes, prepared by researchers and curators, into PDF files. The `stylesheet.css` file is used to define the style of the PDF output. You will either need a `config.json` file containing some variables in order to make it work (such as your local path and the name of the directory containing the HTML essays), or write them directly into the code as variables.},
	urldate = {2023-05-24},
	publisher = {Zenodo},
	author = {Barzaghi, Sebastian},
	month = nov,
	year = {2021},
	doi = {10.5281/zenodo.5707527},
	keywords = {digital humanities, digital edition, national edition of aldo moro's works, python},
	file = {Zenodo Snapshot:files/4162/5707527.html:text/html},
}

@article{barzaghi_controlled_2021,
	title = {Controlled vocabulary of {Aldo} {Moro}'s roles},
	url = {https://zenodo.org/record/5653547},
	doi = {10.5281/zenodo.5653547},
	abstract = {A SKOS controlled vocabulary of the possible roles assumed by Aldo Moro during his lifetime. https://www.w3id.org/moro/voc/roles/ is the namespace of the vocabulary. Its preferred prefix is `mrv`. The naming convention `\{prefix\}:\{element\}\{number\}` does not strictly convey meaning per se, but it has been followed to avoid excessively long URIs. In order to understand the meaning of any concept, please refer to its respective documentation properties, such as `skos:prefLabel`. The vocabulary imports the Publication Roles Ontology (PRO, http://purl.org/spar/pro), in order to take advantage of its classes and properties, by aligning the class `mrv:Role` as a subclass of `pro:Role`.},
	urldate = {2023-05-24},
	author = {Barzaghi, Sebastian},
	month = nov,
	year = {2021},
	note = {Publisher: Zenodo},
	keywords = {semantic web, digital humanities, digital edition, national edition of aldo moro's works, controlled vocabulary, knowledge organization, skos},
	file = {Zenodo Snapshot:files/4164/5653547.html:text/html},
}

@article{barzaghi_controlled_2021-1,
	title = {Controlled vocabulary of {Aldo} {Moro}'s works subjects},
	url = {https://zenodo.org/record/5653557},
	doi = {10.5281/zenodo.5653557},
	abstract = {A SKOS controlled vocabulary of the possible subjects covered in Aldo Moro's works. https://www.w3id.org/moro/voc/subjects/ is the namespace of the vocabulary. Its preferred prefix is `msv`. The naming convention `\{prefix\}:\{element\}\{number\}` does not strictly convey meaning per se, but it has been followed to avoid excessively long URIs. In order to understand the meaning of any concept, please refer to its respective documentation properties, such as `skos:prefLabel`.},
	urldate = {2023-05-24},
	author = {Barzaghi, Sebastian},
	month = nov,
	year = {2021},
	note = {Publisher: Zenodo},
	keywords = {semantic web, digital humanities, digital edition, national edition of aldo moro's works, controlled vocabulary, knowledge organization, skos},
	file = {Zenodo Snapshot:files/4166/5653557.html:text/html},
}

@article{barzaghi_controlled_2021-2,
	title = {Controlled vocabulary of {Aldo} {Moro}'s works types},
	url = {https://zenodo.org/record/5653608},
	doi = {10.5281/zenodo.5653608},
	abstract = {A SKOS controlled vocabulary of the possible document types of Aldo Moro's works. https://www.w3id.org/moro/voc/types/ is the namespace of the vocabulary. Its preferred prefix is `mtv`. The naming convention `\{prefix\}:\{element\}\{number\}` does not strictly convey meaning per se, but it has been followed to avoid excessively long URIs. In order to understand the meaning of any concept, please refer to its respective documentation properties, such as `skos:prefLabel`.},
	urldate = {2023-05-24},
	author = {Barzaghi, Sebastian},
	month = nov,
	year = {2021},
	note = {Publisher: Zenodo},
	keywords = {semantic web, digital humanities, digital edition, national edition of aldo moro's works, controlled vocabulary, knowledge organization, skos},
	file = {Zenodo Snapshot:files/4168/5653608.html:text/html},
}

@misc{barzaghi_source_2021-2,
	title = {Source code for generating the {National} {Edition} of {Aldo} {Moro}'s works {DOIs}},
	url = {https://zenodo.org/record/5651219},
	abstract = {A collection of the source codes used to automatically register the Digital Object Identifiers of the works published on the National Edition of Aldo Moro's works. The software connects to both an external MongoDB database and the DataCite API in order to assign to each document its respective DOI and register it on DataCite Fabrica. To start the program, fill in the blanks in the code (marked with '@') accordingly, then run `python doifier.py` in the command prompt, and select the HTTP method to run.},
	urldate = {2023-05-24},
	publisher = {Zenodo},
	author = {Barzaghi, Sebastian},
	month = nov,
	year = {2021},
	doi = {10.5281/zenodo.5651219},
	note = {Language: eng},
	keywords = {digital edition, national edition of aldo moro's works, python, datacite, digital object identifier},
	file = {Zenodo Snapshot:files/4170/5651219.html:text/html},
}

@misc{barzaghi_benchmark_2021,
	title = {Benchmark {Dataset} for designing and developing the {National} {Edition} of {Aldo} {Moro}'s works},
	url = {https://zenodo.org/record/4779123},
	doi = {10.5281/zenodo.4779123},
	abstract = {The dataset collects a series of values associated with a sample of 30 digital editions, and based on some evaluation criteria for reviewing scholarly digital editions compiled by Patrick Sahle in collaboration with Georg Voegler and IDE (Institut für Dokumentologie und Editorik) members (Sahle 2014). In particular, the aspects that have been taken into consideration during the evaluation process are the following: Documentation (Documentation, Scholarly objectives, Mission focusing on the objectives, Documentation and associated texts); Audience (Mission, focusing on the audience); Representation (Representation of documents and texts); Data model (Data modelling); Browse; Search; Indices; Quality of the presentation; Metadata (Metadata for description of and interlinkage between objects in the edition); Identification (Identification and citation); Formats (Spin offs and export formats); OS-OA (Access to basic data, Rights and licences); Additional features; Each aspect (except for Audience and Data model) has been given a score between 0, 0.5, and 1, where: 0 represents a value that witnesses either the total absence or the lack of quality of the edition in terms of that specific aspect; 0.5 represents a value that witnesses a suboptimal implementation of that specific aspect in the edition; 1 represents a value that witnesses an optimal implementation of that specific aspect in the edition.},
	language = {eng},
	urldate = {2023-05-24},
	publisher = {Zenodo},
	author = {Barzaghi, Sebastian},
	month = may,
	year = {2021},
	keywords = {digital humanities, benchmark, digital editions},
	file = {Zenodo Snapshot:files/4172/4779123.html:text/html},
}

@incollection{barbuti_alla_2019,
	title = {Alla ricerca dell’arca perduta. {Ovvero}: dov’è il digital cultural heritage?},
	isbn = {978-88-905077-8-6},
	shorttitle = {Alla ricerca dell’arca perduta. {Ovvero}},
	url = {https://doi.org/10.26314/GARR-Conf18-proceedings-05},
	abstract = {L’identificazione del digital cultural heritage (DCH) asserita nell’art. 2 delle Conclusioni del Consiglio dell'UE del 21 maggio 2014 sul Patrimonio culturale come risorsa strategica per un'Europa sostenibile (2014 / C 183/08) rende indispensabile ripensare i processi di digitalizzazione e di co-creazione digitale, al fine di individuare approcci e metodi che consentano di individuare cosa e quanto possa essere riconoscibile come patrimonio culturale tra le risorse digitali create fino a oggi e in produzione.},
	language = {it},
	urldate = {2023-05-24},
	booktitle = {Conferenza {GARR}\_18 {Selected} papers},
	publisher = {GARR},
	author = {Barbuti, Nicola and Ferilli, Stefano},
	year = {2019},
	file = {Barbuti e Ferilli - 2019 - Alla ricerca dell’arca perduta. Ovvero dov’è il d.pdf:files/4173/Barbuti e Ferilli - 2019 - Alla ricerca dell’arca perduta. Ovvero dov’è il d.pdf:application/pdf},
}

@article{de_lusenet_tending_2007,
	title = {Tending the {Garden} or {Harvesting} the {Fields}: {Digital} {Preservation} and the {UNESCO} {Charter} on the {Preservation} of the {Digital} {Heritage}},
	copyright = {Copyright 2007 Board of Trustees of the University of Illinois},
	issn = {0024-2594},
	shorttitle = {Tending the {Garden} or {Harvesting} the {Fields}},
	url = {https://hdl.handle.net/2142/3780},
	abstract = {The UNESCO Charter on the Preservation of Digital Heritage,
adopted in October 2003, is important for affirming the role of
(national) heritage institutions and extending existing systems for
preservation of documentary heritage to cover digital materials. This
approach has distinct advantages, but has also been criticized for taking
too narrow a view of the dynamic diversity of the digital environment,
particularly as found on the Web. To understand what digital
heritage is, it is useful to look at the current debate on preservation
of intangible heritage, as both share a number of characteristics.
The charter is examined in the context of UNESCO programs on
culture to indicate its relevance for UNESCO’s mission and to point
to political aspects of digital preservation that cannot be ignored.},
	language = {en},
	urldate = {2023-05-24},
	author = {de Lusenet, Yola},
	year = {2007},
	note = {Publisher: Johns Hopkins University Press and the Graduate School of Library and Information Science. University of Illinois at Urbana-Champaign.},
	file = {Full Text PDF:files/4176/de Lusenet - 2007 - Tending the Garden or Harvesting the Fields Digit.pdf:application/pdf},
}

@techreport{noauthor_commission_2011,
	title = {Commission {Recommendation} of 27 {October} 2011 on the digitisation and online accessibility of cultural material and digital preservation},
	url = {http://data.europa.eu/eli/reco/2011/711/oj/eng},
	language = {en},
	urldate = {2023-05-24},
	month = oct,
	year = {2011},
	note = {Code Number: 283
Code: OJ L
Legislative Body: COM},
	file = {EUR-Lex HTML (EN):files/4181/HTML.html:text/html;EUR-Lex PDF (EN):files/4180/2011 - Commission Recommendation of 27 October 2011 on th.pdf:application/pdf},
}

@misc{noauthor_notitle_nodate-1,
	url = {https://unesdoc.unesco.org/ark:/48223/pf0000131787/PDF/131773eng.pdf.multi.nameddest=131787},
	urldate = {2023-05-24},
	file = {https\://unesdoc.unesco.org/ark\:/48223/pf0000131787/PDF/131773eng.pdf.multi.nameddest=131787:files/4183/131773eng.pdf.multi.html:text/html},
}

@article{barbuti_thinking_2021,
	title = {Thinking digital libraries for preservation as digital cultural heritage: by {R} to {R4} facet of {FAIR} principles},
	volume = {22},
	issn = {1432-1300},
	shorttitle = {Thinking digital libraries for preservation as digital cultural heritage},
	url = {https://doi.org/10.1007/s00799-020-00291-7},
	doi = {10.1007/s00799-020-00291-7},
	abstract = {The Art. 2 of the UE Council conclusions of 21 May 2014 on cultural heritage as a strategic resource for a sustainable Europe (2014/C 183/08) states: “Cultural heritage consists of the resources inherited from the past in all forms and aspects—tangible, intangible and digital (born digital and digitized), including monuments, sites, landscapes, skills, practices, knowledge and expressions of human creativity, as well as collections conserved and managed by public and private bodies such as museums, libraries and archives”. Starting from this assumption, we have to rethink digital and digitization as social and cultural expressions of the contemporary age. We need to rethink digital libraries produced by digitization as cultural entities and no longer as mere dataset for enhancing fruition of cultural heritage, by defining clear and homogeneous criteria to validate and certify them as memory and sources of knowledge for future generations. By expanding R: Re-usable of the FAIR Guiding Principles for scientific data management and stewardship into R4: Re-usable, Relevant, Reliable and Resilient, this paper aims to propose a more reflective approach to creation of descriptive metadata for managing digital resource of cultural heritage, which can guarantee their long term preservation.},
	language = {en},
	number = {3},
	urldate = {2023-05-24},
	journal = {International Journal on Digital Libraries},
	author = {Barbuti, Nicola},
	month = sep,
	year = {2021},
	keywords = {Digital libraries, Metadata, Digital cultural heritage, R4, Re-usable, Relevant, Reliable, Resilient},
	pages = {309--318},
	file = {Full Text PDF:files/4227/Barbuti - 2021 - Thinking digital libraries for preservation as dig.pdf:application/pdf},
}

@article{barbuti_creating_2020,
	title = {Creating {Digital} {Culture} by co-creation of {Digital} {Cultural} {Heritage}: the {Crowddreaming} living lab method},
	copyright = {Copyright (c) 2020 Nicola Barbuti, Giuliano De Felice, Annalisa Di Zanni, Paolo Russo, Altheo Valentini},
	issn = {2532-8816},
	shorttitle = {Creating {Digital} {Culture} by co-creation of {Digital} {Cultural} {Heritage}},
	url = {https://umanisticadigitale.unibo.it/article/view/9956},
	doi = {10.6092/issn.2532-8816/9956},
	abstract = {Since 2015, the Digital Cultural Heritage, Arts \&amp; Humanities School (DiCultHer) – an interdisciplinary network of over 70 Italian organizations including universities, research entities, cultural institutions and associations – has tested models to build soft skills required to co-create, manage, preserve and safeguard digital cultural heritage. This paper outlines the current state of advancement in the development of an innovative living lab methodology named The Art of Crowddreaming. Such methodology has been implemented within the network activities, and it has been proven to be able to engage innovators, researchers, schools of any grade and other societal actors as a community in the challenge to invent, co-design and build prototypes of cross-generational digital monuments. The methodology is illustrated by means of two case studies. Quintana 4D engaged schools of any grade in the City of Foligno in an trans-disciplinary effort to design, expand and manage the Museater of the Joust of Quintana. Heritellers engaged students of “F. De Sanctis” high school for classical studies in the City of Trani in the making of "CastleTrApp", a digital storytelling app and a Museater performance about the famous Swabian Castle of their City.},
	language = {en},
	number = {9},
	urldate = {2023-05-24},
	journal = {Umanistica Digitale},
	author = {Barbuti, Nicola and Felice, Giuliano De and Zanni, Annalisa Di and Russo, Paolo and Valentini, Altheo},
	month = dec,
	year = {2020},
	note = {Number: 9},
	keywords = {Theory U},
	pages = {19--34},
	file = {Full Text PDF:files/4229/Barbuti et al. - 2020 - Creating Digital Culture by co-creation of Digital.pdf:application/pdf},
}

@inproceedings{barbuti_digital_2018,
	address = {New York, NY, USA},
	series = {{DTUC} '18},
	title = {From {Digital} {Cultural} {Heritage} to {Digital} {Culture}: {Evolution} in {Digital} {Humanities}},
	isbn = {978-1-4503-6451-5},
	shorttitle = {From {Digital} {Cultural} {Heritage} to {Digital} {Culture}},
	url = {https://doi.org/10.1145/3240117.3240142},
	doi = {10.1145/3240117.3240142},
	abstract = {The paper focuses on the need to rethink digital and digitization process for long term digital preservation, aiming to redefine them as the new Cultural Heritage of the contemporary era. This new way to observe digital artifacts and their co-creation process is the indispensable prerequisite for the growth of an aware Digital Culture and for giving due importance to digitization and dematerialisation realized starting by an approach focused on data preservation and, to this goal, on the decisive role that the descriptive metadata play. The case study was the digitization project of the "Historical Archive of the Giuseppe Laterza \& Figli Publishing House". In particular, the attention to preservation focused on structuring the schema of metadata and, above all, on descriptive writing, with regard to the choice of tags, elements and attributes, and to draft descriptive information of each digital artifact.},
	urldate = {2023-05-24},
	booktitle = {Proceedings of the 1st {International} {Conference} on {Digital} {Tools} \& {Uses} {Congress}},
	publisher = {Association for Computing Machinery},
	author = {Barbuti, Nicola},
	month = oct,
	year = {2018},
	keywords = {Metadata, Digital Cultural Heritage, Dematerialization, Digital Culture, Digitization},
	pages = {1--3},
}

@inproceedings{barbuti_creating_2020-1,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Creating {Digital} {Cultural} {Heritage} with {Open} {Data}: {From} {FAIR} to {FAIR5} {Principles}},
	isbn = {978-3-030-39905-4},
	shorttitle = {Creating {Digital} {Cultural} {Heritage} with {Open} {Data}},
	doi = {10.1007/978-3-030-39905-4_17},
	abstract = {The Art. 2 of the EU Council Conclusions of 21 May 2014 on cultural heritage as a strategic resource for a sustainable Europe (2014/C 183/08) states the existence of the new Digital Cultural Heritage (born digital and digitized). Starting from this assumption, we must rethink digitization, digitalization and digital transformation as recording and representing the processes of contemporary life cycles, no longer as simple tools to improve access to reality. So, we must define clear and homogeneous criteria to validate and certify what among contemporary digital magma we can identify as Digital Cultural Heritage (DCH). This paper outlines a proposal in such way starting from the extension of the R: Reusable requirement of FAIR Principles to R5 adding the requirements: Readable, Relevant, Reliable and Resilient. These requirements should lead the design and creation of descriptive metadata in open format for indexing and managing digital cultural resources. The Terra delle Gravine between sharing economy and experiential tourism project was a case study for testing this proposal. Three digital libraries of the municipal libraries of Massafra, Mottola and Grottaglie were designed and implemented by creating an open data schema for indexing and describing the digital resources.},
	language = {en},
	booktitle = {Digital {Libraries}: {The} {Era} of {Big} {Data} and {Data} {Science}},
	publisher = {Springer International Publishing},
	author = {Barbuti, Nicola},
	editor = {Ceci, Michelangelo and Ferilli, Stefano and Poggi, Antonella},
	year = {2020},
	keywords = {Digital Cultural Heritage, Relevant, Reliable, Resilient, Digitization, Born digital, Metadati descrittivi, R5, Readable, Reusable},
	pages = {173--181},
}

@article{marras_universita_nodate,
	title = {Università {Cattolica} del {Sacro} {Cuore}},
	language = {it},
	author = {Marras, Cristina and Passarotti, Marco and Franzini, Greta and Litta, Eleonora},
	file = {AIUCD_2020_volume_FINAL.pdf:files/4232/AIUCD_2020_volume_FINAL.pdf:application/pdf},
}

@article{barbuti_ripensare_2019,
	title = {Ripensare i formati, ripensare i metadati: prove “tecniche” di conservazione digitale},
	copyright = {Copyright (c) 2019},
	issn = {2532-8816},
	shorttitle = {Ripensare i formati, ripensare i metadati},
	url = {https://umanisticadigitale.unibo.it/article/view/9055},
	doi = {10.6092/issn.2532-8816/9055},
	abstract = {Digital Revolution brings the most complex challenge of contemporaneity. Digital has transformed the way to produce, transmit, share and interact with knowledge. Rethinking digital and digitization as social and cultural expressions of the contemporary era becomes unavoidable. This implies the need to rethink digital data as cultural entities produced by societies, and no longer as mere tools for simplifying administrative management or as virtual surrogates of analog cultural heritage. It is urgent to undertake serious policies aimed at ensuring the data preservation not only in theri formal aspects, but above all in their structural and descriptive contents which qualify and identify their creative and evolutionary processes: we have to assess data in their new role as witnesses of our processes evolution and as memory to be transferred to the future. The present contribution aims at proposing a structural redefinition of digital data, with the goal to renew their function and role as cultural resources by which the future generation will know the processes of contemporary digital age, entrusting metadata with the function of primary sources of information and knowledge to read, study, share and reuse.},
	language = {it},
	number = {5},
	urldate = {2023-05-24},
	journal = {Umanistica Digitale},
	author = {Barbuti, Nicola},
	month = may,
	year = {2019},
	note = {Number: 5},
	keywords = {digital cultural ecosystem},
	file = {Full Text PDF:files/4235/Barbuti - 2019 - Ripensare i formati, ripensare i metadati prove “.pdf:application/pdf},
}

@article{noauthor_digitalizzazione_2022,
	title = {Digitalizzazione e {Patrimonio} {Culturale} {Digitale} {\textbar} {AIDAinformazioni}},
	url = {https://www.aidainformazioni.it/index.php/aidainformazioni/article/view/20},
	abstract = {Since the beginning of the Digital Transformation, the eu has classified the Cultural Heritage into the three categories: tangible, intangible and digital, the latter declined in digitized and born digital. However, which requirements should characterizedigital for allowing us to identify it as cultural heritage is still an open issue. In Italy, both all the processes linked to the dt and the resources produced by these processes are confusedly identified as digitalizzazione. English language distinguishes digitizationand digitalization concepts for defining with the one the process for creating digital entities, with the other the innovation of administrative and business processes. Starting by clarifying the Italian digitalizzazione faced to English digitization both applied tocultural heritage, this paper aims to outline the requirements of digitization process for creating the new Digital Cultural Heritage. As case study we present the experience of the Victorian \&amp; Albert Museum of London.},
	language = {it-IT},
	urldate = {2023-05-24},
	month = aug,
	year = {2022},
}

@inproceedings{declerck_porting_2017,
	address = {New York, NY, USA},
	series = {{DATeCH2017}},
	title = {Porting past {Classification} {Schemes} for {Narratives} to a {Linked} {Data} {Framework}},
	isbn = {978-1-4503-5265-9},
	url = {https://dl.acm.org/doi/10.1145/3078081.3078105},
	doi = {10.1145/3078081.3078105},
	abstract = {In this paper we give an overview on a number of achieved and on-going efforts dealing with porting to the Linked Data framework electronic versions of past classification schemes in the field of folktale narratives. Three of those schemes are in the field of folktales, including: (1) the work by Vladimir Propp on the Morphology of the Folktale, (2) the Stith Thompson's Motif-Index of Folk-Literature, and (3) the Aarne-Thompson-Uther classification system of types of international folktales. We are recently also considering the work by Georges Polti on categorizing the dramatic situations ("The thirty-six Dramatic Situations"), enlarging thus our focus on folktales to other literary genres. Our aim is primarily to make those past schemes available in a formal representation system -- implemented as a set of integrated OWL ontologies -- in order to transform them in machine-readable data sets. This way, we are additionally supporting a cross-linking of distinct elements included in those influential classification schemes, and we are also able to populate the resulted integrated ontology with (elements of) stories.},
	urldate = {2023-05-25},
	booktitle = {Proceedings of the 2nd {International} {Conference} on {Digital} {Access} to {Textual} {Cultural} {Heritage}},
	publisher = {Association for Computing Machinery},
	author = {Declerck, Thierry and Schäfer, Lisa},
	month = jun,
	year = {2017},
	keywords = {Ontologies, Linked Data, Classification Schemes for Folktales},
	pages = {123--127},
	file = {Full Text PDF:files/4299/Declerck e Schäfer - 2017 - Porting past Classification Schemes for Narratives.pdf:application/pdf},
}

@article{pastor-sanchez_greek_nodate,
	title = {Greek {Mythology} as a {Knowledge} {Graph}: {From} {Chaos} to {Zeus} and {Beyond}},
	abstract = {Greek mythology has been exerting a lasting influence on Western culture, but a respective ontology has been missing from the Semantic Web until now. To remedy this deficiency, from 5377 Wikidata items with 283 properties, 34 of these properties were selected to generate a first version of an Ontology of Greek Mythology (OGM). This limited set of properties was used to define a set of classes to instantiate the descriptions of the individuals according to reification requirements. The ontology also includes the representation of contradictions between statements, a well-known symptom of classical storytelling. A retrieval tool was added to use the Wikidata Query Service through SPARQL queries in order to display and download results in various formats, thereby developing OGM into a scholarly tool. Further, as Wikidata has little information about classical sources grounding the truth of its statements, we tested a semantic enrichment workflow to extract additional statement types from source texts in the ‘Theoi Project’ as statement anchors. This workflow experiment proved necessary to go beyond Wikipedia to address mythological complexities in a knowledge graph, but, as discussed in the article, its scalable automation requires further development.},
	language = {en},
	author = {Pastor-Sánchez, Juan-Antonio and Kontopoulos, Efstratios and Saorín, Tomás and Bebis, Thomas},
	file = {Pastor-Sánchez et al. - Greek Mythology as a Knowledge Graph From Chaos t.pdf:files/4300/Pastor-Sánchez et al. - Greek Mythology as a Knowledge Graph From Chaos t.pdf:application/pdf},
}

@article{figa_enhancing_2004,
	title = {Enhancing the virtual storytelling experience with metadata driven voice enabled conversational agents},
	volume = {41},
	issn = {1550-8390},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/meet.1450410147},
	doi = {10.1002/meet.1450410147},
	abstract = {This paper describes a software component deployed as a Web service which enhances a user's online experience with a Virtual Storytelling Library through the use of voice-enabled Web-based conversational agents. The agents extract query answering information from story-specific XML/RDFmetadata files and expand its coverage through inferences based on a variety of knowledge sources like the WordNet, Open Mind and by metasearching the Web for topics matching the story's content.},
	language = {en},
	number = {1},
	urldate = {2023-05-25},
	journal = {Proceedings of the American Society for Information Science and Technology},
	author = {Figa, Elizabeth and Tarau, Paul and Ephraim, Jesse},
	year = {2004},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/meet.1450410147},
	pages = {403--410},
	file = {Full Text PDF:files/4303/Figa et al. - 2004 - Enhancing the virtual storytelling experience with.pdf:application/pdf},
}

@article{sartini_icon_2023,
	title = {{ICON}: an {Ontology} for {Comprehensive} {Artistic} {Interpretations}},
	issn = {1556-4673},
	shorttitle = {{ICON}},
	url = {https://dl.acm.org/doi/10.1145/3594724},
	doi = {10.1145/3594724},
	abstract = {In this work, we introduce ICON, an ontology that models artistic interpretations of artworks’ subject matter (i.e. iconographies) and meanings (i.e. symbols, iconological aspects). Developed by conceptualizing authoritative knowledge and notions taken from Panofsky’s levels of interpretation theory, ICON ontology focuses on the granularity of interpretations. It can be used to describe an interpretation of an artwork from the Pre-iconographical, Icongraphical, and Iconological levels. Its main classes have been aligned to ontologies that come from the domains of cultural descriptions (ArCo, CIDOC-CRM, VIR), semiotics (DOLCE), bibliometrics (CITO), and symbolism (Simulation Ontology), to grant a robust schema that can be extendable using additional classes and properties coming from these ontologies. The ontology was evaluated through competency questions that range from simple recognition on a specific level of interpretation to complex scenarios. Data written using this model was compared to state-of-the-art ontologies and schemas to both highlight the current lack of a domain-specific ontology on art interpretation and show how our work fills some of the current gaps. The ontology is openly available and compliant with FAIR principles. With our ontology, we hope to encourage digital art historians working for cultural institutions in making more detailed linked open data about the content of their artefacts, to exploit the full potential of Semantic Web in linking artworks through not only subjects and common metadata, but also specific symbolic interpretations, intrinsic meanings, and the motifs through which their subjects are represented. Additionally, by basing our work on theories made by different art history scholars in the last century, we make sure that their knowledge and studies will not be lost in the transition to the digital, linked open data era.},
	urldate = {2023-05-25},
	journal = {Journal on Computing and Cultural Heritage},
	author = {Sartini, Bruno and Baroncini, Sofia and van Erp, Marieke and Tomasi, Francesca and Gangemi, Aldo},
	month = apr,
	year = {2023},
	note = {Just Accepted},
	keywords = {cultural heritage, ontology, semantic web, art interpretation, iconography, iconology},
	file = {Full Text PDF:files/4305/Sartini et al. - 2023 - ICON an Ontology for Comprehensive Artistic Inter.pdf:application/pdf},
}

@book{uther_types_2004,
	address = {Helsinki},
	series = {{FF} communications no. 284-286},
	title = {The types of international folktales: a classification and bibliography, based on the system of {Antti} {Aarne} and {Stith} {Thompson}},
	isbn = {978-951-41-0955-3},
	shorttitle = {The types of international folktales},
	language = {eng},
	publisher = {Suomalainen Tiedeakatemia, Academia Scientiarum Fennica},
	author = {Uther, Hans-Jörg},
	collaborator = {{Folklore Fellows}},
	year = {2004},
	note = {HOLLIS number: 99153865918803941},
	keywords = {Bibliography, Classification, Folklore, History and criticism, Tales},
}

@book{uther_types_2011,
	address = {Helsinki},
	series = {{FF} communications no. 284-286},
	title = {The types of international folktales: a classification and bibliography, based on the system of {Antti} {Aarne} and {Stith} {Thompson}},
	isbn = {978-951-41-1054-2},
	shorttitle = {The types of international folktales},
	language = {eng},
	publisher = {Suomalainen Tiedeakatemia, Academia Scientiarum Fennica},
	author = {Uther, Hans-Jörg},
	collaborator = {{Folklore Fellows} and {Suomalainen Tiedeakatemia} and {Suomen Tiedeseura}},
	year = {2011},
	note = {HOLLIS number: 990096808860203941},
	keywords = {Bibliography, Classification, Folklore, History and criticism, Tales},
}

@article{uther_classifying_2009,
	title = {{CLASSIFYING} {TALES}: {REMARKS} {TO} {INDEXES} {AND} {SYSTEMS} {OF} {ORDERING}},
	language = {en},
	author = {Uther, Hans-Jörg},
	year = {2009},
	file = {Uther - 2009 - CLASSIFYING TALES REMARKS TO INDEXES AND SYSTEMS .pdf:files/4370/Uther - 2009 - CLASSIFYING TALES REMARKS TO INDEXES AND SYSTEMS .pdf:application/pdf},
}

@article{portales_digital_2018-1,
	title = {Digital {Cultural} {Heritage}},
	volume = {2},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2414-4088},
	url = {https://www.mdpi.com/2414-4088/2/3/58},
	doi = {10.3390/mti2030058},
	abstract = {n/a},
	language = {en},
	number = {3},
	urldate = {2023-05-27},
	journal = {Multimodal Technologies and Interaction},
	author = {Portalés, Cristina and Rodrigues, João M. F. and Rodrigues Gonçalves, Alexandra and Alba, Ester and Sebastián, Jorge},
	month = sep,
	year = {2018},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {n/a},
	pages = {58},
	file = {Full Text PDF:files/4373/Portalés et al. - 2018 - Digital Cultural Heritage.pdf:application/pdf},
}

@article{xu_ontology_nodate,
	title = {An {Ontology} {Model} for {Narrative} {Image} {Annotation} in the {Field} of {Cultural} {Heritage}},
	abstract = {Traditional event models couldn’t model temporal-spatial information very well in narrative image tagging task especially in the ﬁeld of culture heritage. In this paper, we design a narrative image annotation ontology (NIAO) model and tool (NIA) to address this issue by using ontology design patterns and other related vocabularies for reusability. The annotation model, combining with OAC (Open Annotation Collaboration) framework and regarding Plot as central class, makes a mapping between annotated image regions and high-level image semantics. It has been embedded in NIA which is designed based on html5 and applied in annotation task of narrative paintings successfully. This tool can record annotation region pixels and related property values according to NIAO, and these annotation data can be stored as various formats such as csv, json, and rdf. We have built a SPARQL endpoint, in which end users can make semantic queries based on these annotation data for visualization of the results with pictures rather than tables.},
	language = {en},
	author = {Xu, Lei and Meroo-Peuela, Albert and Huang, Zhisheng and van Harmelen, Frank},
	file = {Xu et al. - An Ontology Model for Narrative Image Annotation i.pdf:files/4374/Xu et al. - An Ontology Model for Narrative Image Annotation i.pdf:application/pdf},
}

@inproceedings{mulholland_storyscope_2015,
	address = {New York, NY, USA},
	series = {{WebSci} '15},
	title = {Storyscope: {Supporting} the authoring and reading of museum stories using online data sources},
	isbn = {978-1-4503-3672-7},
	shorttitle = {Storyscope},
	url = {https://dl.acm.org/doi/10.1145/2786451.2786462},
	doi = {10.1145/2786451.2786462},
	abstract = {Museum staff tell stories to assist visitor interpretation of artworks. Visitors also tell their own stories to articulate their understanding and opinion of artworks. Additional knowledge about the concepts mentioned or tagged in these stories can be found from online data sources. These could be used to assist reader interpretation or author development of stories. However, the potentially vast network of heterogeneous knowledge that can be created around the tags or annotations of a story could be bewildering for the story reader or author. Here we present Storyscope, a test-bed environment for the authoring, reading and semantic annotation of museum stories. The integration of online knowledge within the task of story authoring or interpretation is facilitated by mapping the available knowledge to a set of facts and simple events related to each story annotation. Narrative principles of theme and setting are used to discover and highlight aspects of the knowledge of potential value to the author or reader. Preliminary studies indicate the potential of the approach for providing a form of semantic navigation across stories and concepts having a better cognitive fit to story related tasks than existing forms of navigation.},
	urldate = {2023-05-27},
	booktitle = {Proceedings of the {ACM} {Web} {Science} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Mulholland, Paul and Wolff, Annika and Kilfeather, Eoin},
	month = jun,
	year = {2015},
	keywords = {Museums, digital storytelling, events, story settings, story themes},
	pages = {1--10},
	file = {Full Text PDF:files/4383/Mulholland et al. - 2015 - Storyscope Supporting the authoring and reading o.pdf:application/pdf},
}

@misc{niccolucci_heritage_2023-2,
	title = {The {Heritage} {Digital} {Twin}: a bicycle made for two. {The} integration of digital methodologies into cultural heritage research},
	shorttitle = {The {Heritage} {Digital} {Twin}},
	url = {http://arxiv.org/abs/2302.07138},
	doi = {10.48550/arXiv.2302.07138},
	abstract = {The paper concerns the definition of a novel ontology for cultural heritage based on the concept of digital twin. The ontology, called Heritage Digital Twin ontology, is a compatible extension of the well-known CIDOC CRM ISO standard for cultural heritage documentation and incorporates all the different documentation systems presently in use for cultural heritage documentation. In the authors' view, it supports documentation interoperability at a higher level than the ones currently in use and enables effective cooperation among different users.},
	urldate = {2023-05-27},
	publisher = {arXiv},
	author = {Niccolucci, Franco and Markhoff, Béatrice and Theodoridou, Maria and Felicetti, Achille and Hermon, Sorin},
	month = feb,
	year = {2023},
	note = {arXiv:2302.07138 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Information Retrieval, E.1, H.2.3, H.3.1, J.5},
	file = {arXiv Fulltext PDF:files/4388/Niccolucci et al. - 2023 - The Heritage Digital Twin a bicycle made for two..pdf:application/pdf;arXiv.org Snapshot:files/4389/2302.html:text/html},
}

@article{dragoni_knowledge_2017-1,
	title = {A {Knowledge} {Management} {Architecture} for {Digital} {Cultural} {Heritage}},
	volume = {10},
	issn = {1556-4673},
	url = {https://dl.acm.org/doi/10.1145/3012289},
	doi = {10.1145/3012289},
	abstract = {The increasing demand of technological facilities for galleries, museums, and archives has led to the need for designing practical and effective solutions for managing the digital life cycle of cultural heritage collections. These facilities have to support users in addressing several challenges directly related to the creation, management, preservation, and visualization of digital collections. Such challenges include, for example, the support for a collaborative management of the produced information, their curation from a multilingual perspective to break the language barriers and make collections available to different stakeholders, and the development of services for exposing structured version of data both to users and machines. Platforms satisfying all of these requirements have to support curators activities and, at the same time, provide facilities for engaging the virtual consumers of the produced data. In this article, we propose a description of an abstract architecture for managing digital collections built on a set of components, services, and APIs able to address the challenges mentioned previously. An instantiation of this architecture is discussed, and we present a use case concerning the management of a digital archive of verbo-visual art. Lessons learned from this experience are reported to outline future activities.},
	number = {3},
	urldate = {2023-05-27},
	journal = {Journal on Computing and Cultural Heritage},
	author = {Dragoni, Mauro and Tonelli, Sara and Moretti, Giovanni},
	month = jul,
	year = {2017},
	keywords = {curation, digital heritage, Knowledge management, services, visualization},
	pages = {15:1--15:18},
	file = {Full Text PDF:files/4392/Dragoni et al. - 2017 - A Knowledge Management Architecture for Digital Cu.pdf:application/pdf},
}

@article{ziku_digital_2020,
	title = {Digital {Cultural} {Heritage} and {Linked} {Data}: {Semantically}-informed conceptualisations and practices with a focus on intangible cultural heritage},
	volume = {30},
	copyright = {Copyright (c) 2020},
	issn = {2213-056X},
	shorttitle = {Digital {Cultural} {Heritage} and {Linked} {Data}},
	url = {https://liberquarterly.eu/article/view/10753},
	doi = {10.18352/lq.10315},
	abstract = {The emerging field of Linked Data for Digital Cultural Heritage presents new challenges and possibilities for memory institutions and the way they model their digital collections for open access. The essay reviews current semantically-informed practices and conceptualisations, standards and applied frameworks on this topic, with a focus on Intangible Cultural Heritage (ICH). In particular, the essay identifies and reviews the scope of applied frameworks for a semantically informed digital documentation of intangible cultural heritage by memory institutions, a topic with limited contributions in academic literature so far. The essay starts with an overview of the current digital transformation in the GLAM sector. Following a data centered approach, it analyses conceptual models of linked data in connection to digital heritage. It further reviews the working models and metadata schemas of linked data in particular for Intangible Cultural Heritage including innovative examples and finally, discusses challenges and new concepts for future research on the topic.},
	language = {en},
	number = {1},
	urldate = {2023-05-27},
	journal = {LIBER Quarterly: The Journal of the Association of European Research Libraries},
	author = {Ziku, Mariana},
	month = apr,
	year = {2020},
	note = {Number: 1},
	keywords = {digital cultural heritage},
	pages = {1--16},
	file = {Full Text PDF:files/4395/Ziku - 2020 - Digital Cultural Heritage and Linked Data Semanti.pdf:application/pdf},
}

@misc{noauthor_digital_2018,
	title = {Digital {Cultural} {Heritage} - {ICOM} {Italia}},
	url = {https://www.icom-italia.org/gruppo-ricerca-digital-cultural-heritage/},
	abstract = {E-mail: digital.cultural.IcomItalia@gmail.com Il Gruppo di ricerca Digital Cultural Heritage di ICOM Italia (DCH) nasce nel 2015 per valutare le opportunità e criticità del Web per le Istituzioni culturali. Il Digital Cultural Heritage è la nuova disciplina che esplora l’evoluzione del web per immaginare nuove forme di narrazione e di valorizzazione per i musei e},
	language = {it-IT},
	urldate = {2023-05-27},
	month = feb,
	year = {2018},
	file = {Snapshot:files/4400/gruppo-ricerca-digital-cultural-heritage.html:text/html},
}

@misc{noauthor_sulla_nodate,
	title = {Sulla riproduzione (digitale) dei beni culturali. {Il} {P}.{N}.{R}.{R}. per il ‘digital cultural heritage’ – {Amministrazione} in {Cammino}},
	url = {https://www.amministrazioneincammino.luiss.it/2022/11/23/sulla-riproduzione-digitale-dei-beni-culturali-il-p-n-r-r-per-il-digital-cultural-heritage/},
	language = {en-US},
	urldate = {2023-05-27},
	file = {Snapshot:files/4402/sulla-riproduzione-digitale-dei-beni-culturali-il-p-n-r-r-per-il-digital-cultural-heritage.html:text/html},
}

@article{barbuti_thinking_2021-1,
	title = {Thinking digital libraries for preservation as digital cultural heritage: by {R} to {R4} facet of {FAIR} principles},
	volume = {22},
	issn = {1432-1300},
	shorttitle = {Thinking digital libraries for preservation as digital cultural heritage},
	url = {https://doi.org/10.1007/s00799-020-00291-7},
	doi = {10.1007/s00799-020-00291-7},
	abstract = {The Art. 2 of the UE Council conclusions of 21 May 2014 on cultural heritage as a strategic resource for a sustainable Europe (2014/C 183/08) states: “Cultural heritage consists of the resources inherited from the past in all forms and aspects—tangible, intangible and digital (born digital and digitized), including monuments, sites, landscapes, skills, practices, knowledge and expressions of human creativity, as well as collections conserved and managed by public and private bodies such as museums, libraries and archives”. Starting from this assumption, we have to rethink digital and digitization as social and cultural expressions of the contemporary age. We need to rethink digital libraries produced by digitization as cultural entities and no longer as mere dataset for enhancing fruition of cultural heritage, by defining clear and homogeneous criteria to validate and certify them as memory and sources of knowledge for future generations. By expanding R: Re-usable of the FAIR Guiding Principles for scientific data management and stewardship into R4: Re-usable, Relevant, Reliable and Resilient, this paper aims to propose a more reflective approach to creation of descriptive metadata for managing digital resource of cultural heritage, which can guarantee their long term preservation.},
	language = {en},
	number = {3},
	urldate = {2023-05-27},
	journal = {International Journal on Digital Libraries},
	author = {Barbuti, Nicola},
	month = sep,
	year = {2021},
	keywords = {Digital libraries, Metadata, Digital cultural heritage, R4, Re-usable, Relevant, Reliable, Resilient},
	pages = {309--318},
	file = {Full Text PDF:files/4407/Barbuti - 2021 - Thinking digital libraries for preservation as dig.pdf:application/pdf},
}

@article{gillman_achieving_2023,
	title = {Achieving {Transparency}: {A} {Metadata} {Perspective}},
	volume = {5},
	issn = {2641-435X},
	shorttitle = {Achieving {Transparency}},
	url = {https://doi.org/10.1162/dint_a_00188},
	doi = {10.1162/dint_a_00188},
	abstract = {Transparency is vital to realizing the promise of evidenced-based policymaking, where “evidence-based” means including information as to what data mean and why they should be trusted. Transparency, in turn, requires that enough of this information is provided. Loosely speaking then, transparency is achieved when sufficient documentation is provided. Sufficiency is situation specific, both for the provider and consumer of the documentation. These ideas are presented in two recent US commissioned reports: The Promise of Evidence-Based Policymaking and Transparency in Statistical Information for the National Center for Science and Engineering Statistics and All Federal Statistical Agencies.Metadata are a more formalized kind of documentation, and in this paper, we provide and demonstrate necessary, sufficient, and general conditions for achieving transparency from the metadata perspective: conforming to a specification, providing quality metadata, and creating a usable interface to the metadata. These conditions are important for any metadata system, but here the specification is tied to our framework for metadata quality based on the situation-specific needs for transparency. These ideas are described, and their interrelationships are explored.},
	number = {1},
	urldate = {2023-05-27},
	journal = {Data Intelligence},
	author = {Gillman, Daniel},
	month = mar,
	year = {2023},
	pages = {261--274},
	file = {Full Text PDF:files/4413/Gillman - 2023 - Achieving Transparency A Metadata Perspective.pdf:application/pdf},
}

@misc{akoury_storium_2020,
	title = {{STORIUM}: {A} {Dataset} and {Evaluation} {Platform} for {Machine}-in-the-{Loop} {Story} {Generation}},
	shorttitle = {{STORIUM}},
	url = {http://arxiv.org/abs/2010.01717},
	doi = {10.48550/arXiv.2010.01717},
	abstract = {Systems for story generation are asked to produce plausible and enjoyable stories given an input context. This task is underspecified, as a vast number of diverse stories can originate from a single input. The large output space makes it difficult to build and evaluate story generation models, as (1) existing datasets lack rich enough contexts to meaningfully guide models, and (2) existing evaluations (both crowdsourced and automatic) are unreliable for assessing long-form creative text. To address these issues, we introduce a dataset and evaluation platform built from STORIUM, an online collaborative storytelling community. Our author-generated dataset contains 6K lengthy stories (125M tokens) with fine-grained natural language annotations (e.g., character goals and attributes) interspersed throughout each narrative, forming a robust source for guiding models. We evaluate language models fine-tuned on our dataset by integrating them onto STORIUM, where real authors can query a model for suggested story continuations and then edit them. Automatic metrics computed over these edits correlate well with both user ratings of generated stories and qualitative feedback from semi-structured user interviews. We release both the STORIUM dataset and evaluation platform to spur more principled research into story generation.},
	urldate = {2023-05-27},
	publisher = {arXiv},
	author = {Akoury, Nader and Wang, Shufan and Whiting, Josh and Hood, Stephen and Peng, Nanyun and Iyyer, Mohit},
	month = oct,
	year = {2020},
	note = {arXiv:2010.01717 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
	file = {arXiv Fulltext PDF:files/4418/Akoury et al. - 2020 - STORIUM A Dataset and Evaluation Platform for Mac.pdf:application/pdf;arXiv.org Snapshot:files/4419/2010.html:text/html},
}

@article{kim_visualizing_2018,
	title = {Visualizing {Nonlinear} {Narratives} with {Story} {Curves}},
	volume = {24},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2017.2744118},
	abstract = {In this paper, we present story curves, a visualization technique for exploring and communicating nonlinear narratives in movies. A nonlinear narrative is a storytelling device that portrays events of a story out of chronological order, e.g., in reverse order or going back and forth between past and future events. Many acclaimed movies employ unique narrative patterns which in turn have inspired other movies and contributed to the broader analysis of narrative patterns in movies. However, understanding and communicating nonlinear narratives is a difficult task due to complex temporal disruptions in the order of events as well as no explicit records specifying the actual temporal order of the underlying story. Story curves visualize the nonlinear narrative of a movie by showing the order in which events are told in the movie and comparing them to their actual chronological order, resulting in possibly meandering visual patterns in the curve. We also present Story Explorer, an interactive tool that visualizes a story curve together with complementary information such as characters and settings. Story Explorer further provides a script curation interface that allows users to specify the chronological order of events in movies. We used Story Explorer to analyze 10 popular nonlinear movies and describe the spectrum of narrative patterns that we discovered, including some novel patterns not previously described in the literature. Feedback from experts highlights potential use cases in screenplay writing and analysis, education and film production. A controlled user study shows that users with no expertise are able to understand visual patterns of nonlinear narratives using story curves.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kim, Nam Wook and Bach, Benjamin and Im, Hyejin and Schriber, Sasha and Gross, Markus and Pfister, Hanspeter},
	month = jan,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Visualization, storytelling, Metadata, Motion pictures, visualization, Production, Games, Nonlinear narrative, Tools, Writing},
	pages = {595--604},
	file = {IEEE Xplore Abstract Record:files/4429/8017584.html:text/html;Versione accettata:files/4428/Kim et al. - 2018 - Visualizing Nonlinear Narratives with Story Curves.pdf:application/pdf},
}

@inproceedings{viana_semantic_2020,
	address = {New York, NY, USA},
	series = {{MM} '20},
	title = {Semantic {Storytelling} {Automation}: {A} {Context}-{Aware} and {Metadata}-{Driven} {Approach}},
	isbn = {978-1-4503-7988-5},
	shorttitle = {Semantic {Storytelling} {Automation}},
	url = {https://dl.acm.org/doi/10.1145/3394171.3416528},
	doi = {10.1145/3394171.3416528},
	abstract = {Multimedia content production is nowadays widespread due to technological advances, namely supported by smartphones and social media. Although the massive amount of media content brings new opportunities to the industry, it also obfuscates the relevance of marketing content, meant to maintain and lure new audiences. This leads to an emergent necessity of producing these kinds of contents as quickly and engagingly as possible. Creating these automatically would decrease both the production costs and time, particularly by using static media for the creation of short storytelling animated clips. We propose an innovative approach that uses context and content information to transform a still photo into an appealing context-aware video clip. Thus, our solution presents a contribution to the state-of-the-art in computer vision and multimedia technologies and assists content creators with a value-added service to automatically build rich contextualized multimedia stories from single photographs.},
	urldate = {2023-05-27},
	booktitle = {Proceedings of the 28th {ACM} {International} {Conference} on {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Viana, Paula and Carvalho, Pedro and Andrade, Maria Teresa and Jonker, Pieter P. and Papanikolaou, Vasileios and Teixeira, Inês N. and Vilaça, Luis and Pinto, José P. and Costa, Tiago},
	month = oct,
	year = {2020},
	keywords = {storytelling, metadata, computer vision, video generation},
	pages = {4491--4493},
	file = {Full Text PDF:files/4432/Viana et al. - 2020 - Semantic Storytelling Automation A Context-Aware .pdf:application/pdf},
}

@article{brenner_storytelling_2006,
	title = {Storytelling in an automated environment: {Using} metadata analysis to develop curated guides to a digital image collection},
	volume = {22},
	issn = {1065-075X},
	shorttitle = {Storytelling in an automated environment},
	url = {https://doi.org/10.1108/10650750610664012},
	doi = {10.1108/10650750610664012},
	abstract = {Purpose – The purpose of this study is to report the results of a project incorporating metadata analysis for the creation of curated guides to a digital library of historic photographic images. Design/methodology/approach – The general format and scope of the curated guides was determined by members of the project team. Automated processing was developed to analyze subject terms in metadata of digital images submitted to the digital library collection. The results of the metadata processing were used to narrow the themes of the curated guides, and to help create canned searches that would expose representative collection content. The curated guides were created and made available to users of the digital image collection. Findings – Processing and analyzing metadata can be a useful tool in the creation of digital library collection guides. However, the usefulness of this method is highly dependent upon consistency and accuracy of the source metadata records. Practical implications – Creators of digital library collections are shown a method of using existing resources to create collection guides. The value of metadata demonstrated by this application may affect considerations of the cost of metadata creation. Originality/value – This activity discussed in this paper addresses an established need among digital library practitioners – the need to provide users with guided access to the content of their collections. The method discussed for creating curated guides is repeatable, and could be improved in further applications.},
	number = {2},
	urldate = {2023-05-27},
	journal = {OCLC Systems \& Services: International digital library perspectives},
	author = {Brenner, Aaron L. and Mihalega, Anna Maria},
	month = jan,
	year = {2006},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Digital libraries, Computer applications},
	pages = {122--131},
	file = {Snapshot:files/4434/html.html:text/html},
}

@article{brenner_storytelling_2006-1,
	title = {Storytelling in an automated environment: {Using} metadata analysis to develop curated guides to a digital image collection},
	volume = {22},
	issn = {1065-075X},
	shorttitle = {Storytelling in an automated environment},
	url = {https://doi.org/10.1108/10650750610664012},
	doi = {10.1108/10650750610664012},
	abstract = {Purpose – The purpose of this study is to report the results of a project incorporating metadata analysis for the creation of curated guides to a digital library of historic photographic images. Design/methodology/approach – The general format and scope of the curated guides was determined by members of the project team. Automated processing was developed to analyze subject terms in metadata of digital images submitted to the digital library collection. The results of the metadata processing were used to narrow the themes of the curated guides, and to help create canned searches that would expose representative collection content. The curated guides were created and made available to users of the digital image collection. Findings – Processing and analyzing metadata can be a useful tool in the creation of digital library collection guides. However, the usefulness of this method is highly dependent upon consistency and accuracy of the source metadata records. Practical implications – Creators of digital library collections are shown a method of using existing resources to create collection guides. The value of metadata demonstrated by this application may affect considerations of the cost of metadata creation. Originality/value – This activity discussed in this paper addresses an established need among digital library practitioners – the need to provide users with guided access to the content of their collections. The method discussed for creating curated guides is repeatable, and could be improved in further applications.},
	number = {2},
	urldate = {2023-05-27},
	journal = {OCLC Systems \& Services: International digital library perspectives},
	author = {Brenner, Aaron L. and Mihalega, Anna Maria},
	month = jan,
	year = {2006},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Digital libraries, Computer applications},
	pages = {122--131},
	file = {Full Text PDF:files/4436/Brenner e Mihalega - 2006 - Storytelling in an automated environment Using me.pdf:application/pdf},
}

@article{gadolou_storytelling_2010,
	title = {Storytelling, {Spatial} {Standards} and {Cultural} {Heritage} {Management}},
	abstract = {The paper presents the project “Non-linear Digital Storytelling for the Battleship Georgios Averof” that currently takes place under the integrated action program between the German Academic Exchange Service (DAAD) and the Greek State Scholarship Foundation (I.K.Y.). The methodology applied, the objectives that the research focuses on and the first outcomes of the project are described.},
	language = {en},
	author = {Gadolou, Eleni and Papadaki, Haroula and Stefanakis, Emmanuel and Kritikos, Georgios and Cao, Yiwei and Hannemann, Anna and Klamma, Ralf and Kovachev, Dejan},
	year = {2010},
	file = {Gadolou et al. - 2010 - Storytelling, Spatial Standards and Cultural Herit.pdf:files/4438/Gadolou et al. - 2010 - Storytelling, Spatial Standards and Cultural Herit.pdf:application/pdf},
}

@article{kwiecien_metadata_2021,
	title = {Metadata {Schema} for {Folktales} in the {Mekong} {River} {Basin}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2227-9709},
	url = {https://www.mdpi.com/2227-9709/8/4/82},
	doi = {10.3390/informatics8040082},
	abstract = {The aim of this study was to analyze the content, context, and structure of folktales from the Mekong River Basin, and to develop a metadata schema for data description and folktale storage. The research was conducted using the MAAT metadata lifecycle model, which comprises the following four steps: (1) conducting an information content analysis; (2) creating metadata requirements, (3) developing a metadata schema; and (4) carrying out a metadata service and evaluation. The folktale analysis, based on Anne Gilliland’s information object analysis, revealed the following: (1) the folktale content consists of types of tales, and the morals, beliefs, and parts they incorporate; (2) the folktale context consists of and names distributors, characters, scenes, magical objects, ethnic groups, languages, countries, relationships between tales, and their sources; (3) the folktale structure includes verbal, non-verbal, and mixed forms. The metadata schema development adopted the functional requirements for bibliographic records concepts and existing metadata standards, resulting in metadata with the following 18 elements: identifier, title, creator, contributor, description, relation, language, medium, sources, date, rights, keyword, character, moral, ethnic group, motif, place, and country. The metadata elements were described using the categories: name, definition, format, example, and note.},
	language = {en},
	number = {4},
	urldate = {2023-05-27},
	journal = {Informatics},
	author = {Kwiecien, Kanyarat and Chansanam, Wirapong and Supnithi, Thepchai and Chitiyaphol, Jaturong and Tuamsuk, Kulthida},
	month = dec,
	year = {2021},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {folktale metadata, functional requirements for bibliographic records, information object analysis, Mekong River Basin, metadata schema},
	pages = {82},
	file = {Full Text PDF:files/4443/Kwiecien et al. - 2021 - Metadata Schema for Folktales in the Mekong River .pdf:application/pdf},
}

@inproceedings{reithinger_meta-data_2005,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Meta-{Data} for {Interactive} {Storytelling}},
	isbn = {978-3-540-32285-6},
	doi = {10.1007/11590361_20},
	abstract = {In this contribution we demonstrate how metadata for storytelling is represented using Semantic Web technologies. Three examples introduce the use of ontologies for the modelling of a database for story elements, for narratie structures, and for the domain of a game.},
	language = {en},
	booktitle = {Virtual {Storytelling}. {Using} {Virtual} {Reality} {Technologies} for {Storytelling}},
	publisher = {Springer},
	author = {Reithinger, Norbert and Pecourt, Elsa and Nikolova, Mina},
	editor = {Subsol, Gérard},
	year = {2005},
	keywords = {Domain Ontology, Description Logic Ontology, Dialogue Game, Interactive Storytelling, Story Element},
	pages = {172--175},
	file = {Full Text PDF:files/4446/Reithinger et al. - 2005 - Meta-Data for Interactive Storytelling.pdf:application/pdf},
}

@inproceedings{lombardo_ontologies_2013-1,
	title = {Ontologies for the metadata annotation of stories},
	volume = {2},
	doi = {10.1109/DigitalHeritage.2013.6744747},
	abstract = {Semantic web and ontology technologies offer cultural heritage the conceptualization of a number of domains of interest. A relevant issue in the annotation of digital heritage is the abstraction of concepts that underlie a number of cultural heritage items, conceived for different media, in libraries and collections. This is the case for a category we call dramatic items, expressed in a large number of media (e.g., novels, screenplay, stage performance, videogames, audiovisuals, the latter including feature films, TV series, music videoclips). The primary notion of story underpins the dramatic media. This paper presents an ontology for the representation of the story elements in media heritage. Story elements are employed to describe the dramatic qualities (e.g., the agents or characters of a story, their goals, their conflicts), abstracting from the specific media in which they appear. An annotation schema derived from the ontology was employed in a web platform for the annotation of the dramatic metadata on the digital heritage items (in textual and audiovisual form). Formal reasoning on the metadata representation points out a number of issues that are of interest for scholars and enthusiast of the drama cultural heritage, so are useful in research, teaching, and fruition.},
	booktitle = {2013 {Digital} {Heritage} {International} {Congress} ({DigitalHeritage})},
	author = {Lombardo, Vincenzo and Pizzo, Antonio},
	month = oct,
	year = {2013},
	keywords = {Cultural differences, Ontologies, Visualization, Encoding, Media, Motion pictures, TV},
	pages = {153--160},
	file = {IEEE Xplore Abstract Record:files/4449/6744747.html:text/html},
}

@inproceedings{lombardo_ontologies_2013-2,
	title = {Ontologies for the metadata annotation of stories},
	volume = {2},
	doi = {10.1109/DigitalHeritage.2013.6744747},
	abstract = {Semantic web and ontology technologies offer cultural heritage the conceptualization of a number of domains of interest. A relevant issue in the annotation of digital heritage is the abstraction of concepts that underlie a number of cultural heritage items, conceived for different media, in libraries and collections. This is the case for a category we call dramatic items, expressed in a large number of media (e.g., novels, screenplay, stage performance, videogames, audiovisuals, the latter including feature films, TV series, music videoclips). The primary notion of story underpins the dramatic media. This paper presents an ontology for the representation of the story elements in media heritage. Story elements are employed to describe the dramatic qualities (e.g., the agents or characters of a story, their goals, their conflicts), abstracting from the specific media in which they appear. An annotation schema derived from the ontology was employed in a web platform for the annotation of the dramatic metadata on the digital heritage items (in textual and audiovisual form). Formal reasoning on the metadata representation points out a number of issues that are of interest for scholars and enthusiast of the drama cultural heritage, so are useful in research, teaching, and fruition.},
	booktitle = {2013 {Digital} {Heritage} {International} {Congress} ({DigitalHeritage})},
	author = {Lombardo, Vincenzo and Pizzo, Antonio},
	month = oct,
	year = {2013},
	keywords = {Cultural differences, Ontologies, Visualization, Encoding, Media, Motion pictures, TV},
	pages = {153--160},
	file = {IEEE Xplore Abstract Record:files/4452/6744747.html:text/html;IEEE Xplore Full Text PDF:files/4451/Lombardo e Pizzo - 2013 - Ontologies for the metadata annotation of stories.pdf:application/pdf},
}

@inproceedings{davies_adapting_2013,
	address = {New York, NY, USA},
	series = {{NHT} '13},
	title = {Adapting historical drama for the web: a model for metadata backed publishing of historical drama programmes},
	isbn = {978-1-4503-2005-4},
	shorttitle = {Adapting historical drama for the web},
	url = {https://dl.acm.org/doi/10.1145/2462216.2462222},
	doi = {10.1145/2462216.2462222},
	abstract = {In this paper we describe how creative writing techniques were used to develop a non-linear model of narrative structure for historical drama and how an ontology was developed to facilitate publishing it on the web as transmedia content.},
	urldate = {2023-05-27},
	booktitle = {Proceedings of the 3rd {Narrative} and {Hypertext} {Workshop}},
	publisher = {Association for Computing Machinery},
	author = {Davies, Rosamund and Rissen, Paul and Jewell, Michael O.},
	month = may,
	year = {2013},
	keywords = {narrative, linked data, modeling, transmedia},
	pages = {1--5},
	file = {Full Text PDF:files/4455/Davies et al. - 2013 - Adapting historical drama for the web a model for.pdf:application/pdf},
}

@book{sartori_metadata_2009,
	address = {Berlin, Heidelberg},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Metadata and {Semantic} {Research}: {Third} {International} {Conference}, {MTSR} 2009, {Milan}, {Italy}, {October} 1-2, 2009. {Proceedings}},
	volume = {46},
	isbn = {978-3-642-04589-9 978-3-642-04590-5},
	shorttitle = {Metadata and {Semantic} {Research}},
	url = {http://link.springer.com/10.1007/978-3-642-04590-5},
	language = {en},
	urldate = {2023-05-27},
	publisher = {Springer},
	editor = {Sartori, Fabio and Sicilia, Miguel Ángel and Manouselis, Nikos},
	year = {2009},
	doi = {10.1007/978-3-642-04590-5},
	keywords = {ontology, semantic web, machine learning, semantics, XML, Dublin Core, Design, breast cancer, Bridging, data mining, digital librery, indexing algorithms, knowledge management, topic maps, XML metadata},
}

@article{colla_bringing_2022,
	title = {Bringing {Semantics} into {Historical} {Archives} with {Computer}-aided {Rich} {Metadata} {Generation}},
	volume = {15},
	issn = {1556-4673},
	url = {https://dl.acm.org/doi/10.1145/3484398},
	doi = {10.1145/3484398},
	abstract = {This article relies on the idea that a semantically rich metadata layer is required in order to provide an effective, intelligent, and engaging access to historical archives. However, building such a semantic layer represents a well-known bottleneck that can be overcome only by a hybrid strategy, integrating user-generated content and automatic techniques. The PRiSMHA project provides a contribution in this direction with the design and development of the prototype of an ontology-driven platform supporting users in semantic metadata generation. In particular, the main contribution of this article is to show how automatic information extraction techniques (namely, Named Entity and Temporal Expression Recognition) and information retrieved from external datasets in the LOD cloud can support users in the identification and characterization of new entities to annotate documents with.},
	number = {3},
	urldate = {2023-05-27},
	journal = {Journal on Computing and Cultural Heritage},
	author = {Colla, Davide and Goy, Annamaria and Leontino, Marco and Magro, Diego and Picardi, Claudia},
	month = sep,
	year = {2022},
	keywords = {ontologies, linked data, Artificial intelligence and archives, entity extraction, semantic metadata generation, semantic processing, synergies between computational and human-based methods},
	pages = {39:1--39:24},
	file = {Full Text PDF:files/4459/Colla et al. - 2022 - Bringing Semantics into Historical Archives with C.pdf:application/pdf},
}

@article{gaeta_smart_2015,
	title = {A smart methodology to improve the story-building process},
	volume = {11},
	issn = {1826-6223},
	url = {https://www.learntechlib.org/p/150725/},
	abstract = {Museum narratives are created from a conceptualization of events that can be structurally organized and referred to as the story. Therefore, the main process of developing a museum narrative is one of story-building. This paper presents a methodology to enrich the creation of stories for digital storytelling. The methodology is at the basis of a smart authoring system that supports authors of digital storytelling in the identification of contents from external repositories and their automatic mapping on different narrative structures, according to syntactic and semantic rules and well-...},
	language = {en},
	number = {1},
	urldate = {2023-05-27},
	journal = {Journal of e-Learning and Knowledge Society},
	author = {Gaeta, Angelo and Gaeta, Matteo and Guarino, Giuseppe and Miranda, Sergio},
	month = jan,
	year = {2015},
	note = {Publisher: Italian e-Learning Association},
	file = {Full Text PDF:files/4462/Gaeta et al. - 2015 - A smart methodology to improve the story-building .pdf:application/pdf},
}

@inproceedings{ribaud_end-user_2010,
	title = {End-user storytelling with a {CIDOC} {CRM} - based semantic wiki},
	url = {https://hal.univ-brest.fr/hal-00630580},
	abstract = {This paper presents the current state of an experiment intended to use the CIDOC CRM as a knowledge representation language. STEM freshers freely constitute groups of 2 to 4 members and choose a theme; groups have to model, structure, write and present a story within a web-hosted semantic wiki. The main part of the CIDOC CRM is used as an ontological core where students are hanging up classes and properties of the domain related to the story. The hypothesis is made that once the entry ticket has been paid, the CRM guides the end-user in a fairly natural manner for reading - and writing - the story. The intermediary assessment of the wikis allowed us to detect confusion between immaterial work and (physical) realisation of the work; and difficulty in having event-centred modelling. Final assessment results are satisfactory but may be improved. Some groups did not acquire modelling abilities - although this is a central issue in a semantic web course. Results also indicate that the scope of the course (semantic web) is somewhat too ambitious. This experience was performed in order to attract students to computer science studies but it did not produce the expected results. It did however succeed in arousing student interest, and it may contribute to the dissemination of ontologies and to making CIDOC CRM widespread.},
	language = {en},
	urldate = {2023-05-27},
	author = {Ribaud, Vincent},
	year = {2010},
	pages = {1},
	file = {Full Text PDF:files/4465/Ribaud - 2010 - End-user storytelling with a CIDOC CRM - based sem.pdf:application/pdf},
}

@inproceedings{desjardins_data_2021,
	address = {New York, NY, USA},
	series = {{CHI} '21},
	title = {Data {Epics}: {Embarking} on {Literary} {Journeys} of {Home} {Internet} of {Things} {Data}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {Data {Epics}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445241},
	doi = {10.1145/3411764.3445241},
	abstract = {In this paper, we use fiction as a method to complicate the commonplace narratives of data as intangible and objective, in the particular context of Internet of Things (IoT) in the home. We, a team of two design researchers, partnered with a fiction writer and a single IoT enthusiast, Susan, to create The Data Epics: four short stories based on Susan's monthly home IoT data logs. The Data Epics revealed new imaginaries for data, showing new world-views and lively data, but also surfaced data's entanglement in meshes and hierarchies, and concerns about control and power. Our work also examines the labor of tending to and interpreting data and a particular interest in anomalies. We conclude with discussions of how data imaginaries from fiction might be imperfect, but are uniquely generative, offering a path to get closer to IoT data by trying things on and zooming in and slowing down.},
	urldate = {2023-05-27},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Desjardins, Audrey and Biggs, Heidi R.},
	month = may,
	year = {2021},
	keywords = {Data, Epics, Fiction, Home, IoT, RtD, Speculative},
	pages = {1--17},
	file = {Full Text PDF:files/4472/Desjardins e Biggs - 2021 - Data Epics Embarking on Literary Journeys of Home.pdf:application/pdf},
}

@article{welhouse_what_2015,
	title = {“{What} {Am} {I} {Fighting} {For}?”: {Creating} a {Controlled} {Vocabulary} for {Video} {Game} {Plot} {Metadata}},
	volume = {53},
	issn = {0163-9374},
	shorttitle = {“{What} {Am} {I} {Fighting} {For}?},
	url = {https://doi.org/10.1080/01639374.2014.963776},
	doi = {10.1080/01639374.2014.963776},
	abstract = {A video game's plot is one of its defining features, and prior research confirms the importance of plot metadata to users through persona analysis, interviews, and surveys. However, existing organizational systems, including library catalogs, game-related websites, and traditional plot classification systems, do not adequately describe the plot information of video games, in other words, what the game is really about. We attempt to address the issue by creating a controlled vocabulary based on a domain analysis involving a review of relevant literature and existing data structures. The controlled vocabulary is constructed in a pair structure for maximizing flexibility and extensibility. Adopting this controlled vocabulary for describing plot information of games will allow for useful search and collocation of video games.},
	number = {2},
	urldate = {2023-05-27},
	journal = {Cataloging \& Classification Quarterly},
	author = {Welhouse, Zach and Lee, Jin Ha and Bancroft, Jennifer},
	month = feb,
	year = {2015},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/01639374.2014.963776},
	keywords = {narrative, metadata, controlled vocabulary, interactive media, plot, thesaurus, video games},
	pages = {157--189},
	file = {Versione inviata:files/4474/Welhouse et al. - 2015 - “What Am I Fighting For” Creating a Controlled V.pdf:application/pdf},
}

@article{glowacka-musial_chapter_2020,
	title = {Chapter 1. {Visualization} and {Digital} {Collections}},
	volume = {57},
	copyright = {Copyright (c) 2020 Monika Glowacka-Musial},
	issn = {0024-2586},
	url = {https://journals.ala.org/index.php/ltr/article/view/7481},
	abstract = {Chapter 1 of Library Technology Reports (vol. 57, no. 1) focuses on the opportunities that visualizations of digital collections’ data create for library users and the collections’ curators. Based on a literature review, the chapter discusses visualization as a method for exploration and analysis of digital content applied in business, academia, and cultural heritage institutions. Aesthetically appealing, rooted in data analysis, and easy to comprehend, visual representations enhance the value of digital collections and inspire library users to engage with digitized sources in new, creative ways.},
	language = {en-US},
	number = {1},
	urldate = {2023-05-27},
	journal = {Library Technology Reports},
	author = {Glowacka-Musial, Monika},
	month = dec,
	year = {2020},
	note = {Number: 1},
	pages = {5--10},
	file = {Full Text PDF:files/4477/Glowacka-Musial - 2020 - Chapter 1. Visualization and Digital Collections.pdf:application/pdf},
}

@article{weber_data_2018,
	title = {Data stories. {Rethinking} journalistic storytelling in the context of data journalism},
	volume = {18},
	issn = {2296-4150, 1424-4896},
	url = {https://www.hope.uzh.ch/scoms/article/view/j.scoms.2018.01.013},
	doi = {10.24434/j.scoms.2018.01.013},
	abstract = {This paper addresses the increased use of data and data visualization in newsrooms, which has yielded a new form of storytelling: data stories. In journalism, data stories or storytelling with data are the new buzzwords. What journalists mean by data stories, however, remains blurred. We use the emergence of data stories as an opportunity to describe the changing understanding of journalistic storytelling. Based on interviews with editorial leaders, data journalists, developers, and designers in 26 major news organizations in Europe, we focus on practitioners’ perspective on data stories. In our empirical study, we identified seven key features of journalistic data stories: data, communicative function, the textual-visual relationship, structure and design of a story, interactivity, and the meta-story. These findings contribute to rethinking the narrative approach to journalism.},
	language = {en},
	number = {1},
	urldate = {2023-05-27},
	journal = {Studies in Communication Sciences},
	author = {Weber, Wibke and Engebretsen, Martin and Kennedy, Helen},
	month = nov,
	year = {2018},
	file = {Weber et al. - 2018 - Data stories. Rethinking journalistic storytelling.pdf:files/4479/Weber et al. - 2018 - Data stories. Rethinking journalistic storytelling.pdf:application/pdf},
}

@article{lee_more_2015,
	title = {More {Than} {Telling} a {Story}: {Transforming} {Data} into {Visually} {Shared} {Stories}},
	volume = {35},
	issn = {1558-1756},
	shorttitle = {More {Than} {Telling} a {Story}},
	doi = {10.1109/MCG.2015.99},
	abstract = {The authors take a closer look at how the visualization community has discussed visual storytelling and present a visual data storytelling process, incorporating steps involved in finding insights (explore data), turning these insights into a narrative (make a story), and communicating this narrative to an audience (tell a story). They also discuss opportunities for future research in visualization as a storytelling medium in the light of this broader process.},
	number = {5},
	journal = {IEEE Computer Graphics and Applications},
	author = {Lee, Bongshin and Riche, Nathalie Henry and Isenberg, Petra and Carpendale, Sheelagh},
	month = sep,
	year = {2015},
	note = {Conference Name: IEEE Computer Graphics and Applications},
	keywords = {Visualization, storytelling, Media, Narratives, visualization, communication, Data visualization, computer graphics, Context awareness, narrative visualization, presentation, Professional communication, Programming, storytelling process, visual data story},
	pages = {84--90},
	file = {IEEE Xplore Abstract Record:files/4487/7274435.html:text/html;IEEE Xplore Full Text PDF:files/4486/Lee et al. - 2015 - More Than Telling a Story Transforming Data into .pdf:application/pdf},
}

@article{martinez_storyworld_2014,
	title = {Storyworld {Possible} {Selves} and the {Phenomenon} of {Narrative} {Immersion}: {Testing} a {New} {Theoretical} {Construct}},
	volume = {22},
	issn = {1063-3685},
	shorttitle = {Storyworld {Possible} {Selves} and the {Phenomenon} of {Narrative} {Immersion}},
	url = {https://www.jstor.org/stable/24615412},
	number = {1},
	urldate = {2023-05-27},
	journal = {Narrative},
	author = {Martínez, M. Angeles},
	year = {2014},
	note = {Publisher: Ohio State University Press},
	pages = {110--131},
	file = {JSTOR Full Text PDF:files/4491/Martínez - 2014 - Storyworld Possible Selves and the Phenomenon of N.pdf:application/pdf},
}

@article{johnston_greek_2015,
	title = {The {Greek} {Mythic} {Story} {World}},
	volume = {48},
	issn = {0004-0975},
	url = {https://www.jstor.org/stable/26314624},
	number = {3},
	urldate = {2023-05-27},
	journal = {Arethusa},
	author = {Johnston, Sarah Iles},
	year = {2015},
	note = {Publisher: The Johns Hopkins University Press},
	pages = {283--311},
	file = {JSTOR Full Text PDF:files/4496/Johnston - 2015 - The Greek Mythic Story World.pdf:application/pdf},
}

@inproceedings{vanoverschelde_no_2019,
	address = {New York, NY, USA},
	series = {{NHT} '19},
	title = {No {Story} without a {Backstory}: {The} role and importance of the backstory in an augmented reality application for cultural heritage},
	isbn = {978-1-4503-6901-5},
	shorttitle = {No {Story} without a {Backstory}},
	url = {https://dl.acm.org/doi/10.1145/3345511.3349282},
	doi = {10.1145/3345511.3349282},
	abstract = {The research presented below is an early-stage research project regarding the role and importance of backstory in an augmented reality application for cultural heritage. Literature and desk research show little attention for backstory when developing a storyline for extended reality applications in the cultural heritage field. However when looking at cinematic productions, theme parks and games for example, it can be stated that backstory plays an important role as a storytelling element to create a cohesive and immersive narrative. The hypothesis presented by Scan4Stories is that adding a backstory to the applications designed for cultural heritage sites, could help enhance the immersivity of the experience. To test the hypothesis presented above, we will develop a prototype, examining how the backstory of characters can be presented to the audience in an extended reality application on a cultural heritage site. By eventually combining the results from literature research and the development of a prototype we aim to formulate preliminary results concerning the use of backstory in cultural heritage extended reality applications.},
	urldate = {2023-05-27},
	booktitle = {Proceedings of the 8th {International} {Workshop} on {Narrative} and {Hypertext}},
	publisher = {Association for Computing Machinery},
	author = {Vanoverschelde, Fauve},
	month = sep,
	year = {2019},
	keywords = {cultural heritage, storytelling, backstory, extended reality},
	pages = {1--3},
	file = {Full Text PDF:files/4499/Vanoverschelde - 2019 - No Story without a Backstory The role and importa.pdf:application/pdf},
}

@inproceedings{katifori_applying_2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Applying {Interactive} {Storytelling} in {Cultural} {Heritage}: {Opportunities}, {Challenges} and {Lessons} {Learned}},
	isbn = {978-3-030-04028-4},
	shorttitle = {Applying {Interactive} {Storytelling} in {Cultural} {Heritage}},
	doi = {10.1007/978-3-030-04028-4_70},
	abstract = {Digital storytelling in cultural heritage contexts has been recognized as a direction that cultural heritage institutions, including museums and historical sites, need to invest in to attract and engage their audiences. The term “interactive storytelling” is often used to characterize existing digital applications, whether these incorporate narrative structures or not. However, is “interactive storytelling” with its strict definition actually strongly present as an art form within the domain of cultural heritage, especially for on-site mobile experiences? In this work, we report on our experience and lessons learnt during our efforts to apply the genre of interactive storytelling in the heritage sector with the aim to more effectively support both authors and users of mobile interactive storytelling apps.},
	language = {en},
	booktitle = {Interactive {Storytelling}},
	publisher = {Springer International Publishing},
	author = {Katifori, Akrivi and Karvounis, Manos and Kourtis, Vassilis and Perry, Sara and Roussou, Maria and Ioanidis, Yannis},
	editor = {Rouse, Rebecca and Koenitz, Hartmut and Haahr, Mads},
	year = {2018},
	keywords = {Cultural heritage, Authoring, Branching narratives, Interactive storytelling},
	pages = {603--612},
	file = {Full Text PDF:files/4502/Katifori et al. - 2018 - Applying Interactive Storytelling in Cultural Heri.pdf:application/pdf},
}

@article{barr_video_2007,
	title = {Video game values: {Human}–computer interaction and games},
	volume = {19},
	issn = {09535438},
	shorttitle = {Video game values},
	url = {https://academic.oup.com/iwc/article-lookup/doi/10.1016/j.intcom.2006.08.008},
	doi = {10.1016/j.intcom.2006.08.008},
	abstract = {As videogames become more and more popular, their ability to generate and communicate mythologies (mythopoiesis) appears clearer. Pokémon, The Legend of Zelda, and Halo are just a few of the specific transmedial storyworlds created through (relatively few) years of reiteration. At the same time, recent examples of massively diffused products also picture remediations of heritage, folk tales, architecture, and other cultural elements, reaching users of any background. Franchises like Assassin’s Creed, God of War, or Final Fantasy take large inspiration from various cultural heritages. By doing so, video-ludic remediations add to previously shared imaginary some peculiar interactive (ergodic) features: since video games have specific features that imply interaction by (and with) the user, the remediated cultural elements acquire properties that were not present in any previous representation. The interest of this study is to enlighten how it is possible for blockbuster videogames to build over previous archetypes and imaginaries, creating common knowledge about certain cultural objects, myths, and figures, among players on a global scale. The main focus of this research will be Japanese cultural heritage representation in recent popular videogames such as Nioh, Ghost of Tsushima, and Sekiro: Shadows Die Twice. In a comparative analysis of these products, the study will try to underline the common elements of blockbuster remediations, while exploring the emerging interactive (ergodic) features that the mentioned videogames add to previously shared imaginary of portrayed cultural elements. Any emerging evidence will then serve to build a tentative framework or method to remediate and represent any given cultural element in future videogame projects that aim to properly communicate heritage on a large scale such as the global digital game market.},
	language = {en},
	number = {2},
	urldate = {2023-05-27},
	journal = {Interacting with Computers},
	author = {Barr, Pippin and Noble, James and Biddle, Robert},
	month = mar,
	year = {2007},
	pages = {180--195},
	file = {Barr et al. - 2007 - Video game values Human–computer interaction and .pdf:files/4505/Barr et al. - 2007 - Video game values Human–computer interaction and .pdf:application/pdf},
}

@article{petousi_promoting_nodate,
	title = {Promoting {Historical} {Understanding} and {Meaning} {Making}},
	abstract = {Role-playing games” refer to “the multiple styles of play activities revolving around the rule-structured creation and enactment of characters in a fictional world”. Role-play, combined with storytelling is a natural part of human development and RPGs have the potential to expand the affective, cognitive, and behavioral skills of players. In this work we discuss tabletop RPGs as museum kits to promote historical understanding, meaning making and empathy in the informal learning context of cultural heritage.},
	language = {en},
	author = {Petousi, Dimitra and Katifori, Akrivi and Chyrsanthi, Angeliki and Servi, Katerina and Sakellariadis, Pantelis and Ioannidis, Yannis},
	file = {Petousi et al. - Promoting Historical Understanding and Meaning Mak.pdf:files/4508/Petousi et al. - Promoting Historical Understanding and Meaning Mak.pdf:application/pdf},
}

@inproceedings{corallo_transmedia_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Transmedia {Digital} {Storytelling} for {Cultural} {Heritage} {Visiting} {Enhanced} {Experience}},
	isbn = {978-3-030-25999-0},
	doi = {10.1007/978-3-030-25999-0_19},
	abstract = {The Italian cultural heritage is the richest in the world and its attractiveness is still far from a complete exploitation. The technological innovation is an opportunity to enhance the valorisation process and cultural institutions are willing to exploit this potential in order to attract even more visitors. New communication paradigms are needed to satisfy the emerging need for cultural knowledge and experience of citizens and tourists. This paper introduces an innovative technological and methodological framework aimed at facilitating the collaborative creation and sharing of cultural narrative experiences. The potential benefits and implication related to the framework development are described. The framework starts from the research and systematization of cultural heritage contents, which are then digitalized and virtually reconstructed in order to create interactive and immersive experiences.},
	language = {en},
	booktitle = {Augmented {Reality}, {Virtual} {Reality}, and {Computer} {Graphics}},
	publisher = {Springer International Publishing},
	author = {Corallo, Angelo and Esposito, Marco and Marra, Manuela and Pascarelli, Claudio},
	editor = {De Paolis, Lucio Tommaso and Bourdot, Patrick},
	year = {2019},
	keywords = {Cultural heritage, Digital Storytelling, Transmediality},
	pages = {221--229},
	file = {Full Text PDF:files/4512/Corallo et al. - 2019 - Transmedia Digital Storytelling for Cultural Herit.pdf:application/pdf},
}

@article{martinez_storyworld_2014-1,
	title = {Storyworld {Possible} {Selves} and the {Phenomenon} of {Narrative} {Immersion}: {Testing} a {New} {Theoretical} {Construct}},
	volume = {22},
	issn = {1063-3685},
	shorttitle = {Storyworld {Possible} {Selves} and the {Phenomenon} of {Narrative} {Immersion}},
	url = {https://www.jstor.org/stable/24615412},
	number = {1},
	urldate = {2023-05-27},
	journal = {Narrative},
	author = {Martínez, M. Angeles},
	year = {2014},
	note = {Publisher: Ohio State University Press},
	pages = {110--131},
	file = {JSTOR Full Text PDF:files/4515/Martínez - 2014 - Storyworld Possible Selves and the Phenomenon of N.pdf:application/pdf},
}

@inproceedings{chenu_transmedia_2014,
	title = {Transmedia storytelling and cultural heritage interpretation : the {CULTE} project},
	shorttitle = {Transmedia storytelling and cultural heritage interpretation},
	url = {https://hal.science/hal-01504222},
	abstract = {The theme of this year’s conference “Open Museums and Smart cities: Storytelling and Connected Culture” relates significantly to the lines of research and experimentation of the CULTE (Cultural Urban Learning Transmedia Experience) project that began in 2013 and that will lead to the development of an ambitious transmedia pervasive game in and around the Quai Branly museum in Paris. The project brings together four partners with complementary skills: LUTIN, a laboratory dedicated to usability studies; CEDRIC a group of researchers interested in interactive applications, specifically in the domain of transmedia and pervasive games; Mazedia, a communication agency that is designing a transmedia platform for cultural heritage and gaming project, and the Quai Branly museum which is heavily involved in the growing presence of transmedia inside museums and whose collections will be the subject of the experiments. This project fits in a context where museums and smart-cities infrastructures are tightly interwoven. This influences the way people discover and interact with cultural heritage. Paris is known worldwide for being highly involved in the promotion of cultural tourism. Museums and public policy makers are very well aware that in order to welcome and satisfy millions of visitors (both French and foreign) every year, they have to make smart investments to offer new meaningful experiences around the discovery of their collections. But how can we design these new experiences? How can we rewrite the relationship between people and their environment ? CULTE aims at promoting and experimenting with transmedia storytelling and innovative game play as a way to spark interest and involvement before, during and after a visit to the museum. Transmedia storytelling focuses on spreadability and the circulation of cultural contents in various social spaces. By using both elaborate and traditional media platforms, our objective is to create a sense of continuity and coherence. Gamification is a way to achieve this goal and to sustain the visitors’ engagement throughout the visit timeline. The Quai Branly museum is both a museum and a research center in anthropology, ethnology and art history studies. What is interesting about its collections is that they reflect many current issues: respect, diversity, tolerance, open-mindedness… thus allowing the visitors to relate more intimately to them. It offers a perspective on the world we live in and encourages civic thinking. For these reasons, the museum can build multiple entry points in the city by using adapted media platforms which is one of the strengths of transmedia. The game can start in the museum or outside its walls, thus building bridges between the collections and the daily experience in the city. CULTE has the following objectives: an interactive system inside and outside the Quai Branly museum as proof of the concept; a usability study to analyze the pedagogical fallout; the design of a model for a pervasive, transmedia serious-game (audio/visual augmented reality); generic elements of game design for non-programmer staff members; the participation of other museums; an evaluation made by a committee of experts in transmedia and digital technologies for museums.},
	language = {en},
	urldate = {2023-05-27},
	author = {Chenu, Candice and German, Ronan and Gressier-Soudan, Eric and Levillain, Florent and Astic, Isabelle and Roirand, Vincent},
	month = feb,
	year = {2014},
	file = {Full Text PDF:files/4518/Chenu et al. - 2014 - Transmedia storytelling and cultural heritage inte.pdf:application/pdf},
}

@article{branch_representing_2017,
	title = {Representing transmedia fictional worlds through ontology},
	volume = {68},
	issn = {2330-1643},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.23886},
	doi = {10.1002/asi.23886},
	abstract = {Currently, there is no structured data standard for representing elements commonly found in transmedia fictional worlds. Although there are websites dedicated to individual universes, the information found on these sites separate out the various formats, concentrate on only the bibliographic aspects of the material, and are only searchable with full text. We have created an ontological model that will allow various user groups interested in transmedia to search for and retrieve the information contained in these worlds based upon their structure. We conducted a domain analysis and user studies based on the contents of Harry Potter, Lord of the Rings, the Marvel Universe, and Star Wars in order to build a new model using Ontology Web Language (OWL) and an artificial intelligence-reasoning engine. This model can infer connections between transmedia properties such as characters, elements of power, items, places, events, and so on. This model will facilitate better search and retrieval of the information contained within these vast story universes for all users interested in them. The result of this project is an OWL ontology reflecting real user needs based upon user research, which is intuitive for users and can be used by artificial intelligence systems.},
	language = {en},
	number = {12},
	urldate = {2023-05-27},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Branch, Frank and Arias, Theresa and Kennah, Jolene and Phillips, Rebekah and Windleharth, Travis and Lee, Jin Ha},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.23886},
	pages = {2771--2782},
	file = {Full Text PDF:files/4521/Branch et al. - 2017 - Representing transmedia fictional worlds through o.pdf:application/pdf;Snapshot:files/4522/asi.html:text/html},
}

@article{ryan_transmedia_2015,
	title = {Transmedia {Storytelling}: {Industry} {Buzzword} or {New} {Narrative} {Experience}?},
	volume = {7},
	issn = {1946-2204},
	shorttitle = {Transmedia {Storytelling}},
	url = {https://www.jstor.org/stable/10.5250/storyworlds.7.2.0001},
	doi = {10.5250/storyworlds.7.2.0001},
	number = {2},
	urldate = {2023-05-27},
	journal = {Storyworlds: A Journal of Narrative Studies},
	author = {Ryan, Marie-Laure},
	year = {2015},
	note = {Publisher: University of Nebraska Press},
	pages = {1--19},
	file = {JSTOR Full Text PDF:files/4533/Ryan - 2015 - Transmedia Storytelling Industry Buzzword or New .pdf:application/pdf},
}

@article{scolari_transmedia_2009,
	title = {Transmedia {Storytelling}: {Implicit} {Consumers}, {Narrative} {Worlds}, and {Branding} in {Contemporary} {Media} {Production}},
	copyright = {Aquest document està subjecte a aquesta llicència Creative Commons},
	issn = {1932-8036},
	shorttitle = {Transmedia {Storytelling}},
	url = {http://dspace.uvic.cat/xmlui/handle/10854/2867},
	abstract = {Many concepts have been developed to describe the convergence of media, languages, 
and formats in contemporary media systems. This article is a theoretical reflection on 
“transmedia storytelling” from a perspective that integrates semiotics and narratology in 
the context of media studies. After dealing with the conceptual chaos around transmedia 
storytelling, the article analyzes how these new multimodal narrative structures create 
different implicit consumers and construct a narrative world. The analysis includes a 
description of the multimedia textual structure created around the Fox television series 
24. Finally, the article analyzes transmedia storytelling from the perspective of a 
semiotics of branding.},
	language = {eng},
	urldate = {2023-05-27},
	author = {Scolari, Carlos Alberto},
	year = {2009},
	note = {Accepted: 2014-04-10T10:18:52Z
Publisher: University of Southern California},
	file = {Full Text PDF:files/4536/Scolari - 2009 - Transmedia Storytelling Implicit Consumers, Narra.pdf:application/pdf},
}

@article{gambarato_signs_nodate,
	title = {Signs, {Systems} and {Complexity} of {Transmedia} {Storytelling}},
	abstract = {This article addresses key concepts such as sign, system and complexity in order to approach transmedia storytelling and better understand its intricate nature. The theoretical framework chosen to investigate transmedia storytelling meanders is Semiotics by Charles Sanders Peirce (1839-1914) and General Systems Theory by Mario Bunge (1919-). The complexity of transmedia storytelling is not simply the one of the signs of the works included in a transmedia franchise. It also includes the complexity of the dispositions of users/consumers/players as interpreters of semiotic elements (e.g. characters, themes, environments, events and outcomes) presented by transmedia products. It extends further to the complexity of social, cultural, economical and political constructs. The German transmedia narrative The Ultimate SuperHeroBlog by Stefan Gieren and Soﬁa’s Diary, a Portuguese multiplatform production by BeActive, are presented as examples of closed and open system transmedia storytelling respectively.},
	language = {en},
	author = {Gambarato, Renira Rampazzo},
	file = {Gambarato - Signs, Systems and Complexity of Transmedia Storyt.pdf:files/4538/Gambarato - Signs, Systems and Complexity of Transmedia Storyt.pdf:application/pdf},
}

@article{javanshir_structural_2020,
	title = {Structural patterns for transmedia storytelling},
	volume = {15},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0225910},
	doi = {10.1371/journal.pone.0225910},
	abstract = {Transmedia storytelling involves telling a story using multiple distinct media. The remit of stories that fall under this broad definition is vast, consequently causing theorists to examine different phenomena using tools that are not suitable for all forms of transmedia storytelling. The lack of critical tools means we are unable to describe, compare and analyse different experiences using common language. In this paper, we present our model that can be used to identify the fundamental structural features of a variety of transmedia storytelling forms. We illustrate its usage with twenty case studies and discuss how three groups of patterns emerge which can be identifiable in all transmedia stories. These patterns can be used to extend transmedia language and help form taxonomies, by identifying common patterns and their usages amongst various forms of transmedia stories.},
	language = {en},
	number = {1},
	urldate = {2023-05-27},
	journal = {PLOS ONE},
	author = {Javanshir, Ryan and Carroll, Beth and Millard, David},
	month = jan,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Virtual reality, Games, Language, Robots, Social media, Sports, Taxonomy, Video games},
	pages = {e0225910},
	file = {Full Text PDF:files/4542/Javanshir et al. - 2020 - Structural patterns for transmedia storytelling.pdf:application/pdf},
}

@article{chu_embodied_2019,
	title = {Embodied {Engagement} with {Narrative}: {A} {Design} {Framework} for {Presenting} {Cultural} {Heritage} {Artifacts}},
	volume = {3},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2414-4088},
	shorttitle = {Embodied {Engagement} with {Narrative}},
	url = {https://www.mdpi.com/2414-4088/3/1/1},
	doi = {10.3390/mti3010001},
	abstract = {An increasing number of museum exhibits incorporate multi-modal technologies and interactions; yet these media divert visitors’ attention away from the cultural heritage artifacts on display. This paper proposes an overarching conceptual structure for designing tangible and embodied narrative interaction with cultural heritage artifacts within a museum exhibit so that visitors can interact with them to comprehend their cultural context. The Tangible and Embodied Narrative Framework (TENF) consists of three spectra (diegetic vs. non-diegetic, internal vs. external, and ontological vs. exploratory) and, considering how different interactions map along these three spectra, can guide designers in the way they integrate digital media, narrative, and embodiment. In this paper, we examine interactive narrative scholarship, existing frameworks for tangible and embodied interactions, and tangible and embodied narrative projects. We then describe the design of the TENF and its application to the pilot project, Mapping Place, and to the case study project, Multi-Sensory Prayer Nuts. The findings indicate that embodied engagement with artifacts through a narrative role can help visitors (1) contextualize the meaning of artifacts and (2) make personalized connections to the artifacts. Based on this work, we suggest design recommendations for tailoring the use of the TENF in the cultural heritage domain: simulate cultural practices, associate visitors with cultural perspectives, and provide simultaneous digital feedback. We conclude by describing future directions for the research, which include generating other possible projects using the TENF; collaborating with other designers and museum professionals; and exploring applications of the TENF in museum spaces.},
	language = {en},
	number = {1},
	urldate = {2023-05-28},
	journal = {Multimodal Technologies and Interaction},
	author = {Chu, Jean Ho and Mazalek, Ali},
	month = mar,
	year = {2019},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {digital cultural heritage, framework, interactive digital storytelling, tangible interfaces},
	pages = {1},
	file = {Full Text PDF:files/4550/Chu e Mazalek - 2019 - Embodied Engagement with Narrative A Design Frame.pdf:application/pdf},
}

@article{meghini_representing_2021-1,
	title = {Representing narratives in digital libraries: {The} narrative ontology},
	volume = {12},
	issn = {1570-0844},
	shorttitle = {Representing narratives in digital libraries},
	url = {https://content.iospress.com/articles/semantic-web/sw200421},
	doi = {10.3233/SW-200421},
	abstract = {Digital Libraries (DLs), especially in the Cultural Heritage domain, are rich in narratives. Every digital object in a DL tells some kind of story, regardless of the medium, the genre, or the type of the object. However, DLs do not offer services abo},
	language = {en},
	number = {2},
	urldate = {2023-05-28},
	journal = {Semantic Web},
	author = {Meghini, Carlo and Bartalesi, Valentina and Metilli, Daniele},
	month = jan,
	year = {2021},
	note = {Publisher: IOS Press},
	pages = {241--264},
	file = {Full text:files/4553/Meghini et al. - 2021 - Representing narratives in digital libraries The .pdf:application/pdf},
}

@inproceedings{snelson_digital_2009,
	title = {Digital {Storytelling} in a {Web} 2.0 {World}},
	url = {https://www.learntechlib.org/p/43792/},
	abstract = {Digital storytelling has arisen as a form of narrative expression that is crafted into a media production. While there appears to be general agreement that digital storytelling integrates meaningful stories with media, and characteristics of digital stories have been described, the definition of and purpose for digital storytelling remains somewhat open to interpretation. Even more unclear is how the growing array of interactive Web 2.0 video-sharing technologies are being used to facilitate digital storytelling. This paper presents a pilot study conducted to begin learning how digital...},
	language = {en},
	urldate = {2023-05-28},
	publisher = {TCCHawaii},
	author = {Snelson, Chareen and Sheffield, Annie},
	year = {2009},
	pages = {159--167},
	file = {Full Text PDF:files/4556/Snelson e Sheffield - 2009 - Digital Storytelling in a Web 2.0 World.pdf:application/pdf},
}

@inproceedings{rishes_generating_2013,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Generating {Different} {Story} {Tellings} from {Semantic} {Representations} of {Narrative}},
	isbn = {978-3-319-02756-2},
	doi = {10.1007/978-3-319-02756-2_24},
	abstract = {In order to tell stories in different voices for different audiences, interactive story systems require: (1) a semantic representation of story structure, and (2) the ability to automatically generate story and dialogue from this semantic representation using some form of Natural Language Generation (nlg). However, there has been limited research on methods for linking story structures to narrative descriptions of scenes and story events. In this paper we present an automatic method for converting from Scheherazade’s story intention graph, a semantic representation, to the input required by the personagenlg engine. Using 36 Aesop Fables distributed in DramaBank, a collection of story encodings, we train translation rules on one story and then test these rules by generating text for the remaining 35. The results are measured in terms of the string similarity metrics Levenshtein Distance and BLEU score. The results show that we can generate the 35 stories with correct content: the test set stories on average are close to the output of the Scheherazade realizer, which was customized to this semantic representation. We provide some examples of story variations generated by personage. In future work, we will experiment with measuring the quality of the same stories generated in different voices, and with techniques for making storytelling interactive.},
	language = {en},
	booktitle = {Interactive {Storytelling}},
	publisher = {Springer International Publishing},
	author = {Rishes, Elena and Lukin, Stephanie M. and Elson, David K. and Walker, Marilyn A.},
	editor = {Koenitz, Hartmut and Sezen, Tonguc Ibrahim and Ferri, Gabriele and Haahr, Mads and Sezen, Digdem and C̨atak, Güven},
	year = {2013},
	keywords = {Natural Language Generation, Semantic Narrative Representation, Story Variation},
	pages = {192--204},
	file = {Full Text PDF:files/4559/Rishes et al. - 2013 - Generating Different Story Tellings from Semantic .pdf:application/pdf},
}

@article{psomadaki_digital_2019,
	title = {Digital storytelling and audience engagement in cultural heritage management: {A} collaborative model based on the {Digital} {City} of {Thessaloniki}},
	volume = {36},
	issn = {1296-2074},
	shorttitle = {Digital storytelling and audience engagement in cultural heritage management},
	url = {https://www.sciencedirect.com/science/article/pii/S1296207417302583},
	doi = {10.1016/j.culher.2018.07.016},
	abstract = {Cities are complex, networked and continuously changing social ecosystems, shaped and transformed through the interaction of different interests and ambitions. They are linked to places, where various aspects of past events are projected and expressed by means of personal memories and narrations (urban memory), representing a promise for future: a vision of freedom, creativity, opportunity and prosperity. At the same time, technology is currently promoting unprecedented changes in urban areas, which are often marked as smart city developments. This paper studies the history of cultural and creative industries, bringing forward the dedicated digital storytelling strategies that promote active audience engagement in urban cultural heritage. A collaborative model is proposed and analyzed (in multiple perspectives), aiming at providing an integrated manner for heritage documentation, management and dissemination. The development deals with the Digital City of Thessaloniki, Greece, a big city, not a boundless one, rich in culture, but with rather poor heritage management mechanisms. The research focuses on theoretical and practical aspects for the citizens’ collection and interpretation of “digital heritage” documents (artifacts, places, etc.), resulting in a model that fuels audience engagement and collaboration of cultural organizations. Model-design is validated through state-of-the-art review and formative evaluation processes (both qualitative and quantitative), with an associated SWOT analysis that points out strengths, weaknesses, opportunities and threats. Although the proposed methodology has been adapted to the needs of a particular (digital) city, the current paper goes beyond a case study, as it brings forward novel technological and methodological guidelines, which could be successfully deployed in districts with similar cultural, geographical, and technical features.},
	language = {en},
	urldate = {2023-05-28},
	journal = {Journal of Cultural Heritage},
	author = {Psomadaki, Ofilia I. and Dimoulas, Charalampos A. and Kalliris, George M. and Paschalidis, Gregory},
	month = mar,
	year = {2019},
	keywords = {Arts participation, Audience engagement, Collaborative heritage management, Crowdsourcing, Heritage policy, Mediated cultural experience, Non-linear storytelling},
	pages = {12--22},
	file = {ScienceDirect Snapshot:files/4562/S1296207417302583.html:text/html},
}

@article{dimoulas_cultural_2022,
	title = {Cultural {Heritage} {Storytelling}, {Engagement} and {Management} in the {Era} of {Big} {Data} and the {Semantic} {Web}},
	volume = {14},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2071-1050},
	url = {https://www.mdpi.com/2071-1050/14/2/812},
	doi = {10.3390/su14020812},
	abstract = {Cultural heritage (CH) refers to a highly multidisciplinary research and application field, intending to collect, archive, and disseminate the traditions, monuments/artworks, and overall civilization legacies that have been preserved throughout the years of humankind [...]},
	language = {en},
	number = {2},
	urldate = {2023-05-28},
	journal = {Sustainability},
	author = {Dimoulas, Charalampos A.},
	month = jan,
	year = {2022},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {n/a},
	pages = {812},
	file = {Full Text PDF:files/4565/Dimoulas - 2022 - Cultural Heritage Storytelling, Engagement and Man.pdf:application/pdf},
}

@article{bartalesi_unstructured_2023,
	title = {From unstructured texts to semantic story maps},
	volume = {16},
	issn = {1753-8947},
	url = {https://doi.org/10.1080/17538947.2023.2168774},
	doi = {10.1080/17538947.2023.2168774},
	abstract = {Digital maps greatly support storytelling about territories, especially when enriched with data describing cultural, societal, and ecological aspects, conveying emotional messages that describe the territory as a whole. Story maps are interactive online digital narratives that can describe a territory beyond its map by enriching the map with text, pictures, videos, and other multimedia information. This paper presents a semi-automatic workflow to produce story maps from textual documents containing territory data. An expert first assembles one territory-contextual document containing text and images. Then, automatic processes use natural language processing and Wikidata services to (i) extract key concepts (entities) and geospatial coordinates associated with the territory, (ii) assemble a logically-ordered sequence of enriched story-map events, and (iii) openly publish online story maps and an interoperable Linked Open Data semantic knowledge base for event exploration and inter-story correlation analyses. Our workflow uses an Open Science-oriented methodology to publish all processes and data. Through our workflow, we produced story maps for the value chains and territories of 23 rural European areas of 16 countries. Through numerical evaluation, we demonstrated that territory experts considered the story maps effective in describing their territories, and appropriate for communicating with citizens and stakeholders.},
	number = {1},
	urldate = {2023-05-28},
	journal = {International Journal of Digital Earth},
	author = {Bartalesi, Valentina and Coro, Gianpaolo and Lenzi, Emanuele and Pagano, Pasquale and Pratelli, Nicolò},
	month = dec,
	year = {2023},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/17538947.2023.2168774},
	keywords = {ontology, semantic web, e-infrastructures, narratives, natural language processing, Story maps, virtual research environments},
	pages = {234--250},
	file = {Full Text PDF:files/4568/Bartalesi et al. - 2023 - From unstructured texts to semantic story maps.pdf:application/pdf},
}

@inproceedings{mulholland_curate_2012-1,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Curate and {Storyspace}: {An} {Ontology} and {Web}-{Based} {Environment} for {Describing} {Curatorial} {Narratives}},
	isbn = {978-3-642-30284-8},
	shorttitle = {Curate and {Storyspace}},
	doi = {10.1007/978-3-642-30284-8_57},
	abstract = {Existing metadata schemes and content management systems used by museums focus on describing the heritage objects that the museum holds in its collection. These are used to manage and describe individual heritage objects according to properties such as artist, date and preservation requirements. Curatorial narratives, such as physical or online exhibitions tell a story that spans across heritage objects and have a meaning that does not necessarily reside in the individual heritage objects themselves. Here we present curate, an ontology for describing curatorial narratives. This draws on structuralist accounts that distinguish the narrative from the story and plot, and also a detailed analysis of two museum exhibitions and the curatorial processes that contributed to them. storyspace, our web based interface and API to the ontology, is being used by curatorial staff in two museums to model curatorial narratives and the processes through which they are constructed.},
	language = {en},
	booktitle = {The {Semantic} {Web}: {Research} and {Applications}},
	publisher = {Springer},
	author = {Mulholland, Paul and Wolff, Annika and Collins, Trevor},
	editor = {Simperl, Elena and Cimiano, Philipp and Polleres, Axel and Corcho, Oscar and Presutti, Valentina},
	year = {2012},
	keywords = {ontology, Cultural heritage, narrative, plot, museum, story},
	pages = {748--762},
	file = {Full Text PDF:files/4613/Mulholland et al. - 2012 - Curate and Storyspace An Ontology and Web-Based E.pdf:application/pdf},
}

@article{ciotti_toward_2016,
	title = {Toward a {Formal} {Ontology} for {Narrative}},
	volume = {4},
	doi = {10.14195/2182-8830_4-1_2},
	abstract = {In this paper the rationale and the first draft of a formal ontology for modeling narrative texts are presented. Building on the semiotic and structuralist narratology, and on the work carried out in the late 1980s by Giuseppe Gigliozzi in Italy, the focus of my research are the concepts of character and of narrative world/space. This formal model is expressed in the OWL 2 ontology language. The main reason to adopt a formal modeling approach is that I consider the purely probabilistic-quantitative methods (now widespread in digital literary studies) inadequate. An ontology, on one hand provides a tool for the analysis of strictly literary texts. On the other hand (though beyond the scope of the present work), its formalization can also represent a significant contribution towards grounding the application of storytelling methods outside of scholarly contexts. DOI: http://dx.doi.org/10.14195/2182-8830\_4-1\_2},
	journal = {Matlit},
	author = {Ciotti, Fabio},
	month = feb,
	year = {2016},
	pages = {29--44},
	file = {Full text:files/4773/Ciotti - 2016 - Toward a Formal Ontology for Narrative.pdf:application/pdf},
}

@inproceedings{nakasone_storytelling_2006,
	address = {Hong Kong, China},
	title = {Storytelling {Ontology} {Model} {Using} {RST}},
	isbn = {978-0-7695-2748-2},
	url = {http://ieeexplore.ieee.org/document/4052915/},
	doi = {10.1109/IAT.2006.114},
	abstract = {Storytelling applications are increasingly being used and researched due to the fact that they are capable of conveying information and experience to users in a more natural and familiar way for them. The range of developed applications increases as we realize new ways to present content as stories or “sequences of narrative significant events”. Nevertheless, implemented storytelling models are usually constrained to a particular application because of the nature of the narrated events and the way those events are linked. In order to develop a more generic model to create storytelling applications, we need to focus the solution on the manner the content is organized and conveyed to the user.},
	language = {en},
	urldate = {2023-05-28},
	booktitle = {2006 {IEEE}/{WIC}/{ACM} {International} {Conference} on {Intelligent} {Agent} {Technology}},
	publisher = {IEEE},
	author = {Nakasone, Arturo and Ishizuka, Mitsuru},
	year = {2006},
	pages = {163--169},
	file = {Nakasone e Ishizuka - 2006 - Storytelling Ontology Model Using RST.pdf:files/4776/Nakasone e Ishizuka - 2006 - Storytelling Ontology Model Using RST.pdf:application/pdf},
}

@article{lagoze_abc_2001,
	title = {The {ABC} {Ontology} and {Model}},
	issn = {1939-1366},
	url = {https://dcpapers.dublincore.org/pubs/article/view/655},
	abstract = {This paper describes the latest version of the ABC metadata model. This model has been developed within the Harmony international digital library project to provide a common conceptual model to facilitate interoperability between metadata vocabularies from different domains. This updated ABC model is the result of collaboration with the CIMI consortium whereby earlier versions of the ABC model were applied to metadata descriptions of complex objects provided by CIMI museums and libraries. The result is a metadata model with more logically grounded time and entity semantics. Based on this model we have been able to build a metadata repository of RDF descriptions and a search interface which is capable of more sophisticated queries than less-expressive, object-centric metadata models will allow.},
	language = {en},
	urldate = {2023-05-28},
	journal = {International Conference on Dublin Core and Metadata Applications},
	author = {Lagoze, Carl and Hunter, Jane},
	month = oct,
	year = {2001},
	pages = {160--176},
	file = {Full Text PDF:files/4791/Lagoze e Hunter - 2001 - The ABC Ontology and Model.pdf:application/pdf},
}

@inproceedings{scherp_f--model_2009,
	address = {New York, NY, USA},
	series = {K-{CAP} '09},
	title = {F--a model of events based on the foundational ontology dolce+{DnS} ultralight},
	isbn = {978-1-60558-658-8},
	url = {https://dl.acm.org/doi/10.1145/1597735.1597760},
	doi = {10.1145/1597735.1597760},
	abstract = {The lack of a formal model of events hinders interoperability in distributed event-based systems. In this paper, we present a formal model of events, called Event-Model-F. The model is based on the foundational ontology DOLCE+DnS Ultralight (DUL) and provides comprehensive support to represent time and space, objects and persons, as well as mereological, causal, and correlative relationships between events. In addition, the Event-Model-F provides a flexible means for event composition, modeling event causality and event correlation, and representing different interpretations of the same event. The Event-Model-F is developed following the pattern-oriented approach of DUL, is modularized in different ontologies, and can be easily extended by domain specific ontologies.},
	urldate = {2023-05-28},
	booktitle = {Proceedings of the fifth international conference on {Knowledge} capture},
	publisher = {Association for Computing Machinery},
	author = {Scherp, Ansgar and Franz, Thomas and Saathoff, Carsten and Staab, Steffen},
	month = sep,
	year = {2009},
	keywords = {events, core ontology, objects, pattern-oriented ontology design},
	pages = {137--144},
	file = {Full Text PDF:files/4793/Scherp et al. - 2009 - F--a model of events based on the foundational ont.pdf:application/pdf},
}

@inproceedings{shaw_lode_2009,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{LODE}: {Linking} {Open} {Descriptions} of {Events}},
	isbn = {978-3-642-10871-6},
	shorttitle = {{LODE}},
	doi = {10.1007/978-3-642-10871-6_11},
	abstract = {People conventionally refer to an action or occurrence taking place at a certain time at a specific location as an event. This notion is potentially useful for connecting individual facts recorded in the rapidly growing collection of linked data sets and for discovering more complex relationships between data. In this paper, we provide an overview and comparison of existing event models, looking at the different choices they make of how to represent events. We describe a model for publishing records of events as Linked Data. We present tools for populating this model and a prototype “event directory” web service, which can be used to locate stable URIs for events that have occurred, provide RDFS+OWL descriptions and link to related resources.},
	language = {en},
	booktitle = {The {Semantic} {Web}},
	publisher = {Springer},
	author = {Shaw, Ryan and Troncy, Raphaël and Hardman, Lynda},
	editor = {Gómez-Pérez, Asunción and Yu, Yong and Ding, Ying},
	year = {2009},
	keywords = {Datatype Property, Event Concept, Event Instance, Event Ontology, Foundational Ontology},
	pages = {153--167},
	file = {Full Text PDF:files/4795/Shaw et al. - 2009 - LODE Linking Open Descriptions of Events.pdf:application/pdf},
}

@inproceedings{noauthor_challenges_2018,
	title = {Challenges and {Opportunities} for {Knowledge} {Organization} in the {Digital} {Age}},
	isbn = {978-3-95650-420-4 978-3-95650-421-1},
	url = {https://www.nomos-elibrary.de/10.5771/9783956504211/challenges-and-opportunities-for-knowledge-organization-in-the-digital-age?page=1},
	doi = {10.5771/9783956504211},
	language = {en},
	urldate = {2023-05-28},
	publisher = {Ergon-Verlag},
	month = jul,
	year = {2018},
}

@incollection{ribeiro_conceptual_2018,
	title = {A {Conceptual} model for an {OWL} ontology to represent the knowledge of transmedia storytelling},
	isbn = {978-3-95650-421-1},
	url = {https://www.nomos-elibrary.de/index.php?doi=10.5771/9783956504211-511},
	abstract = {This paper proposes a conceptual model and an OWL ontology for the representation and knowledge organization of transmedia narratives and the creation of RDF datasets. The authors have adopted an approach based on the development of a flexible conceptual model for the management and representation of information accessible in a network environment. The conceptual model identifies a series of entities, attributes and relationships to describe, organize and interrelate the knowledge of transmedia contents. From the conceptual model an OWL ontology has been developed in which SKOS has been widely used in the ontology to separate the conceptual description of resources. The conceptual model allows the design of architectures for the consumption of contents and the ontology offers a first conceptual level for the organization of knowledge of transmedia narratives.},
	language = {en},
	urldate = {2023-05-28},
	booktitle = {Challenges and {Opportunities} for {Knowledge} {Organization} in the {Digital} {Age}},
	publisher = {Ergon Verlag},
	author = {Sánchez, Juan Antonio Pastor and Pérez, Tomás Saorín},
	editor = {Ribeiro, Fernanda and Cerveira, Maria Elisa},
	year = {2018},
	doi = {10.5771/9783956504211-511},
	pages = {511--520},
	file = {Sánchez e Pérez - 2018 - A Conceptual model for an OWL ontology to represen.pdf:files/4874/Sánchez e Pérez - 2018 - A Conceptual model for an OWL ontology to represen.pdf:application/pdf},
}

@article{vukadin_bits_2014,
	title = {Bits and {Pieces} of {Information}: {Bibliographic} {Modeling} of {Transmedia}},
	volume = {52},
	issn = {0163-9374},
	shorttitle = {Bits and {Pieces} of {Information}},
	url = {https://doi.org/10.1080/01639374.2013.879976},
	doi = {10.1080/01639374.2013.879976},
	abstract = {Transmedia is a technique of telling a single narrative or creating a continuous imaginary world across multiple media platforms. The article seeks to explore this emerging phenomenon in terms of bibliographic organization. It analyzes transmedia features in the context of bibliographic entities and relationships, particularly those outlined in the Functional Requirements for Bibliographic Records FRBR and FRBROO (object-oriented redefinition) conceptual models.},
	number = {3},
	urldate = {2023-05-28},
	journal = {Cataloging \& Classification Quarterly},
	author = {Vukadin, Ana},
	month = apr,
	year = {2014},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/01639374.2013.879976},
	keywords = {FRBR, transmedia, bibliographic relationships, expression, FRBROO, work},
	pages = {285--302},
}

@book{jenkins_convergence_2006,
	address = {New York},
	title = {Convergence culture: where old and new media collide},
	isbn = {978-0-8147-4281-5},
	shorttitle = {Convergence culture},
	language = {en},
	publisher = {New York University Press},
	author = {Jenkins, Henry},
	year = {2006},
	note = {OCLC: ocm64594290},
	keywords = {Mass media and culture, Popular culture, United States},
	file = {Jenkins - 2006 - Convergence culture where old and new media colli.pdf:files/5022/Jenkins - 2006 - Convergence culture where old and new media colli.pdf:application/pdf},
}

@book{bolter_remediation_1999,
	address = {Cambridge, Mass},
	title = {Remediation: understanding new media},
	isbn = {978-0-262-02452-5},
	shorttitle = {Remediation},
	language = {en},
	publisher = {MIT Press},
	author = {Bolter, J. David and Grusin, Richard A.},
	year = {1999},
	keywords = {Mass media, Technological innovations},
	file = {Bolter e Grusin - 1999 - Remediation understanding new media.pdf:files/5024/Bolter e Grusin - 1999 - Remediation understanding new media.pdf:application/pdf},
}

@book{propp_morphology_1968,
	title = {Morphology of the {Folktale}: {Second} {Edition}},
	isbn = {978-0-292-78376-8},
	shorttitle = {Morphology of the {Folktale}},
	abstract = {This book is the classic work on forms of the European folktale.},
	language = {en},
	publisher = {University of Texas Press},
	author = {Propp, Vladimir I͡Akovlevich},
	year = {1968},
	note = {Google-Books-ID: 3Md3u9UPgOEC},
	keywords = {Social Science / Folklore \& Mythology},
}

@inproceedings{mulholland_story_2004,
	address = {New York, NY, USA},
	series = {{IUI} '04},
	title = {Story fountain: intelligent support for story research and exploration},
	isbn = {978-1-58113-815-3},
	shorttitle = {Story fountain},
	url = {https://dl.acm.org/doi/10.1145/964442.964455},
	doi = {10.1145/964442.964455},
	abstract = {Increasingly heritage institutions are making digital artifacts available to the general public and research groups to promote the active exploration of heritage and encourage visits to heritage sites. Stories, such as folklore and first person accounts form a useful and engaging heritage resource for this purpose. Story Fountain provides intelligent support for the exploration of digital stories. The suite of functions provided in Story Fountain together support the investigation of questions and topics that require the accumulation, association or induction of information across the story archive. Story Fountain provides specific support toward this end such as for comparing and contrasting story concepts, the presentation of story paths between concepts, and mapping stories and events according to properties such as who met whom and who lived where.},
	urldate = {2023-05-28},
	booktitle = {Proceedings of the 9th international conference on {Intelligent} user interfaces},
	publisher = {Association for Computing Machinery},
	author = {Mulholland, Paul and Collins, Trevor and Zdrahal, Zdenek},
	month = jan,
	year = {2004},
	keywords = {ontologies, intelligent exploration, personalization and customization of interfaces, ubiquitous interfaces and smart environments, web-based interfaces},
	pages = {62--69},
	file = {Full Text PDF:files/5031/Mulholland et al. - 2004 - Story fountain intelligent support for story rese.pdf:application/pdf},
}

@inproceedings{cataldi_integrating_2011,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Integrating {Commonsense} {Knowledge} into the {Semantic} {Annotation} of {Narrative} {Media} {Objects}},
	isbn = {978-3-642-23954-0},
	doi = {10.1007/978-3-642-23954-0_29},
	abstract = {In this paper we present an innovative approach for semantic annotation of narrative media objects (video, text, audio, etc.) that integrates vast commonsense ontological knowledge to a novel ontology-based model of narrative, Drammar (focused on the dramatic concepts of ‘character’ and ‘action’), to permit the annotation of their narrative features.},
	language = {en},
	booktitle = {{AI}*{IA} 2011: {Artificial} {Intelligence} {Around} {Man} and {Beyond}},
	publisher = {Springer},
	author = {Cataldi, Mario and Damiano, Rossana and Lombardo, Vincenzo and Pizzo, Antonio and Sergi, Dario},
	editor = {Pirrone, Roberto and Sorbello, Filippo},
	year = {2011},
	keywords = {ontology, Media annotation, narrative annotation},
	pages = {312--323},
	file = {Full Text PDF:files/5033/Cataldi et al. - 2011 - Integrating Commonsense Knowledge into the Semanti.pdf:application/pdf},
}

@inproceedings{cua_representing_2010,
	address = {Los Angeles, California},
	title = {Representing {Story} {Plans} in {SUMO}},
	url = {https://aclanthology.org/W10-0306},
	urldate = {2023-05-28},
	booktitle = {Proceedings of the {NAACL} {HLT} 2010 {Second} {Workshop} on {Computational} {Approaches} to {Linguistic} {Creativity}},
	publisher = {Association for Computational Linguistics},
	author = {Cua, Jeffrey and Manurung, Ruli and Ong, Ethel and Pease, Adam},
	month = jun,
	year = {2010},
	pages = {40--48},
	file = {Full Text PDF:files/5035/Cua et al. - 2010 - Representing Story Plans in SUMO.pdf:application/pdf},
}

@article{van_hage_design_2011,
	series = {Provenance in the {Semantic} {Web}},
	title = {Design and use of the {Simple} {Event} {Model} ({SEM})},
	volume = {9},
	issn = {1570-8268},
	url = {https://www.sciencedirect.com/science/article/pii/S1570826811000199},
	doi = {10.1016/j.websem.2011.03.003},
	abstract = {Events have become central elements in the representation of data from domains such as history, cultural heritage, multimedia and geography. The Simple Event Model (SEM) is created to model events in these various domains, without making assumptions about the domain-specific vocabularies used. SEM is designed with a minimum of semantic commitment to guarantee maximal interoperability. In this paper, we discuss the general requirements of an event model for Web data and give examples from two use cases: historic events and events in the maritime safety and security domain. The advantages and disadvantages of several existing event models are discussed in the context of the historic example. We discuss the design decisions underlying SEM. SEM is coupled with a Prolog API that enables users to create instances of events without going into the details of the implementation of the model. By a tight coupling to existing Prolog packages, the API facilitates easy integration of event instances to Linked Open Data. We illustrate use of the API with examples from the maritime domain.},
	language = {en},
	number = {2},
	urldate = {2023-05-29},
	journal = {Journal of Web Semantics},
	author = {van Hage, Willem Robert and Malaisé, Véronique and Segers, Roxane and Hollink, Laura and Schreiber, Guus},
	month = jul,
	year = {2011},
	keywords = {Ontology, Semantic Web, API, Event, Event model, Prolog},
	pages = {128--136},
	file = {ScienceDirect Full Text PDF:files/5284/van Hage et al. - 2011 - Design and use of the Simple Event Model (SEM).pdf:application/pdf;ScienceDirect Snapshot:files/5285/S1570826811000199.html:text/html},
}

@book{bal_narratology_2009,
	title = {Narratology: {Introduction} to the {Theory} of {Narrative}},
	isbn = {978-0-8020-9631-9},
	shorttitle = {Narratology},
	abstract = {Since its first publication in English in 1985, Mieke Bal\&\#39;s Narratology has become the international classic and comprehensive introduction to the theory of narrative texts. Narratology is a systematic account of narrative techniques, methods, their transmission, and reception, in which Bal distills years of study of the ways in which we understand both literary and non-literary works. In this third edition, Bal updates the book to include more analysis of film narratives while also sharpening and tightening her language to make it the most readable and student-friendly edition to date. Bal also introduces new sections that treat and clarify several modernist texts that pose narratological challenges. With changes prompted by ten years of feedback from scholars and teachers, Narratology remains the most important contribution to the study of the way narratives work, are formed, and are received.},
	language = {en},
	publisher = {University of Toronto Press},
	author = {Bal, Mieke and Boheemen, Christine van},
	month = jan,
	year = {2009},
	note = {Google-Books-ID: jPj4Bq0H4JoC},
	keywords = {Literary Criticism / Semiotics \& Theory},
}

@book{chatman_story_1978,
	title = {Story and {Discourse}: {Narrative} {Structure} in {Fiction} and {Film}},
	isbn = {978-0-8014-9186-3},
	shorttitle = {Story and {Discourse}},
	abstract = {Narrative and poetics - Is narrative a semiotic structure? - Narrative inference, selection, and coherence - A sketch of narrative structure - Sequence, contingency, causality - Kernels and satellites - Suspense and surprise - How time distinctions are manifested - Narrative macrostructure and the typology of plot - Story-space and discourse-space - Story-space in cinematic narrative - Story-existents : character - Todorov and barthes on character - Toward an open theory of character - Real author, implied author, narrator, real reader, implied reader, narratee - Narrators' and characters' speech acts - Soliloquy - Stream of consciousness = free association - Covert narrators - Limitation of authority in narrative transmission - Overt narration : set descriptions - Reports of what characters Did not think or say - Implicit commentary : ironic narrator and unreliable narrator - Commentary on the story : interpretation - Commentary on the story : generalization - Commentary on the discou ...},
	language = {en},
	publisher = {Cornell University Press},
	author = {Chatman, Seymour Benjamin},
	year = {1978},
	note = {Google-Books-ID: ewrOp9uPjYUC},
}

@article{hyvonen_semantic_nodate,
	title = {Semantic {Kalevala} —{Accessing} {Cultural} {Content} {Through} {Semantically} {Annotated} {Stories}},
	abstract = {An event-based approach is presented for annotating events and narrative structures underlying texts and stories semantically. The idea is applied to using the Finnish national epic Kalevala for accessing related cultural contents, such as artifacts, paintings etc. in the semantic portal “CultureSampo—Finnish Culture on the Semantic Web”.},
	language = {en},
	author = {Hyvonen, Eero and Takala, Joeli and Alm, Olli and Ruotsalo, Tuukka and Makela, Eetu},
	file = {Hyvonen et al. - Semantic Kalevala —Accessing Cultural Content Thro.pdf:files/5290/Hyvonen et al. - Semantic Kalevala —Accessing Cultural Content Thro.pdf:application/pdf},
}

@inproceedings{hyvonen_biographysampo_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{BiographySampo} – {Publishing} and {Enriching} {Biographies} on the {Semantic} {Web} for {Digital} {Humanities} {Research}},
	isbn = {978-3-030-21348-0},
	doi = {10.1007/978-3-030-21348-0_37},
	abstract = {This paper argues for making a paradigm shift in publishing and using biographical dictionaries on the web, based on Linked Data. The idea is to provide the user with enhanced reading experience of biographies by enriching contents with data linking and reasoning. In addition, versatile tooling for (1) biographical research of individual persons as well as for (2) prosopographical research on groups of people are provided. To demonstrate and evaluate the new possibilities, we present the semantic portal “BiographySampo – Finnish Biographies on the Semantic Web”. The system is based on a knowledge graph extracted automatically from a collection of 13 100 textual biographies, enriched with data linking to 16 external data sources, and by harvesting external collection data from libraries, museums, and archives. The portal was released in September 2018 for free public use at http://biografiasampo.fi.},
	language = {en},
	booktitle = {The {Semantic} {Web}},
	publisher = {Springer International Publishing},
	author = {Hyvönen, Eero and Leskinen, Petri and Tamper, Minna and Rantala, Heikki and Ikkala, Esko and Tuominen, Jouni and Keravuori, Kirsi},
	editor = {Hitzler, Pascal and Fernández, Miriam and Janowicz, Krzysztof and Zaveri, Amrapali and Gray, Alasdair J.G. and Lopez, Vanessa and Haller, Armin and Hammar, Karl},
	year = {2019},
	pages = {574--589},
	file = {Full Text PDF:files/5293/Hyvönen et al. - 2019 - BiographySampo – Publishing and Enriching Biograph.pdf:application/pdf},
}

@article{mulholland_using_2002,
	title = {Using digital narratives to support the collaborative learning and exploration of cultural heritage},
	issn = {1529-4188},
	url = {https://oro.open.ac.uk/23742/},
	abstract = {Cultural institutions increasingly see the need to play an important role in the lifelong learning of citizens. Recent trends, particularly in science museums, have been toward supporting visitors to actively learn rather than passively receive information. We propose how narrative can be used within the design of new technologies to support lifelong learning in a cultural setting. Narratives can be used to construct explanations and make sense of the world. Narrative is also central to collaboration and the building of community identity. Heritage collections, whether held privately or curated by a cultural institution convey narratives. Our conceptualisation of narrative, learning theory and curatorial practice indicates that new technology in the cultural domain should: support active interpretation; help reveal the context and process underpinning cultural artifacts; support learning and creativity; and address the challenge to provide an experience that is both entertaining and educational.},
	language = {en},
	urldate = {2023-05-29},
	journal = {Proceedings of the 16th International Workshop on Database \& Expert Systems Applications (DEXA)},
	author = {Mulholland, P. and Collins, T.},
	year = {2002},
	pages = {527--531},
	file = {Snapshot:files/5295/23742.html:text/html},
}

@inproceedings{fernie_paths_2012,
	title = {{PATHS}: {Personalising} access to cultural heritage spaces},
	shorttitle = {{PATHS}},
	doi = {10.1109/VSMM.2012.6365960},
	abstract = {Digitisation of the cultural heritage means that a significant amount of material is now available through online digital library portals. However, the vast quantity of cultural heritage material can also be overwhelming for many users who lack knowledge of the collections, subject knowledge and the specialist language used to describe this content. Search portals often provide little or no guidance on how to find and interpret this information. The situation is very different in museums and galleries where collections are organized in exhibitions which offer themes and stories that visitors can explore. The PATHS project, which is funded under the European Commission's FP7 programme, is developing a system that explores the familiar metaphor of a trail (pathway) to enhance the discovery and use of the content made available in digital libraries. This paper will report on the findings of the user requirements analysis and the specifications for the first prototype of the PATHS system which is based on contents from Europeana and the Alinari Archives.},
	booktitle = {2012 18th {International} {Conference} on {Virtual} {Systems} and {Multimedia}},
	author = {Fernie, Kate and Griffiths, Jillian and Stevenson, Mark and Clough, Paul and Goodale, Paula and Hall, Mark and Archer, Phil and Chandrinos, Konstantinos and Agirre, Eneko and de Lacalle, Oier Lopez and de Polo, Andrea and Bergheim, Runar},
	month = sep,
	year = {2012},
	keywords = {Cultural differences, Libraries, cultural heritage, Europe, storytelling, Europeana, Materials, Data visualization, digital libraries, pathways, Portals, Prototypes},
	pages = {469--474},
	file = {IEEE Xplore Abstract Record:files/5298/similar.html:text/html;IEEE Xplore Full Text PDF:files/5297/Fernie et al. - 2012 - PATHS Personalising access to cultural heritage s.pdf:application/pdf},
}

@article{damiano_exploring_2016,
	title = {Exploring cultural heritage repositories with creative intelligence. {The} {Labyrinth} {3D} system},
	volume = {16},
	issn = {1875-9521},
	url = {https://www.sciencedirect.com/science/article/pii/S1875952116300167},
	doi = {10.1016/j.entcom.2016.05.002},
	abstract = {In cultural heritage, the use of ontologies makes the description of artworks clearer and self-explanatory, with advantages in terms of interoperability. The current shift towards semantic encoding opens the way to the creation of interfaces that allow the users to build personal paths in heritage collections by exploiting the relations over the artworks. In the attempt to leverage this multiplicity of paths, we designed and implemented a system, called Labyrinth 3D, which integrates the semantic annotation of cultural objects with the interaction style of 3D games. The system immerses the user into a virtual 3D labyrinth, where turning points and paths represent the semantic relations over cultural objects, with the goal of engaging the user in the exploration of the collection.},
	language = {en},
	urldate = {2023-05-29},
	journal = {Entertainment Computing},
	author = {Damiano, Rossana and Lombardo, Vincenzo and Lieto, Antonio and Borra, Davide},
	month = jul,
	year = {2016},
	keywords = {Cultural heritage, 3D visualization, Computational ontologies},
	pages = {41--52},
	file = {ScienceDirect Full Text PDF:files/5300/Damiano et al. - 2016 - Exploring cultural heritage repositories with crea.pdf:application/pdf;ScienceDirect Snapshot:files/5301/S1875952116300167.html:text/html},
}

@inproceedings{oinonen_designing_2006,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Designing a {Story} {Database} for {Use} in {Automatic} {Story} {Generation}},
	isbn = {978-3-540-45261-4},
	doi = {10.1007/11872320_36},
	abstract = {In this paper we propose a model for the representation of stories in a story database. The use of such a database will enable computational story generation systems to learn from previous stories and associated user feedback, in order to create believable stories with dramatic plots that invoke an emotional response from users. Some of the distinguishing characteristics of our proposal are the inclusion of what we call ‘narratological concepts’ and user feedback in the story database.},
	language = {en},
	booktitle = {Entertainment {Computing} - {ICEC} 2006},
	publisher = {Springer},
	author = {Oinonen, Katri and Theune, Mariët and Nijholt, Anton and Uijlings, Jasper},
	editor = {Harper, Richard and Rauterberg, Matthias and Combetto, Marco},
	year = {2006},
	keywords = {automatic story generation, Story database, story representation},
	pages = {298--301},
	file = {Full Text PDF:files/5324/Oinonen et al. - 2006 - Designing a Story Database for Use in Automatic St.pdf:application/pdf},
}

@misc{branch_knowledge_2016,
	title = {Knowledge {Organization} in {Transmedia} {Fictional} {Worlds}: {A} {Study} of {Harry} {Potter}, {Lord} of the {Rings}, {Marvel} {Universe}, and {Star} {Wars}},
	copyright = {Attribution-NonCommercial-NoDerivs 3.0 United States},
	shorttitle = {Knowledge {Organization} in {Transmedia} {Fictional} {Worlds}},
	url = {https://digital.lib.washington.edu:443/researchworks/handle/1773/36214},
	abstract = {Currently there is no structured data standard for representing elements commonly found in transmedia fictional universes. There are websites dedicated to individual universes, however, information found on these sites separates the various formats into books, movies, comics, etc.; concentrate on only the bibliographic aspects of the material; and are only full-text searchable. We have created an ontological model that will allow researchers, fans, brand managers, and creators to search for and retrieve the information contained in these worlds based on how they are structured. We conducted a domain analysis and user studies based on the contents of Harry Potter, Lord of the Rings, the Marvel Universe, and Star Wars in order to build a new model using the Ontology Web Language (OWL) and an artificial intelligence reasoning engine. This model can infer connections between characters, elements of power, items, places, events, etc. This model will facilitate better search and retrieval of the information contained within these vast story universes for all users interested in them. The result of this project is and OWL ontology that is intuitive for users; can be used by AI systems; and has been updated to reflect real user needs based on user research.},
	language = {en\_US},
	urldate = {2023-05-29},
	author = {Branch, Frank and Arias, Theresa and Kennah, Jolene and Phillips, Rebekah},
	month = may,
	year = {2016},
	note = {Accepted: 2016-06-02T22:11:15Z},
}

@article{menard_entertainment_2015,
	title = {Entertainment {Assembled}: {The} {Marvel} {Cinematic} {Universe}, a {Case} {Study} in {Transmedia}},
	shorttitle = {Entertainment {Assembled}},
	url = {https://digitalcommons.liberty.edu/masters/354},
	journal = {Masters Theses},
	author = {Menard, Drew},
	month = jun,
	year = {2015},
	file = {"Entertainment Assembled\: The Marvel Cinematic Universe, a Case Study i" by Drew Menard:files/5426/354.html:text/html},
}

@book{polkinghorne_narrative_1988,
	title = {Narrative {Knowing} and the {Human} {Sciences}},
	isbn = {978-0-88706-623-8},
	abstract = {This book expands the concept of the nature of science and provides a practical research alternative for those who work with people and organizations.Using literary criticism, philosophy, and history, as well as recent developments in the cognitive and social sciences, Narrative Knowing and the Human Sciences shows how to use research information organized by the narrative form--such information as clinical life histories, organizational case studies, biographic material, corporate cultural designs, and literary products. The relationship between the narrative format and classical and statistical and experimental designs is clarified and made explicit. Suggestions for doing research are given as well as criteria for judging the accuracy and quality of narrative research results.},
	language = {en},
	publisher = {SUNY Press},
	author = {Polkinghorne, Donald E.},
	month = apr,
	year = {1988},
	note = {Google-Books-ID: kWpGAAAAQBAJ},
	keywords = {Psychology / General},
}

@inproceedings{gervas_need_2014,
	address = {Dagstuhl, Germany},
	series = {{OpenAccess} {Series} in {Informatics} ({OASIcs})},
	title = {The {Need} for {Multi}-{Aspectual} {Representation} of {Narratives} in {Modelling} their {Creative} {Process}},
	volume = {41},
	isbn = {978-3-939897-71-2},
	url = {http://drops.dagstuhl.de/opus/volltexte/2014/4645},
	doi = {10.4230/OASIcs.CMN.2014.61},
	urldate = {2023-05-29},
	booktitle = {2014 {Workshop} on {Computational} {Models} of {Narrative}},
	publisher = {Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik},
	author = {Gervás, Pablo and León, Carlos},
	editor = {Finlayson, Mark A. and Meister, Jan Christoph and Bruneau, Emile G.},
	year = {2014},
	note = {ISSN: 2190-6807},
	keywords = {conceptual representation of narrative, creative process, narrative construction},
	pages = {61--76},
	file = {Full Text PDF:files/5555/Gervás e León - 2014 - The Need for Multi-Aspectual Representation of Nar.pdf:application/pdf;Snapshot:files/5556/4645.html:text/html},
}

@inproceedings{van_den_akker_digital_2011,
	address = {New York, NY, USA},
	series = {{WebSci} '11},
	title = {Digital hermeneutics: {Agora} and the online understanding of cultural heritage},
	isbn = {978-1-4503-0855-7},
	shorttitle = {Digital hermeneutics},
	url = {https://dl.acm.org/doi/10.1145/2527031.2527039},
	doi = {10.1145/2527031.2527039},
	abstract = {Cultural heritage institutions are currently rethinking access to their collections to allow the public to interpret and contribute to their collections. In this work, we present the Agora project, an interdisciplinary project in which Web technology and theory of interpretation meet. This we call digital hermeneutics. The Agora project facilitates the understanding of historical events and improves the access to integrated online history collections. In this contribution, we focus on defining and modeling prototypical object-event and event-event relationships that support the interpretation of objects in cultural heritage collections. We present a use case in which we model historical events as well as relations between objects and events for a set of paintings from the Rijksmuseum Amsterdam collection. Our use case shows how Web technology and theory of interpretation meet in the present, and what technological hurdles still need to be taken to fully support digital hermeneutics.},
	urldate = {2023-05-29},
	booktitle = {Proceedings of the 3rd {International} {Web} {Science} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {van den Akker, Chiel and Legêne, Susan and van Erp, Marieke and Aroyo, Lora and Segers, Roxane and van der Meij, Lourens and van Ossenbruggen, Jacco and Schreiber, Guus and Wielinga, Bob and Oomen, Johan and Jacobs, Geertje},
	month = jun,
	year = {2011},
	keywords = {collection enrichment, digital hermeneutics, online cultural heritage},
	pages = {1--7},
	file = {Full Text PDF:files/5558/van den Akker et al. - 2011 - Digital hermeneutics Agora and the online underst.pdf:application/pdf},
}

@book{freeman_routledge_2018,
	title = {The {Routledge} {Companion} to {Transmedia} {Studies}},
	isbn = {978-1-351-05488-1},
	abstract = {Around the globe, people now engage with media content across multiple platforms, following stories, characters, worlds, brands and other information across a spectrum of media channels. This transmedia phenomenon has led to the burgeoning of transmedia studies in media, cultural studies and communication departments across the academy. The Routledge Companion to Transmedia Studies is the definitive volume for scholars and students interested in comprehending all the various aspects of transmediality. This collection, which gathers together original articles by a global roster of contributors from a variety of disciplines, sets out to contextualize, problematize and scrutinize the current status and future directions of transmediality, exploring the industries, arts, practices, cultures, and methodologies of studying convergent media across multiple platforms.},
	language = {en},
	publisher = {Routledge},
	author = {Freeman, Matthew and Gambarato, Renira Rampazzo},
	month = oct,
	year = {2018},
	note = {Google-Books-ID: CatxDwAAQBAJ},
	keywords = {Business \& Economics / Industries / Media \& Communications, Language Arts \& Disciplines / Communication Studies},
}

@inproceedings{javanshir_model_2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Model} for {Describing} {Alternate} {Reality} {Games}},
	isbn = {978-3-030-04028-4},
	doi = {10.1007/978-3-030-04028-4_25},
	abstract = {Alternate Reality Games (ARGs) are a form of transmedia storytelling that are difficult to describe and analyse due to their inherent ephemerality and use of multiple media channels. But critical analyses of ARGs and a deeper understanding of how they work are needed for both improvements in ARG design theory, and to aid in the preservation of ARG content and structure. This paper presents a way to describe and analyse ARGs, the ARG Descriptive Model (ADM), that combines together features from several existing approaches to create a more holistic description of an ARG. The ADM is then applied to two case studies to demonstrate how it can be used to model the media channels, potential navigation routes between these channels, and how these channels evolve over time. The paper shows that this approach can be applied to create a basis for a common methodology for ARG analyses.},
	language = {en},
	booktitle = {Interactive {Storytelling}},
	publisher = {Springer International Publishing},
	author = {Javanshir, Ryan and Carroll, Beth and Millard, David E.},
	editor = {Rouse, Rebecca and Koenitz, Hartmut and Haahr, Mads},
	year = {2018},
	keywords = {Narrative, Alternate Reality Games, Transmedia storytelling},
	pages = {250--258},
	file = {Full Text PDF:files/5736/Javanshir et al. - 2018 - A Model for Describing Alternate Reality Games.pdf:application/pdf},
}

@inproceedings{klastrup_transmedial_2004,
	title = {Transmedial worlds - rethinking cyberworld design},
	doi = {10.1109/CW.2004.67},
	abstract = {In this paper we introduce the concept of transmedial worlds, relating it to genre and adaptation theory, and presenting a framework for how to look for transmedial traits in a world. Through some examples, we argue that applying this concept to the analysis of cyberworlds can reveal interesting results, as well as being a useful tool for designers of cyberworlds to plan their content.},
	booktitle = {2004 {International} {Conference} on {Cyberworlds}},
	author = {Klastrup, L. and Tosca, S.},
	month = nov,
	year = {2004},
	keywords = {Earth, Writing, Books, Computer graphics, Fans, Game theory, Marine animals},
	pages = {409--416},
	file = {IEEE Xplore Abstract Record:files/5739/1366205.html:text/html;IEEE Xplore Full Text PDF:files/5738/Klastrup e Tosca - 2004 - Transmedial worlds - rethinking cyberworld design.pdf:application/pdf},
}

@book{atkinson_beyond_2014,
	title = {Beyond the {Screen}: {Emerging} {Cinema} and {Engaging} {Audiences}},
	isbn = {978-1-62356-823-8},
	shorttitle = {Beyond the {Screen}},
	abstract = {Runner-up for the British Association of Film, Television and Screen Studies Best Book Prize 2015Beyond the Screen presents an expanded conceptualization of cinema which encompasses the myriad ways film can be experienced in a digitally networked society where the auditorium is now just one location amongst many in which audiences can encounter and engage with films. The book includes considerations of mobile, web, social media and live cinema through numerous examples and case studies of recent and near-future developments. Through analyses of narrative, text, process, apparatus and audience this book traces the metamorphosis of an emerging cinema and maps the new spaces of spectatorship which are currently challenging what it means to be cinematic in a digitally networked era.},
	language = {en},
	publisher = {Bloomsbury Publishing USA},
	author = {Atkinson, Sarah},
	month = apr,
	year = {2014},
	note = {Google-Books-ID: MTwkAwAAQBAJ},
	keywords = {Social Science / Media Studies},
}

@inproceedings{aarseth_narrative_2012,
	address = {New York, NY, USA},
	series = {{FDG} '12},
	title = {A narrative theory of games},
	isbn = {978-1-4503-1333-9},
	url = {https://dl.acm.org/doi/10.1145/2282338.2282365},
	doi = {10.1145/2282338.2282365},
	abstract = {This paper presents a narrative theory of games, building on standard narratology, as a solution to the conundrum that has haunted computer game studies from the start: How to approach software that combines games and stories?},
	urldate = {2023-05-29},
	booktitle = {Proceedings of the {International} {Conference} on the {Foundations} of {Digital} {Games}},
	publisher = {Association for Computing Machinery},
	author = {Aarseth, Espen},
	month = may,
	year = {2012},
	keywords = {ludonarrative model, narratology, storygames},
	pages = {129--133},
	file = {Full Text PDF:files/5744/Aarseth - 2012 - A narrative theory of games.pdf:application/pdf},
}

@article{ruppel_visualizing_2012,
	title = {Visualizing {Transmedia} {Networks}: {Links}, {Paths} and {Peripheries}},
	shorttitle = {Visualizing {Transmedia} {Networks}},
	url = {http://hdl.handle.net/1903/13589},
	abstract = {`Visualizing Transmedia Networks: Links, Paths and Peripheries' examines the increasingly complex rhetorical intersections between narrative and media (`old' and `new') in the creation of transmedia fictions, loosely defined as multisensory and multimodal stories told extensively across a diverse media set. In order to locate the `language' of transmedia expressions, this project calls attention to the formally locatable network structures placed by transmedia producers in disparate media like film, the print novel and video games. Using network visualization software and computational metrics, these structures can be used as data to graph these fictions for both quantitative and qualitative analysis. This study also, however, examines the limits to this approach, arguing that the process of transremediation, where redundancy and multiformity take precedence over networked connection, forms a second axis for understanding transmedia practices, one equally bound to the formation of new modes of meaning and literacy.},
	language = {en},
	urldate = {2023-05-29},
	author = {Ruppel, Marc},
	year = {2012},
	file = {Full Text PDF:files/5746/Ruppel - 2012 - Visualizing Transmedia Networks Links, Paths and .pdf:application/pdf},
}

@book{peer_new_2001,
	title = {New {Perspectives} on {Narrative} {Perspective}},
	isbn = {978-0-7914-4787-1},
	abstract = {Narrative perspective is the faculty through which humans understand, structure, and explore the world that confronts them. This is the first volume to bring together the theoretical study of perspective with the rigor of experimental studies, combining work in narratology with that in linguistics, philosophy, film studies, literary theory, and cognitive psychology. The chapters are grouped thematically and drawn together by the editors, who provide guidance through this new and fascinating interdisciplinary territory.},
	language = {en},
	publisher = {SUNY Press},
	author = {Peer, Willie van and Chatman, Seymour Benjamin},
	month = mar,
	year = {2001},
	note = {Google-Books-ID: jU8OXcgs07UC},
	keywords = {Literary Criticism / General, Language Arts \& Disciplines / Rhetoric},
}

@inproceedings{khan_leveraging_2016,
	address = {Dagstuhl, Germany},
	series = {{OpenAccess} {Series} in {Informatics} ({OASIcs})},
	title = {Leveraging a {Narrative} {Ontology} to {Query} a {Literary} {Text}},
	volume = {53},
	isbn = {978-3-95977-020-0},
	url = {http://drops.dagstuhl.de/opus/volltexte/2016/6711},
	doi = {10.4230/OASIcs.CMN.2016.10},
	urldate = {2023-05-29},
	booktitle = {7th {Workshop} on {Computational} {Models} of {Narrative} ({CMN} 2016)},
	publisher = {Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik},
	author = {Khan, Anas Fahad and Bellandi, Andrea and Benotto, Giulia and Frontini, Francesca and Giovannetti, Emiliano and Reboul, Marianne},
	editor = {Miller, Ben and Lieto, Antonio and Ronfard, Rémi and Ware, Stephen G. and Finlayson, Mark A.},
	year = {2016},
	note = {ISSN: 2190-6807},
	keywords = {Ontology, Semantic Web, Computational Narratology, Lexicon, Time},
	pages = {10:1--10:10},
	file = {Full Text PDF:files/5926/Khan et al. - 2016 - Leveraging a Narrative Ontology to Query a Literar.pdf:application/pdf;Snapshot:files/5925/6711.html:text/html},
}

@inproceedings{lawrence_ontomedia_2005,
	title = {{OntoMedia} - {Creating} an {Ontology} for {Marking} {Up} the {Contents} of {Heterogeneous} {Media}},
	url = {https://eprints.soton.ac.uk/261153/},
	abstract = {This paper describes the OntoMedia ontology, an ontology for describing the semantic content of hetrogeneous media. We present our motivation for creating this ontology and consider how it relates to similar ontologies in the bibliographic and multimedia domains.},
	language = {en},
	urldate = {2023-05-29},
	author = {Lawrence, K. Faith and Tuffield, Mischa M. and Jewell, Mike O. and Prugel-Bennett, Adam and Millard, David E. and Nixon, Mark S. and schraefel, m c and Shadbolt, Nigel R.},
	collaborator = {Lawrence, K. Faith and Tuffield, Mischa M. and Jewell, Mike O. and Prugel-Bennett, Adam and Millard, David E. and Nixon, Mark S. and schraefel, m c and Shadbolt, Nigel R.},
	year = {2005},
	file = {Full Text PDF:files/5928/Lawrence et al. - 2005 - OntoMedia - Creating an Ontology for Marking Up th.pdf:application/pdf;Snapshot:files/5929/261153.html:text/html},
}

@article{dennett_interpretation_1990,
	title = {The {Interpretation} of {Texts}, {People} and {Other} {Artifacts}},
	volume = {50},
	issn = {0031-8205},
	url = {https://www.jstor.org/stable/2108038},
	doi = {10.2307/2108038},
	urldate = {2023-05-29},
	journal = {Philosophy and Phenomenological Research},
	author = {Dennett, Daniel C.},
	year = {1990},
	note = {Publisher: [International Phenomenological Society, Philosophy and Phenomenological Research, Wiley]},
	pages = {177--194},
	file = {JSTOR Full Text PDF:files/5931/Dennett - 1990 - The Interpretation of Texts, People and Other Arti.pdf:application/pdf},
}

@book{eco_role_1979,
	title = {The {Role} of the {Reader}: {Explorations} in the {Semiotics} of {Texts}},
	isbn = {978-0-253-20318-2},
	shorttitle = {The {Role} of the {Reader}},
	abstract = {" . . . not merely interesting and novel, but also exceedingly provocative and heuristically fertile." —The Review of Metaphysics" . . . essential reading for anyone interesting in . . . the new reader-centered forms of criticism." —Library JournalIn this erudite and imaginative book, Umberto Eco sets forth a dialectic between 'open' and 'closed' texts.},
	language = {en},
	publisher = {Indiana University Press},
	author = {Eco, Umberto},
	year = {1979},
	note = {Google-Books-ID: KlJNp\_hUmEIC},
	keywords = {Literary Criticism / Semiotics \& Theory},
}

@incollection{ribeiro_conceptual_2018-1,
	title = {A {Conceptual} model for an {OWL} ontology to represent the knowledge of transmedia storytelling},
	isbn = {978-3-95650-421-1},
	url = {https://www.nomos-elibrary.de/index.php?doi=10.5771/9783956504211-511},
	abstract = {This paper proposes a conceptual model and an OWL ontology for the representation and knowledge organization of transmedia narratives and the creation of RDF datasets. The authors have adopted an approach based on the development of a flexible conceptual model for the management and representation of information accessible in a network environment. The conceptual model identifies a series of entities, attributes and relationships to describe, organize and interrelate the knowledge of transmedia contents. From the conceptual model an OWL ontology has been developed in which SKOS has been widely used in the ontology to separate the conceptual description of resources. The conceptual model allows the design of architectures for the consumption of contents and the ontology offers a first conceptual level for the organization of knowledge of transmedia narratives.},
	language = {en},
	urldate = {2023-05-29},
	booktitle = {Challenges and {Opportunities} for {Knowledge} {Organization} in the {Digital} {Age}},
	publisher = {Ergon Verlag},
	author = {Sánchez, Juan Antonio Pastor and Pérez, Tomás Saorín},
	editor = {Ribeiro, Fernanda and Cerveira, Maria Elisa},
	year = {2018},
	doi = {10.5771/9783956504211-511},
	pages = {511--520},
	file = {Sánchez e Pérez - 2018 - A Conceptual model for an OWL ontology to represen.pdf:files/5947/Sánchez e Pérez - 2018 - A Conceptual model for an OWL ontology to represen.pdf:application/pdf},
}

@article{gambarato_transmedia_2013,
	title = {Transmedia {Project} {Design}: {Theoretical} and {Analytical} {Considerations}},
	volume = {1},
	shorttitle = {Transmedia {Project} {Design}},
	url = {https://sciendo.com/article/10.1515/bsmr-2015-0006},
	doi = {10.1515/bsmr-2015-0006},
	abstract = {Abstract Theoretical and analytical considerations around the development of transmedia projects are evolving, but are still widely open, probably because transmedia storytelling is a relatively new subject that does not yet have its own specific methods and methodology of analysis. Moreover, transmedia projects are complex phenomena involving multiple dimensions, such as narrative, cultural context, marketing, business models, and legal framework. Currently, the usual approach gives place to methodologically separate analytical perspectives related to some of these dimensions. This article first discusses the elusive concept of transmedia storytelling and later presents analytical considerations outlining relevant aspects that can contribute to perceive the process of developing transmedia projects. The significance of these discussions is to address essential features of the design process behind transmedia projects and contribute to support the analytic needs of transmedia designers and the applied research in the interest of the media industry.},
	language = {en},
	number = {1},
	urldate = {2023-05-29},
	journal = {Baltic Screen Media Review},
	author = {Gambarato, Renira Rampazzo},
	month = oct,
	year = {2013},
	pages = {80--100},
	file = {Full Text PDF:files/6081/Gambarato - 2013 - Transmedia Project Design Theoretical and Analyti.pdf:application/pdf},
}

@article{jung_computational_2017,
	title = {A computational model of transmedia ecosystem for story-based contents},
	volume = {76},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-016-3626-5},
	doi = {10.1007/s11042-016-3626-5},
	abstract = {Story-based contents (e.g., novel, movies, and computer games) have been dynamically transformed into various media. In this environment, the contents are not complete in themselves, but closely connected with each other. Also, they are not simply transformed form a medium to other media, but expanding their stories. It is called as a transmedia storytelling, and a group of contents following it is called as a transmedia ecosystem. Since the contents are highly connected in terms of the story in the transmedia ecosystem, the existing content analysis methods are hard to extract relationships between the contents. Therefore, a proper content analysis method is needed with considering expansions of the story. The aim of this work is to understand how (and why) such contents are transformed by i) defining the main features of the transmedia storytelling and ii) building the taxonomy among the transmedia patterns. More importantly, computational transmedia ecosystem is designed to process a large number of the contents, and to support high understandability of the complex transmedia patterns.},
	language = {en},
	number = {8},
	urldate = {2023-05-29},
	journal = {Multimedia Tools and Applications},
	author = {Jung, Jai E. and Lee, O-Joun and You, Eun-Soon and Nam, Myoung-Hee},
	month = apr,
	year = {2017},
	keywords = {Storytelling, Computational ecosystem, Digital contents, Multimedia analysis, Transmedia},
	pages = {10371--10388},
	file = {Full Text PDF:files/6083/Jung et al. - 2017 - A computational model of transmedia ecosystem for .pdf:application/pdf},
}

@article{biasio_percorsi_2020,
	title = {Percorsi della narratività/letterarietà},
	abstract = {The essay is divided into two parts. The first section offers a review of some influential narratological studies that in the last two decades have dealt with the challenge posed by transmediality. Special attention is given to key-concepts such as ‘storyworld,’ ‘narrativity,’ and more media-neutral descriptions of the functioning of the narrative voice and perspective. The discussion stresses the apparent marginalization of the literary model, which in fact re-emerges as an essential reference point of ‘postclassical narratology.’ The second part of the essay focuses on the television show Game of Thrones (2011-2019) as an adaptation of the fantasy novel series A Song of Ice and Fire (1996-2011) by George R. R. Martin. The first part of the analysis discusses collective authorship (or ‘transauthorship’) as a typical phenomenon of transmedia narratives, emphasizing the conflicts that it may entail. The second part of the analysis examines the pilot of Game of Thrones in a (neo-)narratological perspective, paying special attention to the audiovisual adaptation of Martin’s use of the limited point of view. The empowerment of the level of discourse in the episode has the paradoxical effect of increasing its ‘literariness,’ in the sense of the density and porosity of form. The second part of the essay, therefore, reinforces the relevance—at several levels—of the literary model to the comprehension of transmedia narratives.},
	language = {it},
	number = {16},
	author = {Biasio, Anna De},
	year = {2020},
	file = {Biasio - 2020 - Percorsi della narrativitàletterarietà.pdf:files/6095/Biasio - 2020 - Percorsi della narrativitàletterarietà.pdf:application/pdf},
}

@article{vukadin_bits_2014-1,
	title = {Bits and {Pieces} of {Information}: {Bibliographic} {Modeling} of {Transmedia}},
	volume = {52},
	issn = {0163-9374},
	shorttitle = {Bits and {Pieces} of {Information}},
	url = {https://doi.org/10.1080/01639374.2013.879976},
	doi = {10.1080/01639374.2013.879976},
	abstract = {Transmedia is a technique of telling a single narrative or creating a continuous imaginary world across multiple media platforms. The article seeks to explore this emerging phenomenon in terms of bibliographic organization. It analyzes transmedia features in the context of bibliographic entities and relationships, particularly those outlined in the Functional Requirements for Bibliographic Records FRBR and FRBROO (object-oriented redefinition) conceptual models.},
	number = {3},
	urldate = {2023-05-29},
	journal = {Cataloging \& Classification Quarterly},
	author = {Vukadin, Ana},
	month = apr,
	year = {2014},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/01639374.2013.879976},
	keywords = {FRBR, transmedia, bibliographic relationships, expression, FRBROO, work},
	pages = {285--302},
	file = {Full Text PDF:files/6127/Vukadin - 2014 - Bits and Pieces of Information Bibliographic Mode.pdf:application/pdf},
}

@article{branch_representing_2017-1,
	title = {Representing transmedia fictional worlds through ontology},
	volume = {68},
	copyright = {© 2017 ASIS\&T},
	issn = {2330-1643},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.23886},
	doi = {10.1002/asi.23886},
	abstract = {Currently, there is no structured data standard for representing elements commonly found in transmedia fictional worlds. Although there are websites dedicated to individual universes, the information found on these sites separate out the various formats, concentrate on only the bibliographic aspects of the material, and are only searchable with full text. We have created an ontological model that will allow various user groups interested in transmedia to search for and retrieve the information contained in these worlds based upon their structure. We conducted a domain analysis and user studies based on the contents of Harry Potter, Lord of the Rings, the Marvel Universe, and Star Wars in order to build a new model using Ontology Web Language (OWL) and an artificial intelligence-reasoning engine. This model can infer connections between transmedia properties such as characters, elements of power, items, places, events, and so on. This model will facilitate better search and retrieval of the information contained within these vast story universes for all users interested in them. The result of this project is an OWL ontology reflecting real user needs based upon user research, which is intuitive for users and can be used by artificial intelligence systems.},
	language = {en},
	number = {12},
	urldate = {2023-05-30},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Branch, Frank and Arias, Theresa and Kennah, Jolene and Phillips, Rebekah and Windleharth, Travis and Lee, Jin Ha},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.23886},
	pages = {2771--2782},
	file = {Full Text PDF:files/6269/Branch et al. - 2017 - Representing transmedia fictional worlds through o.pdf:application/pdf;Snapshot:files/6270/asi.html:text/html},
}

@article{group_ifla_2020,
	title = {{IFLA} {Library} {Reference} {Model}: {Un} modello concettuale per le informazioni bibliografiche},
	copyright = {CC BY 4.0},
	shorttitle = {{IFLA} {Library} {Reference} {Model}},
	url = {https://repository.ifla.org/handle/123456789/44},
	abstract = {IFLA Library Reference Model (LRM) is a high-level conceptual reference model developed within an entity-relationship modelling framework. It is the consolidation of the separately developed IFLA conceptual models: FRBR, FRAD, FRSAD. 
IFLA LRM was developed to resolve inconsistencies between the three separate models. Every user task, entity, attribute and relationship from the original three models was examined, definitions had to be revised, but also some remodelling was required in order to develop a meaningful consolidation. The result is a single, streamlined, and logically consistent model that covers all aspects of bibliographic data and that at the same time brings the modelling up-to-date with current conceptual modelling practices. 
IFLA LRM was designed to be used in linked data environments and to support and promote the use of bibliographic data in linked data environments.},
	language = {it},
	urldate = {2023-05-30},
	author = {Group, IFLA Functional Requirements for Bibliographic Records (FRBR) Review and Riva, Pat and Le Boeuf, Patrick and Žumer, Maja},
	month = nov,
	year = {2020},
	note = {Accepted: 2020-12-17T16:05:14Z
Publisher: International Federation of Library Associations and Institutions (IFLA)},
	file = {Full Text PDF:files/6293/Group et al. - 2020 - IFLA Library Reference Model Un modello concettua.pdf:application/pdf},
}

@article{group_ifla_2018-1,
	title = {{IFLA} {Library} {Reference} {Model}: {A} {Conceptual} {Model} for {Bibliographic} {Information}},
	copyright = {CC BY 4.0},
	shorttitle = {{IFLA} {Library} {Reference} {Model}},
	url = {https://repository.ifla.org/handle/123456789/40},
	abstract = {IFLA Library Reference Model (LRM) is a high-level conceptual reference model developed within an entity-relationship modelling framework. It is the consolidation of the separately developed IFLA conceptual models: FRBR, FRAD, FRSAD. 
IFLA LRM was developed to resolve inconsistencies between the three separate models. Every user task, entity, attribute and relationship from the original three models was examined, definitions had to be revised, but also some remodelling was required in order to develop a meaningful consolidation. The result is a single, streamlined, and logically consistent model that covers all aspects of bibliographic data and that at the same time brings the modelling up-to-date with current conceptual modelling practices. 
IFLA LRM was designed to be used in linked data environments and to support and promote the use of bibliographic data in linked data environments.},
	language = {en},
	urldate = {2023-05-30},
	author = {Group, IFLA Functional Requirements for Bibliographic Records (FRBR) Review and Riva, Pat and Le Boeuf, Patrick and Žumer, Maja},
	month = jan,
	year = {2018},
	note = {Accepted: 2020-12-17T15:13:08Z
Publisher: International Federation of Library Associations and Institutions (IFLA)},
	file = {Full Text PDF:files/6295/Group et al. - 2018 - IFLA Library Reference Model A Conceptual Model f.pdf:application/pdf},
}

@book{vukadin_metadata_2019,
	title = {Metadata for {Transmedia} {Resources}},
	isbn = {978-0-08-101300-7},
	abstract = {Transmedia is a technique of delivering a single piece of content in individual parts via different media and communication platforms (books, films, TV shows, games, live performances, etc.). In the book transmedia is considered as a case-in-point for the need to rethink library cataloguing and metadata practices in a new, heterogeneous information environment where the ability to bring together information from various sources into a meaningful whole becomes a critical information skill. Transmedia sheds new light on some of the long-existing questions of bibliographic information organisation (the definition of work, modelling of bibliographic relationships, subject analysis of fiction, etc.) and introduces libraries to new, transient and interactive media forms such as interactive fiction, gaming events, or performances. The book investigates how various theories and practices of bibliographic information organisation can be applied to transmedia, focusing on the solutions provided by the new bibliographic conceptual model IFLA LRM, as well as linked open data models and standards. It strongly advocates collaborative practices and reuse of knowledge that underpin an emerging vision of the library catalogue as a 'mediation tool' that assembles, links and integrates information across a variety of communication contexts.  Explores transmedia from the point-of-view of information organisation Presents one of the first extensive analyses of the IFLA LRM bibliographic conceptual model Uses examples of recent publishing practices to assess current bibliographic data models, standards, formats and technologies},
	language = {en},
	publisher = {Chandos Publishing},
	author = {Vukadin, Ana},
	month = jul,
	year = {2019},
	note = {Google-Books-ID: OUqiDwAAQBAJ},
	keywords = {Language Arts \& Disciplines / Library \& Information Science / Archives \& Special Libraries, Language Arts \& Disciplines / Library \& Information Science / General},
}

@article{pastor-sanchez_greek_nodate-1,
	title = {Greek {Mythology} as a {Knowledge} {Graph}: {From} {Chaos} to {Zeus} and {Beyond}},
	abstract = {Greek mythology has been exerting a lasting influence on Western culture, but a respective ontology has been missing from the Semantic Web until now. To remedy this deficiency, from 5377 Wikidata items with 283 properties, 34 of these properties were selected to generate a first version of an Ontology of Greek Mythology (OGM). This limited set of properties was used to define a set of classes to instantiate the descriptions of the individuals according to reification requirements. The ontology also includes the representation of contradictions between statements, a well-known symptom of classical storytelling. A retrieval tool was added to use the Wikidata Query Service through SPARQL queries in order to display and download results in various formats, thereby developing OGM into a scholarly tool. Further, as Wikidata has little information about classical sources grounding the truth of its statements, we tested a semantic enrichment workflow to extract additional statement types from source texts in the ‘Theoi Project’ as statement anchors. This workflow experiment proved necessary to go beyond Wikipedia to address mythological complexities in a knowledge graph, but, as discussed in the article, its scalable automation requires further development.},
	language = {en},
	author = {Pastor-Sánchez, Juan-Antonio and Kontopoulos, Efstratios and Saorín, Tomás and Bebis, Thomas},
	file = {Pastor-Sánchez et al. - Greek Mythology as a Knowledge Graph From Chaos t.pdf:files/6312/Pastor-Sánchez et al. - Greek Mythology as a Knowledge Graph From Chaos t.pdf:application/pdf},
}

@article{kiryakos_building_2018,
	title = {Building a bibliographic hierarchy for manga through the aggregation of institutional and hobbyist descriptions},
	volume = {75},
	issn = {0022-0418},
	url = {https://doi.org/10.1108/JD-06-2018-0089},
	doi = {10.1108/JD-06-2018-0089},
	abstract = {Purpose Multiple studies have illustrated that the needs of various users seeking descriptive bibliographic data for pop culture resources (e.g. manga, anime, video games) have not been properly met by cultural heritage institutions and traditional models. With a focus on manga as the central resource, the purpose of this paper is to address these issues to better meet user needs. Design/methodology/approach Based on an analysis of existing bibliographic metadata, this paper proposes a unique bibliographic hierarchy for manga that is also extendable to other pop culture sources. To better meet user requirements of descriptive data, an aggregation-based approach relying on the Object Reuse and Exchange-Open Archives Initiative (OAI-ORE) model utilized existing, fan-created data on the web. Findings The proposed hierarchy is better able to portray multiple entities of manga as they exist across data providers compared to existing models, while the utilization of OAI-ORE-based aggregation to build and provide bibliographic metadata for said hierarchy resulted in levels of description that more adequately meet user demands. Originality/value Though studies have proposed alternative models for resources like games or comics, manga has remained unexamined. As manga is a major component of many popular multimedia franchises, a focus here with the intention while building the model to support other resource types provides a foundation for future work seeking to incorporate these resources.},
	number = {2},
	urldate = {2023-05-30},
	journal = {Journal of Documentation},
	author = {Kiryakos, Senan and Sugimoto, Shigeo},
	month = jan,
	year = {2018},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {FRBR, Transmedia, Bibliographic families, Bibliographic hierarchies, Knowledge organizations, Manga, Metadata aggregation, OAI-ORE, Superwork},
	pages = {287--313},
	file = {Full Text PDF:files/6426/Kiryakos e Sugimoto - 2018 - Building a bibliographic hierarchy for manga throu.pdf:application/pdf},
}

@article{couprie_iconclass_1983,
	title = {Iconclass: an iconographic classification system},
	volume = {8},
	issn = {0307-4722, 2059-7525},
	shorttitle = {Iconclass},
	url = {https://www.cambridge.org/core/journals/art-libraries-journal/article/abs/iconclass-an-iconographic-classification-system/DD119669E055893AB632E5C7CE6FF417},
	doi = {10.1017/S0307472200003436},
	abstract = {Iconclass is a classification of subjects, themes and motifs in Western art. It was developed and published in Holland, at the University of Leiden, with financial aid from both the Netherlands Organisation for the Advancement of Pure Research (Z. W.O.) and the Royal Netherlands Academy of Arts and Sciences.Iconclass is used in a growing number of projects, whether computerised or not. One of these projects could be the Witt Library pilot project, discussed elsewhere in this issue of the Art Libraries Journal (pp. 27-31).In this paper the classification as such is briefly explained, mainly with the help of two examples: scenes from the stories of St. Antony Abbot and Hercules. Information on the alphabetical index to the classification is given, mainly because this extensive part of Iconclass is something more than the usual index to a publication.Applications of the classification are dealt with in diagrammatic form; one application, the Iconclass bibliography, is discussed in greater detail.},
	language = {en},
	number = {2},
	urldate = {2023-05-30},
	journal = {Art Libraries Journal},
	author = {Couprie, L. D.},
	month = jul,
	year = {1983},
	note = {Publisher: Cambridge University Press},
	pages = {32--49},
}

@article{damiano_ontological_2013-1,
	title = {Ontological {Representations} of {Narratives}: a {Case} {Study} on {Stories} and {Actions}},
	shorttitle = {Ontological {Representations} of {Narratives}},
	url = {http://drops.dagstuhl.de/opus/volltexte/2013/4149/},
	doi = {10.4230/OASICS.CMN.2013.76},
	language = {en},
	urldate = {2023-05-30},
	author = {Damiano, Rossana and Lieto, Antonio},
	collaborator = {Herbstritt, Marc},
	year = {2013},
	note = {Artwork Size: 18 pages
Medium: application/pdf
Publisher: Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik GmbH, Wadern/Saarbruecken, Germany},
	keywords = {000 Computer science, knowledge, general works, Computer Science},
	pages = {18 pages},
}

@article{rafferty_disrupting_2019,
	title = {Disrupting the {Metanarrative}: {A} {Little} {History} of {Image} {Indexing} and {Retrieval}},
	volume = {46},
	issn = {0943-7444},
	shorttitle = {Disrupting the {Metanarrative}},
	url = {https://www.nomos-elibrary.de/10.5771/0943-7444-2019-1-4/disrupting-the-metanarrative-a-little-history-of-image-indexing-and-retrieval-jahrgang-46-2019-heft-1?page=1},
	doi = {10.5771/0943-7444-2019-1-4},
	language = {en},
	number = {1},
	urldate = {2023-05-30},
	journal = {KO KNOWLEDGE ORGANIZATION},
	author = {Rafferty, Pauline},
	month = feb,
	year = {2019},
	note = {Publisher: Nomos Verlagsgesellschaft mbH \& Co. KG},
	pages = {4--14},
	file = {Full Text PDF:files/6431/Rafferty - 2019 - Disrupting the Metanarrative A Little History of .pdf:application/pdf},
}

@article{carboni_ontological_2019,
	title = {An {Ontological} {Approach} to the {Description} of {Visual} and {Iconographical} {Representations}},
	volume = {2},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2571-9408},
	url = {https://www.mdpi.com/2571-9408/2/2/78},
	doi = {10.3390/heritage2020078},
	abstract = {The perception of our heritage is based on sign-functions, which relate visual representations to cognitive types, allowing us to make perceptual judgements over physical objects. The recording of these types of assertions is paramount for the comprehension and analysis of our heritage. The article investigates a theoretical framework for the organization of information related to visual works on the basis of the identity and symbolic value of their single constituent elements. The framework developed is then used as a driver for the grounding of a new ontology called VIR (Visual Representation), constructed as an extension of CIDOC-CRM (CIDOC Conceptual Reference Model). VIR sustains the recording of statements about the different structural units and relationships of a visual representation, differentiating between object and interpretative act. The result, tested with data describing Byzantine and Renaissance artworks, presents solutions for describing symbols and meanings of iconographical objects, providing new clustering methods in relation to their constitutive elements, subjects or interpretations.},
	language = {en},
	number = {2},
	urldate = {2023-05-30},
	journal = {Heritage},
	author = {Carboni, Nicola and de Luca, Livio},
	month = jun,
	year = {2019},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {ontology, semantic web, CIDOC-CRM, iconography, art history, digital art history, digital iconology},
	pages = {1191--1210},
	file = {Full Text PDF:files/6433/Carboni e de Luca - 2019 - An Ontological Approach to the Description of Visu.pdf:application/pdf},
}

@inproceedings{breit_interlinking_2020,
	address = {Marseille, France},
	title = {Interlinking {Iconclass} {Data} with {Concepts} of {Art} \& {Architecture} {Thesaurus}},
	isbn = {979-10-95546-63-4},
	url = {https://aclanthology.org/2020.ai4hi-1.2},
	abstract = {Iconclass, being a a well established classification system, could benefit from interconnections with other ontologies in order to semantically enrich its content. This work presents a disambiguating and interlinking approach which is used to map Iconclass Subjects to concepts of the Art and Architecture Thesaurus. In a preliminary evaluation, the system is able to produce promising predictions, though the task is highly challenging due to conceptual and schema heterogeneity. Several algorithmic improvements for this specific interlinking task, as well as and future research directions are suggestions. The produced mappings, as well as the source code and additional information can be found at https://github.com/annabreit/taxonomy-interlinking.},
	language = {English},
	urldate = {2023-05-30},
	booktitle = {Proceedings of the 1st {International} {Workshop} on {Artificial} {Intelligence} for {Historical} {Image} {Enrichment} and {Access}},
	publisher = {European Language Resources Association (ELRA)},
	author = {Breit, Anna},
	month = may,
	year = {2020},
	pages = {11--15},
	file = {Full Text PDF:files/6435/Breit - 2020 - Interlinking Iconclass Data with Concepts of Art &.pdf:application/pdf},
}

@incollection{posthumus_iconclass_2016,
	title = {Iconclass: {A} key to collaboration in the digital humanities},
	isbn = {978-1-315-29837-5},
	shorttitle = {Iconclass},
	abstract = {The Infonet project aimed to produce printed versions of the Iconclass schedules, bibliography, and the alphabetic index. The keywords, originally handpicked for the alphabetic index, are shown in italics. As the Decimal Index of the Art of the Low Countries (DIAL) was first of all a collection of photocards, ordered by subject – that is, Iconclass notation – the identification of multiple subjects in the same picture necessitated multiple prints. The Infonet brief, the DIAL, and the general introduction to the first Iconclass volume described an elaborate system of cross-references that Henri Van de Waal hoped would be “in itself a tool for iconographic research. The Iconclass system in its unabridged form can be of great use for such a task”. When Van de Waal wrote this, in 1968, using Iconclass in a computerized format was not yet a realistic option, and working with a limitless number of digital reproductions of works of art was not even a fantasy.},
	booktitle = {The {Routledge} {Companion} to {Medieval} {Iconography}},
	publisher = {Routledge},
	author = {Posthumus, Etienne, Hans Brandhorst},
	year = {2016},
	note = {Num Pages: 18},
}

@inproceedings{segers_circumstantial_2017,
	address = {Vancouver, Canada},
	title = {The {Circumstantial} {Event} {Ontology} ({CEO})},
	url = {https://aclanthology.org/W17-2706},
	doi = {10.18653/v1/W17-2706},
	abstract = {In this paper we describe the ongoing work on the Circumstantial Event Ontology (CEO), a newly developed ontology for calamity events that models semantic circumstantial relations between event classes. The circumstantial relations are designed manually, based on the shared properties of each event class. We discuss and contrast two types of event circumstantial relations: semantic circumstantial relations and episodic circumstantial relations. Further, we show the metamodel and the current contents of the ontology and outline the evaluation of the CEO.},
	urldate = {2023-05-30},
	booktitle = {Proceedings of the {Events} and {Stories} in the {News} {Workshop}},
	publisher = {Association for Computational Linguistics},
	author = {Segers, Roxane and Caselli, Tommaso and Vossen, Piek},
	month = aug,
	year = {2017},
	pages = {37--41},
	file = {Full Text PDF:files/6441/Segers et al. - 2017 - The Circumstantial Event Ontology (CEO).pdf:application/pdf},
}

@article{doerr_documenting_nodate,
	title = {Documenting {Events} in {Metadata}},
	abstract = {In this paper we outline the importance of event-centric documentation for structuring cultural metadata and historical context. Historical analysis can be seen as an analysis of events involving participation of people and things, meeting each other and thus creating history. Event modeling is so abstract that it can be used to describe cultural items and documentations of scientiﬁc observations. This work aims to show how event modeling provides more accurate information about life histories, relates and aggregates relevant information, and so helps to a more effective search and retrieval than currently achieved with Dublin Core and VRA.},
	language = {en},
	author = {Doerr, M and Kritsotaki, A},
	file = {Doerr e Kritsotaki - Documenting Events in Metadata.pdf:files/6444/Doerr e Kritsotaki - Documenting Events in Metadata.pdf:application/pdf},
}

@book{daquino_historical_2015-2,
	title = {Historical {Context} {Ontology} ({HiCO}): {A} {Conceptual} {Model} for {Describing} {Context} {Information} of {Cultural} {Heritage} {Objects}},
	isbn = {978-3-319-24128-9},
	shorttitle = {Historical {Context} {Ontology} ({HiCO})},
	abstract = {Communities addressing the problem of a shareable description of cultural heritage objects agree that a data-centric and context oriented approach should be reached in order to exchange and reuse heterogenous information. Here we present HiCO, an OWL 2 DL ontology aiming to outline relevant issues related to the workflow for stating, and formalizing, authoritative assertions about context information. The conceptual model outlines requirements for defining an authoritative statement and focuses on how a description of context information can be carried out when data are extracted from full-text of documents.},
	author = {Daquino, Marilena and Tomasi, Francesca},
	month = sep,
	year = {2015},
	doi = {10.1007/978-3-319-24129-6_37},
	file = {Full Text PDF:files/6495/Daquino e Tomasi - 2015 - Historical Context Ontology (HiCO) A Conceptual M.pdf:application/pdf},
}

@article{baroncini_is_2023,
	title = {Is dc:subject enough? {A} landscape on iconography and iconology statements of knowledge graphs in the semantic web},
	volume = {79},
	issn = {0022-0418},
	shorttitle = {Is dc},
	url = {https://doi.org/10.1108/JD-09-2022-0207},
	doi = {10.1108/JD-09-2022-0207},
	abstract = {Purpose In the last few years, the size of Linked Open Data (LOD) describing artworks, in general or domain-specific Knowledge Graphs (KGs), is gradually increasing. This provides (art-)historians and Cultural Heritage professionals with a wealth of information to explore. Specifically, structured data about iconographical and iconological (icon) aspects, i.e. information about the subjects, concepts and meanings of artworks, are extremely valuable for the state-of-the-art of computational tools, e.g. content recognition through computer vision. Nevertheless, a data quality evaluation for art domains, fundamental for data reuse, is still missing. The purpose of this study is filling this gap with an overview of art-historical data quality in current KGs with a focus on the icon aspects. Design/methodology/approach This study’s analyses are based on established KG evaluation methodologies, adapted to the domain by addressing requirements from art historians’ theories. The authors first select several KGs according to Semantic Web principles. Then, the authors evaluate (1) their structures’ suitability to describe icon information through quantitative and qualitative assessment and (2) their content, qualitatively assessed in terms of correctness and completeness. Findings This study’s results reveal several issues on the current expression of icon information in KGs. The content evaluation shows that these domain-specific statements are generally correct but often not complete. The incompleteness is confirmed by the structure evaluation, which highlights the unsuitability of the KG schemas to describe icon information with the required granularity. Originality/value The main contribution of this work is an overview of the actual landscape of the icon information expressed in LOD. Therefore, it is valuable to cultural institutions by providing them a first domain-specific data quality evaluation. Since this study’s results suggest that the selected domain information is underrepresented in Semantic Web datasets, the authors highlight the need for the creation and fostering of such information to provide a more thorough art-historical dimension to LOD.},
	number = {7},
	urldate = {2023-05-31},
	journal = {Journal of Documentation},
	author = {Baroncini, Sofia and Sartini, Bruno and Van Erp, Marieke and Tomasi, Francesca and Gangemi, Aldo},
	month = jan,
	year = {2023},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Iconography, Iconology, Knowledge graph evaluation, Visual works},
	pages = {115--136},
	file = {Full Text PDF:files/6497/Baroncini et al. - 2023 - Is dcsubject enough A landscape on iconography a.pdf:application/pdf},
}

@misc{baroncini_modelling_2021,
	title = {Modelling {Art} {Interpretation} and {Meaning}. {A} {Data} {Model} for {Describing} {Iconology} and {Iconography}},
	url = {http://arxiv.org/abs/2106.12967},
	doi = {10.48550/arXiv.2106.12967},
	abstract = {Iconology is a branch of art history that investigates the meaning of artworks in relation to their social and cultural background. Nowadays, several interdisciplinary research fields leverage theoretical frameworks close to iconology to pursue quantitative Art History with data science methods and Semantic Web technologies. However, while Iconographic studies have been recently addressed in ontologies, a complete description of aspects relevant to iconological studies is still missing. In this article, we present a preliminary study on eleven case studies selected from the literature and we envision new terms for extending existing ontologies. We validate new terms according to a common evaluation method and we discuss our results in the light of the opportunities that such an extended ontology would arise in the community of Digital Art History.},
	urldate = {2023-05-31},
	publisher = {arXiv},
	author = {Baroncini, S. and Daquino, M. and Tomasi, F.},
	month = jun,
	year = {2021},
	note = {arXiv:2106.12967 [cs]},
	keywords = {J.5, Computer Science - Digital Libraries, Computer Science - Artificial Intelligence, I.2.4},
	file = {arXiv Fulltext PDF:files/6500/Baroncini et al. - 2021 - Modelling Art Interpretation and Meaning. A Data M.pdf:application/pdf;arXiv.org Snapshot:files/6501/2106.html:text/html},
}

@article{sartini_icon_2023-1,
	title = {{ICON}: an {Ontology} for {Comprehensive} {Artistic} {Interpretations}},
	issn = {1556-4673},
	shorttitle = {{ICON}},
	url = {https://dl.acm.org/doi/10.1145/3594724},
	doi = {10.1145/3594724},
	abstract = {In this work, we introduce ICON, an ontology that models artistic interpretations of artworks’ subject matter (i.e. iconographies) and meanings (i.e. symbols, iconological aspects). Developed by conceptualizing authoritative knowledge and notions taken from Panofsky’s levels of interpretation theory, ICON ontology focuses on the granularity of interpretations. It can be used to describe an interpretation of an artwork from the Pre-iconographical, Icongraphical, and Iconological levels. Its main classes have been aligned to ontologies that come from the domains of cultural descriptions (ArCo, CIDOC-CRM, VIR), semiotics (DOLCE), bibliometrics (CITO), and symbolism (Simulation Ontology), to grant a robust schema that can be extendable using additional classes and properties coming from these ontologies. The ontology was evaluated through competency questions that range from simple recognition on a specific level of interpretation to complex scenarios. Data written using this model was compared to state-of-the-art ontologies and schemas to both highlight the current lack of a domain-specific ontology on art interpretation and show how our work fills some of the current gaps. The ontology is openly available and compliant with FAIR principles. With our ontology, we hope to encourage digital art historians working for cultural institutions in making more detailed linked open data about the content of their artefacts, to exploit the full potential of Semantic Web in linking artworks through not only subjects and common metadata, but also specific symbolic interpretations, intrinsic meanings, and the motifs through which their subjects are represented. Additionally, by basing our work on theories made by different art history scholars in the last century, we make sure that their knowledge and studies will not be lost in the transition to the digital, linked open data era.},
	urldate = {2023-05-31},
	journal = {Journal on Computing and Cultural Heritage},
	author = {Sartini, Bruno and Baroncini, Sofia and van Erp, Marieke and Tomasi, Francesca and Gangemi, Aldo},
	month = apr,
	year = {2023},
	note = {Just Accepted},
	keywords = {cultural heritage, ontology, semantic web, art interpretation, iconography, iconology},
	file = {Full Text PDF:files/6503/Sartini et al. - 2023 - ICON an Ontology for Comprehensive Artistic Inter.pdf:application/pdf},
}

@article{porzel_formalizing_nodate,
	title = {On {Formalizing} {Narratives}},
	abstract = {The activities of people as well as of artificial agents in reality, virtual reality or simulation can be recorded as data that discretize trajectories of body parts and the ensuing force events. While these data provide vast amounts of information they are, by themselves, meaningless. Only when we put them into context we assign a specific meaning to these data. Increasingly, the notion of narratives is being used to describe the result of this semiotic process, i.e. we observe events and fit them into a story that makes sense to us. In this work a formal model is presented and discussed that can be employed to represent a narrative using the subset of FOL that is expressible in OWL DL.},
	language = {en},
	author = {Porzel, Robert},
	file = {Porzel - On Formalizing Narratives.pdf:files/6504/Porzel - On Formalizing Narratives.pdf:application/pdf},
}

@incollection{thon_narratological_2018,
	title = {A {Narratological} {Approach} to {Transmedial} {Storyworlds} and {Transmedial} {Universes}},
	isbn = {978-1-351-05490-4},
	abstract = {This chapter presents a narratological approach to the analysis of transmedial franchises’ specific brand of narrative complexity that goes beyond the model of the “single world.” Instead, it employs the theoretical frame of transmedial narratology to distinguish between work-specific storyworlds, transmedial storyworlds as noncontradictory compounds of work-specific storyworlds, and transmedial universes as occasionally quite contradictory compounds of transmedial storyworlds. In order to describe the sometimes rather complex storyworld interrelation within transmedial universes in more detail, such an approach can further ask to what extent two narrative works within a transmedial franchise are defined by a relation of redundancy, by a relation of expansion, or by a relation of modification.},
	booktitle = {The {Routledge} {Companion} to {Transmedia} {Studies}},
	publisher = {Routledge},
	author = {Thon, Jan-Noël},
	year = {2018},
	note = {Num Pages: 8},
}

@article{scolari_transmedia_2009-1,
	title = {Transmedia {Storytelling}: {Implicit} {Consumers}, {Narrative} {Worlds}, and {Branding} in {Contemporary} {Media} {Production}},
	volume = {3},
	copyright = {The  International Journal of Communication  is an academic journal. As such, it is dedicated to the open exchange of information. For this reason, IJoC is freely available to individuals and institutions. Copies of this journal or articles in this journal may be distributed for research or educational purposes free of charge and without permission. However, commercial use of the IJoC website or the articles contained herein is expressly prohibited without the written consent of the editor. Authors who publish in The  International Journal of Communication  will release their articles under the   Creative Commons Attribution Non-Commercial No Derivatives (by-nc-nd) license  . This license allows anyone to copy and distribute the article for non-commercial purposes provided that appropriate attribution is given. For details of the rights authors grants users of their work, see the  "human-readable summary" of the license , with a link to the full license. (Note that "you" refers to a user, not an author, in the summary.) This journal utilizes the  LOCKSS system to create a distributed archiving system among participating libraries and permits those libraries to create permanent archives of the journal for purposes of preservation and restoration. The publisher perpetually authorizes participants in the LOCKSS system to archive and restore our publication through the LOCKSS System for the benefit of all LOCKSS System participants. Specifically participating libraries may:  Collect and preserve currently accessible materials;  Use material consistent with original license terms;  Provide copies to other LOCKSS appliances for purposes of audit and repair.        Fair Use The U.S. Copyright Act of 1976 specifies, in Section 107, the terms of the Fair Use exception: Notwithstanding the provisions of sections 106 and 106A, the fair use of a copyrighted work, including such use by reproduction in copies or phonorecords or by any other means specified by that section, for purposes such as criticism, comment, news reporting, teaching (including multiple copies for classroom use), scholarship, or research, is not an infringement of copyright. In determining whether the use made of a work in any particular case is a fair use the factors to be considered shall include:  the purpose and character of the use, including whether such use is of a commercial nature or is for nonprofit educational purposes;  the nature of the copyrighted work;  the amount and substantiality of the portion used in relation to the copyrighted work as a whole; \&amp;  the effect of the use upon the potential market for or value of the copyrighted work.   The fact that a work is unpublished shall not itself bar a finding of fair use if such finding is made upon consideration of all the above factors. In accord with these provisions, the  International Journal of Communication  believes in the vigorous assertion and defense of Fair Use by scholars engaged in academic research, teaching and non-commercial publishing. Thus, we view the inclusion of “quotations” from existing print, visual, audio and audio-visual texts to be appropriate examples of Fair Use, as are reproductions of visual images for the purpose of scholarly analysis. We encourage authors to obtain appropriate permissions to use materials originally produced by others, but do not require such permissions as long as the usage of such materials falls within the boundaries of Fair Use.  The  International Journal of Communication  encourages authors to employ fair use in their scholarly publishing wherever appropriate. Fair use is the right to use unlicensed copyrighted material (whether it is text, images, audio-visual, or other) in your own work, in some circumstances. We consult the  Code of Best Practices in Fair Use for Scholarly Research in Communication , created by the International Communication Association and endorsed by the National Communication Association, and you should too. If you have any questions about whether fair use applies to your uses of copyrighted material (whether it is text, images, audio-visual, or other) in your scholarship, simply include your rationale, grounded in the Best Practices, as a supplementary document with your submission.},
	issn = {1932-8036},
	shorttitle = {Transmedia {Storytelling}},
	url = {https://ijoc.org/index.php/ijoc/article/view/477},
	abstract = {Many concepts have been developed to describe the convergence of media, languages, and formats in contemporary media systems. This article is a theoretical reflection on “transmedia storytelling” from a perspective that integrates semiotics and narratology in the context of media studies. After dealing with the conceptual chaos around transmedia storytelling, the article analyzes how these new multimodal narrative structures create different implicit consumers and construct a narrative world. The analysis includes a description of the multimedia textual structure created around the Fox television series 24. Finally, the article analyzes transmedia storytelling from the perspective of a semiotics of branding.},
	language = {en},
	number = {0},
	urldate = {2023-06-01},
	journal = {International Journal of Communication},
	author = {Scolari, Carlos Alberto},
	month = jun,
	year = {2009},
	note = {Number: 0},
	pages = {21},
	file = {Full Text PDF:files/6533/Scolari - 2009 - Transmedia Storytelling Implicit Consumers, Narra.pdf:application/pdf},
}

@article{podara_digital_2021,
	title = {Digital {Storytelling} in {Cultural} {Heritage}: {Audience} {Engagement} in the {Interactive} {Documentary} {New} {Life}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2071-1050},
	shorttitle = {Digital {Storytelling} in {Cultural} {Heritage}},
	url = {https://www.mdpi.com/2071-1050/13/3/1193},
	doi = {10.3390/su13031193},
	abstract = {This paper casts light on cultural heritage storytelling in the context of interactive documentary, a hybrid media genre that employs a full range of multimedia tools to document reality, provide sustainability of the production and successful engagement of the audience. The main research hypotheses are enclosed in the statements: (a) the interactive documentary is considered a valuable tool for the sustainability of cultural heritage and (b) digital approaches to documentary storytelling can provide a sustainable form of viewing during the years. Using the Greek interactive documentary (i-doc) NEW LIFE (2013) as a case study, the users’ engagement is evaluated by analyzing items from a seven-year database of web metrics. Specifically, we explore the adopted ways of the interactive documentary users to engage with the storytelling, the depth to which they were involved along with the most popular sections/traffic sources and finally, the differences between the first launch period and latest years were investigated. We concluded that interactivity affordances of this genre enhance the social dimension of cultural, while the key factors for sustainability are mainly (a) constant promotion with transmedia approach; (b) data-driven evaluation and reform; and (c) a good story that gathers relevant niches, with specific interest to the story.},
	language = {en},
	number = {3},
	urldate = {2023-06-01},
	journal = {Sustainability},
	author = {Podara, Anna and Giomelakis, Dimitrios and Nicolaou, Constantinos and Matsiola, Maria and Kotsakis, Rigas},
	month = jan,
	year = {2021},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {cultural heritage, digital storytelling, audience engagement, intangible heritage, interactive documentary, media users’ engagement, sustainability},
	pages = {1193},
	file = {Full Text PDF:files/6535/Podara et al. - 2021 - Digital Storytelling in Cultural Heritage Audienc.pdf:application/pdf},
}

@article{basaraba_public_2023,
	title = {Public history and transmedia storytelling for conflicting narratives},
	volume = {27},
	issn = {1364-2529},
	url = {https://doi.org/10.1080/13642529.2023.2184969},
	doi = {10.1080/13642529.2023.2184969},
	abstract = {Histories of events can be told from multiple perspectives, and there is rarely just one linear narrative or a single interpretation of the past. This paper takes an interdisciplinary approach to explain how the concept of shared authority in public history can be applied to transmedia storytelling, in the context of media studies, to address conflicting narratives on historical events. Transmedia narratives allow for more opportunities to target different audiences and offer alternatives, and perhaps conflicting interpretations, to official mainstream interpretations of historical events. This is achieved through three primary methods of public participation in the development of conflicting narratives which can be presented through a variety of different media. The theoretical challenges in sharing authority of transmedia narrative creation with different publics ranges from strong to little control (i.e. radical trust). Thus, we discuss a series of methodologies that can be strategically used in future research projects that wish to share authority with different publics in the development of historical transmedia narratives with conflicting interpretations. This approach can be particularly relevant in contexts of segregation, discrimination, identity, political changes or cultural wars.},
	number = {2},
	urldate = {2023-06-01},
	journal = {Rethinking History},
	author = {Basaraba, Nicole and Cauvin, Thomas},
	month = apr,
	year = {2023},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/13642529.2023.2184969},
	keywords = {co-authoring, conflicting narratives, digital media, public history, Shared authority, transmedia storytelling},
	pages = {221--247},
	file = {Full Text PDF:files/6537/Basaraba e Cauvin - 2023 - Public history and transmedia storytelling for con.pdf:application/pdf},
}

@article{declerck_towards_nodate-1,
	title = {Towards a {Linked} {Data} {Access} to {Folktales} classified by {Thompson}’s {Motifs} and {Aarne}-{Thompson}-{Uther}’s {Types}},
	language = {en},
	author = {Declerck, Thierry and Ko, Antónia},
	file = {Declerck e Ko - Towards a Linked Data Access to Folktales classifi.pdf:files/6538/Declerck e Ko - Towards a Linked Data Access to Folktales classifi.pdf:application/pdf},
}

@inproceedings{dfki_gmbh_multilingual_technologies_saarbrucken_germany_multilingual_2017,
	title = {Multilingual {Ontologies} for the {Representation} and {Processing} of {Folktales}},
	isbn = {978-954-452-046-5},
	url = {http://www.acl-bg.org/proceedings/2017/RANLP_W5%202017/pdf/LT4DH-CEE003.pdf},
	doi = {10.26615/978-954-452-046-5_003},
	abstract = {We describe work done in the field of folkloristics and consisting in creating ontologies based on well-established studies proposed by “classical” folklorists. This work is supporting the availability of a huge amount of digital and structured knowledge on folktales to digital humanists. The ontological encoding of past and current motif-indexation and classification systems for folktales was in the first step limited to English language data. This led us to focus on making those newly generated formal knowledge sources available in a few more languages, like German, Russian and Bulgarian. We stress the importance of achieving this multilingual extension of our ontologies at a larger scale, in order for example to support the automated analysis and classification of such narratives in a large variety of languages, as those are getting more and more accessible on the Web.},
	language = {en},
	urldate = {2023-06-01},
	booktitle = {Proceedings of the {Workshop} on {Language} technology for {Digital} {Humanities} in {Central} and ({South}-){Eastern} {Europe}},
	publisher = {Incoma Ltd. Shoumen, Bulgaria},
	author = {{DFKI GmbH, Multilingual Technologies, Saarbrücken, Germany} and Declerck, Thierry and Aman, Anastasija and {Saarland University, Computational Linguistics Department,Saarbrücken, Germany} and Banzer, Martin and {Saarland University, Computational Linguistics Department,Saarbrücken, Germany} and Macháček, Dominik and {Saarland University, Computational Linguistics Department,Saarbrücken, Germany} and Schäfer, Lisa and {Saarland University, Computational Linguistics Department,Saarbrücken, Germany} and Skachkova, Natalia and {Saarland University, Computational Linguistics Department,Saarbrücken, Germany}},
	month = nov,
	year = {2017},
	pages = {20--23},
	file = {DFKI GmbH, Multilingual Technologies, Saarbrücken, Germany et al. - 2017 - Multilingual Ontologies for the Representation and.pdf:files/6540/DFKI GmbH, Multilingual Technologies, Saarbrücken, Germany et al. - 2017 - Multilingual Ontologies for the Representation and.pdf:application/pdf},
}

@article{rahaman_digital_2018,
	title = {Digital heritage interpretation: a conceptual framework},
	volume = {29},
	issn = {1462-6268},
	shorttitle = {Digital heritage interpretation},
	url = {https://doi.org/10.1080/14626268.2018.1511602},
	doi = {10.1080/14626268.2018.1511602},
	abstract = {‘Heritage Interpretation’ has always been considered as an effective learning, communication and management tool that increases visitors’ awareness of and empathy to heritage sites or artefacts. Yet the definition of ‘digital heritage interpretation’ is still wide and so far, no significant method and objective are evident within the domain of ‘digital heritage’ theory and discourse. Considering ‘digital heritage interpretation’ as a process rather than as a tool to present or communicate with end-users, this paper presents a critical application of a theoretical construct ascertained from multiple disciplines and explicates four objectives for a comprehensive interpretive process. A conceptual model is proposed and further developed into a conceptual framework with fifteen considerations. This framework is then implemented and tested on an online platform to assess its impact on end-users’ interpretation level. We believe the presented interpretive framework (PrEDiC) will help heritage professionals and media designers to develop interpretive heritage project.},
	number = {2-3},
	urldate = {2023-06-01},
	journal = {Digital Creativity},
	author = {Rahaman, Hafizur},
	month = jul,
	year = {2018},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14626268.2018.1511602},
	keywords = {Digital heritage, conceptual framework, end-users, guidelines, interpretation},
	pages = {208--234},
}

@article{amico_ontological_nodate,
	title = {Ontological {Entities} for {Planning} and {Describing} {Cultural} {Heritage} {3D} {Models} {Creation}},
	abstract = {In the last decades the rapid development of technologies and methodologies in the �eld of digitization and 3D modelling has led to an increasing proliferation of 3D technologies in the Cultural Heritage domain. Despite the great potential of 3D digital heritage, the "special e�ects" of 3D may often overwhelm its importance in research. Projects and consortia of scholars have tried to put order in the di�erent �elds of application of these technologies, providing guidelines and proposing work�ows. The use of computer graphics as an e�ective methodology for CH research and communication highlighted the need of transparent provenance data to properly document digital assets and understand the degree of scienti�c quality and reliability of their outcomes. The building and release of provenance knowledge, consisting in the complete formal documentation of each phase of the process, is therefore of fundamental importance to ensure its repeatability and to guarantee the integration and interoperability of the generated metadata on the Semantic Web. This paper proposes a methodology for documenting the planning and creation of 3D models used in archaeology and Cultural Heritage, by means of an application pro�le based on the CIDOC CRM ecosystem and other international standards. CCS Concepts: • Information systems ! Ontologies; Semantic web description languages; • Computing methodologies ! 3D imaging.},
	language = {en},
	author = {Amico, Nicola and Felicetti, Achille},
	file = {Amico e Felicetti - Ontological Entities for Planning and Describing C.pdf:files/6544/Amico e Felicetti - Ontological Entities for Planning and Describing C.pdf:application/pdf},
}

@techreport{padilla_responsible_2019,
	title = {Responsible {Operations}: {Data} {Science}, {Machine} {Learning}, and {AI} in {Libraries}. {OCLC} {Research} {Position} {Paper}},
	shorttitle = {Responsible {Operations}},
	url = {https://eric.ed.gov/?id=ED603715},
	abstract = {Responsible Operations is intended to help chart library community engagement with data science, machine learning, and artificial intelligence (AI) and was developed in partnership with an advisory group and a landscape group comprised of more than 70 librarians and professionals from universities, libraries, museums, archives, and other organizations. This research agenda presents an interdependent set of technical, organizational, and social challenges to be addressed en route to library operationalization of data science, machine learning, and AI. Challenges are organized across seven areas of investigation: (1) Committing to Responsible Operations; (2) Description and Discovery; (3) Shared Methods and Data; (4) Machine-Actionable Collections; (5) Workforce Development; (6) Data Science Services; (7) Sustaining Interprofessional and Interdisciplinary Collaboration. Organizations can use Responsible Operations to make a case for addressing challenges, and the recommendations provide an excellent starting place for discussion and action.},
	language = {en},
	urldate = {2023-06-01},
	institution = {OCLC Online Computer Library Center, Inc},
	author = {Padilla, Thomas},
	month = dec,
	year = {2019},
	note = {ISBN: 9781556531514
Publication Title: OCLC Online Computer Library Center, Inc.
ERIC Number: ED603715},
	keywords = {Academic Libraries, Accountability, Artificial Intelligence, Bias, Competence, Data Analysis, Data Collection, Educational Technology, Electronic Libraries, Evidence Based Practice, Information Technology, Interdisciplinary Approach, Labor Force Development, Library Research, Library Role, Man Machine Systems, Technology Uses in Education},
	file = {Full Text PDF:files/6549/Padilla - 2019 - Responsible Operations Data Science, Machine Lear.pdf:application/pdf},
}

@article{hyvonen_using_2020,
	title = {Using the {Semantic} {Web} in digital humanities: {Shift} from data publishing to data-analysis and serendipitous knowledge discovery},
	volume = {11},
	issn = {1570-0844},
	shorttitle = {Using the {Semantic} {Web} in digital humanities},
	url = {https://content.iospress.com/articles/semantic-web/sw190386},
	doi = {10.3233/SW-190386},
	abstract = {This paper discusses a shift of focus in research on Cultural Heritage semantic portals, based on Linked Data, and envisions and proposes new directions of research. Three generations of portals are identified: Ten years ago the research focus in sem},
	language = {en},
	number = {1},
	urldate = {2023-06-01},
	journal = {Semantic Web},
	author = {Hyvönen, Eero},
	month = jan,
	year = {2020},
	note = {Publisher: IOS Press},
	pages = {187--193},
	file = {Versione accettata:files/6551/Hyvönen - 2020 - Using the Semantic Web in digital humanities Shif.pdf:application/pdf},
}

@misc{peroni_approaching_2022,
	title = {Approaching {Digital} {Humanities} at the {University}: a {Cultural} {Challenge}},
	shorttitle = {Approaching {Digital} {Humanities} at the {University}},
	url = {http://arxiv.org/abs/2209.06091},
	doi = {10.48550/arXiv.2209.06091},
	abstract = {The University of Bologna has a long tradition in Digital Humanities, both at the level of research and teaching. In this article, we want to introduce some experiences in developing new educational models based on the idea of transversal learning, collaborative approaches and projects-oriented outputs, together with the definition of research fields within this vast domain, accompanied by practical examples. The creation of an international master's degree (DHDK), a PhD (CHeDE) and a research centre (/DH.arc) are the results of refining our notion of Digital Humanities in a new bidirectional way: to reflect on computational methodologies and models in the cultural sphere and to suggest a cultural approach to Informatics.},
	urldate = {2023-06-01},
	publisher = {arXiv},
	author = {Peroni, Silvio and Tomasi, Francesca},
	month = nov,
	year = {2022},
	note = {arXiv:2209.06091 [cs]},
	keywords = {Computer Science - Digital Libraries},
	file = {arXiv Fulltext PDF:files/6554/Peroni e Tomasi - 2022 - Approaching Digital Humanities at the University .pdf:application/pdf;arXiv.org Snapshot:files/6555/2209.html:text/html},
}

@article{machotka_method_2019,
	title = {Method in {Interdisciplinary} {Research}: {Data} {Science} for {Digital} {Art} {History}},
	copyright = {Copyright (c) 2020 International Journal for Digital Art History},
	issn = {2363-5401},
	shorttitle = {Method in {Interdisciplinary} {Research}},
	url = {https://journals.ub.uni-heidelberg.de/index.php/dah/article/view/72068},
	doi = {10.11588/dah.2019.4.72068},
	abstract = {This paper creates a conceptual frame and explanatory point of reference for the collection of papers presented at the exploratory workshop “Data Science for Digital Art History: Tackling Big Data Challenges, Algorithms, and Systems” organized at the KDD 2018 Conference in Data Mining and Knowledge Discovery held in London in August 2018. The goal of the workshop was to probe the field and to build a constructive interdisciplinary dialogue between two research areas: Data Science and Art History. The workshop’s chairs and the authors of this paper share the conviction that Data Science can enrich art studies while analysis of visual data can have a positive impact on Data Science. Thus, the research initiative tried to critically reflect on the interdisciplinary collaboration between diverse research communities and its epistemological and ontological effects.},
	language = {en},
	number = {4},
	urldate = {2023-06-02},
	journal = {International Journal for Digital Art History},
	author = {Machotka, Ewa and Papapetrou, Panagiotis},
	month = dec,
	year = {2019},
	note = {Number: 4},
	keywords = {deep learning},
	pages = {5.03--5.11},
	file = {Full Text PDF:files/6633/Machotka e Papapetrou - 2019 - Method in Interdisciplinary Research Data Science.pdf:application/pdf},
}

@article{mcgillivray_challenges_2020,
	title = {The challenges and prospects of the intersection of humanities and data science: {A} white paper from {The} {Alan} {Turing} {Institute}},
	shorttitle = {The challenges and prospects of the intersection of humanities and data science},
	url = {https://www.repository.cam.ac.uk/handle/1810/309670},
	abstract = {This paper was produced as part of the activities of the Humanities and Data Science Special Interest Group based at The Alan Turing Institute. The group has created the opportunity for fruitful conversations in this area and has brought together voices from a range of different disciplinary backgrounds. This document shows an example of how conversations of this type can benefit and advance computational methods and understandings in and between the humanities and data science, bringing together a diverse community. We believe the Turing can act as a nexus of discussion on humanities and data science research at the national (and international) level, in areas such as education strategy, research best practices, and funding policy, and can promote and encourage research activities in this interdisciplinary area.},
	language = {en},
	urldate = {2023-06-02},
	author = {McGillivray, Barbara and Alex, Beatrice and Ames, Sarah and Armstrong, Guyda and Beavan, David and Ciula, Arianna and Colavizza, Giovanni and Cummings, James and De Roure, David and Farquhar, Adam and Hengchen, Simon and Lang, Anouk and Loxley, James and Goudarouli, Eirini and Nanni, Federico and Nini, Andrea and Nyhan, Julianne and Osborne, Nicola and Poibeau, Thierry and Ridge, Mia and Ranade, Sonia and Smithies, James and Terras, Melissa and Vlachidis, Andreas and Willcox, Pip},
	month = aug,
	year = {2020},
	file = {Full Text PDF:files/6635/McGillivray et al. - 2020 - The challenges and prospects of the intersection o.pdf:application/pdf},
}

@incollection{viola_importance_2023,
	address = {Cham},
	title = {The {Importance} of {Being} {Digital}},
	isbn = {978-3-031-16950-2},
	url = {https://doi.org/10.1007/978-3-031-16950-2_2},
	abstract = {In this chapter, I present the post-authentic framework, a theoretical framework for knowledge creation in the digital, and I introduce two concepts central to the framework, symbiosis and mutualism. In light of the considerations reasoned in Chap. 1, I discuss and question the relevance of notions of authenticity and completeness in relation to digital objects. I take the example of a digital cultural heritage object to highlight how ideas of authenticity and completeness have consequences not only for the production of digital heritage and with respect to heritage values and practices but, more widely, for our understanding of digital objects and knowledge production in a digital society. Finally, I rework such notions using the formation of the digital heritage collection ChroniclItaly 3.0 as an example of how the post-authentic framework can guide the fluid interactions between human and technological processes that are required in the contemporary context of digital knowledge creation.},
	language = {en},
	urldate = {2023-06-02},
	booktitle = {The {Humanities} in the {Digital}: {Beyond} {Critical} {Digital} {Humanities}},
	publisher = {Springer International Publishing},
	author = {Viola, Lorella},
	editor = {Viola, Lorella},
	year = {2023},
	doi = {10.1007/978-3-031-16950-2_2},
	pages = {37--56},
	file = {Full Text PDF:files/6637/Viola - 2023 - The Importance of Being Digital.pdf:application/pdf},
}

@article{padilla_final_2019,
	title = {Final {Report} --- {Always} {Already} {Computational}: {Collections} as {Data}},
	shorttitle = {Final {Report} --- {Always} {Already} {Computational}},
	url = {https://zenodo.org/record/7883759},
	doi = {10.5281/zenodo.7883759},
	abstract = {From 2016-2018 Always Already Computational: Collections as Data documented, iterated on, and shared current and potential approaches to developing cultural heritage collections that support computationally-driven research and teaching. With funding from the Institute of Museum and Library Services, Always Already Computational held two national forums, organized multiple workshops, shared project outcomes in disciplinary and professional conferences, and generated nearly a dozen deliverables meant to guide institutions as they consider development of collections as data.   This report documents the activities and impacts of the Always Already Computational project, delineates findings, and identifies areas for further inquiry. This publication is part of the Collections as Data Framework hosted at https://osf.io/mx6uk/.},
	language = {eng},
	urldate = {2023-06-02},
	author = {Padilla, Thomas and Allen, Laurie and Frost, Hannah and Potvin, Sarah and Russey Roke, Elizabeth and Varner, Stewart},
	month = may,
	year = {2019},
	note = {Publisher: Zenodo},
	keywords = {data, museums, archives, collections, libraries},
	file = {Zenodo Full Text PDF:files/6736/Padilla et al. - 2019 - Final Report --- Always Already Computational Col.pdf:application/pdf},
}

@article{franzosi_narrative_1998,
	title = {Narrative as {Data}: {Linguistic} and {Statistical} {Tools} for the {Quantitative} {Study} of {Historical} {Events}},
	volume = {43},
	issn = {0020-8590},
	shorttitle = {Narrative as {Data}},
	url = {https://www.jstor.org/stable/26405514},
	urldate = {2023-06-02},
	journal = {International Review of Social History},
	author = {Franzosi, Roberto},
	year = {1998},
	note = {Publisher: Cambridge University Press},
	pages = {81--104},
	file = {JSTOR Full Text PDF:files/6738/Franzosi - 1998 - Narrative as Data Linguistic and Statistical Tool.pdf:application/pdf},
}

@incollection{serra_software_2018,
	address = {Cham},
	title = {A {Software} {Architecture} for {Narratives}},
	volume = {806},
	isbn = {978-3-319-73164-3 978-3-319-73165-0},
	url = {http://link.springer.com/10.1007/978-3-319-73165-0_3},
	abstract = {The current Digital Libraries (DLs) usually return as answer of a user’s query a ranked list of the resources included in the DLs but no semantic relation among the resources are reported. Using the Semantic Web technologies it is possible to improve these search functionalities introducing narratives as new search method. As narratives we intend semantic networks of events that are linked to the objects of the DLs and are endowed with a set of semantic relations that connect an event to another. These semantic networks may help the users to obtain a more complete knowledge on the subject of their searches. In this paper, we present a software architecture for building narratives in order to introduce them in DLs. Our architecture is composed of several tools (automatic and semi-automatic tools) for creating, storing and visualizing narratives. When possible, we reused open source components already available on-line, and for the software we developed, we freely distribute it for research aims.},
	language = {en},
	urldate = {2023-06-02},
	booktitle = {Digital {Libraries} and {Multimedia} {Archives}},
	publisher = {Springer International Publishing},
	author = {Meghini, Carlo and Bartalesi, Valentina and Metilli, Daniele and Benedetti, Filippo},
	editor = {Serra, Giuseppe and Tasso, Carlo},
	year = {2018},
	doi = {10.1007/978-3-319-73165-0_3},
	note = {Series Title: Communications in Computer and Information Science},
	pages = {23--29},
	file = {Meghini et al. - 2018 - A Software Architecture for Narratives.pdf:files/6739/Meghini et al. - 2018 - A Software Architecture for Narratives.pdf:application/pdf},
}

@article{duarte_course_2020,
	title = {“{Of} {Course}, {Data} {Can} {Never} {Fully} {Represent} {Reality}”},
	volume = {91},
	issn = {0018-7143, 1534-6617},
	url = {https://bioone.org/journals/human-biology/volume-91/issue-3/humanbiology.91.3.03/Of-Course-Data-Can-Never-Fully-Represent-Reality/10.13110/humanbiology.91.3.03.full},
	doi = {10.13110/humanbiology.91.3.03},
	abstract = {Multiple terms describe Indigenous peoples' creative expressions, including “Indigenous knowledge” (IK), “traditional ecological knowledge” (TEK), “traditional knowledge” (TK), and increasingly, “Indigenous data” (ID). Variation in terms contributes to disciplinary divides, challenges in organizing and finding prior studies about Indigenous peoples' creative expressions, and intellectually divergent chains of reference. The authors applied a decolonial, digital, feminist, ethics-of-care approach to citation analysis of records about Indigenous peoples knowledge and data, including network analyses of author-generated keywords and research areas, and content analysis of peer-reviewed studies about ID. Results reveal ambiguous uses of the term “Indigenous data”; the influence of ecology and environmental studies in research areas and topics associated with IK, TEK, and TK; and the influence of public administration and governance studies in research areas and topics associated with ID studies. Researchers of ID would benefit from applying a more nuanced and robust vocabulary, one informed by studies of IK, TEK, and TK. Researchers of TEK and TK would benefit from the more people-centered approaches of IK. Researchers and systems designers who work with data sets can practice relational accountability by centering the Indigenous peoples from whom observations are sourced, combining narrative methodologies with computational methods to sustain the holism favored by Indigenous science and the relationality of Indigenous peoples.},
	number = {3},
	urldate = {2023-06-02},
	journal = {Human Biology},
	author = {Duarte, Marisa Elena and Vigil-Hayes, Morgan and Littletree, Sandra and Belarde-Lewis, Miranda},
	month = jun,
	year = {2020},
	note = {Publisher: Wayne State University Press},
	pages = {163--178},
}

@misc{lee_collections_2022,
	title = {The "{Collections} as {ML} {Data}" {Checklist} for {Machine} {Learning} \& {Cultural} {Heritage}},
	url = {http://arxiv.org/abs/2207.02960},
	doi = {10.48550/arXiv.2207.02960},
	abstract = {Within the cultural heritage sector, there has been a growing and concerted effort to consider a critical sociotechnical lens when applying machine learning techniques to digital collections. Though the cultural heritage community has collectively developed an emerging body of work detailing responsible operations for machine learning in libraries and other cultural heritage institutions at the organizational level, there remains a paucity of guidelines created specifically for practitioners embarking on machine learning projects. The manifold stakes and sensitivities involved in applying machine learning to cultural heritage underscore the importance of developing such guidelines. This paper contributes to this need by formulating a detailed checklist with guiding questions and practices that can be employed while developing a machine learning project that utilizes cultural heritage data. I call the resulting checklist the "Collections as ML Data" checklist, which, when completed, can be published with the deliverables of the project. By surveying existing projects, including my own project, Newspaper Navigator, I justify the "Collections as ML Data" checklist and demonstrate how the formulated guiding questions can be employed and operationalized.},
	urldate = {2023-06-02},
	publisher = {arXiv},
	author = {Lee, Benjamin Charles Germain},
	month = jul,
	year = {2022},
	note = {arXiv:2207.02960 [cs]},
	keywords = {Computer Science - Digital Libraries, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:files/6746/Lee - 2022 - The Collections as ML Data Checklist for Machine.pdf:application/pdf;arXiv.org Snapshot:files/6747/2207.html:text/html},
}

@article{moezzi_using_2017,
	series = {Narratives and {Storytelling} in {Energy} and {Climate} {Change} {Research}},
	title = {Using stories, narratives, and storytelling in energy and climate change research},
	volume = {31},
	issn = {2214-6296},
	url = {https://www.sciencedirect.com/science/article/pii/S2214629617302050},
	doi = {10.1016/j.erss.2017.06.034},
	abstract = {Energy and climate change research has been dominated by particular methods and approaches to defining and addressing problems, accomplished by gathering and analysing the corresponding forms of evidence. This special issue starts from the broad concepts of stories, narratives, and storytelling to go beyond these analytic conventions, approaching the intersection of nature, humanity, and technology in multiple ways, using lenses from social sciences, humanities, and practitioners’ perspectives. The contributors use stories as data objects to gather, analyse, and critique; stories as an approach to research an inquiry; narrative analysis as a way of crystallising arguments and assumptions; and storytelling as a way of understanding, communicating, and influencing others. In using these forms of evidence and communication, and applying methods, analytical stances, and interpretations that these invite, something new and different results. This essay is a brief introduction to how, in our view, stories and their kin fit in energy and climate change research. We outline the diversity of data, approaches, and goals represented in the contributions to the special issue. And we reflect on some of the challenges of, and possibilities for, continuing to develop ‘stories’ as data sources, as modes of inquiry, and as creative paths toward social engagement.},
	language = {en},
	urldate = {2023-06-02},
	journal = {Energy Research \& Social Science},
	author = {Moezzi, Mithra and Janda, Kathryn B. and Rotmann, Sea},
	month = sep,
	year = {2017},
	keywords = {Narratives, Storytelling, Climate change, Energy, Imaginaries, Stories},
	pages = {1--10},
	file = {Full text:files/6787/Moezzi et al. - 2017 - Using stories, narratives, and storytelling in ene.pdf:application/pdf;ScienceDirect Snapshot:files/6786/S2214629617302050.html:text/html},
}

@article{bleakley_stories_2005,
	title = {Stories as data, data as stories: making sense of narrative inquiry in clinical education*},
	volume = {39},
	issn = {1365-2923},
	shorttitle = {Stories as data, data as stories},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2929.2005.02126.x},
	doi = {10.1111/j.1365-2929.2005.02126.x},
	abstract = {Background Narrative inquiry is a form of qualitative research that takes story as either its raw data or its product. Science and narrative can be seen as two kinds of knowing, reflected in the distinction between evidence-based medicine derived from population studies and narrative-based medicine focused upon the single case. A similar tension exists in the field of narrative inquiry between cognitive-orientated analytical methods and affective-orientated methods of synthesis. Aims This paper aims to make sense of narrative inquiry in clinical education through definition of ‘narrative’, articulation of a typology of narrative research approaches, and critical examination in particular of analytical methods, the dominant approach in the literature. The typology is illustrated by research examples, and the role of medical education in developing expertise in narrative inquiry is discussed. An argument is made that the tension between analysis of the structure of stories and empathic use of stories can be seen as productive, stimulating expertise encompassing both approaches. Discussion Analytical methods tend to lose the concrete story and its emotional impact to abstract categorisations, which may claim explanatory value but often remain descriptive. Stemming from discomfort with more integrative methods derived from the humanities, a science-orientated medical education may privilege analytical methods over approaches of synthesis. Medical education can redress this imbalance through attention to ‘thinking with stories’ to gain empathy for a patient's experience of illness. Such an approach can complement understanding of story as discourse − how narratives may be used rhetorically to manage both social interactions and identity.},
	language = {en},
	number = {5},
	urldate = {2023-06-05},
	journal = {Medical Education},
	author = {Bleakley, Alan},
	year = {2005},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2929.2005.02126.x},
	keywords = {education, clinical competence/standards, curriculum/methods, empathy, literature, medical, research design, undergraduate/*methods},
	pages = {534--540},
	file = {Full Text PDF:files/6967/Bleakley - 2005 - Stories as data, data as stories making sense of .pdf:application/pdf;Snapshot:files/6968/j.1365-2929.2005.02126.html:text/html},
}

@article{nadar_stories_2014,
	title = {“{Stories} are data with {Soul}” – lessons from black feminist epistemology},
	volume = {28},
	issn = {1013-0950},
	url = {https://doi.org/10.1080/10130950.2014.871838},
	doi = {10.1080/10130950.2014.871838},
	abstract = {When asked to give the keynote address at the Annual Women in Research Lecture at the University of South Africa the author decided to change the topic from ‘Women in Research’ to ‘Feminist Research’. Here she submits that researchers have much to learn from African feminist epistemology and research values, and draws attention to one particular defining feature of African feminist epistemology, namely ‘narrative knowing’. She argues for the power of story as integral to qualitative research practice and at the very least as complementary to quantitative research practice. The benefits of STORY for researchers are that stories encourage and encompass:Suspicion of master narratives of knowledge;Tools of knowledge gathering and dissemination;Objection to objectivity;Reflexivity of the positioning of researchers; andYearning for and working for transformation and change. Drawing on the works of Black feminist scholars like Patricia Hill Collins and Obioma Nnaemeka, she discusses each of these benefits of narrative knowing for research and teaching in turn, by extracting and explicating the stories she has collected over the years as a researcher and a teacher. These stories provide a critique to conventional academic ways of knowing, particularly its claim to be science. This article concludes, in agreement with Brene Brown, that indeed ‘stories are just data with soul’.},
	number = {1},
	urldate = {2023-06-05},
	journal = {Agenda},
	author = {Nadar, Sarojini},
	month = jan,
	year = {2014},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/10130950.2014.871838},
	keywords = {Feminist epistemology, narrative knowing, social transformation},
	pages = {18--28},
}

@article{pavlenko_autobiographic_2007,
	title = {Autobiographic {Narratives} as {Data} in {Applied} {Linguistics}},
	volume = {28},
	issn = {0142-6001},
	url = {https://doi.org/10.1093/applin/amm008},
	doi = {10.1093/applin/amm008},
	abstract = {In the past decade, language memoirs, linguistic autobiographies, and learners’ journals and diaries have become a popular means of data collection in applied linguistics. It is not always clear however how one should go about analyzing these data. The aim of this paper is to offer a critical review of analytical frameworks applied to second language users’ personal narratives. I discuss the strengths and weaknesses of these frameworks in relation to the type of information they seek: subject reality, life reality, and text reality. I argue that some analytical approaches, in particular content and thematic analyses, are insensitive to the interpretive nature of autobiographic data. Subsequently, I offer recommendations for systematic analysis of bi- and multilinguals’ narratives on macro- and micro-levels in terms of content, context, and form.},
	number = {2},
	urldate = {2023-06-05},
	journal = {Applied Linguistics},
	author = {Pavlenko, Aneta},
	month = jun,
	year = {2007},
	pages = {163--188},
	file = {Full Text PDF:files/6972/Pavlenko - 2007 - Autobiographic Narratives as Data in Applied Lingu.pdf:application/pdf},
}

@article{pepper_using_2009,
	title = {Using {Narratives} as a {Research} {Strategy}},
	volume = {9},
	issn = {1443-9883},
	url = {https://doi.org/10.3316/QRJ0902018},
	doi = {10.3316/QRJ0902018},
	abstract = {This paper reports on our use of narrative accounts in qualitative research about educational leadership in Western Australia. Data for the research were gathered through semistructured interviews. We wanted to know whether interview data constructed as narrative accounts then analysed would help us understand the phenomenon of leading for sustainability. We had used this approach previously (Wildy \& Pepper, 2005; Clarke, Wildy \& Pepper, 2007) in our examination of school leadership. Our commitment to an interpretive approach (Connelly \& Clandinin, 1990; Kvale, 1996), to delve into our participants’ understanding of their experiences remains strong. Rich insights into the experiences of participants are revealed in narrative accounts crafted from semistructured interviews. Stories and descriptions of experience are given status when presented as narratives so contribute to participants’ wellbeing and meet the criteria for ‘good educational research’. In this paper we describe collecting data, constructing narratives, confirming quality and conducting analysis to describe the ‘wakefulness’ and transparency we adhere to when using narrative accounts as a research strategy.},
	number = {2},
	urldate = {2023-06-05},
	journal = {Qualitative Research Journal},
	author = {Pepper, Coral and Wildy, Helen},
	month = jan,
	year = {2009},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Narrative accounts, Research strategy},
	pages = {18--26},
	file = {Snapshot:files/6976/html.html:text/html},
}

@article{matthews_digital_2013,
	title = {Digital {Life}-{Story} {Narratives} as {Data} for {Policy} {Makers} and {Practitioners}: {Thinking} {Through} {Methodologies} for {Large}-{Scale} {Multimedia} {Qualitative} {Datasets}},
	volume = {57},
	issn = {0883-8151},
	shorttitle = {Digital {Life}-{Story} {Narratives} as {Data} for {Policy} {Makers} and {Practitioners}},
	url = {https://doi.org/10.1080/08838151.2012.761703},
	doi = {10.1080/08838151.2012.761703},
	abstract = {Digital life stories have been solicited, archived, and Web-cast by organizations and individuals as a way of amplifying marginalized voices in the public domain. Despite the now large collections of digital stories that are available, researchers and policy makers have rarely discussed these stories as qualitative data and powerful evidence for decision making. We analyze the political, ethical and methodological tensions that have limited the use of digital life-story archives to date. In conclusion, we begin to set out future directions for analyzing and applying on-line archives of digital life stories research, drawing on debates within existing research that uses large-scale qualitative datasets.},
	number = {1},
	urldate = {2023-06-05},
	journal = {Journal of Broadcasting \& Electronic Media},
	author = {Matthews, Nicole and Sunderland, Naomi},
	month = jan,
	year = {2013},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/08838151.2012.761703},
	pages = {97--114},
	file = {Full Text PDF:files/6978/Matthews e Sunderland - 2013 - Digital Life-Story Narratives as Data for Policy M.pdf:application/pdf},
}

@article{franzosi_narrative_1998-1,
	title = {Narrative as {Data}: {Linguistic} and {Statistical} {Tools} for the {Quantitative} {Study} of {Historical} {Events}},
	volume = {43},
	issn = {1469-512X, 0020-8590},
	shorttitle = {Narrative as {Data}},
	url = {https://www.cambridge.org/core/journals/international-review-of-social-history/article/narrative-as-data-linguistic-and-statistical-tools-for-the-quantitative-study-of-historical-events/1719D8B6E64D2B46292C246B1E2CF54E},
	doi = {10.1017/S002085900011510X},
	abstract = {This paper illustrates some linguistic and statistical tools that can be profitably used by historians and social historians in the study of events (such as strikes, demonstrations and other types of collective conflict). More specifically, the paper shows that “semantic grammars” provide rigorous tools for the collection of rich event narratives. Semantic grammars structure information around the “canonical form” of the language: noun phrase/verb phrase, or subject, action, object and their modifiers (e.g. time, space). The fact that semantic grammars can be easily implemented in a computer environment using relational database systems (RDBMS) makes feasible the practical application of such powerful coding schemes. The data that computer-based semantic grammars make available are richer, more flexible and more reliable than those delivered by more traditional content analysis methods. They are also very well suited for the application of new tools of data analysis such as network models. Both semantic grammars and network models are fundamentally concerned with actors and their actions, with agents and agency. As such, these linguistic and statistical tools should draw sociology closer to history, traditionally much more concerned with issues of agency. I illustrate the power of both the linguistic and statistical tools using data that I collected from some 15,000 newspaper articles on the 1919-1922 period of Italian history, a period characterized by widespread working-class mobilization (1919–1920, the “red years”) and fascist counter-mobilization (1921-1922, the “black years”).},
	language = {en},
	number = {S6},
	urldate = {2023-06-05},
	journal = {International Review of Social History},
	author = {Franzosi, Roberto},
	month = dec,
	year = {1998},
	note = {Publisher: Cambridge University Press},
	pages = {81--104},
	file = {Full Text PDF:files/6980/Franzosi - 1998 - Narrative as Data Linguistic and Statistical Tool.pdf:application/pdf},
}

@inproceedings{el_outa_towards_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Towards a {Conceptual} {Model} for {Data} {Narratives}},
	isbn = {978-3-030-62522-1},
	doi = {10.1007/978-3-030-62522-1_19},
	abstract = {Data narration is the activity of producing stories supported by facts extracted from data analysis, possibly using interactive visualizations. In spite of the increasing interest in data narration in several communities (e.g. journalism, business, e-government), there is no consensual definition of data narrative, let alone a conceptual or logical model of it. In this paper, we propose a conceptual model of data narrative for exploratory data analysis. It is based on four layers that reflect the transition from raw data to the visual rendering of the data story: factual, intentional, structural and presentational. This model aims to support the entire lifecycle of building a data narrative, starting from an intentional goal: fetch and explore data, bring out highlights, derive important messages, structure the plot of the data narrative, and render it in a visual manner. Our contributions include a description of the model and its instantiation for several real examples showing that it covers data narration needs.},
	language = {en},
	booktitle = {Conceptual {Modeling}},
	publisher = {Springer International Publishing},
	author = {El Outa, Faten and Francia, Matteo and Marcel, Patrick and Peralta, Veronika and Vassiliadis, Panos},
	editor = {Dobbie, Gillian and Frank, Ulrich and Kappel, Gerti and Liddle, Stephen W. and Mayr, Heinrich C.},
	year = {2020},
	keywords = {Data exploration, Data narrative, Data storytelling, Visual narrative},
	pages = {261--270},
	file = {Full Text PDF:files/6982/El Outa et al. - 2020 - Towards a Conceptual Model for Data Narratives.pdf:application/pdf},
}

@article{buthe_taking_2002,
	title = {Taking {Temporality} {Seriously}: {Modeling} {History} and the {Use} of {Narratives} as {Evidence}},
	volume = {96},
	issn = {1537-5943, 0003-0554},
	shorttitle = {Taking {Temporality} {Seriously}},
	url = {https://www.cambridge.org/core/journals/american-political-science-review/article/taking-temporality-seriously-modeling-history-and-the-use-of-narratives-as-evidence/291CAE2C423025880C422112A4EA900B},
	doi = {10.1017/S0003055402000278},
	abstract = {Social scientists interested in explaining historical processes can, indeed should, refuse the choice between modeling causal relationships and studying history. Identifying temporality as the defining characteristic of processes that can be meaningfully distinguished as “history,” I show that modeling such phenomena engenders particular difficulties but is both possible and fruitful. Narratives, as a way of presenting empirical information, have distinctive strengths that make them especially suited for historical scholarship, and structuring the narratives based on the model allows us to treat them as data on which to test the model. At the same time, this use of narratives raises methodological problems not identified in recent debates. I specify these problems, analyze their implications, and suggest ways of solving or minimizing them. There is no inherent incompatibility between—but much potential gain from—modeling history and using historical narratives as data.},
	language = {en},
	number = {3},
	urldate = {2023-06-05},
	journal = {American Political Science Review},
	author = {Büthe, Tim},
	month = sep,
	year = {2002},
	note = {Publisher: Cambridge University Press},
	pages = {481--493},
	file = {Full Text PDF:files/6984/Büthe - 2002 - Taking Temporality Seriously Modeling History and.pdf:application/pdf},
}

@incollection{paolini_storytelling_2014,
	address = {Cham},
	series = {Sxi — {Springer} per l’{Innovazione} / {Sxi} — {Springer} for {Innovation}},
	title = {Storytelling for {Cultural} {Heritage}},
	isbn = {978-3-319-03798-1},
	url = {https://doi.org/10.1007/978-3-319-03798-1_4},
	abstract = {Digital storytelling is emerging as the most relevant way to deliver content in the digital age. In essence, a digital story combines visual communication (slideshows, videos or animations) with audio. Optional text can be used for additional details. Most people agree today that digital stories are the best way for engaging users across several devices: from tablets to desktops, from smartphones to even phones, for audio only. Different narratives styles can be used and different situations can be envisioned, including immersive storytelling or augmented-reality storytelling.},
	language = {en},
	urldate = {2023-06-05},
	booktitle = {Innovative {Technologies} in {Urban} {Mapping}: {Built} {Space} and {Mental} {Space}},
	publisher = {Springer International Publishing},
	author = {Paolini, Paolo and Di Blas, Nicoletta},
	editor = {Contin, Antonella and Paolini, Paolo and Salerno, Rossella},
	year = {2014},
	doi = {10.1007/978-3-319-03798-1_4},
	keywords = {Cultural Heritage, Content Item, Interactive Multimedia, Multimedia Communication, Virtual Tour},
	pages = {33--45},
}

@article{barber_digital_2019,
	title = {Digital {Storytelling} and {Open}, {Networked} {Social} {Scholarship}: {A} {Narrative}},
	volume = {3},
	issn = {2398-4112},
	shorttitle = {Digital {Storytelling} and {Open}, {Networked} {Social} {Scholarship}},
	url = {https://www.erudit.org/en/journals/kula/1900-v1-n1-kula06582/1084210ar/abstract/},
	doi = {10.5334/kula.37},
	abstract = {This essay responds to a challenge of the INKE 2018 gathering: To highlight activities that focus on the engagement and implementation of networked open social scholarship. One response to this challenge is to distribute scholarly communication as storytelling through multiple digital media channels. The author participated in an international, multidisciplinary fellowship focused on how to implement such an undertaking. This narrative describes the collaborative efforts, presentations, and practices that emerged from this open, social scholarship endeavor.},
	language = {en},
	number = {1},
	urldate = {2023-06-05},
	journal = {KULA: Knowledge Creation, Dissemination, and Preservation Studies},
	author = {Barber, John},
	year = {2019},
	note = {Publisher: University of Victoria Libraries},
	keywords = {Network, digital media, collaboration, interdisciplinary, multimodal, open social scholarship, social network, usability},
	pages = {1--10},
	file = {Full text:files/6987/Barber - 2019 - Digital Storytelling and Open, Networked Social Sc.pdf:application/pdf;Snapshot:files/6988/abstract.html:text/html},
}

@article{wilson_playful_2019,
	title = {Playful {Lenses}: {Using} {Twine} to {Facilitate} {Open} {Social} {Scholarship} through {Game}-based {Inquiry}, {Research}, and {Scholarly} {Communication}},
	volume = {3},
	issn = {2398-4112},
	shorttitle = {Playful {Lenses}},
	url = {https://www.erudit.org/en/journals/kula/1900-v1-n1-kula06582/1084223ar/},
	doi = {10.5334/kula.11},
	abstract = {In academic contexts, digital games are often studied as texts or are used as pedagogical tools to teach basic concepts in early education situations. Less usefully, their systems and economies are often co-opted and decontextualized in short-sighted attempts to “gamify” various aspects of learning or training. However, given that games are highly controlled, conditional, choice-and-consequence-based, problem-solving environments in which players are expected to interact with simulated settings and elements after agreeing to take on particular roles and subject positions, there are promising potential uses of these experiences in academic contexts that have not been fully considered. Motivated by the imperative to explore alternative modes and methods of scholarly research and communication, and guided by the values of open social scholarship practices, this paper reconsiders games not as things to study, but as instruments to study with. Given that games can function as simulations, models, arguments and creative collaboratories, game-based inquiry can be used as a potential method of post-secondary and post-graduate humanities research and scholarly communication. While these ideas have been explored in a preliminary way in relation to a number of different academic disciplines (Donchin 1995; Boot 2015; Mitgutsch and Weise 2011; Westecott 2011) this paper is meant to catalyse a humanities-calibrated consideration of the pragmatics and potentials of game-based research, games as instances of critical making and scholarly communication, and more complex forms of game-based learning than those currently practiced. A number of examples that make use of the open source Twine platform will be featured.},
	language = {en},
	number = {1},
	urldate = {2023-06-05},
	journal = {KULA: Knowledge Creation, Dissemination, and Preservation Studies},
	author = {Wilson, Rebecca and Saklofske, Jon},
	year = {2019},
	note = {Publisher: University of Victoria Libraries},
	keywords = {digital humanities, communication, open social scholarship, digital games, research, Twine},
	pages = {1--10},
	file = {Full text:files/6991/Wilson e Saklofske - 2019 - Playful Lenses Using Twine to Facilitate Open Soc.pdf:application/pdf;Snapshot:files/6990/abstract.html:text/html},
}

@article{rehm_semantic_nodate,
	title = {Semantic {Storytelling}: {Towards} {Identifying} {Storylines} in {Large} {Amounts} of {Text} {Content}},
	abstract = {In this position paper we present an approach and vision we call Semantic Storytelling. The idea is to develop a system that, given an incoming document collection, is able to (semi-)automatically extract or generate diﬀerent story paths or plot lines towards the goal of supporting knowledge workers (journalists, authors, scholars, politicians, business analysts etc.) in their daily work of processing huge amounts of incoming content. We outline the diﬀerent components needed, which can be summarised as preprocessing, semantic analysis and content enrichment, as well as generating storylines. Our idea is to take into account the speciﬁcities of diﬀerent text genres, which, we believe, will help us to generate better results according to the needs and characteristics of the respective text genre. We give a brief example where Semantic Storytelling can be applied and try to pinpoint the main conceptual, scientiﬁc and technical gaps that still need to be addressed fully to realise our vision of a Semantic Storytelling system.},
	language = {en},
	author = {Rehm, Georg and Zaczynska, Karolina and Moreno-Schneider, Julian},
	file = {Rehm et al. - Semantic Storytelling Towards Identifying Storyli.pdf:files/6992/Rehm et al. - Semantic Storytelling Towards Identifying Storyli.pdf:application/pdf},
}

@article{dahlstrom_using_2014,
	title = {Using narratives and storytelling to communicate science with nonexpert audiences},
	volume = {111},
	url = {https://www.pnas.org/doi/10.1073/pnas.1320645111},
	doi = {10.1073/pnas.1320645111},
	abstract = {Although storytelling often has negative connotations within science, narrative formats of communication should not be disregarded when communicating science to nonexpert audiences. Narratives offer increased comprehension, interest, and engagement. Nonexperts get most of their science information from mass media content, which is itself already biased toward narrative formats. Narratives are also intrinsically persuasive, which offers science communicators tactics for persuading otherwise resistant audiences, although such use also raises ethical considerations. Future intersections of narrative research with ongoing discussions in science communication are introduced.},
	number = {supplement\_4},
	urldate = {2023-06-05},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Dahlstrom, Michael F.},
	month = sep,
	year = {2014},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {13614--13620},
	file = {Full Text PDF:files/6995/Dahlstrom - 2014 - Using narratives and storytelling to communicate s.pdf:application/pdf},
}

@inproceedings{rizvic_guidelines_2017,
	title = {Guidelines for interactive digital storytelling presentations of cultural heritage},
	doi = {10.1109/VS-GAMES.2017.8056610},
	abstract = {Interactive digital storytelling becomes a form of information presentation in many fields. Its application spans from media industry through digital cultural heritage, serious games, information visualization to contemporary theater and visual arts. In order to develop a new digital storytelling methodology hyper-storytelling, we engaged a team of multidisciplinary experts from computer science, visual arts, literature, film directing, psychology, communicology and human computer interaction. In this paper we present the first findings of this team in form of guidelines for interactive digital storytelling presentations of cultural heritage.},
	booktitle = {2017 9th {International} {Conference} on {Virtual} {Worlds} and {Games} for {Serious} {Applications} ({VS}-{Games})},
	author = {Rizvic, Selma and Djapo, Nermin and Alispahic, Fatmir and Hadzihalilovic, Bojan and Cengic, Fahira Fejzic and Imamovic, Ahmed and Okanovic, Vensada and Boskovic, Dusanka},
	month = sep,
	year = {2017},
	note = {ISSN: 2474-0489},
	keywords = {Cultural differences, Visualization, Media, Art, Games, interactive digital storytelling, Guidelines, hyper-storytelling, Sarajevo charter, serious games for cultural heritage, user evaluation studies, Virtual environments},
	pages = {253--259},
	file = {IEEE Xplore Abstract Record:files/6997/8056610.html:text/html;IEEE Xplore Full Text PDF:files/6998/Rizvic et al. - 2017 - Guidelines for interactive digital storytelling pr.pdf:application/pdf},
}

@article{thon_converging_2015,
	title = {Converging {Worlds}: {From} {Transmedial} {Storyworlds} to {Transmedial} {Universes}},
	volume = {7},
	issn = {1946-2204},
	shorttitle = {Converging {Worlds}},
	url = {https://www.jstor.org/stable/10.5250/storyworlds.7.2.0021},
	doi = {10.5250/storyworlds.7.2.0021},
	number = {2},
	urldate = {2023-06-05},
	journal = {Storyworlds: A Journal of Narrative Studies},
	author = {Thon, Jan-Noël},
	year = {2015},
	note = {Publisher: University of Nebraska Press},
	pages = {21--53},
	file = {JSTOR Full Text PDF:files/7000/Thon - 2015 - Converging Worlds From Transmedial Storyworlds to.pdf:application/pdf},
}

@misc{crawford_research_nodate-1,
	title = {Research {Guides}: {Library} {Research} {Guide} for {Folklore} and {Mythology}: {Tale}-{Type} and {Motif} {Indices}},
	copyright = {Copyright Harvard Library 2023},
	shorttitle = {Research {Guides}},
	url = {https://guides.library.harvard.edu/folk_and_myth/indices},
	abstract = {Research Guides: Library Research Guide for Folklore and Mythology: Tale-Type and Motif Indices},
	language = {en},
	urldate = {2023-06-05},
	author = {Crawford, Ramona},
}

@article{perossini_digital_2020,
	title = {Digital {Preservation} (challenges, preparedness and reaction)},
	volume = {949},
	issn = {1757-899X},
	url = {https://dx.doi.org/10.1088/1757-899X/949/1/012112},
	doi = {10.1088/1757-899X/949/1/012112},
	abstract = {The STORM (H2020 700191), experience give us evidence on how it is important to address risks coming from natural hazards with the proper preparedness. Anyhow the project left one face of the picture uncovered. The aim of this paper is to stimulate further discussions related to digitised documentation and digital cultural assets safety either if they are digital born or reproduction of real ones. In 2003, UNESCO released the “Charter on the Preservation of Digital Heritage”[1], which defines digital heritage as “made up of computer-based materials of enduring value that should be kept for future generations (UNESCO 2003)”. Digital heritage emanates from different communities, industries, sectors and regions. Not all digital material is of enduring value, but a paramount volume of digital objects, especially the digital documentation related to cultural heritage, require active preservation approaches regardless the technology evolution. . It should be a priority to preserve that digital patrimony as well as to preserve the physical one. For this reason we aggregate the two view points in the “Digital heritage”. The challenge is represented by the preservation from one side of the digital born objects (including all the cultural heritage documentation), from the other objects coming from the conversion of existing/disappeared ones, must be protected and preserved. We are facing day by day a wider scenario where gallery, library, archive, and museum (GLAM)[2] dependence from digital content preservation is growing so the need for a lifecycle management of digital materials is necessary to ensure their continuity.},
	language = {en},
	number = {1},
	urldate = {2023-06-08},
	journal = {IOP Conference Series: Materials Science and Engineering},
	author = {Perossini, F. and Boi, S. and Capua, M. C.},
	month = nov,
	year = {2020},
	note = {Publisher: IOP Publishing},
	pages = {012112},
	file = {IOP Full Text PDF:files/7003/Perossini et al. - 2020 - Digital Preservation (challenges, preparedness and.pdf:application/pdf},
}

@article{dahlstrom_documentary_2019,
	title = {Documentary {Provenance} and {Digitized} {Collections}: {Concepts} and {Problems}},
	volume = {6},
	issn = {2473-215X},
	shorttitle = {Documentary {Provenance} and {Digitized} {Collections}},
	url = {https://ideaexchange.uakron.edu/docam/vol6/iss1/8},
	doi = {10.35492/docam/6/1/8},
	number = {1},
	journal = {Proceedings from the Document Academy},
	author = {Dahlström, Mats and Hansson, Joacim},
	month = dec,
	year = {2019},
	file = {Full text:files/7005/Dahlström e Hansson - 2019 - Documentary Provenance and Digitized Collections .pdf:application/pdf},
}

@article{parent_unescopersist_2021,
	title = {The {UNESCO}/{PERSIST} {Guidelines} for the {Selection} of {Digital} {Heritage} for {Long}-{Term} {Preservation} - 2nd {Edition}},
	copyright = {CC BY 4.0},
	url = {https://repository.ifla.org/handle/123456789/1863},
	abstract = {The 2nd Edition of the UNESCO/PERSIST Guidelines for the Selection of Digital Heritage for Long-Term Preservation seeks to continue helping practitioners and decision-makers in memory institutions make informed choices regarding what digital resources to preserve for long-term access. The PERSIST Content Task Force, under the Preservation Subcommittee of UNESCO Memory of the World, convened a writing group of experts and representatives from IFLA, the International Council on Archives (ICA), and the International Council of Museums (ICOM) to create this update, which expands on the first edition of the Guidelines (2016). This resource offers a starting point, communicating key concepts and tools that practitioners might consider in their own context.},
	language = {en},
	urldate = {2023-06-10},
	author = {Parent, Ingrid and Seles, Anthea and Storti, Davide and Banda, Fackson and Blin, Frédéric and McKenna, Gordon and Lee, Ivy and Murdock Smith, Jenna and Chee, Julia and Hagedorn-Saupe, Monika and Knight, Steve and Roberts, Winston},
	month = sep,
	year = {2021},
	note = {Accepted: 2022-02-08T08:04:50Z},
	file = {Full Text PDF:files/7144/Parent et al. - 2021 - The UNESCOPERSIST Guidelines for the Selection of.pdf:application/pdf},
}

@article{blair_3052_2018,
	title = {305.2 {PREMIS} 3 {OWL} {Ontology}: {Engaging} sets of linked data -- {Award} {Winner}: {Best} {Short} {Paper}},
	shorttitle = {305.2 {PREMIS} 3 {OWL} {Ontology}},
	url = {https://osf.io/e8vj6/},
	doi = {10.17605/OSF.IO/E8VJ6},
	abstract = {The PREMIS 3.0 Ontology Working Group recognized the need for the preservation community to be able to use Semantic Web tech- nology to leverage systems managing the long-term preservation of digital holdings. Driven by the main principle of adherence to the PREMIS Data Dictionary, and a set of well-established Linked Data principles, the draft release of the PREMIS 3 OWL ontology comes after two years of conceptualization, discussion and experi- mentation. The release of the draft was followed by a public review of the revised ontology soliciting a wider discussion about the con- ceptual choices expressed by the ontology. This article explains how interoperability issues have been addressed, with the intent of maintaining continuity between the PREMIS Data Dictionary and the PREMIS OWL ontology. 
This paper won the iPres 2018 Best Short Paper Award 
    Hosted on the Open Science Framework},
	language = {en},
	urldate = {2023-06-12},
	author = {Blair, Charles and Bountouri, Lina and Caron, Bertrand and Cowles, Esmé and Iorio, Angela Di and Guenther, Rebecca and McLellan, Evelyn and Roke, Elizabeth Russey},
	month = sep,
	year = {2018},
	note = {Publisher: OSF},
	file = {Snapshot:files/7283/e8vj6.html:text/html},
}

@misc{congress_premis_nodate,
	type = {webpage},
	title = {{PREMIS} {OWL} {Ontology} for {PREMIS} {Data} {Dictionary} version 3 ({PREMIS}, {Preservation} {Metadata} {Maintenance} {Activity}, {Library} of {Congress})},
	url = {https://www.loc.gov/standards/premis/ontology/owl-version3.html},
	abstract = {The PREMIS OWL Ontology Revision Working Group, appointed by the PREMIS Editorial Committee, worked on the ontology between early 2016 and September 2018. This revision is based on the PREMIS Data Dictionary, version 3.0 and has substantially remodeled the previous ontology, incorporating emerging Linked Data best practices and connections to other relevant RDF ontologies, e.g. PROV-O (Provenance ontology), Dublin Core metadata terms, and the preservation vocabularies at http://id.loc.gov/preservationdescriptions/, among others.},
	language = {eng},
	urldate = {2023-06-12},
	author = {Congress, Library of and Committee, PREMIS Editorial},
	file = {Snapshot:files/7285/owl-version3.html:text/html},
}

@article{coppens_premis_2015,
	title = {{PREMIS} {OWL}},
	volume = {15},
	issn = {1432-1300},
	url = {https://doi.org/10.1007/s00799-014-0136-9},
	doi = {10.1007/s00799-014-0136-9},
	abstract = {In this article, we present PREMIS OWL. This is a semantic formalisation of the PREMIS 2.2 data dictionary of the Library of Congress. PREMIS 2.2 are metadata implementation guidelines for digitally archiving information for the long term. Nowadays, the need for digital preservation is growing. A lot of the digital information produced merely a decade ago is in danger of getting lost as technologies are changing and getting obsolete. This also threatens a lot of information from heritage institutions. PREMIS OWL is a semantic long-term preservation schema. Preservation metadata are actually a mixture of provenance information, technical information on the digital objects to be preserved and rights information. PREMIS OWL is an OWL schema that can be used as data model supporting digital archives. It can be used for dissemination of the preservation metadata as Linked Open Data on the Web and, at the same time, for supporting semantic web technologies in the preservation processes. The model incorporates 24 preservation vocabularies, published by the LOC as SKOS vocabularies. Via these vocabularies, PREMIS descriptions from different institutions become highly interoperable. The schema is approved and now managed by the Library of Congress. The PREMIS OWL schema is published at http://www.loc.gov/premis/rdf/v1.},
	language = {en},
	number = {2},
	urldate = {2023-06-12},
	journal = {International Journal on Digital Libraries},
	author = {Coppens, Sam and Verborgh, Ruben and Peyrard, Sébastien and Ford, Kevin and Creighton, Tom and Guenther, Rebecca and Mannens, Erik and Van de Walle, Rik},
	month = apr,
	year = {2015},
	keywords = {Ontology, Metadata, Linked open data, PREMIS OWL, Preservation, Semantic},
	pages = {87--101},
	file = {Full Text PDF:files/7287/Coppens et al. - 2015 - PREMIS OWL.pdf:application/pdf},
}

@article{huvila_documenting_2021,
	title = {Documenting {Information} {Processes} and {Practices}: {Paradata}, {Provenance} {Metadata}, {Life}-{Cycles} and {Pipelines}},
	volume = {58},
	copyright = {84th Annual Meeting of the Association for Information Science \& Technology {\textbar} Oct. 29 – Nov. 3, 2021 {\textbar} Salt Lake City, UT. Author(s) retain copyright, but ASIS\&T receives an exclusive publication license.},
	issn = {2373-9231},
	shorttitle = {Documenting {Information} {Processes} and {Practices}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pra2.509},
	doi = {10.1002/pra2.509},
	abstract = {Processes and practices—and in general, informational doings and their diverse constellations—are pertinent elements of the information landscape. This panel presents research on documentation and description of processes and practices in the information field addressing: 1) how different conceptualisations of processes and practices influence how they emerge as describable entities; 2) what different approaches to document and describe processes and practices exist and have been proposed in information science and technology research; 3) what aspects of processes and practices different documentation approaches capture, make visible and invisible; and 4) what novel insights from the current state-of-the-art research can be drawn to support practitioners in different areas of the information field, including knowledge organisation, information management, information literacy instruction, and development of information systems and services.},
	language = {en},
	number = {1},
	urldate = {2023-06-12},
	journal = {Proceedings of the Association for Information Science and Technology},
	author = {Huvila, Isto and Greenberg, Jane and Sköld, Olle and Thomer, Andrea and Trace, Ciaran and Zhao, Xintong},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pra2.509},
	keywords = {pipelines, paradata, practices, processes, provenance metadata},
	pages = {604--609},
	file = {Snapshot:files/7290/pra2.html:text/html;Versione inviata:files/7289/Huvila et al. - 2021 - Documenting Information Processes and Practices P.pdf:application/pdf},
}

@article{karoune_removing_2022,
	title = {Removing {Barriers} to {Reproducible} {Research} in {Archaeology}},
	doi = {10.5281/zenodo.7320029},
	abstract = {Reproducible research is being implemented at different speeds in different disciplines, and Archaeology is at the start of this journey. Reproducibility is the practice of reanalysing data by taking the same steps and producing the same or similar results. Enabling reproducibility is an important step to ensure research quality and validate interpretations. There are currently many barriers to moving towards reproducible research such as the skill level of researchers in the practices, software and infrastructure needed to do reproducible research and concerns relating to opening up research such as how to share sensitive data. In this article, we seek to introduce reproducible research in an understandable manner so that archaeologists can learn where and how to start improving the reproducibility of their research. We describe what reproducible archaeological research can look like and propose three different computational skill levels of reproducible workflows with examples. Finally, in an extensive appendix, we address common questions about reproducible research to remove the stigma about these issues and suggest ways to overcome them.},
	journal = {Pci Journal},
	author = {Karoune, Emma and Plomp, Esther},
	month = nov,
	year = {2022},
	file = {Full Text PDF:files/7334/Karoune e Plomp - 2022 - Removing Barriers to Reproducible Research in Arch.pdf:application/pdf},
}

@article{teytelman_protocolsio_2015,
	title = {Protocols.io: {Reducing} the knowledge that perishes because we do not publish it},
	volume = {35},
	issn = {0167-5265},
	shorttitle = {Protocols.io},
	url = {https://content.iospress.com/articles/information-services-and-use/isu769},
	doi = {10.3233/ISU-150769},
	abstract = {The way life scientists communicate has hardly changed since the days of Gregor Mendel. Even though mobile and Internet technology has transformed a wide array of communication channels, academic publishing has largely resisted change. As a consequen},
	language = {en},
	number = {1-2},
	urldate = {2023-06-15},
	journal = {Information Services \& Use},
	author = {Teytelman, Leonid and Stoliartchouk, Alexei},
	month = jan,
	year = {2015},
	note = {Publisher: IOS Press},
	pages = {109--115},
	file = {Full Text PDF:files/7336/Teytelman e Stoliartchouk - 2015 - Protocols.io Reducing the knowledge that perishes.pdf:application/pdf},
}

@article{teytelman_protocolsio_2016,
	title = {Protocols.io: {Virtual} {Communities} for {Protocol} {Development} and {Discussion}},
	volume = {14},
	issn = {1545-7885},
	shorttitle = {Protocols.io},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002538},
	doi = {10.1371/journal.pbio.1002538},
	abstract = {The detailed know-how to implement research protocols frequently remains restricted to the research group that developed the method or technology. This knowledge often exists at a level that is too detailed for inclusion in the methods section of scientific articles. Consequently, methods are not easily reproduced, leading to a loss of time and effort by other researchers. The challenge is to develop a method-centered collaborative platform to connect with fellow researchers and discover state-of-the-art knowledge. Protocols.io is an open-access platform for detailing, sharing, and discussing molecular and computational protocols that can be useful before, during, and after publication of research results.},
	language = {en},
	number = {8},
	urldate = {2023-06-15},
	journal = {PLOS Biology},
	author = {Teytelman, Leonid and Stoliartchouk, Alexei and Kindler, Lori and Hurwitz, Bonnie L.},
	month = aug,
	year = {2016},
	note = {Publisher: Public Library of Science},
	keywords = {Computer software, Reproducibility, Community ecology, Open science, Research and analysis methods, Scientific publishing, Scientists, Vendors},
	pages = {e1002538},
	file = {Full Text PDF:files/7338/Teytelman et al. - 2016 - Protocols.io Virtual Communities for Protocol Dev.pdf:application/pdf},
}

@incollection{bruseker_cultural_2017-1,
	address = {Cham},
	series = {Quantitative {Methods} in the {Humanities} and {Social} {Sciences}},
	title = {Cultural {Heritage} {Data} {Management}: {The} {Role} of {Formal} {Ontology} and {CIDOC} {CRM}},
	isbn = {978-3-319-65370-9},
	shorttitle = {Cultural {Heritage} {Data} {Management}},
	url = {https://doi.org/10.1007/978-3-319-65370-9_6},
	abstract = {Building models for integrating the diverse data generated in Cultural Heritage disciplines is a long-term challenge both for securing presently generated knowledge and for making it progressively more widely accessible and interoperable into the future. This chapter reviews the multiple approaches undertaken to address this problem, finally proposing CIDOC CRM as the most robust solution for information integration in CH. The chapter begins by outlining the data challenge specific to the field and the main approaches that can be taken in facing it. Within this frame, it distinguishes knowledge engineering and formal ontology from other information modelling techniques as the necessary approach for tackling the broader data integration problem. It then outlines the basic principles of CIDOC CRM, the ISO standard formal ontology for CH. From there, an overview is given of some of the work that has been done both theoretically and in practice over the past five years in developing and implementing CRM as a practical data integration strategy in CH, particularly looking at model extensions to handle knowledge provenance across various disciplines and typical documentation and reasoning activities, as well as at successful implementation projects. Lastly, it summarizes the present potentials and challenges for using CIDOC CRM for solving the CH data management and integration puzzle. The intended audience of this chapter are specialists from all backgrounds within the broader domain of CH with an interest in data integration and CIDOC CRM.},
	language = {en},
	urldate = {2023-06-15},
	booktitle = {Heritage and {Archaeology} in the {Digital} {Age}: {Acquisition}, {Curation}, and {Dissemination} of {Spatial} {Cultural} {Heritage} {Data}},
	publisher = {Springer International Publishing},
	author = {Bruseker, George and Carboni, Nicola and Guillem, Anaïs},
	editor = {Vincent, Matthew L. and López-Menchero Bendicho, Víctor Manuel and Ioannides, Marinos and Levy, Thomas E.},
	year = {2017},
	doi = {10.1007/978-3-319-65370-9_6},
	pages = {93--131},
}

@inproceedings{niccolucci_cidoc_2018,
	title = {A {CIDOC} {CRM}-based {Model} for the {Documentation} of {Heritage} {Sciences}},
	doi = {10.1109/DigitalHeritage.2018.8810109},
	abstract = {The paper describes an approach to the documentation of scientific data produced in heritage sciences interdisciplinary research. Since such activities fall within the scope of a scientific discipline (e.g. physics or chemistry) and of cultural heritage, the documentation system must draw from both. The paper proposes an overarching system based on the use of CIDOC CRM and its extensions CRMsci, CRMdig and CRMpe to model physical and digital objects, events and activities, and actors, i.e. people and teams. It is suggested that such a model could address most - if not all - of the issues encountered documenting heritage sciences results. The use of the CRM provides straightforward connection and interoperability with the general documentation of cultural heritage and thus tightly links scientific analyses to their heritage context. A number of examples demonstrate how to apply this approach to different cases and offer an overview of the whole model, which is not fully exposed here: full details will be given in a separate technical document.},
	booktitle = {2018 3rd {Digital} {Heritage} {International} {Congress} ({DigitalHERITAGE}) held jointly with 2018 24th {International} {Conference} on {Virtual} {Systems} \& {Multimedia} ({VSMM} 2018)},
	author = {Niccolucci, Franco and Felicetti, Achille},
	month = oct,
	year = {2018},
	keywords = {Semantics, Cultural differences, CIDOC CRM, Documentation, Resource description framework, Metadata, XML, Heritage Sciences, Scientific Data, Standards},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:files/7342/8810109.html:text/html;IEEE Xplore Full Text PDF:files/7341/Niccolucci e Felicetti - 2018 - A CIDOC CRM-based Model for the Documentation of H.pdf:application/pdf},
}

@article{tomoyose_vocabularies_2022-1,
	title = {Vocabularies for {Publishing} {Research} {Data}},
	volume = {60},
	issn = {0163-9374},
	url = {https://doi.org/10.1080/01639374.2021.2011812},
	doi = {10.1080/01639374.2021.2011812},
	abstract = {Research data are essential for the development of science, and one of the issues to be addressed is its organization and representation. Based on these basic concepts of Information Science, we seek to explore the Data Catalog Vocabulary (DCAT) and the vocabularies used by it in the context of research data publication. We assert that the use of metadata vocabularies to represent research data is necessary to improve access, findability, interoperability, and the retrieval of datasets. We verify that DCAT enables the standardization of catalogs and datasets through specific terms for this purpose, presenting itself as an adequate vocabulary to represent the research data.},
	number = {1},
	urldate = {2023-06-15},
	journal = {Cataloging \& Classification Quarterly},
	author = {Tomoyose, Kazumi and Arakaki, Ana Carolina Simionato},
	month = jan,
	year = {2022},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/01639374.2021.2011812},
	keywords = {controlled vocabularies, Data Catalog Vocabulary (DCAT), information representation, metadata standards, research data},
	pages = {69--85},
	file = {Full Text PDF:files/7373/Tomoyose e Arakaki - 2022 - Vocabularies for Publishing Research Data.pdf:application/pdf},
}

@article{de_haas_fair_nodate,
	title = {{FAIR} survey: improving documentation and archiving practices in archaeological field survey through {CIDOC} {CRM}},
	language = {en},
	author = {de Haas, Tymon and van Leusen, Martijn},
	file = {de Haas e van Leusen - FAIR survey improving documentation and archiving.pdf:files/7533/de Haas e van Leusen - FAIR survey improving documentation and archiving.pdf:application/pdf},
}

@misc{garijo_best_2020,
	title = {Best {Practices} for {Implementing} {FAIR} {Vocabularies} and {Ontologies} on the {Web}},
	url = {http://arxiv.org/abs/2003.13084},
	abstract = {With the adoption of Semantic Web technologies, an increasing number of vocabularies and ontologies have been developed in different domains, ranging from Biology to Agronomy or Geosciences. However, many of these ontologies are still difficult to find, access and understand by researchers due to a lack of documentation, URI resolving issues, versioning problems, etc. In this chapter we describe guidelines and best practices for creating accessible, understandable and reusable ontologies on the Web, using standard practices and pointing to existing tools and frameworks developed by the Semantic Web community. We illustrate our guidelines with concrete examples, in order to help researchers implement these practices in their future vocabularies.},
	urldate = {2023-06-22},
	publisher = {arXiv},
	author = {Garijo, Daniel and Poveda-Villalón, María},
	month = mar,
	year = {2020},
	note = {arXiv:2003.13084 [cs]},
	keywords = {Computer Science - Digital Libraries, Computer Science - Artificial Intelligence, I.2.4, Computer Science - Databases, I.2},
	file = {arXiv.org Snapshot:files/7560/2003.html:text/html;Full Text PDF:files/7561/Garijo e Poveda-Villalón - 2020 - Best Practices for Implementing FAIR Vocabularies .pdf:application/pdf},
}

@article{lee_eden_shape_2019,
	title = {The {Shape} of {Data} in {Digital} {Humanities}: {Modeling} {Texts} and {Text}-{Based} {Resources}},
	volume = {31},
	issn = {1941-126X},
	shorttitle = {The {Shape} of {Data} in {Digital} {Humanities}},
	url = {https://doi.org/10.1080/1941126X.2019.1635787},
	doi = {10.1080/1941126X.2019.1635787},
	number = {3},
	urldate = {2023-06-22},
	journal = {Journal of Electronic Resources Librarianship},
	author = {Lee Eden, Bradford},
	month = jul,
	year = {2019},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/1941126X.2019.1635787},
	pages = {214--214},
	file = {Full Text PDF:files/7564/Lee Eden - 2019 - The Shape of Data in Digital Humanities Modeling .pdf:application/pdf},
}

@article{svoljsak_historical_2022,
	title = {Historical {Collections} and {Library} {Catalogs}: {Provenance} {Metadata}, {Bibliographic} {Standards} and {Frameworks}, and {Catalog} {Functionalities}},
	volume = {60},
	issn = {0163-9374},
	shorttitle = {Historical {Collections} and {Library} {Catalogs}},
	url = {https://doi.org/10.1080/01639374.2022.2124340},
	doi = {10.1080/01639374.2022.2124340},
	abstract = {The article discusses the importance of custodial history metadata in bibliographic standards, formats and frameworks, and in library catalogs. It analyzes the present situation and proposes some basic solutions that would make it possible for the custodial history metadata to be entered in a standardized way and to be functionally linked to the holdings metadata so that catalog users would be able to search and retrieve information on the most relevant copies in terms of their provenance. Visual simulations of various functionalities based on the search and results display interface of the Slovenian National Library’s catalog are also included.},
	number = {8},
	urldate = {2023-06-22},
	journal = {Cataloging \& Classification Quarterly},
	author = {Svoljšak, Sonja},
	month = nov,
	year = {2022},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/01639374.2022.2124340},
	keywords = {Provenance, bibliographic frameworks, bibliographic standards, custodial history, functionalities, library catalogs},
	pages = {775--785},
	file = {Full Text PDF:files/7566/Svoljšak - 2022 - Historical Collections and Library Catalogs Prove.pdf:application/pdf},
}

@article{coppens_premis_2015-1,
	title = {{PREMIS} {OWL}},
	volume = {15},
	issn = {1432-1300},
	url = {https://doi.org/10.1007/s00799-014-0136-9},
	doi = {10.1007/s00799-014-0136-9},
	abstract = {In this article, we present PREMIS OWL. This is a semantic formalisation of the PREMIS 2.2 data dictionary of the Library of Congress. PREMIS 2.2 are metadata implementation guidelines for digitally archiving information for the long term. Nowadays, the need for digital preservation is growing. A lot of the digital information produced merely a decade ago is in danger of getting lost as technologies are changing and getting obsolete. This also threatens a lot of information from heritage institutions. PREMIS OWL is a semantic long-term preservation schema. Preservation metadata are actually a mixture of provenance information, technical information on the digital objects to be preserved and rights information. PREMIS OWL is an OWL schema that can be used as data model supporting digital archives. It can be used for dissemination of the preservation metadata as Linked Open Data on the Web and, at the same time, for supporting semantic web technologies in the preservation processes. The model incorporates 24 preservation vocabularies, published by the LOC as SKOS vocabularies. Via these vocabularies, PREMIS descriptions from different institutions become highly interoperable. The schema is approved and now managed by the Library of Congress. The PREMIS OWL schema is published at http://www.loc.gov/premis/rdf/v1.},
	language = {en},
	number = {2},
	urldate = {2023-06-22},
	journal = {International Journal on Digital Libraries},
	author = {Coppens, Sam and Verborgh, Ruben and Peyrard, Sébastien and Ford, Kevin and Creighton, Tom and Guenther, Rebecca and Mannens, Erik and Van de Walle, Rik},
	month = apr,
	year = {2015},
	keywords = {Ontology, Metadata, Linked open data, PREMIS OWL, Preservation, Semantic},
	pages = {87--101},
	file = {Full Text PDF:files/7568/Coppens et al. - 2015 - PREMIS OWL.pdf:application/pdf},
}

@article{di_iorio_expressing_2019,
	title = {Expressing the {Tacit} {Knowledge} of a {Digital} {Library} {System} as {Linked} {Data}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-431X},
	url = {https://www.mdpi.com/2073-431X/8/2/49},
	doi = {10.3390/computers8020049},
	abstract = {Library organizations have enthusiastically undertaken semantic web initiatives and in particular the data publishing as linked data. Nevertheless, different surveys report the experimental nature of initiatives and the consumer difficulty in re-using data. These barriers are a hindrance for using linked datasets, as an infrastructure that enhances the library and related information services. This paper presents an approach for encoding, as a Linked Vocabulary, the “tacit” knowledge of the information system that manages the data source. The objective is the improvement of the interpretation process of the linked data meaning of published datasets. We analyzed a digital library system, as a case study, for prototyping the “semantic data management” method, where data and its knowledge are natively managed, taking into account the linked data pillars. The ultimate objective of the semantic data management is to curate the correct consumers’ interpretation of data, and to facilitate the proper re-use. The prototype defines the ontological entities representing the knowledge, of the digital library system, that is not stored in the data source, nor in the existing ontologies related to the system’s semantics. Thus we present the local ontology and its matching with existing ontologies, Preservation Metadata Implementation Strategies (PREMIS) and Metadata Objects Description Schema (MODS), and we discuss linked data triples prototyped from the legacy relational database, by using the local ontology. We show how the semantic data management, can deal with the inconsistency of system data, and we conclude that a specific change in the system developer mindset, it is necessary for extracting and “codifying” the tacit knowledge, which is necessary to improve the data interpretation process.},
	language = {en},
	number = {2},
	urldate = {2023-06-22},
	journal = {Computers},
	author = {Di Iorio, Angela and Schaerf, Marco},
	month = jun,
	year = {2019},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {linked data, ontology management, tacit knowledge},
	pages = {49},
	file = {Full text:files/7570/Di Iorio e Schaerf - 2019 - Expressing the Tacit Knowledge of a Digital Librar.pdf:application/pdf},
}

@article{masenya_use_2021,
	title = {The use of metadata systems for the preservation of digital records in cultural heritage institutions},
	volume = {54},
	copyright = {Copyright (c) 2021 Journal of the South African Society of Archivists},
	issn = {1012-2796},
	url = {https://www.ajol.info/index.php/jsasa/article/view/216959},
	doi = {10.4314/jsasa.v54i.5},
	abstract = {Many studies concur that most of the world’s heritage resources, including digital records, are highly vulnerable to loss, and some cannot be recovered due to neglect or mismanagement. Strategies are thus needed to ensure long-term preservation and global access to digital records of enduring value. Metadata systems have been regarded as a suitable strategy to support digital preservation processes and prevent digital records loss within cultural heritage institutions. The purpose of this paper was to investigate the adoption of metadata systems in cultural heritage institutions in South Africa. This study utilised literature review to critically examine the use of metadata systems for the preservation of digital records in cultural heritage institutions. Although various preservation systems and strategies are being developed to enable description, discovery and delivery of digital records, the findings revealed that South African cultural heritage institutions’ level of metadata system adoption is low. This is due to lack of awareness about metadata schemas and standards, lack of technical expertise, inadequate funding and lack of technological infrastructure. Several recommendations are made to enhance preservation of digital records, including increasing awareness and the implementation of metadata systems, schemas and policies.},
	language = {en},
	urldate = {2023-06-22},
	journal = {Journal of the South African Society of Archivists},
	author = {Masenya, Tlou Maggie},
	month = nov,
	year = {2021},
	keywords = {metadata, digital preservation, cultural heritage institutions, digital records, digitisation},
	pages = {55--70},
	file = {Full Text PDF:files/7572/Masenya - 2021 - The use of metadata systems for the preservation o.pdf:application/pdf},
}

@article{formenton_metadata_2023,
	title = {Metadata standards in web archiving technological resources for ensuring the digital preservation of archived websites{\textless}sup/{\textgreater}},
	volume = {20},
	issn = {1678-765X, 1678-765X},
	url = {https://www.scielo.br/j/rdbci/a/vGFMKmfHBFcxYthcsPy4f7v/?lang=en},
	abstract = {RESUMO Introdução: A preservação digital no arquivamento da Web só será possível com o uso efetivo de padrões de metadados, pois são eles que determinaram a persistência, a coerência, a compreensibilidade, o acesso e a representação de sites selecionados, coletados e armazenados em arquivos da Web, além de definirem a arquivabilidade de sites e a interoperabilidade entre sistemas. Objetivo: Neste contexto, foi objetivo do artigo identificar e definir quais padrões de metadados poderiam ser julgados por instituições de memória e por universidades para que estas pudessem atender à preservação digital em arquivos da Web. Metodologia: Para isto, fez-se uma pesquisa qualitativa, exploratória e descritiva, que usa o método bibliográfico a partir de levantamento assistemático e de revisão e análise de conteúdo da literatura. Foram selecionados e analisados os padrões Dublin Core, MODS, EAD, VRA Core, PREMIS e METS. Resultados e Conclusão: A análise dos resultados aponta que Dublin Core, MODS, EAD e VRA Core amparam METS e PREMIS na descoberta e na documentação de aspectos técnicos dos sites e na comprovação de sua autenticidade, de seu contexto e de sua proveniência. O METS pode gerir sites arquivados, atuando como pacotes de informação OAIS, sendo que o Dublin Core mostrou ser um expoente para arquivamento da Web por seu uso em iniciativas notáveis da área.},
	language = {en},
	urldate = {2023-06-22},
	journal = {RDBCI: Revista Digital de Biblioteconomia e Ciência da Informação},
	author = {Formenton, Danilo and Gracioso, Luciana de Souza},
	month = jan,
	year = {2023},
	note = {Publisher: Universidade Estadual de Campinas},
	keywords = {Digital preservation, Information Science., Metadata standards, Preservation metadata, Web archiving},
	pages = {e022001},
	file = {Full Text PDF:files/7574/Formenton e Gracioso - 2023 - Metadata standards in web archiving technological .pdf:application/pdf},
}

@inproceedings{xie_using_2019,
	title = {Using {Format} {Migration} and {Preservation} {Metadata} to {Support} {Digital} {Preservation} of {Scientific} {Data}},
	doi = {10.1109/ICSESS47205.2019.9040683},
	abstract = {With the development of e-Science and data intensive scientific discovery, it needs to ensure scientific data available for the long-term, with the goal that the valuable scientific data should be discovered and re-used for downstream investigations, either alone, or in combination with newly generated data. As such, the preservation of scientific data enables that not only might experiment be reproducible and verifiable, but also new questions can be raised by other scientists to promote research and innovation. In this paper, we focus on the two main problems of digital preservation that are format migration and preservation metadata. Format migration includes both format verification and object transformation. The system architecture of format migration and preservation metadata is presented, mapping rules of object transformation are analyzed, data fixity and integrity and authenticity, digital signature and so on are discussed and an example is shown in detail.},
	booktitle = {2019 {IEEE} 10th {International} {Conference} on {Software} {Engineering} and {Service} {Science} ({ICSESS})},
	author = {Xie, JiaJun and Zhang, Min and Ma, YongQi},
	month = oct,
	year = {2019},
	note = {ISSN: 2327-0594},
	keywords = {Metadata, digital preservation, Digital preservation, Chemicals, format migration, Grammar, PREMIS, preservation metadata, Software, Systems architecture},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:files/7577/9040683.html:text/html;IEEE Xplore Full Text PDF:files/7576/Xie et al. - 2019 - Using Format Migration and Preservation Metadata t.pdf:application/pdf},
}

@misc{wilson_information_2013,
	title = {Information {Management} for {Researchers} - {Organising} {Humanities} {Material} ({Oxford})},
	url = {https://zenodo.org/record/28329},
	abstract = {Research information management: Organising humanities material Authors: Sudamih Project, Oxford University Computing Services  Created: 1 January 2011, by Sudamih Project, Oxford University Computing Services Research Information Management: Organising Humanities Material is a course for humanities researchers (including graduate students), designed to occupy about half a day. Included are a course book, a set of sample files for use during course exercises, and a slideshow for classroom use (the course book and exercise files can also be used for individual study). Topics covered include: identifying your working style; organising paper and electronic material; file and folder structures; tagging vs. hierarchical filing; retrieving information; and linking notes and sources. These course materials are part of a set of resources created by the JISC Managing Research Data programme-funded Sudamih Project at Oxford University Computing Services in 2011. Published: 29 July 2013, by University of Oxford Keywords: research skills, study skills, software tools, linking information, information retrieval, tag-based filing, hierarchical filing, file structures, folder structures, organisation, organising research material, organising research information, personal information managment, research data management, research data, researchers, research  Licence: Attribution-NonCommercial-ShareAlike 3.0 Unported},
	urldate = {2023-07-15},
	author = {Wilson, James and Patrick, Meriel},
	month = jul,
	year = {2013},
	doi = {10.5281/zenodo.28329},
	keywords = {information management, postgraduate research skills, research data management, research skills, self study materials, workshop materials},
	file = {Zenodo Snapshot:files/7579/28329.html:text/html},
}

@misc{toth-czifra_creating_2021,
	title = {Creating and analyzing multilingual parliamentary corpora},
	url = {https://shs.hal.science/halshs-03366486},
	abstract = {In this resource, you can follow a step-by-step description of a research data workflow involving the annotation of multilingual parliamentary corpora (French, German, British) according to the guidelines of the Text Encoding Initiative (TEI). Read further if you are interested in working with the TEI, analyzing parliamentary corpora, or simply would like to see a validated example of how FAIR and open data is implemented in the context of a PhD dissertation in Corpus Linguistics.},
	language = {en},
	urldate = {2023-07-15},
	author = {Tóth-Czifra, Erzsébet and Truan, Naomi},
	year = {2021},
	file = {Full Text PDF:files/7581/Tóth-Czifra e Truan - 2021 - Creating and analyzing multilingual parliamentary .pdf:application/pdf},
}

@article{corcho_associate_professor_ontology_2015,
	title = {Ontology engineering in the era of linked data},
	volume = {41},
	copyright = {Copyright © 2015 American Society for Information Science and Technology},
	issn = {2373-9223},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bult.2015.1720410407},
	doi = {10.1002/bult.2015.1720410407},
	abstract = {EDITOR'S SUMMARY Ontology engineering encompasses the method, tools and techniques used to develop ontologies. Without requiring ontologies, linked data is driving a paradigm shift, bringing benefits and drawbacks to the publishing world. Ontologies may be heavyweight, supporting deep understanding of a domain, or lightweight, suited to simple classification of concepts and more adaptable for linked data. They also vary in domain specificity, usability and reusabilty. Hybrid vocabularies drawing elements from diverse sources often suffer from internally incompatible semantics. To serve linked data purposes, ontology engineering teams require a range of skills in philosophy, computer science, web development, librarianship and domain expertise.},
	language = {en},
	number = {4},
	urldate = {2023-07-15},
	journal = {Bulletin of the Association for Information Science and Technology},
	author = {Corcho Associate professor, Oscar and Poveda-Villalón Ph.D. student, María and Gómez-Pérez Full professor, Asunción},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bult.2015.1720410407},
	keywords = {ontologies, linked data, index language construction, information reuse, logic, professional competencies},
	pages = {13--17},
	file = {Full Text PDF:files/7583/Corcho Associate professor et al. - 2015 - Ontology engineering in the era of linked data.pdf:application/pdf;Snapshot:files/7584/bult.2015.html:text/html},
}

@inproceedings{pushkarna_data_2022,
	address = {Seoul Republic of Korea},
	title = {Data {Cards}: {Purposeful} and {Transparent} {Dataset} {Documentation} for {Responsible} {AI}},
	isbn = {978-1-4503-9352-2},
	shorttitle = {Data {Cards}},
	url = {https://dl.acm.org/doi/10.1145/3531146.3533231},
	doi = {10.1145/3531146.3533231},
	language = {en},
	urldate = {2023-07-19},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Pushkarna, Mahima and Zaldivar, Andrew and Kjartansson, Oddur},
	month = jun,
	year = {2022},
	pages = {1776--1826},
	file = {Full text:files/7586/Pushkarna et al. - 2022 - Data Cards Purposeful and Transparent Dataset Doc.pdf:application/pdf},
}

@article{jouan_digital_2020-2,
	title = {Digital {Twin}: {Research} {Framework} to {Support} {Preventive} {Conservation} {Policies}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2220-9964},
	shorttitle = {Digital {Twin}},
	url = {https://www.mdpi.com/2220-9964/9/4/228},
	doi = {10.3390/ijgi9040228},
	abstract = {Preventive strategies for the conservation of heritage sites have gradually been preferred to curative approaches because of their ability to maintain their significance. Furthermore, most experts now agree that conservation management of heritage places based on a common understanding of their cultural values is essential to address all the particularities of their contexts. Recently, significant research has demonstrated the potential of Heritage Building Information Modelling (HBIM) for the collaborative data management in conjunction with conservation projects. The recent development of HBIM web platforms illustrates the value of strengthening the link between the digital model and the physical realm of heritage assets. This paper advocates the application of Digital Twin’s (DT) principles, using HBIM models as a digital replica, to support the preventive conservation of heritage places. Based on an extensive literature review, a comprehensive framework that integrates the DT into the management plan process for the preventive conservation of built heritage is proposed. Several recommendations for its implementation are finally discussed, such as the identification of tangible features of significance, the threats associated with their integrity and the corresponding mitigation strategies, with particular emphasis on the value assessment process. The result is a data model for structuring information on preventive conservation strategies. This framework provides the basis for future implementation and demonstrates the need for a DT approach in this context.},
	language = {en},
	number = {4},
	urldate = {2023-07-19},
	journal = {ISPRS International Journal of Geo-Information},
	author = {Jouan, Pierre and Hallot, Pierre},
	month = apr,
	year = {2020},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {HBIM, preventive conservation, Digital Twin, heritage documentation, risk management},
	pages = {228},
	file = {Full Text PDF:files/7588/Jouan e Hallot - 2020 - Digital Twin Research Framework to Support Preven.pdf:application/pdf},
}

@article{pasqui_look_2022,
	title = {A look at metadata processing beyond {Libraries}},
	volume = {13},
	copyright = {Copyright (c) 2022 Valdo Pasqui},
	issn = {2038-1026},
	url = {https://www.jlis.it/index.php/jlis/article/view/492},
	doi = {10.36253/jlis.it-492},
	abstract = {Since many years libraries, archives and museums, the institutions entrusted with the dissemination and conservation of cultural heritage, contributed to metada standards definition, meta-dating methodologies and metadata representation in different syntaxes, by partecipating to national projects and international initiatives.Management systems and catalogs used in these contexts borrow from information and telecommunication technology tools, metodoligies and techniques to generate, organize, share and use various types of metadata. But the Information and Communication Technology (ICT) area is not only a supplier of technological tools and solutions as it also constitutes a rich basin in which metadata plays a fundamental role in designing architectures, modeling information systems and implementing services.Through an overview that includes national and European initiatives, especially in the digital transformation process of the public sector, this paper aims to offer a look to metadata beyond the traditional boundary of libraries and other cultural institutions and to underline some relevant aspects such as standardization, sharing, reuse and metadata quality assessment.This framework highlights the need to carry on with the path of cooperation between different functional domains and organizational contexts in order to consolidate and extend the (re)use of metadata schemes, ontologies and controlled vocabularies both in the redesign of digitized processes and in the implementation of services supporting them.  By undertaking  since design early stages a multidisciplinary approach based on metadata standards can ensure greater flexibility and higher interoperability. This vision requires the enhancement of intersectorial skills that meld metadata methodologies and syntaxes representation basic knowledge  with the ability to model functional domains using metadata schemes and ontologies.},
	language = {en},
	number = {3},
	urldate = {2023-07-26},
	journal = {JLIS.it},
	author = {Pasqui, Valdo},
	month = sep,
	year = {2022},
	note = {Number: 3},
	keywords = {Interoperability, Ontologies, Metadata, API, Controlled vocabularies, Open Data, Web Services},
	pages = {29--48},
	file = {Full Text PDF:files/7590/Pasqui - 2022 - A look at metadata processing beyond Libraries.pdf:application/pdf},
}

@article{ravankhah_multi-hazard_2020,
	title = {A {Multi}-{Hazard} {Platform} for {Cultural} {Heritage} at {Risk}: {The} {STORM} {Risk} {Assessment} and {Management} {Tool}},
	volume = {949},
	issn = {1757-899X},
	shorttitle = {A {Multi}-{Hazard} {Platform} for {Cultural} {Heritage} at {Risk}},
	url = {https://dx.doi.org/10.1088/1757-899X/949/1/012111},
	doi = {10.1088/1757-899X/949/1/012111},
	abstract = {In response to the adverse effects of natural hazards and climate change threats on cultural heritage, a methodology of risk assessment and management was developed and applied to five pilot sites: the Historical Centre of Rethymno in Greece, the Mellor Heritage Project in the United Kingdom, the Roman Ruins of Tróia in Portugal, the Baths of Diocletian in Italy, and the Ancient City of Ephesus in Turkey. According to the methodology, a practical and easy-to-use tool was implemented to help the end-users in managing the impacts of natural hazards and climate change on their cultural heritage sites. The tool comprises three major phases: Site Hazard Assessment, Risk Assessment, and Risk Management Strategies. It assists site managers and experts to identify sudden- and slow-onset natural hazards and climate change threats and to assess their corresponding risks to different areas of the pilot sites. The tool is linked to a web-GIS service, which is capable of providing hazard and risk information and maps for each pilot site. The module Risk Management Strategies enables the user to define risk treatment strategies and associated measures in response to each hazard. Overall, the tool facilitates a shared understanding of the risk data and maps among the multiple stakeholders engaged in the protection of cultural heritage sites to enable a more effective decision-making process.},
	language = {en},
	number = {1},
	urldate = {2023-07-31},
	journal = {IOP Conference Series: Materials Science and Engineering},
	author = {Ravankhah, M. and Chliaoutakis, A. and Revez, M. J. and Wit, R. de and Argyriou, A. V. and Anwar, A. and Heeley, J. and Birkmann, J. and Sarris, A. and Žuvela-Aloise, M.},
	month = nov,
	year = {2020},
	note = {Publisher: IOP Publishing},
	pages = {012111},
	file = {IOP Full Text PDF:files/7594/Ravankhah et al. - 2020 - A Multi-Hazard Platform for Cultural Heritage at R.pdf:application/pdf},
}

@inproceedings{doulgerakis_estia_2021-1,
	title = {{ESTIA}: {Disaster} {Management} {Platform} for {Cultural} {Heritage} {Sites}},
	shorttitle = {{ESTIA}},
	url = {https://link.springer.com/chapter/10.1007/978-3-030-73043-7_39},
	doi = {10.1007/978-3-030-73043-7_39},
	abstract = {ESTIA is a research and innovation project that aspires to develop a comprehensive platform allowing the forecast, detection and management of incidents that are related with the risk of structural fires within Cultural Heritage (CH) settlements and sites. ESTIA aims...},
	language = {en},
	urldate = {2023-07-31},
	booktitle = {Digital {Heritage}. {Progress} in {Cultural} {Heritage}: {Documentation}, {Preservation}, and {Protection}},
	publisher = {Springer, Cham},
	author = {Doulgerakis, Adam and Kanellos, Anastasios and Thomopoulos, Stelios C. A. and Ioannakis, George Alexios and Arnaoutoglou, Fotios and Pistofidis, Petros and Koutsoudis, Anestis and Pappou, Theodora and Protopsaltis, Byron and Gkouskos, Stelios},
	year = {2021},
	pages = {474--481},
	file = {Full Text PDF:files/7596/Doulgerakis et al. - 2021 - ESTIA Disaster Management Platform for Cultural H.pdf:application/pdf},
}

@article{moreno_art-risk_2022,
	title = {{ART}-{RISK} 3.0 a fuzzy—based platform that combine {GIS} and expert assessments for conservation strategies in cultural heritage},
	volume = {55},
	issn = {1296-2074},
	url = {https://www.sciencedirect.com/science/article/pii/S1296207422000632},
	doi = {10.1016/j.culher.2022.03.012},
	abstract = {Heritage preservation poses numerous difficulties, especially in emergency situations or during budget cuts. In these contexts, having tools that facilitate efficient and rapid management of hazards-vulnerabilities is a priority for the preventive conservation and triage of cultural assets. This paper presents the first (to the authors' knowledge) free and public availability Artificial Intelligence platform designed for conservation strategies in cultural heritage. Art-Risk 3.0 is a platform designed as a fuzzy-logic inference system that combines information from geographical information system maps with expert assessments, in order to identify the contextual threat level and the degree of vulnerability that heritage buildings present. Thanks to the possibilities that the geographic information system offers, 12 Spanish churches (11th - 16th centuries) were analyzed. The artificial intelligence platform developed makes it possible to analyze the index of hazard, vulnerability and functionality, classify buildings according to the risk in order to do a sustainable use of budgets through the rational management of preventive conservation. The data stored in the system allows identify the danger due to geotechnics, precipitation, torrential downpour, thermal oscillation, frost, earthquake and flooding. Through the use of fuzzy logic, the tool interrelates environmental conditions with 14 other variables related to structural risks and the vulnerability of buildings, which are evaluated through bibliographic search and review of photographic images. The geographic information system has identified torrential rains and thermal oscillations as the environmental threats that mostly impact heritage buildings in Spain. The results obtained highlight the Church of Santiago de Jesús as the most vulnerable building due to a lack of preventive conservation programs. These results, consistent with the inclusion of this monument on the list of heritage at risk defined by Hispania Nostra, corroborate the functionality of the model.},
	language = {en},
	urldate = {2023-07-31},
	journal = {Journal of Cultural Heritage},
	author = {Moreno, M. and Ortiz, R. and Cagigas-Muñiz, D. and Becerra, J. and Martin, J. M. and Prieto, A. J. and Garrido-Vizuete, M. A. and Macías-Bernal, J. M. and Chávez, M. J. and Ortiz, P.},
	month = may,
	year = {2022},
	keywords = {Artificial intelligence, Functional life, GIS and vulnerability, Hazards},
	pages = {263--276},
	file = {Full text:files/7599/Moreno et al. - 2022 - ART-RISK 3.0 a fuzzy—based platform that combine G.pdf:application/pdf;ScienceDirect Snapshot:files/7598/S1296207422000632.html:text/html},
}

@article{raco_integrated_2022,
	title = {{INTEGRATED} {DIGITAL} {PLATFORMS} {FOR} {THE} {DOCUMENTATION} {AND} {MANAGEMENT} {OF} {CULTURAL} {HERITAGE} {AT} {RISK}},
	volume = {XLVIII-3-W1-2022},
	issn = {1682-1750},
	url = {https://isprs-archives.copernicus.org/articles/XLVIII-3-W1-2022/45/2022/isprs-archives-XLVIII-3-W1-2022-45-2022.html},
	doi = {10.5194/isprs-archives-XLVIII-3-W1-2022-45-2022},
	abstract = {Research definition of strategies and instruments for the prevention, mitigation, and management of hazards resulting from natural or man-made catastrophes is increasingly experimenting with an integrated approach to the digital documentation and visualisation of the built and cultural heritage. In actuality, recent conflicts and events, as well as the rise in natural disasters in previously unaffected regions, demonstrate the growing interest of governments, public administrations and entities, as well as academics, in the development and preservation of the digital memory of man-made landscapes. However, the management of recent catastrophic events allowed for the development of techniques that today enable the transfer of tools and processes from emergency management to routine management.

Based on data from recent earthquakes in northern Italy, the current work describes some outcomes of the development of an integrated digital platform for seismic risk management that aims to integrate historical data from previous seismic events, data from existing databases, integrated digital surveys, carried out using integrated survey techniques, and semantically enhanced BIM-based models. The tool is being created as part of a transnational research cooperation initiative with thirteen partners from nations and regions along the Adriatic Sea. The program's overall goal is to improve cross-border emergency services while also raising their degree of safety and efficacy.},
	language = {English},
	urldate = {2023-07-31},
	journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Raco, F.},
	month = oct,
	year = {2022},
	note = {Conference Name: ISPRS TC III \& TC IV{\textless}br{\textgreater}14th GeoInformation for Disaster Management (Gi4DM 2022) - 1\&ndash;4 November 2022, Beijing, China
Publisher: Copernicus GmbH},
	keywords = {Cultural Heritage at risk, Digital documentation, Digital platform, Integrated 3D survey, Seismic risk},
	pages = {45--52},
	file = {Full Text PDF:files/7601/Raco - 2022 - INTEGRATED DIGITAL PLATFORMS FOR THE DOCUMENTATION.pdf:application/pdf},
}

@inproceedings{doulgerakis_estia_2022,
	title = {{ESTIA}: a versatile platform for effective fire disaster management in cultural heritage sites and settlements},
	volume = {12122},
	shorttitle = {{ESTIA}},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12122/121220P/ESTIA--a-versatile-platform-for-effective-fire-disaster-management/10.1117/12.2624639.full},
	doi = {10.1117/12.2624639},
	abstract = {Developed within the framework of the ESTIA research and innovation project, the ESTIA platform is a versatile technological solution that allows the prediction, detection and management of incidents that are related with the risk of structural fires within cultural heritage (CH) settlements and sites. The ESTIA platform is a distributed system that consists of collaborating autonomous subsystems, ensuring a broad range of applications through the platform’s potential to adapt to each deployment’s specific needs and according to the requirements of the targeted end-users. {\textless}br/{\textgreater} {\textless}br/{\textgreater} By incorporating advanced procedures for the semi-automatic digitization of the CH built environment as well as an advanced system that simulates the development of the complex phenomena of fire propagation and human crowd behaviour, the platform is an effective tool assisting competent authorities in assessing the fire-related risks and offering training to first responders and field officers. Additionally, the platform offers an effective fire incident management system that includes fire-detection capabilities and a specialised decision support system, enhancing authorities during the management of a developing fire incident. {\textless}br/{\textgreater} {\textless}br/{\textgreater} The validation of the ESTIA solution against the requirements of its distinct use cases was performed including the use of the platform as a simulation-based fire risk assessment tool. Subsequently, an exploratory risk assessment study was conducted aiming to establish and demonstrate a methodology for performing risk assessment studies using the provided technological solution. {\textless}br/{\textgreater} {\textless}br/{\textgreater} This paper presents (i) the use of the ESTIA platform as a tool for the conduction of simulation-based assessment of risk related to fire incidents within a CH environment, (ii) the methodology for the technological validation of the ESTIA platform as a simulation-based fire risk assessment tool and (iii) the methodology for the conduction of the exploratory risk assessment study in the historical center of Xanthi (Greece).},
	urldate = {2023-07-31},
	booktitle = {Signal {Processing}, {Sensor}/{Information} {Fusion}, and {Target} {Recognition} {XXXI}},
	publisher = {SPIE},
	author = {Doulgerakis, Adam and Kanellos, Tassos and Kyriakopoulos, Christos and Thomopoulos, Stelios C. A.},
	month = jun,
	year = {2022},
	pages = {188--203},
}

@article{lee_context-aware_2019,
	title = {Context-aware risk management for architectural heritage using historic building information modeling and virtual reality},
	volume = {38},
	issn = {1296-2074},
	url = {https://www.sciencedirect.com/science/article/pii/S1296207418304692},
	doi = {10.1016/j.culher.2018.12.010},
	abstract = {This research proposes a data structure for context-aware risk management for architectural heritage using Historic Building Information Modeling (HBIM) and Virtual Reality (VR). In cultural heritage domain, risk management plays a key role in the preservation and intervention of the heritage. For effective risk management, it is important to share enriched data between people who monitor and diagnose heritages and people who recognize the context of information. The 5W1H (what, when, where, who, why, and how) model-based metadata structure for context-awareness and the framework for linking the HBIM with VR environment which enables sharing and retrieving of risk management information are proposed in this research. Two prototypes were created; an on-site VR application for the heritage managers and a remote VR application for the conservators. The effectiveness of the applications was verified through an experiment including a user survey to compare the paper-based and the VR-based methods regarding on-site VR application, and a focus-group interview regarding the remote VR application. This study enabled to integrate risk management information scattered across a variety of sources and formats, provide contextualized information. Thereby it shortens the time and effort spent to find and share information by heritage managers and conservators.},
	language = {en},
	urldate = {2023-07-31},
	journal = {Journal of Cultural Heritage},
	author = {Lee, Jongwook and Kim, Junki and Ahn, Jaehong and Woo, Woontack},
	month = jul,
	year = {2019},
	keywords = {HBIM, Architectural heritage, Risk management, Virtual reality, Context-awareness},
	pages = {242--252},
	file = {ScienceDirect Snapshot:files/7606/S1296207418304692.html:text/html},
}

@misc{grabus_temporal_2022,
	title = {Temporal {Concept} {Drift} and {Alignment}: {An} empirical approach to comparing {Knowledge} {Organization} {Systems} over time},
	shorttitle = {Temporal {Concept} {Drift} and {Alignment}},
	url = {http://arxiv.org/abs/2208.07835},
	doi = {10.48550/arXiv.2208.07835},
	abstract = {This research explores temporal concept drift and temporal alignment in knowledge organization systems (KOS). A comparative analysis is pursued using the 1910 Library of Congress Subject Headings, 2020 FAST Topical, and automatic indexing. The use case involves a sample of 90 nineteenth-century Encyclopedia Britannica entries. The entries were indexed using two approaches: 1) full-text indexing; 2) Named Entity Recognition was performed upon the entries with Stanza, Stanford's NLP toolkit, and entities were automatically indexed with the Helping Interdisciplinary Vocabulary application (HIVE), using both 1910 LCSH and FAST Topical. The analysis focused on three goals: 1) identifying results that were exclusive to the 1910 LCSH output; 2) identifying terms in the exclusive set that have been deprecated from the contemporary LCSH, demonstrating temporal concept drift; and 3) exploring the historical significance of these deprecated terms. Results confirm that historical vocabularies can be used to generate anachronistic subject headings representing conceptual drift across time in KOS and historical resources. A methodological contribution is made demonstrating how to study changes in KOS over time and improve the contextualization of historical humanities resources.},
	urldate = {2023-07-31},
	publisher = {arXiv},
	author = {Grabus, Sam and Logan, Peter Melville and Greenberg, Jane},
	month = aug,
	year = {2022},
	note = {arXiv:2208.07835 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:files/7609/Grabus et al. - 2022 - Temporal Concept Drift and Alignment An empirical.pdf:application/pdf;arXiv.org Snapshot:files/7610/2208.html:text/html},
}

@inproceedings{grabus_computational_2021,
	title = {Computational {Curation} and the {Application} of {Large}-{Scale} {Vocabularies}},
	doi = {10.1109/BigData52589.2021.9671611},
	abstract = {Paper presents an exploratory case study comparing stemming and lemmatization results for the automatic application of large-scale controlled vocabularies processed against archival encyclopedia entries. The results report relative recall and precision evaluations across both results. Research shows that while stemming has a higher relative recall, lemmatization results in a higher relevance score and eliminates the over-stemming challenges. Results provide insight into improving automatic curation workflows for archival resources.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Grabus, Sam and Greenberg, Jane},
	month = dec,
	year = {2021},
	keywords = {controlled vocabularies, Vocabulary, automatic curation, Big Data, Conferences, Encyclopedias, lemmatization, natural language processing (NLP), Process control, stemming},
	pages = {2220--2223},
	file = {IEEE Xplore Abstract Record:files/7612/9671611.html:text/html},
}

@article{leipzig_role_2021,
	title = {The role of metadata in reproducible computational research},
	volume = {2},
	issn = {2666-3899},
	url = {https://www.cell.com/patterns/abstract/S2666-3899(21)00170-7},
	doi = {10.1016/j.patter.2021.100322},
	language = {English},
	number = {9},
	urldate = {2023-07-31},
	journal = {Patterns},
	author = {Leipzig, Jeremy and Nüst, Daniel and Hoyt, Charles Tapley and Ram, Karthik and Greenberg, Jane},
	month = sep,
	year = {2021},
	pmid = {34553169},
	note = {Publisher: Elsevier},
	keywords = {ontologies, metadata, FAIR, provenance, containers, notebooks, pipelines, RCR, replicability, reproducibility, reproducible computational research, reproducible research, semantic, software dependencies, workflows},
	file = {Full Text PDF:files/7615/Leipzig et al. - 2021 - The role of metadata in reproducible computational.pdf:application/pdf},
}

@article{huvila_documenting_2021-1,
	title = {Documenting {Information} {Processes} and {Practices}: {Paradata}, {Provenance} {Metadata}, {Life}-{Cycles} and {Pipelines}},
	volume = {58},
	copyright = {84th Annual Meeting of the Association for Information Science \& Technology {\textbar} Oct. 29 – Nov. 3, 2021 {\textbar} Salt Lake City, UT. Author(s) retain copyright, but ASIS\&T receives an exclusive publication license.},
	issn = {2373-9231},
	shorttitle = {Documenting {Information} {Processes} and {Practices}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pra2.509},
	doi = {10.1002/pra2.509},
	abstract = {Processes and practices—and in general, informational doings and their diverse constellations—are pertinent elements of the information landscape. This panel presents research on documentation and description of processes and practices in the information field addressing: 1) how different conceptualisations of processes and practices influence how they emerge as describable entities; 2) what different approaches to document and describe processes and practices exist and have been proposed in information science and technology research; 3) what aspects of processes and practices different documentation approaches capture, make visible and invisible; and 4) what novel insights from the current state-of-the-art research can be drawn to support practitioners in different areas of the information field, including knowledge organisation, information management, information literacy instruction, and development of information systems and services.},
	language = {en},
	number = {1},
	urldate = {2023-07-31},
	journal = {Proceedings of the Association for Information Science and Technology},
	author = {Huvila, Isto and Greenberg, Jane and Sköld, Olle and Thomer, Andrea and Trace, Ciaran and Zhao, Xintong},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pra2.509},
	keywords = {pipelines, paradata, practices, processes, provenance metadata},
	pages = {604--609},
	file = {Snapshot:files/7618/pra2.html:text/html;Versione inviata:files/7617/Huvila et al. - 2021 - Documenting Information Processes and Practices P.pdf:application/pdf},
}

@article{zhao_exploratory_2021,
	title = {An exploratory analysis: extracting materials science knowledge from unstructured scholarly data},
	volume = {39},
	issn = {0264-0473},
	shorttitle = {An exploratory analysis},
	url = {https://doi.org/10.1108/EL-11-2020-0320},
	doi = {10.1108/EL-11-2020-0320},
	abstract = {Purpose The output of academic literature has increased significantly due to digital technology, presenting researchers with a challenge across every discipline, including materials science, as it is impossible to manually read and extract knowledge from millions of published literature. The purpose of this study is to address this challenge by exploring knowledge extraction in materials science, as applied to digital scholarship. An overriding goal is to help inform readers about the status knowledge extraction in materials science. Design/methodology/approach The authors conducted a two-part analysis, comparing knowledge extraction methods applied materials science scholarship, across a sample of 22 articles; followed by a comparison of HIVE-4-MAT, an ontology-based knowledge extraction and MatScholar, a named entity recognition (NER) application. This paper covers contextual background, and a review of three tiers of knowledge extraction (ontology-based, NER and relation extraction), followed by the research goals and approach. Findings The results indicate three key needs for researchers to consider for advancing knowledge extraction: the need for materials science focused corpora; the need for researchers to define the scope of the research being pursued, and the need to understand the tradeoffs among different knowledge extraction methods. This paper also points to future material science research potential with relation extraction and increased availability of ontologies. Originality/value To the best of the authors’ knowledge, there are very few studies examining knowledge extraction in materials science. This work makes an important contribution to this underexplored research area.},
	number = {3},
	urldate = {2023-07-31},
	journal = {The Electronic Library},
	author = {Zhao, Xintong and Greenberg, Jane and Meschke, Vanessa and Toberer, Eric and Hu, Xiaohua},
	month = jan,
	year = {2021},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Knowledge, Ontology, Digital scholarship, Information science, Knowledge extraction, Materials science},
	pages = {469--485},
	file = {Snapshot:files/7620/html.html:text/html},
}

@article{greenberg_building_2023,
	title = {Building {Community} {Consensus} for {Scientific} {Metadata} with {YAMZ}},
	volume = {5},
	issn = {2641-435X},
	url = {https://doi.org/10.1162/dint_a_00211},
	doi = {10.1162/dint_a_00211},
	abstract = {This paper reports on a demonstration of YAMZ (Yet Another Metadata Zoo) as a mechanism for building community consensus around metadata terms. The demonstration is motivated by the complexity of the metadata standards environment and the need for more user-friendly approaches for researchers to achieve vocabulary consensus. The paper reviews a series of metadata standardization challenges, explores crowdsourcing factors that offer possible solutions, and introduces the YAMZ system. A YAMZ demonstration is presented with members of the Toberer materials science laboratory at the Colorado School of Mines, where there is a need to confirm and maintain a shared understanding for the vocabulary supporting research documentation, data management, and their larger metadata infrastructure. The demonstration involves three key steps: 1) Sampling terms for the demonstration, 2) Engaging graduate student researchers in the demonstration, and 3) Reflecting on the demonstration. The results of these steps, including examples of the dialog provenance among lab members and voting, show the ease with YAMZ can facilitate building metadata vocabulary consensus. The conclusion discusses implications and highlights next steps.},
	number = {1},
	urldate = {2023-07-31},
	journal = {Data Intelligence},
	author = {Greenberg, Jane and McClellan, Scott and Rauch, Christopher and Zhao, Xintong and Kelly, Mat and An, Yuan and Kunze, John and Orenstein, Rachel and Porter, Claire and Meschke, Vanessa and Toberer, Eric},
	month = mar,
	year = {2023},
	pages = {242--260},
	file = {Full Text PDF:files/7622/Greenberg et al. - 2023 - Building Community Consensus for Scientific Metada.pdf:application/pdf;Snapshot:files/7623/Building-Community-Consensus-for-Scientific.html:text/html},
}

@incollection{niebling_framework_2021,
	address = {Cham},
	title = {A {Framework} to {Support} {Digital} {Humanities} and {Cultural} {Heritage} {Studies} {Research}},
	volume = {1501},
	isbn = {978-3-030-93185-8 978-3-030-93186-5},
	url = {https://link.springer.com/10.1007/978-3-030-93186-5_11},
	language = {en},
	urldate = {2023-08-03},
	booktitle = {Research and {Education} in {Urban} {History} in the {Age} of {Digital} {Libraries}},
	publisher = {Springer International Publishing},
	author = {Ulutas Aydogan, Selda and Münster, Sander and Girardi, Dino and Palmirani, Monica and Vitali, Fabio},
	editor = {Niebling, Florian and Münster, Sander and Messemer, Heike},
	year = {2021},
	doi = {10.1007/978-3-030-93186-5_11},
	note = {Series Title: Communications in Computer and Information Science},
	pages = {237--267},
	file = {Versione inviata:files/7742/Ulutas Aydogan et al. - 2021 - A Framework to Support Digital Humanities and Cult.pdf:application/pdf},
}

@incollection{noiret_modeling_2022,
	title = {Modeling {Data} {Complexity} in {Public} {History} and {Cultural} {Heritage}},
	isbn = {978-3-11-043029-5},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110430295-041/html},
	urldate = {2023-08-03},
	booktitle = {Handbook of {Digital} {Public} {History}},
	publisher = {De Gruyter},
	author = {Barabucci, Gioele and Tomasi, Francesca and Vitali, Fabio},
	editor = {Noiret, Serge and Tebeau, Mark and Zaagsma, Gerben},
	month = apr,
	year = {2022},
	doi = {10.1515/9783110430295-041},
	pages = {459--474},
}

@article{sovrano_explanatory_2022,
	title = {Explanatory artificial intelligence ({YAI}): human-centered explanations of explainable {AI} and complex data},
	issn = {1384-5810, 1573-756X},
	shorttitle = {Explanatory artificial intelligence ({YAI})},
	url = {https://link.springer.com/10.1007/s10618-022-00872-x},
	doi = {10.1007/s10618-022-00872-x},
	abstract = {Abstract
            
              In this paper we introduce a new class of software tools engaged in delivering successful explanations of complex processes on top of basic Explainable AI (XAI) software systems. These tools, that we call cumulatively Explanatory AI (YAI) systems, enhance the quality of the basic output of a XAI by adopting a user-centred approach to explanation that can cater to the individual needs of the explainees with measurable improvements in usability. Our approach is based on Achinstein’s theory of explanations, where explaining is an illocutionary (i.e., broad yet pertinent and deliberate) act of pragmatically answering a question. Accordingly, user-centrality enters in the equation by considering that the overall amount of information generated by answering all questions can rapidly become overwhelming and that individual users may perceive the need to explore just a few of them. In this paper, we give the theoretical foundations of YAI, formally defining a user-centred explanatory tool and the space of all possible explanations, or
              explanatory space
              , generated by it. To this end, we frame the
              explanatory space
              as an hypergraph of knowledge and we identify a set of heuristics and properties that can help approximating a decomposition of it into a tree-like representation for efficient and user-centred explanation retrieval. Finally, we provide some old and new empirical results to support our theory, showing that explanations are more than textual or visual presentations of the sole information provided by a XAI.},
	language = {en},
	urldate = {2023-08-03},
	journal = {Data Mining and Knowledge Discovery},
	author = {Sovrano, Francesco and Vitali, Fabio},
	month = oct,
	year = {2022},
	file = {Full text:files/7745/Sovrano e Vitali - 2022 - Explanatory artificial intelligence (YAI) human-c.pdf:application/pdf},
}

@incollection{ciula_modelli_2023,
	address = {Rome},
	title = {Modelli, metamodelli e modellizzazione nelle {Digital} {Humanities}},
	isbn = {978-88-290-1843-7},
	booktitle = {Digital {Humanities}},
	publisher = {Carocci Editore},
	author = {Ciula, Arianna and Marras, Cristina},
	editor = {Ciotti, Fabio},
	month = jul,
	year = {2023},
	pages = {51--65},
}

@article{dean-hall_sex_nodate,
	title = {Sex, {Privacy} and {Ontologies}},
	abstract = {Personal proﬁling has long had negative connotations because of its historical association with societal discrimination. Here we re-visit the topic with an ontology driven approach to personal proﬁling that explicitly describes preferences and appearances. We argue that explicit methods are superior to vendor-side inferences and suggest that privacy can be maintained by both exchanging preferences independently from identity and only sharing preferences relevant to the transaction. Furthermore this method is an opportunity for additional sales through the support of anonymous ‘drive by’ shopping that preserve privacy. We close by reviewing the computational advantages of accurate proﬁling and how the ontology can be applied to complex real world situations.},
	language = {en},
	author = {Dean-Hall, Adriel and Warren, Robert},
	file = {Dean-Hall e Warren - Sex, Privacy and Ontologies.pdf:files/7747/Dean-Hall e Warren - Sex, Privacy and Ontologies.pdf:application/pdf},
}

@article{ali_fuzzy_2017,
	title = {A {Fuzzy} {Ontology} and {SVM}–{Based} {Web} {Content} {Classification} {System}},
	volume = {5},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2017.2768564},
	abstract = {The volume of adult content on the world wide web is increasing rapidly. This makes an automatic detection of adult content a more challenging task, when eliminating access to ill-suited websites. Most pornographic webpage-filtering systems are based on n-gram, naïve Bayes, K-nearest neighbor, and keyword-matching mechanisms, which do not provide perfect extraction of useful data from unstructured web content. These systems have no reasoning capability to intelligently filter web content to classify medical webpages from adult content webpages. In addition, it is easy for children to access pornographic webpages due to the freely available adult content on the Internet. It creates a problem for parents wishing to protect their children from such unsuitable content. To solve these problems, this paper presents a support vector machine (SVM) and fuzzy ontology-based semantic knowledge system to systematically filter web content and to identify and block access to pornography. The proposed system classifies URLs into adult URLs and medical URLs by using a blacklist of censored webpages to provide accuracy and speed. The proposed fuzzy ontology then extracts web content to find website type (adult content, normal, and medical) and block pornographic content. In order to examine the efficiency of the proposed system, fuzzy ontology, and intelligent tools are developed using Protégé 5.1 and Java, respectively. Experimental analysis shows that the performance of the proposed system is efficient for automatically detecting and blocking adult content.},
	journal = {IEEE Access},
	author = {Ali, Farman and Khan, Pervez and Riaz, Kashif and Kwak, Daehan and Abuhmed, Tamer and Park, Daeyoung and Kwak, Kyung Sup},
	year = {2017},
	note = {Conference Name: IEEE Access},
	keywords = {Ontologies, Information filters, adult content identification, Data mining, fuzzy ontology, semantic knowledge, Support vector machines, SVM, Uniform resource locators},
	pages = {25781--25797},
	file = {IEEE Xplore Abstract Record:files/7750/8094233.html:text/html;IEEE Xplore Full Text PDF:files/7751/Ali et al. - 2017 - A Fuzzy Ontology and SVM–Based Web Content Classif.pdf:application/pdf},
}

@article{noauthor_41st_2022,
	title = {41st {International} {Conference} on {Conceptual} {Modeling}, {ER} 2022},
	volume = {13607 LNCS},
	issn = {0302-9743},
	abstract = {The proceedings contain 30 papers. The special focus in this conference is on Conceptual Modeling. The topics include: LIREM: A Generic Framework for Effective Online Video Novelty Detection; When IT Service Adoption Meets Behavioral Economics: Addressing Present Bias Challenges; discovery of Spatial Association Rules from Fuzzy Spatial Data; a Comprehensive Approach for the Conceptual Modeling of Genomic Data; A Deep Learning Approach for Ideology Detection and Polarization Analysis Using COVID-19 Tweets; effective Generation of Relational Schema from Multi-Model Data with Reinforcement Learning; ontology-Supported Modeling of Bots in Robotic Process Automation; stra2Bis: A Model-Driven Method for Aligning Business Strategy and Business Processes; online Decision Mining and Monitoring in Process-Aware Information Systems; incorporating Types of Types in Ontology-Driven Conceptual Modeling; OPerA: Object-Centric Performance Analysis; bidirectional Relation Attention for Entity Alignment Based on Graph Convolutional Network; a Behavioural Analysis of Metadata Use in Evaluating the Quality of Repurposed Data; modeling Context for Data Quality Management; a Modeling Rule for Improving the Performance of Graph Models; object Normal Form, Fourth Normal Form and Their Application to Database Security; an Ontology of Security from a Risk Treatment Perspective; Modeling Cybercrime with UFO: An Ontological Analysis of Non-Consensual Pornography Cases; modeling Rates of Change and Aggregations in Runtime Goal Models; trying to Elicit and Assign Goals to the Right Actors; rethinking Model Representation - A Taxonomy of Advanced Information Visualization in Conceptual Modeling; law Modeling for Fairness Requirements Elicitation in Artificial Intelligence Systems; pattern Discovery in Conceptual Models Using Frequent Itemset Mining; legal Power-Subjection Relations: Ontological Analysis and Modeling Pattern; atomically True Ontology Modelling: Residential Buildings; an Ontological Analysis of Digital Technology; “All the Things that Come and Go, Stop and Say Hello": Towards an ontological account of how participants enter and exit events; characterizing Fake News: A Conceptual Modeling-based Approach.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	year = {2022},
	note = {ISBN: 9783031179945},
}

@article{perperis_knowledge_2007,
	title = {A knowledge engineering approach for complex violence identification in movies},
	volume = {247},
	issn = {1571-5736},
	doi = {10.1007/978-0-387-74161-1_39},
	abstract = {Along with the rapid increase of available multimedia data, comes the proliferation of objectionable content such as violence and pornography. We need efficient tools for automatically identifying, classifying and filtering out harmful or undesirable video content for the protection of sensitive user groups (e.g. children). In this paper we present a multimodal approach towards the identification and semantic analysis of violent content in video data. We propose a layered architecture and focus on ontological and knowledge engineering aspects of video analysis. We demonstrate the development of two ontologies defining violent hints hierarchy that low level analysis, in visual and audio modality, respectively should identify. Violence domain ontology, as a reality representation, defines higher-level semantics. Taking under consideration extracted violent hints, spatio-temporal relations and behavior patterns higher-level semantics automatic inference is possible. © 2007 International Federation for Information Processing.},
	language = {English},
	journal = {IFIP International Federation for Information Processing},
	author = {Perperis, T. and Tsekeridou, S.},
	year = {2007},
	note = {ISBN: 9780387741604},
	pages = {357--364},
	file = {Full text:files/7758/Perperis e Tsekeridou - 2007 - A knowledge engineering approach for complex viole.pdf:application/pdf;Snapshot:files/7759/display.html:text/html},
}

@inproceedings{falduti_modeling_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Modeling {Cybercrime} with {UFO}: {An} {Ontological} {Analysis} of {Non}-{Consensual} {Pornography} {Cases}},
	isbn = {978-3-031-17995-2},
	shorttitle = {Modeling {Cybercrime} with {UFO}},
	doi = {10.1007/978-3-031-17995-2_27},
	abstract = {The legal domain has challenging aspects. One is that legislation is written to regulate an unpredictable number of cases and, therefore, the language of the law is made of open texture and ambiguous terms. Another peculiarity is that each country has its own legislation, often using the common legal expressions but with different meanings. This results in difficulty in understanding supranational cases and in the interoperability of knowledge bases as well. For example, cybercrimes, in particular, image-based sexual abuses (also known as “revenge porn” or non-consensual pornography) are on the rise globally. Several countries are responding to this social issue by adopting dedicated regulations. However, these regulations are still fragmented, do not share a common conceptualization. In this work, we face these challenges by proposing the application of an ontology-based conceptual modeling to represent a set of concepts and legal relations in cybercrime law. To evaluate the model built, we analyzed the subdomain of cybercrimes, in particular, cases of non-consensual pornography on digital platforms. The result is a conceptualization capable of being shared with other models, increasing the interoperability and clarity of the meaning of common terms and relations found in the various laws studied.},
	language = {en},
	booktitle = {Conceptual {Modeling}},
	publisher = {Springer International Publishing},
	author = {Falduti, Mattia and Griffo, Cristine},
	editor = {Ralyté, Jolita and Chakravarthy, Sharma and Mohania, Mukesh and Jeusfeld, Manfred A. and Karlapalem, Kamalakar},
	year = {2022},
	keywords = {Cybercrime, Legal knowledge representation, Legal ontology, Non-consensual pornography, UFO-L},
	pages = {380--394},
	file = {Full Text PDF:files/7763/Falduti e Griffo - 2022 - Modeling Cybercrime with UFO An Ontological Analy.pdf:application/pdf},
}

@inproceedings{reiz_ontology_2022,
	address = {Valletta, Malta},
	title = {An {Ontology} for {Ontology} {Metrics}: {Creating} a {Shared} {Understanding} of {Measurable} {Attributes} for {Humans} and {Machines}:},
	isbn = {978-989-758-614-9},
	shorttitle = {An {Ontology} for {Ontology} {Metrics}},
	url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0011551500003335},
	doi = {10.5220/0011551500003335},
	abstract = {Ontology Metrics, NEOntometrics, OntoMetrics, OWL, Ontology Quality.},
	language = {en},
	urldate = {2023-09-11},
	booktitle = {Proceedings of the 14th {International} {Joint} {Conference} on {Knowledge} {Discovery}, {Knowledge} {Engineering} and {Knowledge} {Management}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Reiz, Achim and Sandkuhl, Kurt},
	year = {2022},
	pages = {193--199},
	file = {Reiz e Sandkuhl - 2022 - An Ontology for Ontology Metrics Creating a Share.pdf:files/7764/Reiz e Sandkuhl - 2022 - An Ontology for Ontology Metrics Creating a Share.pdf:application/pdf},
}

@article{hussain_towards_2018,
	title = {Towards ontology-based multilingual {URL} filtering: a big data problem},
	volume = {74},
	issn = {1573-0484},
	shorttitle = {Towards ontology-based multilingual {URL} filtering},
	url = {https://doi.org/10.1007/s11227-018-2338-1},
	doi = {10.1007/s11227-018-2338-1},
	abstract = {Web content filtering is one among many techniques to limit the exposure of selective content on the Internet. It has gotten trivial with time, yet filtering of multilingual web content is still a difficult task, especially while considering big data landscape. The enormity of data increases the challenge of developing an effective content filtering system that can work in real time. There are several systems which can filter the URLs based on artificial intelligence techniques to identify the site with objectionable content. Most of these systems classify the URLs only in the English language. These systems either fail to respond when multilingual URLs are processed, or over-blocking is experienced. This paper introduces a filtering system that can classify multilingual URLs based on predefined criteria for URL, title, and metadata of a web page. Ontological approaches along with local multilingual dictionaries are used as the knowledge base to facilitate the challenging task of blocking URLs not meeting the filtering criteria. The proposed work shows high accuracy in classifying multilingual URLs into two categories, white and black. Evaluation results conducted on a large dataset show that the proposed system achieves promising accuracy, which is on a par with those achieved in state-of-the-art literature on semantic-based URL filtering.},
	language = {en},
	number = {10},
	urldate = {2023-09-11},
	journal = {The Journal of Supercomputing},
	author = {Hussain, Mubashar and Ahmed, Mansoor and Khattak, Hasan Ali and Imran, Muhammad and Khan, Abid and Din, Sadia and Ahmad, Awais and Jeon, Gwanggil and Reddy, Alavalapati Goutham},
	month = oct,
	year = {2018},
	keywords = {Ontology engineering, Big data, Classification, Filtering, Information processing},
	pages = {5003--5021},
	file = {Full Text PDF:files/7767/Hussain et al. - 2018 - Towards ontology-based multilingual URL filtering.pdf:application/pdf},
}

@article{amith_friend_2020,
	title = {Friend of a {Friend} with {Benefits} ontology ({FOAF}+): extending a social network ontology for public health},
	volume = {20},
	issn = {1472-6947},
	shorttitle = {Friend of a {Friend} with {Benefits} ontology ({FOAF}+)},
	url = {https://doi.org/10.1186/s12911-020-01287-8},
	doi = {10.1186/s12911-020-01287-8},
	abstract = {Dyadic-based social networks analyses have been effective in a variety of behavioral- and health-related research areas. We introduce an ontology-driven approach towards social network analysis through encoding social data and inferring new information from the data.},
	number = {10},
	urldate = {2023-09-11},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Amith, Muhammad and Fujimoto, Kayo and Mauldin, Rebecca and Tao, Cui},
	month = dec,
	year = {2020},
	keywords = {Ontology, Disease surveillance, HIV, Public health, Social network analysis},
	pages = {269},
	file = {Full Text PDF:files/7769/Amith et al. - 2020 - Friend of a Friend with Benefits ontology (FOAF+).pdf:application/pdf;Snapshot:files/7770/s12911-020-01287-8.html:text/html},
}

@inproceedings{mika_ontologies_2005,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Ontologies {Are} {Us}: {A} {Unified} {Model} of {Social} {Networks} and {Semantics}},
	isbn = {978-3-540-32082-1},
	shorttitle = {Ontologies {Are} {Us}},
	doi = {10.1007/11574620_38},
	abstract = {In our work we extend the traditional bipartite model of ontologies with the social dimension, leading to a tripartite model of actors, concepts and instances. We demonstrate the application of this representation by showing how community-based semantics emerges from this model through a process of graph transformation. We illustrate ontology emergence by two case studies, an analysis of a large scale folksonomy system and a novel method for the extraction of community-based ontologies from Web pages.},
	language = {en},
	booktitle = {The {Semantic} {Web} – {ISWC} 2005},
	publisher = {Springer},
	author = {Mika, Peter},
	editor = {Gil, Yolanda and Motta, Enrico and Benjamins, V. Richard and Musen, Mark A.},
	year = {2005},
	keywords = {Bipartite Graph, Graph Transformation, Semantic Network, Social Network Analysis, Tripartite Model},
	pages = {522--536},
	file = {Full Text PDF:files/7772/Mika - 2005 - Ontologies Are Us A Unified Model of Social Netwo.pdf:application/pdf},
}

@inproceedings{svatek_knowledge_2004,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Knowledge {Modelling} for {Deductive} {Web} {Mining}},
	isbn = {978-3-540-30202-5},
	doi = {10.1007/978-3-540-30202-5_23},
	abstract = {Knowledge-intensive methods that can altogether be characterised as deductive web mining (DWM) already act as supporting technology for building the semantic web. Reusable knowledge-level descriptions may further ease the deployment of DWM tools. We developed a multi-dimensional, ontology-based framework, and a collection of problem-solving methods, which enable to characterise DWM applications at an abstract level. We show that the heterogeneity and unboundedness of the web demands for some modifications of the problem-solving method paradigm used in the context of traditional artificial intelligence.},
	language = {en},
	booktitle = {Engineering {Knowledge} in the {Age} of the {Semantic} {Web}},
	publisher = {Springer},
	author = {Svátek, Vojtěch and Labský, Martin and Vacura, Miroslav},
	editor = {Motta, Enrico and Shadbolt, Nigel R. and Stutt, Arthur and Gibbins, Nick},
	year = {2004},
	keywords = {Class Constraint, Direct Retrieval, Image Gallery, Knowledge Modelling, Structural Extraction},
	pages = {337--353},
	file = {Full Text PDF:files/7774/Svátek et al. - 2004 - Knowledge Modelling for Deductive Web Mining.pdf:application/pdf},
}

@inproceedings{karamizadeh_methods_2018,
	address = {New York, NY, USA},
	series = {{ICCMS} '18},
	title = {Methods of {Pornography} {Detection}: {Review}},
	isbn = {978-1-4503-6339-6},
	shorttitle = {Methods of {Pornography} {Detection}},
	url = {https://dl.acm.org/doi/10.1145/3177457.3177484},
	doi = {10.1145/3177457.3177484},
	abstract = {In recent years, prone images and other such indecent matter are available on the social media and the Internet for children. Filtering of image porn has become one of the big changes for searches; they are tied to finding methods to filter porn images. Social media network is interested in filter porn images from normal ones. Analysis method uses the bright image to automatically detect and filter images in the media. In this paper, we have reviewed methods such as color based, shape based, local and global feature approach, deep learning and bag-of-words for filtering porn images which include comparing with the advantages and disadvantages.},
	urldate = {2023-09-11},
	booktitle = {Proceedings of the 10th {International} {Conference} on {Computer} {Modeling} and {Simulation}},
	publisher = {Association for Computing Machinery},
	author = {Karamizadeh, Sasan and Arabsorkhi, Abouzar},
	month = jan,
	year = {2018},
	keywords = {Internet, deep learning, color based, filtering, porn image},
	pages = {33--38},
	file = {Full Text PDF:files/7779/Karamizadeh e Arabsorkhi - 2018 - Methods of Pornography Detection Review.pdf:application/pdf},
}

@article{busby_evaluating_2017,
	title = {Evaluating the {Dimensionality} of {Pornography}},
	volume = {46},
	issn = {1573-2800},
	url = {https://doi.org/10.1007/s10508-017-0983-8},
	doi = {10.1007/s10508-017-0983-8},
	abstract = {Pornography may be a construct with a single trait or one with many traits. Research in the past was inconsistent in this regard with most researchers assuming that pornography was unidimensional (with one single trait of pornography). However, the considerable amounts of residual variation found in these studies beyond that explained by the single trait hints at what might be a multidimensional construct (with multiple traits such as sensitization and differentiation). Consequently, in this study, we intended to address the question of whether pornography consisted of a single trait or if it was multidimensional. Using MTurk, 2173 participants from the United States and the Commonwealth of Nations (in which pornography is not strictly illegal) were recruited and asked to rate how pornographic they thought a list of different depictions were. The data were analyzed utilizing the cross-validation procedure in which two subsamples were created from the main sample and one was used to establish the model building and the other to validate the model. Various models, including first-order and higher-order exploratory and confirmatory factor models, were tested. Results indicated that a bi-factor (multidimensional) model generated the best model fit, and that it was most appropriate to consider pornography multidimensional. The final model contained two dimensions (“Sensitization” and “Differentiation”). While sensitization revealed the participants’ general tendency to rate all items to be more or less pornographic, differentiation revealed the participants’ tendency to differentiate highly pornographic items from less pornographic items. Based on the findings of this study, we suggest that future research on the usage and effects of pornography be conducted while taking into consideration the multidimensional nature of pornography.},
	language = {en},
	number = {6},
	urldate = {2023-09-11},
	journal = {Archives of Sexual Behavior},
	author = {Busby, Dean M. and Chiu, Hsin-Yao and Olsen, Joseph A. and Willoughby, Brian J.},
	month = aug,
	year = {2017},
	keywords = {Erotica, Multidimensionality, Pornography, Sexually explicit media},
	pages = {1723--1731},
	file = {Full Text PDF:files/7781/Busby et al. - 2017 - Evaluating the Dimensionality of Pornography.pdf:application/pdf},
}

@article{achich_approach_2020,
	series = {Knowledge-{Based} and {Intelligent} {Information} \& {Engineering} {Systems}: {Proceedings} of the 24th {International} {Conference} {KES2020}},
	title = {Approach to {Reasoning} about {Uncertain} {Temporal} {Data} in {OWL} 2},
	volume = {176},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S187705092032010X},
	doi = {10.1016/j.procs.2020.09.110},
	abstract = {In this paper, we propose an ontology-based approach for representing and reasoning about certain and uncertain temporal data. It handles temporal data in terms of quantitative time intervals and points and the qualitative relations between them (e.g., “before”). It includes three parts. (1) We extend the 4D-fluents approach with certain ontological components to represent the handled temporal data in OWL 2. (2) We extend the Allen’s interval algebra to reason about certain and uncertain time intervals. We adapt these relations to allow relating a time interval and a time point, and two time points. All relations can be used for temporal reasoning by means of transitivity tables. (3) The extended Allen’s algebra instantiates the 4D-fluents-based representation. Inferences are based on SWRL rules. Based on this ontology, a prototype is implemented and integrated into an ontology-based memory prosthesis for Alzheimer’s patients to handle certain and uncertain temporal data inputs.},
	urldate = {2023-09-13},
	journal = {Procedia Computer Science},
	author = {Achich, Nassira and Ghorbel, Fatma and Hamdi, Fayçal and Métais, Elisabeth and Gargouri, Faiez},
	month = jan,
	year = {2020},
	keywords = {4D-Fluents Approach, Allen’s Interval Algebra, Certain Ontology, Certain Temporal Data, Temporal Reasoning, Temporal Representation, Uncertain Temporal Data},
	pages = {1141--1150},
	file = {ScienceDirect Full Text PDF:files/7784/Achich et al. - 2020 - Approach to Reasoning about Uncertain Temporal Dat.pdf:application/pdf;ScienceDirect Snapshot:files/7785/S187705092032010X.html:text/html},
}

@article{de_waard_formalising_nodate,
	title = {Formalising {Uncertainty}: {An} {Ontology} of {Reasoning}, {Certainty} and {Attribution} ({ORCA})},
	abstract = {To enable better representations of biomedical argumentation over collections of research papers, we propose a model and a lightweight ontology to represent interpersonal, discourse-based, data-driven reasoning. This model is applied to a collection of scientiﬁc documents, to show how it can be applied in practice. We present three biomedical applications for this work, and suggest connections with other, existing, ontologies and reasoning tools. Speciﬁcally, this model offers a lightweight way to connect nanopublication-like formal representations to scientiﬁc papers written in natural language.},
	language = {en},
	author = {de Waard, Anita and Schneider, Jodi},
	file = {de Waard e Schneider - Formalising Uncertainty An Ontology of Reasoning,.pdf:files/7786/de Waard e Schneider - Formalising Uncertainty An Ontology of Reasoning,.pdf:application/pdf},
}

@inproceedings{akoka_modeling_2019,
	title = {Modeling {Historical} {Social} {Networks} {Databases}},
	url = {http://hdl.handle.net/10125/59714},
	doi = {10.24251/HICSS.2019.334},
	abstract = {Historical social networks are analyzed using prosopographical methods. Prosopography is a branch of historical research that focuses on the identification of social networks that appear in historical sources. It aims to represent and to interpret historical data, sourced from texts. Conceptual modeling imparts the capability to process these large data sets. This paper outlines a conceptual approach to designing a prosopographical database encompassing uncertainty. Our contribution is threefold: i) a generic certaintybased prosopographical conceptual model; ii) two meta-models with a mapping between them; iii) an illustrative example generating a customized prosopographical relational model. Unlike past approaches, our design process helps us to integrate disparate points of view as expressed in the prosopography community. We apply our approach to the prosopographical database Studium Parisiense dedicated to members of Paris schools and university between the twelfth and sixteenth centuries. This instantiation validates the usefulness of our approach.},
	language = {en},
	urldate = {2023-09-13},
	author = {Akoka, Jacky and Comyn-Wattiau, Isabelle and Lamasse, Stéphane and Du Mouza, Cedric},
	year = {2019},
	file = {Akoka et al. - 2019 - Modeling Historical Social Networks Databases.pdf:files/7788/Akoka et al. - 2019 - Modeling Historical Social Networks Databases.pdf:application/pdf},
}

@inproceedings{bosc_model_2009,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Model} {Based} on {Possibilistic} {Certainty} {Levels} for {Incomplete} {Databases}},
	isbn = {978-3-642-04388-8},
	doi = {10.1007/978-3-642-04388-8_8},
	abstract = {This paper deals with the modeling and querying of a database containing uncertain attribute values, in the situation where some knowledge is available about the more or less certain value (or disjunction of values) that a given attribute in a given tuple can take. This is represented in the setting of possibility theory. A relational database model suited to this context is introduced, and selection, join and union operators of relational algebra are extended so as to handle such relations. It is shown that i) the model in question is a strong representation system for the algebraic operators considered, and that ii) the data complexity associated with the extended operators in this context is the same as in the classical database case, which makes the approach highly scalable. A possibilistic logic encoding of the model is also outlined.},
	language = {en},
	booktitle = {Scalable {Uncertainty} {Management}},
	publisher = {Springer},
	author = {Bosc, Patrick and Pivert, Olivier and Prade, Henri},
	editor = {Godo, Lluís and Pugliese, Andrea},
	year = {2009},
	keywords = {Date Place, Possibilistic Logic, Possibility Distribution, Possibility Theory, Relational Algebra},
	pages = {80--94},
	file = {Full Text PDF:files/7793/Bosc et al. - 2009 - A Model Based on Possibilistic Certainty Levels fo.pdf:application/pdf},
}

@article{liddy_certainty_nodate,
	title = {Certainty {Categorization} {Model}},
	abstract = {We present a theoretical framework and preliminary results for manual categorization of explicit certainty information in 32 English newspaper articles. The explicit certainty markers were identified and categorized according to the four hypothesized dimensions – perspective, focus, timeline, and level of certainty. One hundred twenty one sentences from sample news stories contained a significantly lower frequency of markers per sentence (M=0.46, SD =0.04) than 564 sentences from sample editorials (M=0.6, SD =0.23), p= 0.0056, two-tailed heteroscedastic t-test. Within each dimension, editorials had most numerous markers per sentence in high level of certainty, writer’s point of view, and future and present timeline (0.33, 0.43, 0.24, and 0.22, respectively); news stories – in high and moderate levels, directly involved third party’s point of view, and past timeline (0.19, 0.20, 0.24, and 0.20, respectively). These patterns have practical implications for automation. Further analysis of editorials showed that out of 72 combinations possible under the hypothesized model, the high level of certainty from writer’s perspective expressed abstractly in the present and future time, and expressed factually in the future were very common. Twenty two combinations never occurred; and 35 had ≤ 8 occurrences. This narrows the focus for future linguistic analysis of explicit certainty markers.},
	language = {en},
	author = {Liddy, Elizabeth D and Kando, Noriko and Rubin, Victoria L},
	file = {Liddy et al. - Certainty Categorization Model.pdf:files/7794/Liddy et al. - Certainty Categorization Model.pdf:application/pdf},
}

@inproceedings{da_costa_pr-owl_2008,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{PR}-{OWL}: {A} {Bayesian} {Ontology} {Language} for the {Semantic} {Web}},
	isbn = {978-3-540-89765-1},
	shorttitle = {{PR}-{OWL}},
	doi = {10.1007/978-3-540-89765-1_6},
	abstract = {This paper addresses a major weakness of current technologies for the Semantic Web, namely the lack of a principled means to represent and reason about uncertainty. This not only hinders the realization of the original vision for the Semantic Web, but also creates a barrier to the development of new, powerful features for general knowledge applications that require proper treatment of uncertain phenomena. We present PR-OWL, a probabilistic extension to the OWL web ontology language that allows legacy ontologies to interoperate with newly developed probabilistic ontologies. PR-OWL moves beyond the current limitations of deterministic classical logic to a full first-order probabilistic logic. By providing a principled means of modeling uncertainty in ontologies, PR-OWL can be seen as a supporting tool for many applications that can benefit from probabilistic inference within an ontology language, thus representing an important step toward the W3C’s vision for the Semantic Web. In order to fully present the concepts behind PR-OWL, we also cover Multi-Entity Bayesian Networks (MEBN), the Bayesian first-order logic supporting the language, and UnBBayes-MEBN, an open source GUI and reasoner that implements PR-OWL concepts. Finally, a use case of PR-OWL probabilistic ontologies is illustrated here in order to provide a grasp of the potential of the framework.},
	language = {en},
	booktitle = {Uncertainty {Reasoning} for the {Semantic} {Web} {I}},
	publisher = {Springer},
	author = {da Costa, Paulo Cesar G. and Laskey, Kathryn B. and Laskey, Kenneth J.},
	editor = {da Costa, Paulo Cesar G. and d’Amato, Claudia and Fanizzi, Nicola and Laskey, Kathryn B. and Laskey, Kenneth J. and Lukasiewicz, Thomas and Nickles, Matthias and Pool, Michael},
	year = {2008},
	keywords = {Bayesian Network, Description Logic, Ontology Language, Service Description, Service Orient Architecture},
	pages = {88--107},
	file = {Full Text PDF:files/7797/da Costa et al. - 2008 - PR-OWL A Bayesian Ontology Language for the Seman.pdf:application/pdf},
}

@book{cosic_necessity_2012,
	title = {The necessity of developing a digital evidence ontology},
	author = {Ćosić, Jasmin and Ćosić, Zoran},
	month = jan,
	year = {2012},
	doi = {10.13140/RG.2.1.2803.4640},
	note = {Journal Abbreviation: Proceedings of the 23rd Central European …
Publication Title: Proceedings of the 23rd Central European …},
	file = {Full Text PDF:files/7800/Ćosić e Ćosić - 2012 - The necessity of developing a digital evidence ont.pdf:application/pdf},
}

@article{dosis_semantic_2013,
	series = {17th {International} {Conference} in {Knowledge} {Based} and {Intelligent} {Information} and {Engineering} {Systems} - {KES2013}},
	title = {Semantic {Representation} and {Integration} of {Digital} {Evidence}},
	volume = {22},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050913010077},
	doi = {10.1016/j.procs.2013.09.214},
	abstract = {The ever-increasing complexity and sophistication of computer and network attacks challenge society's dependability on digital infrastructure. Digital investigations recover and reconstruct the digital trails of such events and may employ practices from various subfields (computer, network forensics), each with its own set of techniques and tools. Integration of evidence from heterogeneous sources of data (e.g. disk images, network packet captures, logs) is often a manual and time- consuming process relying significantly on the investigator's expertise. In this paper, we propose and develop an approach, based on the Semantic Web framework, for ontologically representing and integrating digital evidence. The presented approach enhances existing forensic analysis techniques by providing partial and eventually full automation of the investigative process.},
	urldate = {2023-09-13},
	journal = {Procedia Computer Science},
	author = {Dosis, Spyridon and Homem, Irvin and Popov, Oliver},
	month = jan,
	year = {2013},
	keywords = {Ontology, Semantic Web, Digital evidence, Evidence Integration, Knowledge Representation},
	pages = {1266--1275},
	file = {ScienceDirect Snapshot:files/7802/S1877050913010077.html:text/html},
}

@article{brochhausen_adding_2016,
	title = {Adding evidence type representation to {DIDEO}},
	volume = {1747},
	issn = {1613-0073},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7603805/},
	abstract = {In this poster we present novel development and extension of the Drug-drug Interaction and Drug-drug Interaction Evidence Ontology (DIDEO). We demonstrate how reasoning over this extension of DIDEO can a) automatically create a multi-level hierarchy of evidence types from descriptions of the underlying scientific observations and b) automatically subsume individual evidence items under the correct evidence type. Thus DIDEO will enable evidence items added manually by curators to be automatically categorized into a drug-drug interaction framework with precision and minimal effort from curators. As with all previous DIDEO development this extension is consistent with OBO Foundry principles.},
	urldate = {2023-09-13},
	journal = {CEUR workshop proceedings},
	author = {Brochhausen, Mathias and Empey, Philip E. and Schneider, Jodi and Hogan, William R. and Boyce, Richard D.},
	month = aug,
	year = {2016},
	pmid = {33139971},
	pmcid = {PMC7603805},
	pages = {http://ceur--ws.org/Vol--1747/IP02\_ICBO2016.pdf},
	file = {PubMed Central Full Text PDF:files/7805/Brochhausen et al. - 2016 - Adding evidence type representation to DIDEO.pdf:application/pdf},
}

@article{clark_micropublications_2014,
	title = {Micropublications: a semantic model for claims, evidence, arguments and annotations in biomedical communications},
	volume = {5},
	issn = {2041-1480},
	shorttitle = {Micropublications},
	url = {https://doi.org/10.1186/2041-1480-5-28},
	doi = {10.1186/2041-1480-5-28},
	abstract = {Scientific publications are documentary representations of defeasible arguments, supported by data and repeatable methods. They are the essential mediating artifacts in the ecosystem of scientific communications. The institutional “goal” of science is publishing results. The linear document publication format, dating from 1665, has survived transition to the Web.},
	number = {1},
	urldate = {2023-09-13},
	journal = {Journal of Biomedical Semantics},
	author = {Clark, Tim and Ciccarese, Paolo N. and Goble, Carole A.},
	month = jul,
	year = {2014},
	keywords = {Annotation, Argumentation, Data citation, Digital abstract, Methods citation, Nanopublications, Research reproducibility, Scientific discourse, Scientific evidence},
	pages = {28},
	file = {Full Text PDF:files/7807/Clark et al. - 2014 - Micropublications a semantic model for claims, ev.pdf:application/pdf;Snapshot:files/7808/2041-1480-5-28.html:text/html},
}

@article{chibucos_standardized_2014,
	title = {Standardized description of scientific evidence using the {Evidence} {Ontology} ({ECO})},
	volume = {2014},
	issn = {1758-0463},
	url = {https://doi.org/10.1093/database/bau075},
	doi = {10.1093/database/bau075},
	abstract = {The Evidence Ontology (ECO) is a structured, controlled vocabulary for capturing evidence in biological research. ECO includes diverse terms for categorizing evidence that supports annotation assertions including experimental types, computational methods, author statements and curator inferences. Using ECO, annotation assertions can be distinguished according to the evidence they are based on such as those made by curators versus those automatically computed or those made via high-throughput data review versus single test experiments. Originally created for capturing evidence associated with Gene Ontology annotations, ECO is now used in other capacities by many additional annotation resources including UniProt, Mouse Genome Informatics, Saccharomyces Genome Database, PomBase, the Protein Information Resource and others. Information on the development and use of ECO can be found at http://evidenceontology.org . The ontology is freely available under Creative Commons license (CC BY-SA 3.0), and can be downloaded in both Open Biological Ontologies and Web Ontology Language formats at http://code.google.com/p/evidenceontology . Also at this site is a tracker for user submission of term requests and questions. ECO remains under active development in response to user-requested terms and in collaborations with other ontologies and database resources. Database URL: Evidence Ontology Web site: http://evidenceontology.org},
	urldate = {2023-09-13},
	journal = {Database},
	author = {Chibucos, Marcus C. and Mungall, Christopher J. and Balakrishnan, Rama and Christie, Karen R. and Huntley, Rachael P. and White, Owen and Blake, Judith A. and Lewis, Suzanna E. and Giglio, Michelle},
	month = jan,
	year = {2014},
	pages = {bau075},
	file = {Full Text PDF:files/7810/Chibucos et al. - 2014 - Standardized description of scientific evidence us.pdf:application/pdf;Snapshot:files/7811/2634798.html:text/html},
}

@incollection{reed_certainty_2022,
	edition = {Spring 2022},
	title = {Certainty},
	url = {https://plato.stanford.edu/archives/spr2022/entries/certainty/},
	abstract = {Certainty, or the attempt to obtain certainty, has played a centralrole in the history of philosophy. Some philosophers have taken thekind of certainty characteristic of mathematical knowledge to be thegoal at which philosophy should aim. In the Republic,Plato says that geometry “draws the soul towards truth and producesphilosophic thought by directing upwards what we now wrongly directdownwards” (527b). Descartes also thought that a philosophical methodthat proceeds in a mathematical way, enumerating and orderingeverything exactly, “contains everything that gives certainty to therules of mathematics” (Discourse on the Method, PW 1, p.121). Other philosophers have adopted different models for how to bestunderstand certainty. For example, Aristotle and Aquinas takescientific explanation to be essential to certainty (see Pasnau 2017,pp. 5–7), while Al-Ghazālī thought that certaintyarose out of religious practice (see Albertini 2005). For manyempiricists, certainty with respect to empirical matters is to befound in basic beliefs that are grounded in some fundamental aspect ofperceptual experience (see, e.g., Lewis 1952).},
	urldate = {2023-09-15},
	booktitle = {The {Stanford} {Encyclopedia} of {Philosophy}},
	publisher = {Metaphysics Research Lab, Stanford University},
	author = {Reed, Baron},
	editor = {Zalta, Edward N.},
	year = {2022},
	keywords = {epistemology, Descartes, René: epistemology, knowledge: analysis of, knowledge: by acquaintance vs. description},
	file = {SEP - Snapshot:files/7869/certainty.html:text/html},
}

@incollection{kelly_evidence_2016,
	edition = {Winter 2016},
	title = {Evidence},
	url = {https://plato.stanford.edu/archives/win2016/entries/evidence/},
	abstract = {The concept of evidence is central to both epistemology and thephilosophy of science. Of course, ‘evidence’ is hardly aphilosopher's term of art: it is not only, or even primarily,philosophers who routinely speak of evidence, but also lawyers andjudges, historians and scientists, investigative journalists andreporters, as well as the members of numerous other professions andordinary folk in the course of everyday life. The concept of evidencewould thus seem to be on firmer pre-theoretical ground than variousother concepts which enjoy similarly central standing withinphilosophy. (Contrast, for example, the epistemologist'squasi-technical term ‘epistemic justification’.)},
	urldate = {2023-09-15},
	booktitle = {The {Stanford} {Encyclopedia} of {Philosophy}},
	publisher = {Metaphysics Research Lab, Stanford University},
	author = {Kelly, Thomas},
	editor = {Zalta, Edward N.},
	year = {2016},
	keywords = {confirmation, epistemology: Bayesian},
	file = {SEP - Snapshot:files/7871/evidence.html:text/html},
}

@article{kozak_analyzing_2021,
	title = {Analyzing and {Visualizing} {Uncertain} {Knowledge}: {The} {Use} of {TEI} {Annotations} in the {PROVIDEDH} {Open} {Science} {Platform}},
	copyright = {For this publication a Creative Commons Attribution 4.0 International license has been granted by the author(s) who retain full copyright.},
	issn = {2162-5603},
	shorttitle = {Analyzing and {Visualizing} {Uncertain} {Knowledge}},
	url = {https://journals.openedition.org/jtei/4239#tocto1n2},
	doi = {10.4000/jtei.4239},
	abstract = {The underlying uncertainty in digital humanities research data affects decision-making and persists during a project’s lifecycle. This uncertainty is inevitable since most empirical claims cannot be assessed against an absolute truth (Drucker 2011; Binder et al. 2014). This situation has been previously recognized together with the need to report the degrees of uncertainty that accompany such claims (Blau 2011). Although TEI makes it possible to annotate text with notions of certainty or precision, examples of actual projects taking advantage of this are scarce. There are many possible explanations for uncertainty’s lack of visibility in computationally supported humanities research; among them, the need for tools specifically designed to address the goal of defining and managing uncertainty stands out. Thus, efforts to provide technical support for humanities research should focus on managing and making uncertainty more transparent, rather than removing it. Another challenge is the fact that there is no agreement on a generic taxonomy for the different types of uncertainty that researchers may face. Various researchers across disciplines, working on varying projects and data sets, can use different categories to classify the uncertainties present in a particular case.             In this paper, we introduce a collaborative platform for collective annotation of TEI data sets. We briefly present the flexible taxonomy of uncertainty used in the platform and describe two data sets used for its testing. Then we describe use cases of annotations available on the platform, and how they translate into TEI annotations. Creating and interpreting annotations with and without uncertainty should now be easier, especially for researchers who do not know TEI markup.},
	language = {en},
	number = {Issue 14},
	urldate = {2023-09-15},
	journal = {Journal of the Text Encoding Initiative},
	author = {Kozak, Michał and Rodríguez, Alejandro and Benito-Santos, Alejandro and Therón, Roberto and Doran, Michelle and Dorn, Amelie and Edmond, Jennifer and Mazurek, Cezary and Wandl-Vogt, Eveline},
	month = mar,
	year = {2021},
	note = {Number: Issue 14
Publisher: Text Encoding Initiative Consortium},
	keywords = {uncertainty, annotation, visualization, collaborative annotating},
	file = {Full Text PDF:files/7873/Kozak et al. - 2021 - Analyzing and Visualizing Uncertain Knowledge The.pdf:application/pdf},
}

@article{brozek_grade_2021,
	title = {{GRADE} guidelines 30: the {GRADE} approach to assessing the certainty of modeled evidence-an overview in the context of health decision-making},
	volume = {129},
	issn = {0895-4356},
	shorttitle = {{GRADE} guidelines 30},
	doi = {10.1016/j.jclinepi.2020.09.018},
	abstract = {OBJECTIVES: The objective of the study is to present the Grading of Recommendations Assessment, Development, and Evaluation (GRADE) conceptual approach to the assessment of certainty of evidence from modeling studies (i.e., certainty associated with model outputs).STUDY DESIGN AND SETTING: Expert consultations and an international multidisciplinary workshop informed development of a conceptual approach to assessing the certainty of evidence from models within the context of systematic reviews, health technology assessments, and health care decisions. The discussions also clarified selected concepts and terminology used in the GRADE approach and by the modeling community. Feedback from experts in a broad range of modeling and health care disciplines addressed the content validity of the approach.RESULTS: Workshop participants agreed that the domains determining the certainty of evidence previously identified in the GRADE approach (risk of bias, indirectness, inconsistency, imprecision, reporting bias, magnitude of an effect, dose-response relation, and the direction of residual confounding) also apply when assessing the certainty of evidence from models. The assessment depends on the nature of model inputs and the model itself and on whether one is evaluating evidence from a single model or multiple models. We propose a framework for selecting the best available evidence from models: 1) developing de novo, a model specific to the situation of interest, 2) identifying an existing model, the outputs of which provide the highest certainty evidence for the situation of interest, either "off-the-shelf" or after adaptation, and 3) using outputs from multiple models. We also present a summary of preferred terminology to facilitate communication among modeling and health care disciplines.CONCLUSION: This conceptual GRADE approach provides a framework for using evidence from models in health decision-making and the assessment of certainty of evidence from a model or models. The GRADE Working Group and the modeling community are currently developing the detailed methods and related guidance for assessing specific domains determining the certainty of evidence from models across health care-related disciplines (e.g., therapeutic decision-making, toxicology, environmental health, and health economics).},
	journal = {Journal of Clinical Epidemiology},
	author = {Brozek, Jan L. and Canelo-Aybar, Carlos and Akl, Elie A. and Bowen, James M. and Bucher, John and Chiu, Weihsueh A. and Cronin, Mark and Djulbegovic, Benjamin and Falavigna, Maicon and Guyatt, Gordon H. and Gordon, Ami A. and Hilton Boon, Michele and Hutubessy, Raymond C.W. and Joore, Manuela A. and Katikireddi, Vittal and LaKind, Judy and Langendam, Miranda and Manja, Veena and Magnuson, Kristen and Mathioudakis, Alexander G. and Meerpohl, Joerg and Mertz, Dominik and Mezencev, Roman and Morgan, Rebecca and Morgano, Gian Paolo and Mustafa, Reem and O'Flaherty, Martin and Patlewicz, Grace and Riva, John J. and Posso, Margarita and Rooney, Andrew and Schlosser, Paul M. and Schwartz, Lisa and Shemilt, Ian and Tarride, Jean-Eric and Thayer, Kristina A. and Tsaioun, Katya and Vale, Luke and Wambaugh, John and Wignall, Jessica and Williams, Ashley and Xie, Feng and Zhang, Yuan and Schünemann, Holger J. and {GRADE Working Group}},
	month = jan,
	year = {2021},
	keywords = {Guidelines, Certainty of evidence, GRADE, Health care Decision making, Mathematical models, Modelling studies},
	pages = {138--150},
	file = {Versione accettata:files/7876/Brozek et al. - 2021 - GRADE guidelines 30 the GRADE approach to assessi.pdf:application/pdf},
}

@article{gonzalez-blanco_applying_nodate,
	title = {Applying {Ontology} {Engineering} to build a {Poetry} {Domain} {Ontology}.},
	abstract = {The growth of information and communication technologies and the new computational paradigms have fostered an increasingly interdisciplinary approach to research. The idiosyncrasy of literary studies has been an obstacle to its technological improvement for years, especially in representing their knowledge in a machine-readable format. The richness, variety, and different study perspectives that scholars find in their studies make this task a highly complex challenge. This complexity is even more noticed in the poetry genre, where each poetic tradition has independently developed its analytical terminology and methodology. In this work, we have addressed the construction of a poetry ontology to express the scholar´s knowledge spread out in isolated databases or works. Ontopoetry ontology has been developed following NeOn methodology, and it has been structured in three modules: a) Core, b) Poetic Analysis and c) Transmission, covering the essential aspects of a poetry literary study. This paper describes the ontology building process and the design decisions taken during the process focusing on the design of the Core Module, its classes, relationships and proposed controlled vocabularies. Ontopoetry Core Module has reused CIDOCCRM and FRBRoo ontologies guaranteeing its interoperability.},
	language = {en},
	author = {González-Blanco, Elena and Ros, Salvador and Khalil, Omar and Pozo, Alvaro Pérez and de Sisto, Mirella and Hernández, Laura},
	file = {González-Blanco et al. - Applying Ontology Engineering to build a Poetry Do.pdf:files/7943/González-Blanco et al. - Applying Ontology Engineering to build a Poetry Do.pdf:application/pdf},
}

@article{endara_modifier_2018,
	title = {Modifier {Ontologies} for frequency, certainty, degree, and coverage phenotype modifier},
	volume = {6},
	copyright = {2023Lorena Endara, Anne Thessen, Heather Cole, Ramona Walls, Georgios Gkoutos, Yujie Cao, Steven Chong, Hong Cui},
	issn = {1314-2828},
	url = {https://bdj.pensoft.net/article/29232/},
	doi = {10.3897/BDJ.6.e29232},
	abstract = {Background: When phenotypic characters are described in the literature, they may be constrained or clarified with additional information such as the location or degree of expression, these terms are called “modifiers”. With effort underway to convert narrative character descriptions to computable data, ontologies for such modifiers are needed. Such ontologies can also be used to guide term usage in future publications. Spatial and method modifiers are the subjects of ontologies that already have been developed or are under development. In this work, frequency (e.g., rarely, usually), certainty (e.g., probably, definitely), degree (e.g., slightly, extremely), and coverage modifiers (e.g., sparsely, entirely) are collected, reviewed, and used to create two modifier ontologies with different design considerations. The basic goal is to express the sequential relationships within a type of modifiers, for example, usually is more frequent than rarely, in order to allow data annotated with ontology terms to be classified accordingly.
  Method: Two designs are proposed for the ontology, both using the list pattern: a closed ordered list (i.e., five-bin design) and an open ordered list design. The five-bin design puts the modifier terms into a set of 5 fixed bins with interval object properties, for example, one\_level\_more/less\_frequently\_than, where new terms can only be added as synonyms to existing classes. The open list approach starts with 5 bins, but supports the extensibility of the list via ordinal properties, for example, more/less\_frequently\_than, allowing new terms to be inserted as a new class anywhere in the list. The consequences of the different design decisions are discussed in the paper. CharaParser was used to extract modifiers from plant, ant, and other taxonomic descriptions. After a manual screening, 130 modifier words were selected as the candidate terms for the modifier ontologies. Four curators/experts (three biologists and one information scientist specialized in biosemantics) reviewed and categorized the terms into 20 bins using the Ontology Term Organizer (OTO) (http://biosemantics.arizona.edu/OTO). Inter-curator variations were reviewed and expressed in the final ontologies.
  Results: Frequency, certainty, degree, and coverage terms with complete agreement among all curators were used as class labels or exact synonyms. Terms with different interpretations were either excluded or included using “broader synonym” or “not recommended” annotation properties. These annotations explicitly allow for the user to be aware of the semantic ambiguity associated with the terms and whether they should be used with caution or avoided. Expert categorization results showed that 16 out of 20 bins contained terms with full agreements, suggesting differentiating the modifiers into 5 levels/bins balances the need to differentiate modifiers and the need for the ontology to reflect user consensus. Two ontologies, developed using the Protege ontology editor, are made available as OWL files and can be downloaded from https://github.com/biosemantics/ontologies.
  Contribution: We built the first two modifier ontologies following a consensus-based approach with terms commonly used in taxonomic literature. The five-bin ontology has been used in the Explorer of Taxon Concepts web toolkit to compute the similarity between characters extracted from literature to facilitate taxon concepts alignments. The two ontologies will also be used in an ontology-informed authoring tool for taxonomists to facilitate consistency in modifier term usage.},
	language = {en},
	urldate = {2023-09-15},
	journal = {Biodiversity Data Journal},
	author = {Endara, Lorena and Thessen, Anne and Cole, Heather and Walls, Ramona and Gkoutos, Georgios and Cao, Yujie and Chong, Steven and Cui, Hong},
	month = nov,
	year = {2018},
	note = {Publisher: Pensoft Publishers},
	pages = {e29232},
	file = {Full Text PDF:files/7946/Endara et al. - 2018 - Modifier Ontologies for frequency, certainty, degr.pdf:application/pdf},
}

@article{setiawan_ontology-assisted_2021,
	title = {Ontology-{Assisted} {Expert} {System} for {Algae} {Identification} {With} {Certainty} {Factors}},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2021.3123562},
	abstract = {Harmful algal blooms (HABs) are one of nature’s responses to nutrient enrichment in aquatic systems and increasingly occur in coastal waters, such as in Lampung Bay and Jakarta Bay, Indonesia. HABs present environmental and fisheries management challenges due to their unpredictability, spatial coverage, and detrimental health effects on coastal organisms, including humans. Here, an automated algae species identification system assisted and validated by expert judgment was proposed. The system used ontology as guidance to determine the species of algae and certainty factors to indicate the level of confidence of the experts when providing a statement or judgment for a particular object or event under consideration. The system was tested to identify 60 samples using 51 predetermined algal characteristics. The tests were narrowed down to the 20 most common HAB-causing algae types found in the study sites and compared with identification by experts. The results showed that the system successfully identified the test data with an accuracy of 73.33\%. The system also had a high agreement (above 79.75\%) with the identification performed by experts on six algae species. Further improvement of the system’s accuracy could facilitate its use as an alternative tool in rapid algal identification or part of an early warning system for HABs.},
	journal = {IEEE Access},
	author = {Setiawan, Foni A. and Puspasari, Reny and Manik, Lindung P. and Akbar, Zaenal and Kartika, Yulia A. and Satya, Ika A. and Saleh, Dadan R. and Indrawati, Ariani and Suzuki, Keiji and Albasri, Hatim and Wada, Masaaki},
	year = {2021},
	note = {Conference Name: IEEE Access},
	keywords = {ontology, Ontologies, Support vector machines, Algae, algae identification, Aquaculture, certainty factor, expert system, Expert systems, Harmful algal bloom, Sea measurements, Tides},
	pages = {147665--147677},
	file = {IEEE Xplore Abstract Record:files/7949/9591600.html:text/html;IEEE Xplore Full Text PDF:files/7948/Setiawan et al. - 2021 - Ontology-Assisted Expert System for Algae Identifi.pdf:application/pdf},
}

@incollection{journel_modeling_1994,
	address = {Dordrecht},
	series = {Quantitative {Geology} and {Geostatistics}},
	title = {Modeling {Uncertainty}: {Some} {Conceptual} {Thoughts}},
	isbn = {978-94-011-0824-9},
	shorttitle = {Modeling {Uncertainty}},
	url = {https://doi.org/10.1007/978-94-011-0824-9_5},
	abstract = {The place of random experiments and stochastic models in experimental sciences is discussed first. Models of uncertainty are necessarily based on prior decisions about the randomization of either the unknown itself and/or its estimate and, as such, cannot claim to any objectivity. A safeguard for building such models is to charge them maximally with data deemed relevant to the “unknown” at hand.},
	language = {en},
	urldate = {2023-09-15},
	booktitle = {Geostatistics for the {Next} {Century}: {An} {International} {Forum} in {Honour} of {Michel} {David}’s {Contribution} to {Geostatistics}, {Montreal}, 1993},
	publisher = {Springer Netherlands},
	author = {Journel, André G.},
	editor = {Dimitrakopoulos, Roussos},
	year = {1994},
	doi = {10.1007/978-94-011-0824-9_5},
	keywords = {Bayes updating, likelihood functions, non-Gaussian models, random models, sequential simulation, Stochastic simulation},
	pages = {30--43},
}

@article{arceneaux_modeling_2009,
	title = {Modeling {Certainty} with {Clustered} {Data}: {A} {Comparison} of {Methods}},
	volume = {17},
	issn = {1047-1987},
	shorttitle = {Modeling {Certainty} with {Clustered} {Data}},
	url = {https://www.jstor.org/stable/25791967},
	abstract = {Political scientists often analyze data in which the observational units are clustered into politically or socially meaningful groups with an interest in estimating the effects that group-level factors have on individual-level behavior. Even in the presence of low levels of intracluster correlation, it is well known among statisticians that ignoring the clustered nature of such data overstates the precision estimates for group-level effects. Although a number of methods that account for clustering are available, their precision estimates are poorly understood, making it difficult for researchers to choose among approaches. In this paper, we explicate and compare commonly used methods (clustered robust standard errors (SEs), random effects, hierarchical linear model, and aggregated ordinary least squares) of estimating the SEs for group-level effects. We demonstrate analytically and with the help of empirical examples that under ideal conditions there is no meaningful difference in the SEs generated by these methods. We conclude with advice on the ways in which analysts can increase the efficiency of clustered designs.},
	number = {2},
	urldate = {2023-09-15},
	journal = {Political Analysis},
	author = {Arceneaux, Kevin and Nickerson, David W.},
	year = {2009},
	note = {Publisher: [Cambridge University Press, Oxford University Press, Society for Political Methodology]},
	pages = {177--190},
	file = {JSTOR Full Text PDF:files/7952/Arceneaux e Nickerson - 2009 - Modeling Certainty with Clustered Data A Comparis.pdf:application/pdf},
}

@article{karoune_removing_2022-1,
	title = {Removing {Barriers} to {Reproducible} {Research} in {Archaeology}},
	doi = {10.5281/zenodo.7320029},
	abstract = {Reproducible research is being implemented at different speeds in different disciplines, and Archaeology is at the start of this journey. Reproducibility is the practice of reanalysing data by taking the same steps and producing the same or similar results. Enabling reproducibility is an important step to ensure research quality and validate interpretations. There are currently many barriers to moving towards reproducible research such as the skill level of researchers in the practices, software and infrastructure needed to do reproducible research and concerns relating to opening up research such as how to share sensitive data. In this article, we seek to introduce reproducible research in an understandable manner so that archaeologists can learn where and how to start improving the reproducibility of their research. We describe what reproducible archaeological research can look like and propose three different computational skill levels of reproducible workflows with examples. Finally, in an extensive appendix, we address common questions about reproducible research to remove the stigma about these issues and suggest ways to overcome them.},
	journal = {Pci Journal},
	author = {Karoune, Emma and Plomp, Esther},
	month = nov,
	year = {2022},
	file = {Full Text PDF:files/7973/Karoune e Plomp - 2022 - Removing Barriers to Reproducible Research in Arch.pdf:application/pdf},
}

@article{garlick_new_2011,
	title = {A {New} {Sexual} {Revolution}? {Critical} {Theory}, {Pornography}, and the {Internet}},
	volume = {48},
	copyright = {© 2011 Canadian Sociological Association},
	issn = {1755-618X},
	shorttitle = {A {New} {Sexual} {Revolution}?},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1755-618X.2011.01264.x},
	doi = {10.1111/j.1755-618X.2011.01264.x},
	abstract = {La “révolution sexuelle” fut un élément central de la culture nord-américaine durant les années 1960. Aujourd'hui, en grande partie suite à l'avènement de l'Internet, la sexualité occupe un place de plus en plus centrale dans la culture populaire, ce qui pose la question, à savoir si l'on vit présentement une période de l'histoire sexuelle semblable aux années 1960. Au cours de cet article, je discuterai les travaux de Herbert Marcuse, considéré comme le premier à théoriser la révolution sexuelle, afin de mesurer l'ampleur de leur contribution au développement d'une théorie critique de la sexualitéà l'âge numérique. Je rappellerai d'abord les grandes lignes de la théorie Marcusienne du rôle de l'éros dans la vie sociale. Une discussion suivra de deux sites web pornographiques qui combinent érotisme et critique sociale. Le travail de Marcuse prend toute son importance par la façon dont il fait ressortir l'intersection entre le sexe, la technologie et l'économie capitaliste. Cet article vise à compléter ce travail par une analyse de la masculinité et du corps masculin dans la pornographie sur Internet. The “sexual revolution” was a central element of North American culture in the 1960s. Today, sex is increasingly central to mainstream culture, in large part due to the Internet, and we might wonder whether we are living through a comparable period of sexual history. In this article, I revisit the work of Herbert Marcuse—the original theorist of the sexual revolution—to ask whether it can contribute to a critical theory of sexuality in the era of digital technology. After outlining Marcuse's theory of the role of Eros in social life, I discuss two pornographic Web sites that combine eroticism and social critique. I argue that Marcuse's work is valuable for its emphasis on the intersection of sex, technology, and capitalist economy, but that it needs to be supplemented by a focus on masculinity and the male body in Internet pornography.},
	language = {en},
	number = {3},
	urldate = {2023-09-17},
	journal = {Canadian Review of Sociology/Revue canadienne de sociologie},
	author = {Garlick, Steve},
	year = {2011},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1755-618X.2011.01264.x},
	pages = {221--239},
	file = {Full Text PDF:files/8061/Garlick - 2011 - A New Sexual Revolution Critical Theory, Pornogra.pdf:application/pdf;Snapshot:files/8062/j.1755-618X.2011.01264.html:text/html},
}

@article{lacey_theory_1993,
	title = {Theory into {Practice}? {Pornography} and the {Public}/{Private} {Dichotomy}},
	volume = {20},
	issn = {0263-323X},
	shorttitle = {Theory into {Practice}?},
	url = {https://www.jstor.org/stable/1410114},
	doi = {10.2307/1410114},
	number = {1},
	urldate = {2023-09-17},
	journal = {Journal of Law and Society},
	author = {Lacey, Nicola},
	year = {1993},
	note = {Publisher: [Cardiff University, Wiley]},
	pages = {93--113},
	file = {JSTOR Full Text PDF:files/8064/Lacey - 1993 - Theory into Practice Pornography and the PublicP.pdf:application/pdf},
}

@article{ullen_pornography_2009,
	title = {Pornography and its {Critical} {Reception}: {Toward} a {Theory} of {Masturbation}},
	volume = {51, spring 2009},
	shorttitle = {Pornography and its {Critical} {Reception}},
	author = {Ullén, Magnus},
	month = jan,
	year = {2009},
	file = {Full Text PDF:files/8067/Ullén - 2009 - Pornography and its Critical Reception Toward a T.pdf:application/pdf},
}

@article{crawford_toward_2007,
	title = {Toward a {Third}-{Wave} {Feminist} {Legal} {Theory}: {Young} {Women}, {Pornography} and the {Praxis} of {Pleasure}},
	volume = {14},
	shorttitle = {Toward a {Third}-{Wave} {Feminist} {Legal} {Theory}},
	url = {https://heinonline.org/HOL/P?h=hein.journals/mjgl14&i=103},
	language = {eng},
	number = {1},
	urldate = {2023-09-17},
	journal = {Michigan Journal of Gender \& Law},
	author = {Crawford, Bridget J.},
	year = {2007},
	pages = {99--168},
	file = {Full Text PDF:files/8069/Crawford - 2007 - Toward a Third-Wave Feminist Legal Theory Young W.pdf:application/pdf},
}

@incollection{norton_invisible_1999,
	title = {Invisible {Man}: {A} {Queer} {Critique} of {Feminist} {Anti}-{Pornography} {Theory}},
	isbn = {978-1-351-30668-3},
	shorttitle = {Invisible {Man}},
	abstract = {Catharine MacKinnon, Andrea Dworkin, and other anti-pornography “feminists” claim that sexuality in Western societies is constituted as eroticization of dominance and subordination-relations that define masculine and feminine gender roles. MacKinnon’s male dominant/female subordinate model collapses any ambiguity in the power relations between heterosexual partners, and in doing so denies the complexity of subordination itself. There are two central conceptual problems that beset anti-pornography theory of MacKinnon and Dworkin. The first is that typically, in their work, men are treated as Man—with a degree of essentialism no significant feminist thinker would dream of applying to the subject of women. Pornographies are different from each other, too. To lose sight of this fact is to create theoretical confusion. Conceptual inadequacy and political tunnel vision produce rancor and misunderstanding, in readers and audiences, and are therefore counterproductive with respect to the goal of freeing women, men, and trans-people from all forms of sexual and political aggression-forms that notably include aggressively sectarian discourse.},
	booktitle = {Sex {Work} and {Sex} {Workers}},
	publisher = {Routledge},
	author = {Norton, Jody},
	year = {1999},
	note = {Num Pages: 12},
}

@article{kohut_is_2016,
	title = {Is {Pornography} {Really} about “{Making} {Hate} to {Women}”? {Pornography} {Users} {Hold} {More} {Gender} {Egalitarian} {Attitudes} {Than} {Nonusers} in a {Representative} {American} {Sample}},
	volume = {53},
	issn = {0022-4499},
	shorttitle = {Is {Pornography} {Really} about “{Making} {Hate} to {Women}”?},
	url = {https://doi.org/10.1080/00224499.2015.1023427},
	doi = {10.1080/00224499.2015.1023427},
	abstract = {According to radical feminist theory, pornography serves to further the subordination of women by training its users, males and females alike, to view women as little more than sex objects over whom men should have complete control. Composite variables from the General Social Survey were used to test the hypothesis that pornography users would hold attitudes that were more supportive of gender nonegalitarianism than nonusers of pornography. Results did not support hypotheses derived from radical feminist theory. Pornography users held more egalitarian attitudes—toward women in positions of power, toward women working outside the home, and toward abortion—than nonusers of pornography. Further, pornography users and pornography nonusers did not differ significantly in their attitudes toward the traditional family and in their self-identification as feminist. The results of this study suggest that pornography use may not be associated with gender nonegalitarian attitudes in a manner that is consistent with radical feminist theory.},
	number = {1},
	urldate = {2023-09-17},
	journal = {The Journal of Sex Research},
	author = {Kohut, Taylor and Baer, Jodie L. and Watts, Brendan},
	month = jan,
	year = {2016},
	pmid = {26305435},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00224499.2015.1023427},
	pages = {1--11},
	file = {Full Text PDF:files/8072/Kohut et al. - 2016 - Is Pornography Really about “Making Hate to Women”.pdf:application/pdf},
}

@incollection{hald_sexuality_2014,
	address = {Washington, DC, US},
	series = {{APA} handbooks in psychology®},
	title = {Sexuality and pornography},
	isbn = {978-1-4338-1372-6},
	abstract = {In a two-wave legalization process, Denmark, a small Scandinavian country, became the first country in the world to legalize pornography. In 1967, all pornographic text material was legalized, followed by the legalization of all visual pornography in 1969 (Hald, 2007). Both before and after this legalization process, the effects of pornography were hotly debated. Consequently, immediately after legalization, research was launched to investigate the effects of pornography predominantly on sexually aggressive behaviors. Correlational research at the aggregate level connecting the circulation of pornography with sexual aggression was used (for critique of this approach, see also Kingston \& Malamuth, 2011). The results showed a decline in sexual aggression after the legalization of pornography (Kutchinsky, 1991), which was taken as an indication that pornography probably did not adversely affect sexually aggressive behaviors and perhaps even worked as a buffer against them. Subsequently, these Danish studies were frequently used and cited in the first of the grand U.S. investigations of the effects of pornography, namely the President’s Commission on Obscenity and Pornography (1970), set up by President Lyndon B. Johnson. Essentially, the Report of the Commission on Obscenity and Pornography acquitted pornography on all charges. Nonetheless, neither the President’s Commission on Obscenity and Pornography nor subsequent U.S. governmental or other international governmental reports or research on pornography have managed to lessen the debate on pornography that today remains hot among both scientists and the general public (Hald \& Malamuth, 2008). Traditionally, opponents of pornography have claimed that pornography may have damaging effects on beliefs, morals, values, attitudes, and behaviors and hold pornography responsible for a variety of adverse effects, including wrecking marriages, negatively changing men’s perceptions of women and women’s perceptions of themselves, sexual addiction, and unhealthy attitudes and behaviors (e.g., Manning, 2010; P. Paul, 2005). To the contrary, proponents of pornography have claimed that little or no such effects of pornography consumption are evident. Rather, pornography may benefit the individual by enhancing the sex life, contributing to knowledge about sex, providing a recreational sexual outlet or a buffer against sexual assaults, or helping to assess or cure common sexological dysfunctions (e.g., Britton, Maguire, \& Nathanson, 1993; M. Diamond, 2009; M. Diamond, Jozifkova, \& Weiss, 2011; Kontula, 2008; Wylie \& Pacey, 2011) Given the controversial nature of pornography, it is important to stress that the following review is not to be seen as an attack on or defense of pornography but as an attempt to synthesize the most important, prevailing, dominant, and influential theoretical positions and empirical literature on pornography available today. (PsycInfo Database Record (c) 2023 APA, all rights reserved)},
	booktitle = {{APA} handbook of sexuality and psychology, {Vol}. 2: {Contextual} approaches},
	publisher = {American Psychological Association},
	author = {Hald, Gert Martin and Seaman, Christopher and Linz, Daniel},
	year = {2014},
	doi = {10.1037/14194-001},
	keywords = {Pornography, Aggressive Behavior, Knowledge Level, Psychosexual Behavior, Sexual Addiction, Sexual Attitudes, Sexuality, Social Influences},
	pages = {3--35},
	file = {Snapshot:files/8074/2013-05867-001.html:text/html},
}

@article{attwood_reading_2002,
	title = {Reading {Porn}: {The} {Paradigm} {Shift} in {Pornography} {Research}},
	volume = {5},
	issn = {1363-4607},
	shorttitle = {Reading {Porn}},
	url = {https://doi.org/10.1177/1363460702005001005},
	doi = {10.1177/1363460702005001005},
	abstract = {This article examines the paradigm shift in pornography theory and research from a focus on `texts and effects' through to work emerging from the late 1980s onwards. The article considers the reconceptualization of pornography as a category, the location of pornography in relation to cultural hierarchy and form, the changing status of pornography in relation to mainstream representations, the significance of developing technologies and the movement towards more situated accounts of pornographic texts and their audiences as a series of attempts to contextualize the question `what is pornography?'},
	language = {en},
	number = {1},
	urldate = {2023-09-17},
	journal = {Sexualities},
	author = {Attwood, Feona},
	month = feb,
	year = {2002},
	note = {Publisher: SAGE Publications Ltd},
	pages = {91--105},
	file = {SAGE PDF Full Text:files/8076/Attwood - 2002 - Reading Porn The Paradigm Shift in Pornography Re.pdf:application/pdf},
}

@inproceedings{sanchez_supporting_2004,
	title = {Supporting {Structured}, {Semi}-{Structured} and {Unstructured} {Data} in {Digital} {Libraries}},
	isbn = {978-0-7695-2160-2},
	url = {https://www.computer.org/csdl/proceedings-article/enc/2004/21600368/12OmNxGja6P},
	doi = {10.1109/ENC.2004.1342629},
	abstract = {This paper presents an approach to the design of digital libraries by raising and addressing issues involved in supporting services for collections of structured, semi-structured and unstructured objects. We present a system architecture for a digital library that includes provisions for storing and retrieving data with differing structure levels (ranging from highly unstructured to highly structured). We have successfully instantiated this architecture via a practical implementation that integrates technologies such as relational and novel XML databases as well as indexing and information retrieval techniques. A number of digital library applications are using these facilities for handling differing structure levels in an integrated fashion.},
	language = {English},
	urldate = {2023-09-19},
	publisher = {IEEE Computer Society},
	author = {Sánchez, J. Alfredo and Proal, Carlos and Maldonado-Naude, Fernanda},
	month = sep,
	year = {2004},
	pages = {368--375},
}

@article{ferguson_pornography_1995,
	title = {Pornography: {The} {Theory}},
	volume = {21},
	issn = {0093-1896},
	shorttitle = {Pornography},
	url = {https://www.journals.uchicago.edu/doi/abs/10.1086/448768},
	doi = {10.1086/448768},
	number = {3},
	urldate = {2023-09-27},
	journal = {Critical Inquiry},
	author = {Ferguson, Frances},
	month = apr,
	year = {1995},
	note = {Publisher: The University of Chicago Press},
	pages = {670--695},
}

@article{attwood_reading_2002-1,
	title = {Reading {Porn}: {The} {Paradigm} {Shift} in {Pornography} {Research}},
	volume = {5},
	issn = {1363-4607},
	shorttitle = {Reading {Porn}},
	url = {https://doi.org/10.1177/1363460702005001005},
	doi = {10.1177/1363460702005001005},
	abstract = {This article examines the paradigm shift in pornography theory and research from a focus on `texts and effects' through to work emerging from the late 1980s onwards. The article considers the reconceptualization of pornography as a category, the location of pornography in relation to cultural hierarchy and form, the changing status of pornography in relation to mainstream representations, the significance of developing technologies and the movement towards more situated accounts of pornographic texts and their audiences as a series of attempts to contextualize the question `what is pornography?'},
	language = {en},
	number = {1},
	urldate = {2023-09-27},
	journal = {Sexualities},
	author = {Attwood, Feona},
	month = feb,
	year = {2002},
	note = {Publisher: SAGE Publications Ltd},
	pages = {91--105},
	file = {SAGE PDF Full Text:files/8322/Attwood - 2002 - Reading Porn The Paradigm Shift in Pornography Re.pdf:application/pdf},
}

@article{barker_psychology_2014,
	title = {Psychology and pornography: some reflections},
	volume = {1},
	issn = {2326-8743},
	shorttitle = {Psychology and pornography},
	url = {https://doi.org/10.1080/23268743.2013.859468},
	doi = {10.1080/23268743.2013.859468},
	abstract = {This paper provides a brief overview of mainstream psychological research on pornography, which has mainly focused on determining the effects of pornography on human attitudes and behaviour and the possible mechanisms for these effects. The methodological problems with such research are well known in the field of porn studies. Rather than using this as a reason simply to dismiss the contribution of psychology, attention to methods and analyses may be one thing that psychology can particularly offer to work in this area going forward. Just as it is important that we recognize that we are studying pornographies (plural), there are a number of psychologies beyond the classic experimental behaviourist psychology with which people are generally familiar. This paper will argue that critical and applied psychologies, in particular, have much to contribute, with their ability to analyze the ways in which pornographies, sex and gender are constructed, and to hold on to the lived experiences of those engaging with pornographies. Like the rather more conventional forms of experimental psychology, critical and applied psychologies have the potential to offer a useful ‘signal jam’ to polarized debates in this area.},
	number = {1-2},
	urldate = {2023-09-27},
	journal = {Porn Studies},
	author = {Barker, Meg},
	month = jan,
	year = {2014},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/23268743.2013.859468},
	keywords = {applied psychology, critical psychology, effects research, polarization, pornography, psychology, qualitative research},
	pages = {120--126},
	file = {Versione accettata:files/8327/Barker - 2014 - Psychology and pornography some reflections.pdf:application/pdf},
}

@article{stewart_is_2019,
	title = {Is {Feminist} {Porn} {Possible}?},
	volume = {23},
	issn = {1936-4822},
	url = {https://doi.org/10.1007/s12119-018-9553-z},
	doi = {10.1007/s12119-018-9553-z},
	abstract = {This paper begins by exploring the feminist anti-pornography argument proposed by Rae Langton. This argument employs J. L. Austin’s speech act theory to maintain that pornography does not merely harm women (the traditional feminist anti-pornography argument), pornography constitutes harm itself. One outcome of this argument, if successful, would be that feminist porn would not be possible and that the phrase ‘feminist porn’ would be nonsensical. But, I argue, Langton’s argument is problematic and ought to be rejected. This opens up the possibility of feminist porn. Employing philosophical arguments on social construction and what Ian Hacking has called “looping effects,” as well as some writings by people who identify themselves as feminist pornographers, I indicate what such porn looks like and how it represents sexuality in ways that feminists should find less problematic than typical, heterosexual, mainstream porn.},
	language = {en},
	number = {1},
	urldate = {2023-09-27},
	journal = {Sexuality \& Culture},
	author = {Stewart, Robert Scott},
	month = mar,
	year = {2019},
	keywords = {Feminist pornographers, Feminist sex wars, Ian Hacking, Looping effects, Rae Langton, Social construction, Speech act theory},
	pages = {254--270},
	file = {Full Text PDF:files/8329/Stewart - 2019 - Is Feminist Porn Possible.pdf:application/pdf},
}

@book{noauthor_abc_2016,
	address = {Ottawa, ON},
	title = {The {ABC} method a risk management approach to the preservation of cultural heritage},
	isbn = {978-0-660-04134-6},
	abstract = {"This manual offers a comprehensive understanding of risk management applied to the preservation of heritage assets, whether collections, buildings or sites. It provides a step-by-step procedure and a variety of tools to guide the heritage professional in applying the ABC method to their own context. The method can be applied to a range of situations, from analysis of a single risk to a comprehensive risk assessment of the entire heritage asset"--Provided by publisher},
	language = {en},
	publisher = {Canadian Conservation Institute = Institut canadien de conservation},
	year = {2016},
	note = {OCLC: 984839568},
	file = {2016 - The ABC method a risk management approach to the p.pdf:files/8531/2016 - The ABC method a risk management approach to the p.pdf:application/pdf},
}

@misc{noauthor_abc_nodate,
	title = {{ABC} {System}},
	url = {http://localhost/abcsystem/abcsystem/index},
	urldate = {2023-09-29},
	file = {ABC System:files/8959/index.html:text/html},
}

@article{annis_contextualist_1978,
	title = {A {Contextualist} {Theory} of {Epistemic} {Justification}},
	volume = {15},
	issn = {0003-0481},
	url = {https://www.jstor.org/stable/20009716},
	number = {3},
	urldate = {2023-10-05},
	journal = {American Philosophical Quarterly},
	author = {Annis, David B.},
	year = {1978},
	note = {Publisher: [North American Philosophical Publications, University of Illinois Press]},
	pages = {213--219},
	file = {JSTOR Full Text PDF:files/8992/Annis - 1978 - A Contextualist Theory of Epistemic Justification.pdf:application/pdf},
}

@incollection{croce_contextualist_2014,
	series = {Studies in {Language} {Companion} {Series}},
	title = {a contextualist perspective: {The} role of subjective certainty in the epistemology of testimony},
	isbn = {978-90-272-5930-1 978-90-272-6914-0},
	shorttitle = {a contextualist perspective},
	url = {https://benjamins.com/catalog/slcs.165.07cro},
	abstract = {The notion of subjective certainty has been ruled out of epistemological debate as unreliable and deceptive. In contrast, in this paper I argue that it is undoubtedly valuable to the field of epistemology of testimony, where hearers must choose whether or not they trust speakers’ claims. I also argue that the role of subjective certainty depends on the context. In the philosophical context, where the skeptical threat cannot be avoided, subjective certainty can only perform a marginal role in the hearer's acquisition of knowledge from a speaker. In contrast, in the ordinary context subjective certainty can be the key factor that allows the transmission of knowledge, especially in “innocent testimony” cases where the hearer is not required to possess evidential reasons for trusting the speaker.},
	language = {en},
	urldate = {2023-10-05},
	booktitle = {Certainty-uncertainty – and the {Attitudinal} {Space} in {Between}},
	publisher = {John Benjamins Publishing Company},
	author = {Croce, Michel},
	editor = {Cantarini, Sibilla and Abraham, Werner and Leiss, Elisabeth},
	month = nov,
	year = {2014},
	doi = {10.1075/slcs.165.07cro},
	pages = {121--134},
	file = {Snapshot:files/8994/slcs.165.html:text/html},
}

@article{blundell_metadata_nodate,
	title = {Metadata {Requirements} for {3D} {Data}},
	abstract = {The “Metadata Requirements for 3D Data” chapter provides recommendations for metadatai based on the five-stage digital asset lifecycleii. The “Create” section covers some of the principal ways 3D models are created and discusses what metadata can be captured during the creation process. This section looks at not only what metadata could be captured during model creation, but also why capturing that information is important. The “Manage” section covers the metadata needs for organizing, verifying, and providing accessiii to 3D data. Recommendations include grouping files together as much as possible (by 3D object, by collection of objects, and by project) in order to apply organizational metadata that can be used for access and reuse purposes. The Distribution and Publication section discusses the need for a variety of distribution platforms that support the broadly varying metadata needs of different disciplines. Examples include the need for more granular metadata to support reproducibility and privacy in certain fields, as well as concerns around metadata requirements for accessibility for disability more broadly. Though the circulation and access norms for 3D data are still evolving, the Access and Reuse section posits key metadata anticipated to be useful in the discoveryiv and access of 3D data and models for research or reuse. The “Archive” section utilizes PREMIS as a basis for its recommendations. The rapid changes in the tools and platforms that support the creation and utilization of 3D data results in heavier emphasis on metadata that provides context to data that is often no longer supported by the latest technologies. Additional portions of PREMIS that may be of interest to readers are also specified. The chapter ends with an overall table of recommended metadata fields along with future work needed, naming annotation metadata and metadata for accessibility needs as top priorities for standardization and best practice recommendations.},
	language = {en},
	author = {Blundell, Jon and Clark, Jasmine L and DeVet, Katherine E and Hardesty, Juliet L},
	file = {Blundell et al. - Metadata Requirements for 3D Data.pdf:files/9874/Blundell et al. - Metadata Requirements for 3D Data.pdf:application/pdf},
}

@article{homburg_metadata_2021-1,
	title = {Metadata schema and ontology for capturing and processing of {3D} cultural heritage objects},
	volume = {9},
	issn = {2050-7445},
	url = {https://doi.org/10.1186/s40494-021-00561-w},
	doi = {10.1186/s40494-021-00561-w},
	abstract = {Motivated by the increased use of 3D acquisition of objects by cultural heritage institutions, we were investigating ontologies and metadata schemes for the acquisition process to provide details about the 3D capturing, which can be combined with preexisting ontologies describing an object. Therefore we divided the 3D capturing workflow into common steps starting with the object being placed in front of a 3D scanner to preparation and publication of the 3D datasets and/or derived images. While the proposed ontology is well defined on a coarse level of detail for very different techniques, e.g. Stucture from Motion and LiDAR we elaborated the metadata scheme in very fine detail for 3D scanners available at our institutions. This includes practical experiments with measurement data from past and current projects including datasets published at Zenodo as guiding examples and the source code for their computation. Additionally, the free and Open Source GigaMesh Software Framework’s analysis and processing methods have been extended to provide metadata about the 3D processing steps like mesh cleaning as well as 2D image generation. Finally, we discuss the current limitations and give an outlook about future extensions.},
	number = {1},
	urldate = {2023-11-10},
	journal = {Heritage Science},
	author = {Homburg, Timo and Cramer, Anja and Raddatz, Laura and Mara, Hubert},
	month = jul,
	year = {2021},
	keywords = {Ontologies, Metadata, Semantic web, 3D scanning, Data quality},
	pages = {91},
	file = {Full Text PDF:files/9879/Homburg et al. - 2021 - Metadata schema and ontology for capturing and pro.pdf:application/pdf;Snapshot:files/9880/s40494-021-00561-w.html:text/html},
}

@article{flotynski_ontology-based_2017,
	title = {Ontology-{Based} {Representation} and {Modelling} of {Synthetic} {3D} {Content}: {A} {State}-of-the-{Art} {Review}},
	volume = {36},
	copyright = {© 2017 The Authors Computer Graphics Forum © 2017 The Eurographics Association and John Wiley \& Sons Ltd.},
	issn = {1467-8659},
	shorttitle = {Ontology-{Based} {Representation} and {Modelling} of {Synthetic} {3D} {Content}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13083},
	doi = {10.1111/cgf.13083},
	abstract = {An indispensable element of any practical 3D/VR/AR application is synthetic three-dimensional (3D) content. Such content is characterized by a variety of features—geometry, structure, space, appearance, animation and behaviour—which makes the modelling of 3D content a much more complex, difficult and time-consuming task than in the case of other types of content. One of the promising research directions aiming at simplification of modelling 3D content is the use of the semantic web approach. The formalism provided by semantic web techniques enables declarative knowledge-based modelling of content based on ontologies. Such modelling can be conducted at different levels of abstraction, possibly domain-specific, with inherent separation of concerns. The use of semantic web ontologies enables content representation independent of particular presentation platforms and facilitates indexing, searching and analysing content, thus contributing to increased content re-usability. A range of approaches have been proposed to permit semantic representation and modelling of synthetic 3D content. These approaches differ in the methodologies and technologies used as well as their scope and application domains. This paper provides a review of the current state of the art in representation and modelling of 3D content based on semantic web ontologies, together with a classification, characterization and discussion of the particular approaches.},
	language = {en},
	number = {8},
	urldate = {2023-11-10},
	journal = {Computer Graphics Forum},
	author = {Flotyński, Jakub and Walczak, Krzysztof},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13083},
	keywords = {Virtual reality, Artificial augmented and virtual realities, Computer graphics I.3.7: Three-Dimensional Graphics and Realism, Graphical user interfaces (GUI) Virtual reality, Information interfaces and presentation H.5.1: Multimedia information systems, Information interfaces and presentation H.5.2: User Interfaces},
	pages = {329--353},
	file = {Snapshot:files/9883/cgf.html:text/html},
}

@misc{balzani_saving_2023,
	title = {Saving temporary exhibitions in virtual environments: the {Digital} {Renaissance} of {Ulisse} {Aldrovandi}},
	copyright = {All rights reserved},
	shorttitle = {Saving temporary exhibitions in virtual environments},
	url = {http://arxiv.org/abs/2308.15920},
	doi = {10.48550/arXiv.2308.15920},
	abstract = {Our goal was to obtain the digital twin of the temporary exhibition "The Other Renaissance: Ulisse Aldrovandi and the Wonders of the World", to make it accessible online to users using various devices (from smartphones to VR headsets). We started with a preliminary assessment of the exhibition, focussing on possible acquisition constraints - time, space, and materials - and related solutions. Then, we proceeded with the creation of the digital twin by acquiring, processing, modelling, optimising, exporting, metadating, and uploading the exhibition. We adopted a hybrid use of two distinct acquisition techniques, i.e. structured light projection scanning and photogrammetry, to create new digital cultural heritage objects and environments, and we used open technologies, formats and protocols to make available the final digital product. We described the process to collect and curate bibliographical (meta)data of the exhibition and digital twin creation process to foster its findability, accessibility, interoperability and reusability.},
	urldate = {2023-11-10},
	publisher = {arXiv},
	author = {Balzani, Roberto and Barzaghi, Sebastian and Bitelli, Gabriele and Bonifazi, Federica and Bordignon, Alice and Cipriani, Luca and Colitti, Simona and Collina, Federica and Daquino, Marilena and Fabbri, Francesca and Fanini, Bruno and Fantini, Filippo and Ferdani, Daniele and Fiorini, Giulia and Formia, Elena and Forte, Anna and Giacomini, Federica and Girelli, Valentina Alena and Gualandi, Bianca and Heibi, Ivan and Iannucci, Alessandro and Del Fà, Rachele Manganelli and Massari, Arcangelo and Moretti, Arianna and Peroni, Silvio and Pescarin, Sofia and Renda, Giulia and Ronchi, Diego and Sullini, Mattia and Tini, Maria Alessandra and Tomasi, Francesca and Travaglini, Laura and Vittuari, Luca},
	month = aug,
	year = {2023},
	note = {arXiv:2308.15920 [cs]},
	keywords = {Computer Science - Digital Libraries, Computer Science - Graphics},
	file = {arXiv Fulltext PDF:files/9887/Balzani et al. - 2023 - Saving temporary exhibitions in virtual environmen.pdf:application/pdf;arXiv.org Snapshot:files/9888/2308.html:text/html},
}

@article{barzaghi_digitisation_2023,
	title = {Digitisation of {Temporary} {Exhibitions}: the {Aldrovandi} {Case}},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {Digitisation of {Temporary} {Exhibitions}},
	url = {https://diglib.eg.org/handle/10.2312/gch20231176},
	doi = {10.2312/GCH.20231176},
	abstract = {Temporary exhibitions in the cultural heritage system have become diffused. They are tools to enhance cultural heritage and to gather, in the same context, cultural goods that otherwise would never be exposed together. Their temporal limitation gives them the uniqueness of an event that will not be repeated. The exhibition "The Other Renaissance: Ulisse Aldrovandi and the Wonders of the World” was created to offer visitors a tour of an exceptional legacy of objects, some of which have never been exhibited before, combined with objects, works of art from several Italian museums, and digital installations that together tell the story of how the first generation of naturalists took their first steps into science as we know it today. To store this exhibition a photogrammetric and structured light scanner survey campaign was launched to acquire 3D objects. By leveraging a combination of 3D, LOD, and Semantic Web technologies, we propose to create a digital twin (intended as an aggregation of different information about real-world heritage objects) of Aldrovandi exhibitions, to create a new digital tool differentiated from the physical exhibition, but that could store all the information and objects exposed together physically.},
	language = {en},
	urldate = {2023-11-10},
	author = {Barzaghi, Sebastian and Collina, Federica and Fabbri, Francesca and Giacomini, Federica and Bordignon, Alice and Balzani, Roberto and Bitelli, Gabriele and Bonifazi, Federica and Cipriani, Luca and Colitti, Simona and Daquino, Marilena and Fanini, Bruno and Fantini, Filippo and Ferdani, Daniele and Fiorini, Giulia and Formia, Elena and Forte, Anna and Girelli, Valentina Alena and Gualandi, Bianca and Heibi, Ivan and Iannucci, Alessandro and Fà, Rachele Manganelli Del and Massari, Arcangelo and Moretti, Arianna and Peroni, Silvio and Pescarin, Sofia and Renda, Giulia and Ronchi, Diego and Sullini, Mattia and Tini, Maria Alessandra and Tomasi, Francesca and Travaglini, Laura and Vittuari, Luca},
	year = {2023},
	note = {Artwork Size: 3 pages
Publisher: The Eurographics Association},
	keywords = {based design, CCS Concepts: Human-centered computing→User interface design, Scenario-based design, HCI theory, concepts and models, centered computing→User interface design, concepts and models, HCI theory, Human, Scenario},
	pages = {3 pages},
	file = {Barzaghi et al. - 2023 - Digitisation of Temporary Exhibitions the Aldrova.pdf:files/9889/Barzaghi et al. - 2023 - Digitisation of Temporary Exhibitions the Aldrova.pdf:application/pdf},
}

@article{barzaghi_digitisation_2023-1,
	title = {Digitisation of {Temporary} {Exhibitions}: the {Aldrovandi} {Case}},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {Digitisation of {Temporary} {Exhibitions}},
	url = {https://diglib.eg.org/handle/10.2312/gch20231176},
	doi = {10.2312/GCH.20231176},
	abstract = {Temporary exhibitions in the cultural heritage system have become diffused. They are tools to enhance cultural heritage and to gather, in the same context, cultural goods that otherwise would never be exposed together. Their temporal limitation gives them the uniqueness of an event that will not be repeated. The exhibition "The Other Renaissance: Ulisse Aldrovandi and the Wonders of the World” was created to offer visitors a tour of an exceptional legacy of objects, some of which have never been exhibited before, combined with objects, works of art from several Italian museums, and digital installations that together tell the story of how the first generation of naturalists took their first steps into science as we know it today. To store this exhibition a photogrammetric and structured light scanner survey campaign was launched to acquire 3D objects. By leveraging a combination of 3D, LOD, and Semantic Web technologies, we propose to create a digital twin (intended as an aggregation of different information about real-world heritage objects) of Aldrovandi exhibitions, to create a new digital tool differentiated from the physical exhibition, but that could store all the information and objects exposed together physically.},
	language = {en},
	urldate = {2023-11-10},
	author = {Barzaghi, Sebastian and Collina, Federica and Fabbri, Francesca and Giacomini, Federica and Bordignon, Alice and Balzani, Roberto and Bitelli, Gabriele and Bonifazi, Federica and Cipriani, Luca and Colitti, Simona and Daquino, Marilena and Fanini, Bruno and Fantini, Filippo and Ferdani, Daniele and Fiorini, Giulia and Formia, Elena and Forte, Anna and Girelli, Valentina Alena and Gualandi, Bianca and Heibi, Ivan and Iannucci, Alessandro and Fà, Rachele Manganelli Del and Massari, Arcangelo and Moretti, Arianna and Peroni, Silvio and Pescarin, Sofia and Renda, Giulia and Ronchi, Diego and Sullini, Mattia and Tini, Maria Alessandra and Tomasi, Francesca and Travaglini, Laura and Vittuari, Luca},
	year = {2023},
	note = {Artwork Size: 3 pages
Publisher: The Eurographics Association},
	keywords = {based design, CCS Concepts: Human-centered computing→User interface design, Scenario-based design, HCI theory, concepts and models, centered computing→User interface design, concepts and models, HCI theory, Human, Scenario},
	pages = {3 pages},
	file = {Barzaghi et al. - 2023 - Digitisation of Temporary Exhibitions the Aldrova.pdf:files/9892/Barzaghi et al. - 2023 - Digitisation of Temporary Exhibitions the Aldrova.pdf:application/pdf},
}

@article{barzaghi_digitisation_2023-2,
	title = {Digitisation of {Temporary} {Exhibitions}: the {Aldrovandi} {Case}},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {Digitisation of {Temporary} {Exhibitions}},
	url = {https://diglib.eg.org/handle/10.2312/gch20231176},
	doi = {10.2312/GCH.20231176},
	abstract = {Temporary exhibitions in the cultural heritage system have become diffused. They are tools to enhance cultural heritage and to gather, in the same context, cultural goods that otherwise would never be exposed together. Their temporal limitation gives them the uniqueness of an event that will not be repeated. The exhibition "The Other Renaissance: Ulisse Aldrovandi and the Wonders of the World” was created to offer visitors a tour of an exceptional legacy of objects, some of which have never been exhibited before, combined with objects, works of art from several Italian museums, and digital installations that together tell the story of how the first generation of naturalists took their first steps into science as we know it today. To store this exhibition a photogrammetric and structured light scanner survey campaign was launched to acquire 3D objects. By leveraging a combination of 3D, LOD, and Semantic Web technologies, we propose to create a digital twin (intended as an aggregation of different information about real-world heritage objects) of Aldrovandi exhibitions, to create a new digital tool differentiated from the physical exhibition, but that could store all the information and objects exposed together physically.},
	language = {en},
	urldate = {2023-11-10},
	author = {Barzaghi, Sebastian and Collina, Federica and Fabbri, Francesca and Giacomini, Federica and Bordignon, Alice and Balzani, Roberto and Bitelli, Gabriele and Bonifazi, Federica and Cipriani, Luca and Colitti, Simona and Daquino, Marilena and Fanini, Bruno and Fantini, Filippo and Ferdani, Daniele and Fiorini, Giulia and Formia, Elena and Forte, Anna and Girelli, Valentina Alena and Gualandi, Bianca and Heibi, Ivan and Iannucci, Alessandro and Fà, Rachele Manganelli Del and Massari, Arcangelo and Moretti, Arianna and Peroni, Silvio and Pescarin, Sofia and Renda, Giulia and Ronchi, Diego and Sullini, Mattia and Tini, Maria Alessandra and Tomasi, Francesca and Travaglini, Laura and Vittuari, Luca},
	year = {2023},
	note = {Artwork Size: 3 pages
Publisher: The Eurographics Association},
	keywords = {based design, CCS Concepts: Human-centered computing→User interface design, Scenario-based design, HCI theory, concepts and models, centered computing→User interface design, concepts and models, HCI theory, Human, Scenario},
	pages = {3 pages},
	file = {Barzaghi et al. - 2023 - Digitisation of Temporary Exhibitions the Aldrova.pdf:files/9895/Barzaghi et al. - 2023 - Digitisation of Temporary Exhibitions the Aldrova.pdf:application/pdf},
}

@article{fabbri_ai_nodate,
	title = {{AI} and chatbots as a storytelling tool to personalize the visitor experience. {The} case of {National} {Museum} of {Ravenna}.},
	copyright = {All rights reserved},
	abstract = {In the museum sector, interest in visitor engagement methods has been growing for several years. Among these, AI and machine learning have proven to be valid engagement and storytelling tools for museums, in particular for the creation of interactive chatbots and better customize visitor experience. This paper aims to reason about the possibilities of these existing tools, discussing their potential and limitations. The collection of visitor flow data within the museum and the interactive use of chatbots allow different levels of personalization of the visit. The real question is: how can an evolving AI tool be transformed into a storytelling tool that is in harmony with the museum's itinerary and allows for personalization but also respects the museum's own identity and peculiarities? These reflections are part of a research proposal for developing a chatbot to orient visitors within the museum, signaling works of potential interest. The application context is the National Museum of Ravenna, characterised by a vast and heterogeneous collection that is difficult to use.},
	language = {en},
	author = {Fabbri, Francesca and Collina, Federica and Barzaghi, Sebastian},
	file = {Fabbri et al. - AI and chatbots as a storytelling tool to personal.pdf:files/9898/Fabbri et al. - AI and chatbots as a storytelling tool to personal.pdf:application/pdf},
}

@misc{noauthor_assessing_nodate,
	title = {On assessing weaker logical status claims in {Wikidata} cultural heritage records {\textbar} www.semantic-web-journal.net},
	url = {https://www.semantic-web-journal.net/content/assessing-weaker-logical-status-claims-wikidata-cultural-heritage-records-0},
	urldate = {2023-11-18},
	file = {On assessing weaker logical status claims in Wikidata cultural heritage records | www.semantic-web-journal.net:files/9902/assessing-weaker-logical-status-claims-wikidata-cultural-heritage-records-0.html:text/html},
}

@article{devor_toward_1994,
	title = {Toward a {Taxonomy} of {Gendered} {Sexuality}},
	volume = {6},
	issn = {0890-7064},
	url = {https://doi.org/10.1300/J056v06n01_03},
	doi = {10.1300/J056v06n01_03},
	abstract = {Current definitions and conceptualizations of sex, gender, and sexuality lack suffcient subtlety to adequately describe the full range of human sexuality. A taxonomy of gendered sexuality is developed which better defines terms relevant to human sexuality and more fully takes into account the interplay over time among sex, gender, and sexual fantasies, desires, practices of persons in intimate relationships at both the level of self-identity and attribution by others. The proposed taxonomy starts with classifications based on the genetic sexes of persons in relationships and combines them with categorizations based on those persons' social genders to arrive at classifications of gendered sexuality. The terminology used is drawn from everyday language. Examples are provided to illustrate the application of the taxonomy. The proposed taxonomy may be used for descriptive, diagnostic, or theoretical purposes.},
	number = {1},
	urldate = {2023-11-20},
	journal = {Journal of Psychology \& Human Sexuality},
	author = {Devor, Holly},
	month = nov,
	year = {1994},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1300/J056v06n01\_03},
	pages = {23--56},
}

@article{phd_toward_1994,
	title = {Toward a {Taxonomy} of {Gendered} {Sexuality}},
	copyright = {Copyright Taylor and Francis Group, LLC},
	url = {https://www.tandfonline.com/doi/abs/10.1300/J056v06n01_03},
	doi = {10.1300/J056v06n01_03},
	language = {EN},
	urldate = {2023-11-20},
	journal = {Journal of Psychology \&amp; Human Sexuality},
	author = {PhD, Holly Devor},
	month = nov,
	year = {1994},
	note = {Publisher: Taylor \& Francis Group},
	file = {Snapshot:files/9905/J056v06n01_03.html:text/html},
}

@article{ramalhinho_cultural_2019,
	title = {Cultural heritage risk analysis models: {An} overview},
	volume = {10},
	copyright = {openAccess},
	issn = {2067-533X},
	shorttitle = {Cultural heritage risk analysis models},
	url = {https://run.unl.pt/handle/10362/104548},
	abstract = {The risk assessment is a critical step in achieving, defining and supporting the decision-making process. In this context, in the past two decades, an increase in the number of models for assessing/analysis of risks applied to collections and/or immobile cultural heritage was observed. The present work consists of the first review of the literature, from 1999 to 2016, on risk assessment applied to movable and immovable cultural heritage. A total of twenty-seven risk assessment models have been compiled that can be applied to different types of cultural heritage such as: immovable property (26\%) and movable property (74\%). It was possible to conclude that approximately 48\% of the risk analysis models are quantitative, 19\% are semi-quantitative and 33\% of the models are qualitative. Two different tables were created in order to help the reader: one for movable and another to immovable cultural heritage. These tables compile information to characterize the models (name, type, applicability, examples, date and references). The advantages and disadvantages of using each model was discuss in a separated table.},
	language = {eng},
	number = {1},
	urldate = {2023-11-22},
	journal = {International Journal of Conservation Science},
	author = {Ramalhinho, Ana Rita and Macedo, Maria Filomena},
	month = jan,
	year = {2019},
	note = {Accepted: 2020-09-22T22:15:46Z},
	pages = {39--58},
	file = {Full Text PDF:files/9907/Ramalhinho e Macedo - 2019 - Cultural heritage risk analysis models An overvie.pdf:application/pdf},
}

@book{grinberg_flask_2018,
	title = {Flask {Web} {Development}: {Developing} {Web} {Applications} with {Python}},
	isbn = {978-1-4919-9169-5},
	shorttitle = {Flask {Web} {Development}},
	abstract = {Take full creative control of your web applications with Flask, the Python-based microframework. With the second edition of this hands-on book, youâ??ll learn Flask from the ground up by developing a complete, real-world application created by author Miguel Grinberg. This refreshed edition accounts for important technology changes that have occurred in the past three years.Explore the frameworkâ??s core functionality, and learn how to extend applications with advanced web techniques such as database migrations and an application programming interface. The first part of each chapter provides you with reference and background for the topic in question, while the second part guides you through a hands-on implementation.If you have Python experience, youâ??re ready to take advantage of the creative freedom Flask provides. Three sections include:A thorough introduction to Flask: explore web application development basics with Flask and an application structure appropriate for medium and large applicationsBuilding Flasky: learn how to build an open source blogging application step-by-step by reusing templates, paginating item lists, and working with rich textGoing the last mile: dive into unit testing strategies, performance analysis techniques, and deployment options for your Flask application},
	language = {en},
	publisher = {"O'Reilly Media, Inc."},
	author = {Grinberg, Miguel},
	month = mar,
	year = {2018},
	note = {Google-Books-ID: cVlPDwAAQBAJ},
	keywords = {Computers / Internet / Web Programming, Computers / Languages / Python, Computers / Programming / Open Source},
}

@incollection{gangemi_ontology_2009-1,
	address = {Berlin, Heidelberg},
	series = {International {Handbooks} on {Information} {Systems}},
	title = {Ontology {Design} {Patterns}},
	isbn = {978-3-540-92673-3},
	url = {https://doi.org/10.1007/978-3-540-92673-3_10},
	abstract = {Computational ontologies in the context of information systems are artifacts that encode a description of some world, for some purpose. Under the assumption that there exist classes of problems that can be solved by applying common solutions (as it has been experienced in software engineering), we envision small, task-oriented ontologies with explicit documentation of design rationales. In this chapter, we describe components called Ontology Design Patterns (OP), and methods that support pattern-based ontology design.},
	language = {en},
	urldate = {2023-11-22},
	booktitle = {Handbook on {Ontologies}},
	publisher = {Springer},
	author = {Gangemi, Aldo and Presutti, Valentina},
	editor = {Staab, Steffen and Studer, Rudi},
	year = {2009},
	doi = {10.1007/978-3-540-92673-3_10},
	keywords = {Design Pattern, Domain Ontology, Ontology Design, Ontology Engineering, Reference Ontology},
	pages = {221--243},
}

@article{aitsi-selmi_sendai_2015,
	title = {The {Sendai} {Framework} for {Disaster} {Risk} {Reduction}: {Renewing} the {Global} {Commitment} to {People}’s {Resilience}, {Health}, and {Well}-being},
	volume = {6},
	issn = {2192-6395},
	shorttitle = {The {Sendai} {Framework} for {Disaster} {Risk} {Reduction}},
	url = {https://doi.org/10.1007/s13753-015-0050-9},
	doi = {10.1007/s13753-015-0050-9},
	abstract = {The Sendai Framework for Disaster Risk Reduction 2015–2030 (SFDRR) is the first global policy framework of the United Nations’ post-2015 agenda. It represents a step in the direction of global policy coherence with explicit reference to health, development, and climate change. To develop SFDRR, the United Nations Office for Disaster Risk Reduction (UNISDR) organized and facilitated several global, regional, national, and intergovernmental negotiations and technical meetings in the period preceding the World Conference on Disaster Risk Reduction (WCDRR) 2015 where SFDRR was adopted. UNISDR also worked with representatives of governments, UN agencies, and scientists to develop targets and indicators for SFDRR and proposed them to member states for negotiation and adoption as measures of progress and achievement in protecting lives and livelihoods. The multiple efforts of the health community in the policy development process, including campaigning for safe schools and hospitals, helped to put people’s mental and physical health, resilience, and well-being higher up the disaster risk reduction (DRR) agenda compared with the Hyogo Framework for Action 2005–2015. This article reviews the historical and contemporary policy development process that led to the SFDRR with particular reference to the development of the health theme.},
	language = {en},
	number = {2},
	urldate = {2023-11-23},
	journal = {International Journal of Disaster Risk Science},
	author = {Aitsi-Selmi, Amina and Egawa, Shinichi and Sasaki, Hiroyuki and Wannous, Chadia and Murray, Virginia},
	month = jun,
	year = {2015},
	keywords = {Disaster risk reduction, Public health, Global health, Health policy, Safe hospitals},
	pages = {164--176},
	file = {Full Text PDF:files/9912/Aitsi-Selmi et al. - 2015 - The Sendai Framework for Disaster Risk Reduction .pdf:application/pdf},
}

@article{hak_sustainable_2016,
	title = {Sustainable {Development} {Goals}: {A} need for relevant indicators},
	volume = {60},
	issn = {1470-160X},
	shorttitle = {Sustainable {Development} {Goals}},
	url = {https://www.sciencedirect.com/science/article/pii/S1470160X15004240},
	doi = {10.1016/j.ecolind.2015.08.003},
	abstract = {At the UN in New York the Open Working Group created by the UN General Assembly proposed a set of global Sustainable Development Goals (SDGs) which comprises 17 goals and 169 targets. Further to that, a preliminary set of 330 indicators was introduced in March 2015. Some SDGs build on preceding Millennium Development Goals while others incorporate new ideas. A critical review has revealed that indicators of varied quality (in terms of the fulfilment certain criteria) have been proposed to assess sustainable development. Despite the fact that there is plenty of theoretical work on quality standards for indicators, in practice users cannot often be sure how adequately the indicators measure the monitored phenomena. Therefore we stress the need to operationalise the Sustainable Development Goals’ targets and evaluate the indicators’ relevance, the characteristic of utmost importance among the indicators’ quality traits. The current format of the proposed SDGs and their targets has laid a policy framework; however, without thorough expert and scientific follow up on their operationalisation the indicators may be ambiguous. Therefore we argue for the foundation of a conceptual framework for selecting appropriate indicators for targets from existing sets or formulating new ones. Experts should focus on the “indicator-indicated fact” relation to ensure the indicators’ relevance in order for clear, unambiguous messages to be conveyed to users (decision- and policy-makers and also the lay public). Finally we offer some recommendations for indicators providers in order to contribute to the tremendous amount of conceptual work needed to lay a strong foundation for the development of the final indicators framework.},
	urldate = {2023-11-23},
	journal = {Ecological Indicators},
	author = {Hák, Tomáš and Janoušková, Svatava and Moldan, Bedřich},
	month = jan,
	year = {2016},
	keywords = {Indicatorś framework, Indicatorś relevance, Sustainable development assessment, Sustainable Development Goals},
	pages = {565--573},
	file = {ScienceDirect Full Text PDF:files/9914/Hák et al. - 2016 - Sustainable Development Goals A need for relevant.pdf:application/pdf;ScienceDirect Snapshot:files/9915/S1470160X15004240.html:text/html},
}

@article{jokilehto_iccroms_2000,
	title = {Iccrom's {Involvement} in {Risk} {Preparedness}},
	volume = {39},
	issn = {0197-1360},
	url = {https://doi.org/10.1179/019713600806113275},
	doi = {10.1179/019713600806113275},
	abstract = {Since its foundation, ICCROM has been involved in providing response to emergencies, including floods and earthquakes, when cultural artifacts are threatened or damaged. Particularly since the 1979 earthquake in Montenegro, the strategy has been to give particular attention to the development of training and the preparation of guidelines in risk preparedness. Together with UNESCO, ICOMOS, ICOM, and other international organizations, ICCROM has developed international collaboration and the establishment of the Blue Shield movement, opening new frontiers for improved disaster mitigation.},
	number = {1},
	urldate = {2023-11-29},
	journal = {Journal of the American Institute for Conservation},
	author = {Jokilehto, Jukka},
	month = jan,
	year = {2000},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1179/019713600806113275},
	pages = {173--179},
}

@article{tandon_post-disaster_2017,
	title = {Post-disaster damage assessment of cultural heritage: {Are} we prepared?},
	abstract = {Between 2013 and 2016, eight natural hazard events (one typhoon and seven earthquakes) caused death and destruction in the Philippines, Nepal, Myanmar and Italy. These disasters devastated large parts of the territory in the affected countries and resulted in the widespread damage of movable, immovable and intangible heritage. Representing the International Centre for the Study of the Preservation and Restoration of Cultural Property (ICCROM), the author was invited to assist with the post-disaster assessment of damage in the Philippines, Nepal and Myanmar. While in Italy she liaised with the Department of Civil Protection and the relevant cultural agencies to assess the immediate risks to the cultural heritage of the affected area. Based on these experiences, this paper highlights some critical gaps in the existing capacity that prevent timely post-event assessments of the impacts on cultural heritage, which in turn hampers its recovery.},
	language = {en},
	author = {Tandon, Aparna},
	year = {2017},
	file = {Tandon - 2017 - Post-disaster damage assessment of cultural herita.pdf:files/9936/Tandon - 2017 - Post-disaster damage assessment of cultural herita.pdf:application/pdf},
}

@article{durrant_disaster_2023,
	title = {Disaster risk management and cultural heritage: {The} perceptions of {European} world heritage site managers on disaster risk management},
	volume = {89},
	issn = {2212-4209},
	shorttitle = {Disaster risk management and cultural heritage},
	url = {https://www.sciencedirect.com/science/article/pii/S221242092300105X},
	doi = {10.1016/j.ijdrr.2023.103625},
	abstract = {Research into the sustainable management of the world's cultural heritage (CH) is increasing. This is due to the vulnerability of CH to climate-related disasters and the perceived contribution of CH to the achievement of broader sustainability goals. Despite the perceived benefits of bringing together CH and sustainability, researchers have identified barriers that slow integration. These barriers are theoretical and practical, and targeted research would help improve the resilience of our CH. This article aims to explore the perceptions of a group of UNESCO world heritage site managers (WHSM) on disaster risk management. A questionnaire was sent to WHSM via professional email boxes. The questionnaire consisted of 26 questions designed to explore the perception of WHSM. In total, 58 responses were received, and the results produced findings worthy of discussion. WHSM still have limited access to disaster risk management strategies or practical implementation experience. Practitioners in this field perceive multiple risks, not just those related to climate change. The researchers noted that there was a tendency to focus on the most immediate problem, rather than the full range of risks they might face. It is clear that there is an opportunity to improve resilience through knowledge sharing and better communication across all CH. This is also true of individual world cultural heritage sites, with opportunities to engage more effectively with local stakeholders. This article pinpoints the current perceptions of WHSM for the academic community and highlights critical avenues of research that will aid in the overarching theoretical and operational integration of CH and sustainability.},
	urldate = {2023-11-29},
	journal = {International Journal of Disaster Risk Reduction},
	author = {Durrant, Louis J. and Vadher, Atish N. and Teller, Jacques},
	month = apr,
	year = {2023},
	keywords = {Cultural heritage, Survey, Disaster risk management, Perceptions, World heritage site managers},
	pages = {103625},
	file = {Full text:files/9941/Durrant et al. - 2023 - Disaster risk management and cultural heritage Th.pdf:application/pdf;ScienceDirect Snapshot:files/9940/S221242092300105X.html:text/html},
}

@article{romao_risk_2022,
	title = {Risk protection for cultural heritage and historic centres: {Current} knowledge and further research needs},
	volume = {67},
	issn = {2212-4209},
	shorttitle = {Risk protection for cultural heritage and historic centres},
	url = {https://www.sciencedirect.com/science/article/pii/S2212420921006130},
	doi = {10.1016/j.ijdrr.2021.102652},
	abstract = {This article introduces the Special Issue on Risk Protection for Cultural Heritage and Historic Centres. The article starts by reviewing the gaps in knowledge and practice related to disaster risk management of cultural heritage. It then reviews the contributions to the Special Issue, focussing on their multi-disciplinary findings that address some of the referred gaps. Finally, the article proceeds to discuss, in more detail, certain topics related to disaster risk management and cultural heritage that should be targeted by future research, emphasizing specific issues that need to be addressed.},
	urldate = {2023-11-29},
	journal = {International Journal of Disaster Risk Reduction},
	author = {Romão, Xavier and Bertolin, Chiara},
	month = jan,
	year = {2022},
	keywords = {Cultural heritage, Emergency response, Historic centre, Literature review, Post-disaster recovery, Risk assessment, Risk mitigation},
	pages = {102652},
	file = {ScienceDirect Snapshot:files/9943/S2212420921006130.html:text/html},
}

@book{bonazza_safeguarding_2018,
	address = {Luxembourg},
	title = {Safeguarding {Cultural} {Heritage} from {Natural} and {Man}-{Made} {Disasters}: {A} comparative analysis of risk management in the {EU}},
	copyright = {cc\_by},
	isbn = {978-92-79-73945-3},
	shorttitle = {Safeguarding {Cultural} {Heritage} from {Natural} and {Man}-{Made} {Disasters}},
	url = {https://openarchive.icomos.org/id/eprint/2329/},
	abstract = {Natural and man-made hazards, anthropogenic effects and extreme climate change events, are persistently putting the cultural heritage of Europe under pressure, with a daily incremental frequency. In addition, such disasters and catastrophes compound the conservation challenges and needs of the heritage assets. These events also menace the assets’ social, cultural, historic and artistic values, the safety of citizens, and have an impact on local economies linked to tourism. Consequently, research on adaptation strategies, methodologies and other remedial tools is crucial, in order to safeguard Europe's cultural heritage from the continuous pressures it faces and the related decayinducing consequences. This Study presents a comprehensive overview of the existing knowledge, at European and international level, on safeguarding cultural heritage from the effects of natural disasters and threats caused by human action. Furthermore, it maps existing strategies and tools for disaster risk management in the 28 Member States, and provides evidencebased recommendations with the purpose of supporting European cooperation and improving the integration of cultural heritage in national platforms for Disaster Risk Reduction},
	language = {fr},
	urldate = {2023-11-29},
	publisher = {Publications Office of the European Union},
	author = {Bonazza, Alessandra and Maxwell, Ingval and Drdácký, Miloš and Vintzileou, Ellizabeth and Hanus, Christian},
	year = {2018},
	file = {Full Text PDF:files/9947/Bonazza et al. - 2018 - Safeguarding Cultural Heritage from Natural and Ma.pdf:application/pdf;Snapshot:files/9946/2329.html:text/html},
}

@misc{peroni_dasplab_nodate,
	title = {{DASPLab}, {DISI}, {University} of {Bologna}, {Bologna}, {Italy}},
	url = {https://essepuntato.it/papers/samod-owled2016.html},
	urldate = {2023-11-29},
	author = {Peroni, Silvio},
	file = {Snapshot:files/9949/samod-owled2016.html:text/html},
}

@inproceedings{doerr_cidoc_2007,
	title = {The {CIDOC} {Conceptual} {Reference} {Model} - {A} {New} {Standard} for {Knowledge} {Sharing}.},
	doi = {10.13140/2.1.1420.6400},
	abstract = {The tutorial first addresses requirements and semantic problems to integrate digital information into large scale, meaningful networks of knowledge that support not only access to source documents but also use and reuse of integrated information. The pros and cons of developing global ontologies are discussed. It is argued that core ontologies of relationships are fundamental to schema integration and play a completely different role to that of specialist terminologies in practical knowledge management. The CIDOC Conceptual Reference Model (CRM) is presented as an example of such a global model. It is a core ontology and new ISO standard (ISO 21127, accepted September 2006), originally designed for the semantic integration of information from museums, libraries, and archives. It is a product of re-engineering the dominant underlying common concepts from representative data structures. It is not prescriptive, but provides a controlled language to describe common high-level semantics that allow for information integration at the schema level. The tutorial addresses part of the technology needed for information aggregation and integration in the global information environment, namely the question to which extent and in which form global schema integration is feasible. The ability of the CRM to support integration has been demonstrated in a large range of different domains including cultural heritage, e-science and biodiversity. Conceptual modeling by specializing such a well-tested core ontology not only reduces drastically development time and improves system quality, but provides basic semantic interoperability more or less for free. The tutorial will present characteristic applications.},
	author = {Doerr, Martin and Ore, Christian-Emil and Stead, Stephen},
	month = jan,
	year = {2007},
	pages = {51--56},
	file = {Full Text PDF:files/9951/Doerr et al. - 2007 - The CIDOC Conceptual Reference Model - A New Stand.pdf:application/pdf},
}

@article{horekens_disaster_2007,
	title = {Disaster {Reduction} and the {Hyogo} {Framework} for {Action}},
	volume = {26},
	issn = {1020-4067},
	url = {https://www.jstor.org/stable/45054270},
	number = {4},
	urldate = {2023-11-30},
	journal = {Refugee Survey Quarterly},
	author = {Horekens, John},
	year = {2007},
	note = {Publisher: Oxford University Press},
	pages = {250--254},
	file = {JSTOR Full Text PDF:files/9954/Horekens - 2007 - Disaster Reduction and the Hyogo Framework for Act.pdf:application/pdf},
}

@incollection{cunliffe_methods_2023,
	title = {Methods, {Motivations}, and {Actors}: {A} {Risk}-{Based} {Approach} to {Heritage} {Destruction} and {Protection}},
	isbn = {978-1-00-313106-9},
	shorttitle = {Methods, {Motivations}, and {Actors}},
	abstract = {This chapter provides a fresh perspective on cultural heritage damage: by creating a new framework to consider risk to cultural heritage, it provides a first step to approach damage mitigation and prevention more effectively. Damage occurs in a range of contexts: existing studies have examined specific actors and their motivations, specific heritage types, damage types, areas, and/or circumstances across the cycle of peace and conflict. Using the ABC Risk Management Approach as a departure point, this chapter untangles and explores the key facets of damage studies to understand the problem holistically: who are the stakeholders in destruction; what is lost; when does it occur; where is it most likely to occur; how does it occur; and why is it destroyed, placing them in a comparable framework. By understanding their interrelation, broad risk drivers are established, along with the magnifying and reducing factors that affect them, providing a detailed view of potential risks to sites and enabling cross-comparison to develop understanding of risk of loss to cultural heritage, and in doing so, providing steps towards prioritising mitigation.},
	booktitle = {The {Routledge} {Handbook} of {Heritage} {Destruction}},
	publisher = {Routledge},
	author = {Cunliffe, Emma},
	year = {2023},
	note = {Num Pages: 17},
}

@book{bonazza_safeguarding_2018-1,
	address = {Luxembourg},
	title = {Safeguarding {Cultural} {Heritage} from {Natural} and {Man}-{Made} {Disasters}: {A} comparative analysis of risk management in the {EU}},
	copyright = {cc\_by},
	isbn = {978-92-79-73945-3},
	shorttitle = {Safeguarding {Cultural} {Heritage} from {Natural} and {Man}-{Made} {Disasters}},
	url = {https://openarchive.icomos.org/id/eprint/2329/},
	abstract = {Natural and man-made hazards, anthropogenic effects and extreme climate change events, are persistently putting the cultural heritage of Europe under pressure, with a daily incremental frequency. In addition, such disasters and catastrophes compound the conservation challenges and needs of the heritage assets. These events also menace the assets’ social, cultural, historic and artistic values, the safety of citizens, and have an impact on local economies linked to tourism. Consequently, research on adaptation strategies, methodologies and other remedial tools is crucial, in order to safeguard Europe's cultural heritage from the continuous pressures it faces and the related decayinducing consequences. This Study presents a comprehensive overview of the existing knowledge, at European and international level, on safeguarding cultural heritage from the effects of natural disasters and threats caused by human action. Furthermore, it maps existing strategies and tools for disaster risk management in the 28 Member States, and provides evidencebased recommendations with the purpose of supporting European cooperation and improving the integration of cultural heritage in national platforms for Disaster Risk Reduction},
	language = {fr},
	urldate = {2023-11-30},
	publisher = {Publications Office of the European Union},
	author = {Bonazza, Alessandra and Maxwell, Ingval and Drdácký, Miloš and Vintzileou, Ellizabeth and Hanus, Christian},
	year = {2018},
	file = {Full Text PDF:files/9958/Bonazza et al. - 2018 - Safeguarding Cultural Heritage from Natural and Ma.pdf:application/pdf;Snapshot:files/9957/2329.html:text/html},
}

@article{ramalhinho_cultural_2019-1,
	title = {Cultural heritage risk analysis models: {An} overview},
	volume = {10},
	copyright = {openAccess},
	issn = {2067-533X},
	shorttitle = {Cultural heritage risk analysis models},
	url = {https://run.unl.pt/handle/10362/104548},
	abstract = {The risk assessment is a critical step in achieving, defining and supporting the decision-making process. In this context, in the past two decades, an increase in the number of models for assessing/analysis of risks applied to collections and/or immobile cultural heritage was observed. The present work consists of the first review of the literature, from 1999 to 2016, on risk assessment applied to movable and immovable cultural heritage. A total of twenty-seven risk assessment models have been compiled that can be applied to different types of cultural heritage such as: immovable property (26\%) and movable property (74\%). It was possible to conclude that approximately 48\% of the risk analysis models are quantitative, 19\% are semi-quantitative and 33\% of the models are qualitative. Two different tables were created in order to help the reader: one for movable and another to immovable cultural heritage. These tables compile information to characterize the models (name, type, applicability, examples, date and references). The advantages and disadvantages of using each model was discuss in a separated table.},
	language = {eng},
	number = {1},
	urldate = {2023-11-30},
	journal = {International Journal of Conservation Science},
	author = {Ramalhinho, Ana Rita and Macedo, Maria Filomena},
	month = jan,
	year = {2019},
	note = {Accepted: 2020-09-22T22:15:46Z},
	pages = {39--58},
	file = {Full Text PDF:files/9960/Ramalhinho e Macedo - 2019 - Cultural heritage risk analysis models An overvie.pdf:application/pdf},
}

@article{lawrynowicz_hazardous_nodate,
	title = {The {Hazardous} {Situation} {Ontology} {Design} {Pattern}},
	abstract = {This extended abstract describes an ontology design pattern for modeling hazardous situations. We build upon state-of-art models for hazards and hazardous events, and on existing standards in the domain of occupational safety. We also present an example of the application of the pattern in the occupational safety and health domain.},
	language = {en},
	author = {Lawrynowicz, Agnieszka and Lawniczak, Ilona},
	file = {Lawrynowicz e Lawniczak - The Hazardous Situation Ontology Design Pattern.pdf:files/9961/Lawrynowicz e Lawniczak - The Hazardous Situation Ontology Design Pattern.pdf:application/pdf},
}

@article{cheatham_modification_2016,
	title = {A {Modification} to the {Hazardous} {Situation} {ODP} to {Support} {Risk} {Assessment} and {Mitigation}},
	url = {https://www.semanticscholar.org/paper/A-Modification-to-the-Hazardous-Situation-ODP-to-Cheatham-Ferguson/931db5c6b3261e2b8b54ffdeb09242b4de36f741},
	abstract = {This work presents a modification to the Hazardous Situation ontology design pattern that enables it to additionally support proactive questions central to risk assessment and mitigation planning. The Hazardous Situation ontology design pattern models the consequences of exposure of an object to a hazard. In its current form, the ODP is well suited for representing the consequences of exposure after the fact, which is very useful for applications such as damage assessment and recovery planning. In this work, we present a modification to this pattern that enables it to additionally support proactive questions central to risk assessment and mitigation planning.},
	language = {en},
	urldate = {2023-11-30},
	journal = {WOP@ISWC},
	author = {Cheatham, M. and Ferguson, Holly and Vardeman, Charles and Shimizu, C.},
	year = {2016},
	file = {Snapshot:files/9964/931db5c6b3261e2b8b54ffdeb09242b4de36f741.html:text/html},
}

@article{mazimwe_ontology_2019,
	title = {Ontology {Design} {Patterns} for {Representing} {Knowledge} in the {Disaster} {Risk} {Domain}},
	url = {https://ieeexplore.ieee.org/document/8795418/},
	doi = {10.1109/WETICE.2019.00066},
	abstract = {The success of disaster risk management efforts depends on the ability of multiple stakeholders to share disaster-related information. Semantic integration of such heterogeneous information requires ontology building. The top-down approach of ontology building has several disadvantages to knowledge representation. To support the process of ontology engineering, a bottom-up-approach that utilizes modular Ontology Design Patterns (ODPs) with weak dependencies can be used to overcome the disadvantages of the top-down approach. To bridge the availability gap of patterns for representing disaster knowledge, the study identifies existing and emerging patterns that can be used to organize disaster knowledge. Based on the eXtreme Design (XD) methodology and key informant interviews, Competency Questions (CQs) were listed from domain stakeholders. Consequently, corresponding patterns covering the CQs were also identified and developed. This study identifies emerging patterns such as Event Type ODP for representing risky and hazardous events. The QualityCausation ODP is also identified for representing the causality nature of vulnerability. The resulting patterns are aligned to the DOLCE foundational ontology and can be used to organize data in the disaster domain.},
	urldate = {2023-11-30},
	journal = {2019 IEEE 28th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE)},
	author = {Mazimwe, Allan and Hammouda, Imed and Gidudu, Anthony},
	month = jun,
	year = {2019},
	note = {Conference Name: 2019 IEEE 28th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE)
ISBN: 9781728106762
Place: Napoli, Italy
Publisher: IEEE},
	pages = {283--288},
}

@article{gaur_empathi_2019,
	title = {Empathi: {An} {Ontology} for {Emergency} {Managing} and {Planning} {About} {Hazard} {Crisis}},
	shorttitle = {Empathi},
	url = {https://ieeexplore.ieee.org/document/8665539/},
	doi = {10.1109/ICOSC.2019.8665539},
	abstract = {In the domain of emergency management during hazard crises, having sufficient situational awareness information is critical. It requires capturing and integrating information from sources such as satellite images, local sensors and social media content generated by local people. A bold obstacle to capturing, representing and integrating such heterogeneous and diverse information is lack of a proper ontology which properly conceptualizes this domain, aggregates and unifies datasets. Thus, in this paper, we introduce empathi ontology which conceptualizes the core concepts describing the domain of emergency managing and planning of hazard crises. Although empathi has a coarse-grained view, it considers the necessary concepts and relations being essential in this domain. This ontology is available at https://w3id.org/empathi/.},
	urldate = {2023-11-30},
	journal = {2019 IEEE 13th International Conference on Semantic Computing (ICSC)},
	author = {Gaur, Manas and Shekarpour, Saeedeh and Gyrard, Amelie and Sheth, Amit},
	month = jan,
	year = {2019},
	note = {Conference Name: 2019 IEEE 13th International Conference on Semantic Computing (ICSC)
ISBN: 9781538667835
Place: Newport Beach, CA, USA
Publisher: IEEE},
	pages = {396--403},
	file = {Versione inviata:files/9974/Gaur et al. - 2019 - Empathi An Ontology for Emergency Managing and Pl.pdf:application/pdf},
}

@article{mazimwe_implementation_2021,
	title = {Implementation of {FAIR} {Principles} for {Ontologies} in the {Disaster} {Domain}: {A} {Systematic} {Literature} {Review}},
	volume = {10},
	issn = {2220-9964},
	shorttitle = {Implementation of {FAIR} {Principles} for {Ontologies} in the {Disaster} {Domain}},
	url = {https://www.mdpi.com/2220-9964/10/5/324},
	doi = {10.3390/ijgi10050324},
	abstract = {The success of disaster management efforts demands meaningful integration of data that is geographically dispersed and owned by stakeholders in various sectors. However, the difficulty in finding, accessing and reusing interoperable vocabularies to organise disaster management data creates a challenge for collaboration among stakeholders in the disaster management cycle on data integration tasks. Thus the need to implement FAIR principles that describe the desired features ontologies should possess to maximize sharing and reuse by humans and machines. In this review, we explore the extent to which sharing and reuse of disaster management knowledge in the domain is inline with FAIR recommendations. We achieve this through a systematic search and review of publications in the disaster management domain based on a predefined inclusion and exclusion criteria. We then extract social-technical features in selected studies and evaluate retrieved ontologies against the FAIR maturity model for semantic artefacts. Results reveal that low numbers of ontologies representing disaster management knowledge are resolvable via URIs. Moreover, 90.9\% of URIs to the downloadable disaster management ontology artefacts do not conform to the principle of uniqueness and persistence. Also, only 1.4\% of all retrieved ontologies are published in semantic repositories and 84.1\% are not published at all because there are no repositories dedicated to archiving disaster domain knowledge. Therefore, there exists a very low level of Findability (1.8\%) or Accessibility (5.8\%), while Interoperability and Reusability are moderate (49.1\% and 30.2 \% respectively). The low adherence of disaster vocabularies to FAIR Principles poses a challenge to disaster data integration tasks because of the limited ability to reuse previous knowledge during disaster management phases. By using FAIR indicators to evaluate the maturity in sharing, discovery and integration of disaster management ontologies, we reveal potential research opportunities for managing reusable and evolving knowledge in the disaster community.},
	language = {en},
	number = {5},
	urldate = {2023-11-30},
	journal = {ISPRS International Journal of Geo-Information},
	author = {Mazimwe, Allan and Hammouda, Imed and Gidudu, Anthony},
	month = may,
	year = {2021},
	pages = {324},
	file = {Full Text PDF:files/9978/Mazimwe et al. - 2021 - Implementation of FAIR Principles for Ontologies i.pdf:application/pdf},
}

@incollection{tomaszuk_covome_2022,
	title = {{CoVoMe}: {New} {Methodology} for {Building} {Controlled} {Vocabulary}},
	isbn = {978-3-030-98875-3},
	shorttitle = {{CoVoMe}},
	abstract = {The use of methodologies in knowledge management and engineering is deeply comprehensive due to their important advantages. In this paper, we propose CoVoMe that is a methodology for building controlled vocabularies. This methodology covers almost all variants of that vocabularies, and it is designed to be close to the currently available languages for creating thesauri, subject headings, taxonomies, authority files, synonym rings, and glossaries.KeywordsKnowledge organization systemControlled vocabularyMethodology},
	author = {Tomaszuk, Dominik},
	month = jan,
	year = {2022},
	doi = {10.1007/978-3-030-98876-0_4},
	pages = {41--56},
	file = {Full Text PDF:files/9982/Tomaszuk - 2022 - CoVoMe New Methodology for Building Controlled Vo.pdf:application/pdf},
}

@article{gangemi_publishing_2017-1,
	title = {The {Publishing} {Workflow} {Ontology} ({PWO})},
	volume = {8},
	issn = {1570-0844},
	url = {https://content.iospress.com/articles/semantic-web/sw230},
	doi = {10.3233/SW-160230},
	abstract = {In this paper we introduce the Publishing Workflow Ontology (PWO ), i.e., an OWL 2 DL ontology for the description of workflows that is particularly suitable for formalising typical publishing processes such as the publication of articles in journals},
	language = {en},
	number = {5},
	urldate = {2023-12-03},
	journal = {Semantic Web},
	author = {Gangemi, Aldo and Peroni, Silvio and Shotton, David and Vitali, Fabio},
	month = jan,
	year = {2017},
	note = {Publisher: IOS Press},
	pages = {703--718},
	file = {Full text:files/9985/Gangemi et al. - 2017 - The Publishing Workflow Ontology (PWO).pdf:application/pdf},
}

@inproceedings{suarez-figueroa_how_2009,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {How to {Write} and {Use} the {Ontology} {Requirements} {Specification} {Document}},
	isbn = {978-3-642-05151-7},
	doi = {10.1007/978-3-642-05151-7_16},
	abstract = {The goal of the ontology requirements specification activity is to state why the ontology is being built, what its intended uses are, who the end-users are, and which requirements the ontology should fulfill. The novelty of this paper lies in the systematization of the ontology requirements specification activity since the paper proposes detailed methodological guidelines for specifying ontology requirements efficiently. These guidelines will help ontology engineers to capture ontology requirements and produce the ontology requirements specification document (ORSD). The ORSD will play a key role during the ontology development process because it facilitates, among other activities, (1) the search and reuse of existing knowledge-aware resources with the aim of re-engineering them into ontologies, (2) the search and reuse of existing ontological resources (ontologies, ontology modules, ontology statements as well as ontology design patterns), and (3) the verification of the ontology along the ontology development. In parallel to the guidelines, we present the ORSD that resulted from the ontology requirements specification activity within the SEEMP project, and how this document facilitated not only the reuse of existing knowledge-aware resources but also the verification of the SEEMP ontologies. Moreover, we present some use cases in which the methodological guidelines proposed here were applied.},
	language = {en},
	booktitle = {On the {Move} to {Meaningful} {Internet} {Systems}: {OTM} 2009},
	publisher = {Springer},
	author = {Suárez-Figueroa, Mari Carmen and Gómez-Pérez, Asunción and Villazón-Terrazas, Boris},
	editor = {Meersman, Robert and Dillon, Tharam and Herrero, Pilar},
	year = {2009},
	keywords = {and Methodologies, Competency Questions, Ontology Requirements, Ontology Requirements Specification},
	pages = {966--982},
	file = {Full Text PDF:files/9987/Suárez-Figueroa et al. - 2009 - How to Write and Use the Ontology Requirements Spe.pdf:application/pdf},
}

@incollection{damato_widoco_2017,
	address = {Cham},
	title = {{WIDOCO}: {A} {Wizard} for {Documenting} {Ontologies}},
	volume = {10588},
	isbn = {978-3-319-68203-7 978-3-319-68204-4},
	shorttitle = {{WIDOCO}},
	url = {https://link.springer.com/10.1007/978-3-319-68204-4_9},
	abstract = {In this paper we describe WIDOCO, a WIzard for DOCumenting Ontologies that guides users through the documentation process of their vocabularies. Given an RDF vocabulary, WIDOCO detects missing vocabulary metadata and creates a documentation with diagrams, human readable descriptions of the ontology terms and a summary of changes with respect to previous versions of the ontology. The documentation consists on a set of linked enriched HTML pages that can be further extended by end users. WIDOCO is open source and builds on well established Semantic Web tools. So far, WIDOCO has been used to document more than one hundred ontologies in diﬀerent domains.},
	language = {en},
	urldate = {2023-12-04},
	booktitle = {The {Semantic} {Web} – {ISWC} 2017},
	publisher = {Springer International Publishing},
	author = {Garijo, Daniel},
	editor = {d'Amato, Claudia and Fernandez, Miriam and Tamma, Valentina and Lecue, Freddy and Cudré-Mauroux, Philippe and Sequeda, Juan and Lange, Christoph and Heflin, Jeff},
	year = {2017},
	doi = {10.1007/978-3-319-68204-4_9},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {94--102},
	file = {Garijo - 2017 - WIDOCO A Wizard for Documenting Ontologies.pdf:files/9988/Garijo - 2017 - WIDOCO A Wizard for Documenting Ontologies.pdf:application/pdf},
}

@article{poveda-villalon_oops_nodate,
	title = {{OOPS}! – {OntOlogy} {Pitfalls} {Scanner}!},
	abstract = {The application of methodologies for building ontologies has improved the ontology quality. However, such a quality is not totally guaranteed because of the difficulties involved in ontology modelling. These difficulties are related to the inclusion of anomalies or worst practices in the modelling. Several authors have provided lists of typical anomalies detected in ontologies during the last decade. In this context, our aim in this technical report is to describe OOPS! (OntOlogy Pitfalls Scanner!), a tool for pitfalls detection in ontology developments.},
	language = {en},
	author = {Poveda-Villalón, María and Suárez-Figueroa, Mari Carmen},
	file = {Poveda-Villalón e Suárez-Figueroa - OOPS! – OntOlogy Pitfalls Scanner!.pdf:files/9990/Poveda-Villalón e Suárez-Figueroa - OOPS! – OntOlogy Pitfalls Scanner!.pdf:application/pdf},
}

@incollection{gangemi_ontology_2009-2,
	address = {Berlin, Heidelberg},
	series = {International {Handbooks} on {Information} {Systems}},
	title = {Ontology {Design} {Patterns}},
	isbn = {978-3-540-92673-3},
	url = {https://doi.org/10.1007/978-3-540-92673-3_10},
	abstract = {Computational ontologies in the context of information systems are artifacts that encode a description of some world, for some purpose. Under the assumption that there exist classes of problems that can be solved by applying common solutions (as it has been experienced in software engineering), we envision small, task-oriented ontologies with explicit documentation of design rationales. In this chapter, we describe components called Ontology Design Patterns (OP), and methods that support pattern-based ontology design.},
	language = {en},
	urldate = {2023-12-04},
	booktitle = {Handbook on {Ontologies}},
	publisher = {Springer},
	author = {Gangemi, Aldo and Presutti, Valentina},
	editor = {Staab, Steffen and Studer, Rudi},
	year = {2009},
	doi = {10.1007/978-3-540-92673-3_10},
	keywords = {Design Pattern, Domain Ontology, Ontology Design, Ontology Engineering, Reference Ontology},
	pages = {221--243},
}

@article{mazimwe_pattern_2020,
	title = {A {Pattern} {Driven} {Approach} to {Knowledge} {Representation} in the {Disaster} {Domain}},
	volume = {1},
	issn = {2661-8907},
	url = {https://doi.org/10.1007/s42979-020-00342-5},
	doi = {10.1007/s42979-020-00342-5},
	abstract = {Access to integrated disaster-related data through querying is still a problem due to associated semantic barriers. The disaster domain largely relies on the top–down approach of ontology development. This limits reuse due to associated commitments and complex alignments within ontologies. Therefore, there is a need to utilize a bottom-up approach that reuses patterns for representing disaster knowledge. To bridge the availability gap of patterns for representing disaster knowledge, this study identifies existing and emerging patterns for reuse while organizing disaster data from multiple sector stakeholders. Based on the eXtreme Design (XD) methodology and key informant interviews, competency questions (CQs) were elicited from domain stakeholders. The CQs are matched with existing patterns from other contexts. Emerging patterns (e.g the Event Classification and Quality Dependence Description for Objects) are also developed for CQs not captured and subsequently tested using SPARQL queries characterising the CQs. It is in this context that this paper presents a characterisation of disaster risk knowledge using CQs and corresponding patterns (reusable and emerging) covering the knowledge. Accordingly, we illustrate a pattern-driven use case to organise drought hazard data for early warning purposes. This provides a powerful use case for adopting a pattern-based approach to knowledge representation in the disaster domain.},
	language = {en},
	number = {6},
	urldate = {2023-12-04},
	journal = {SN Computer Science},
	author = {Mazimwe, Allan and Hammouda, Imed and Gidudu, Anthony and Barasa, Bernard},
	month = oct,
	year = {2020},
	keywords = {Vulnerability, Ontology design patterns, Risk, Hazard},
	pages = {353},
	file = {Full Text PDF:files/9998/Mazimwe et al. - 2020 - A Pattern Driven Approach to Knowledge Representat.pdf:application/pdf},
}

@article{appiotti_definition_2020,
	title = {Definition of a {Risk} {Assessment} {Model} within a {European} {Interoperable} {Database} {Platform} ({EID}) for {Cultural} {Heritage}},
	volume = {46},
	issn = {1296-2074},
	url = {https://www.sciencedirect.com/science/article/pii/S1296207420304325},
	doi = {10.1016/j.culher.2020.08.001},
	abstract = {Nowadays, the topics related both to the safeguard and the valorization of cultural heritage and cultural assets are getting more attention in the political agenda. Innovative approaches to implement both the risk analysis and the resilience assessment are ever more required. This paper illustrates an original approach, concerning the development of a risk assessment model for cultural assets, with reference to fire, earthquake and flood. The proposed model includes specific evaluation tools, that are based on parameters and indicators related to the factors of hazard and vulnerability for the three considered types of risk. The multi-dimensional set of indicators is used to get synthetics indices, through a multicriteria approach. Furthermore, this evaluation is supported by specific questionnaires to include in the assessment model the opinion of different experts and stakeholders to introduce the indicators weights. The results of this model are represented by specific evaluation tools which can be implemented in the risk assessment of cultural assets in different specific situations.},
	urldate = {2023-12-04},
	journal = {Journal of Cultural Heritage},
	author = {Appiotti, Federica and Assumma, Vanessa and Bottero, Marta and Campostrini, Pierpaolo and Datola, Giulia and Lombardi, Patrizia and Rinaldi, Enrico},
	month = nov,
	year = {2020},
	keywords = {cultural heritage, architecture, evaluation model, indicators and indices, multicriteria analysis, risk analysis},
	pages = {268--277},
	file = {ScienceDirect Snapshot:files/10000/S1296207420304325.html:text/html},
}

@inproceedings{bajena_metadata_2023,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Metadata for {3D} {Digital} {Heritage} {Models}. {In} the {Search} of a {Common} {Ground}},
	isbn = {978-3-031-38871-2},
	doi = {10.1007/978-3-031-38871-2_4},
	abstract = {The publication of 3D models has been an unregulated issue for many years. Recently, it has been possible to identify barriers that have prevented the proper preparation of 3D data for web-based publication, related to uncleared copyright issues, access to 3D files, targeted audiences, or distinction of requirements related to different stages of the digital asset lifecycle. In response to these challenges, numerous scientific infrastructures with diverse backgrounds and purposes have emerged, presenting different approaches to metadata documentation schemes. This publication aims to present an analysis of existing metadata schemas carried out in a workshop with selected initiatives and digital data repositories on metadata for digital heritage to find the common grounds between the various metadata schemas. The compilation of multiple documentation schemas is used to develop an approach for the creation of a universal documentation metadata patterns that could guide the work on the standardisation of 3D models of cultural heritage.},
	language = {en},
	booktitle = {Research and {Education} in {Urban} {History} in the {Age} of {Digital} {Libraries}},
	publisher = {Springer Nature Switzerland},
	author = {Bajena, Igor and Kuroczyński, Piotr},
	editor = {Münster, Sander and Pattee, Aaron and Kröber, Cindy and Niebling, Florian},
	year = {2023},
	keywords = {digital heritage, metadata schema, 3d models, data interoperability, data repositories, documentation},
	pages = {45--64},
	file = {Full Text PDF:files/10008/Bajena e Kuroczyński - 2023 - Metadata for 3D Digital Heritage Models. In the Se.pdf:application/pdf},
}

@inproceedings{roman_infrarisk_2017,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {InfraRisk} {Ontology}: {Enabling} {Semantic} {Interoperability} for {Critical} {Infrastructures} at {Risk} from {Natural} {Hazards}},
	isbn = {978-3-319-69459-7},
	shorttitle = {The {InfraRisk} {Ontology}},
	doi = {10.1007/978-3-319-69459-7_31},
	abstract = {Earthquakes, landslides, and other natural hazard events have severe negative socio-economic impacts. Among other consequences, those events can cause damage to infrastructure networks such as roads and railways. Novel methodologies and tools are needed to analyse the potential impacts of extreme natural hazard events and aid in the decision-making process regarding the protection of existing critical road and rail infrastructure as well as the development of new infrastructure. Enabling uniform, integrated, and reliable access to data on historical failures of critical transport infrastructure can help infrastructure managers and scientist from various related areas to better understand, prevent, and mitigate the impact of natural hazards on critical infrastructures. This paper describes the construction of the InfraRisk ontology for representing relevant information about natural hazard events and their impact on infrastructure components. Furthermore, we present a software prototype that visualizes data published using the proposed ontology.},
	language = {en},
	booktitle = {On the {Move} to {Meaningful} {Internet} {Systems}. {OTM} 2017 {Conferences}},
	publisher = {Springer International Publishing},
	author = {Roman, Dumitru and Sukhobok, Dina and Nikolov, Nikolay and Elvesæter, Brian and Pultier, Antoine},
	editor = {Panetto, Hervé and Debruyne, Christophe and Gaaloul, Walid and Papazoglou, Mike and Paschke, Adrian and Ardagna, Claudio Agostino and Meersman, Robert},
	year = {2017},
	keywords = {Ontology, Events, Infrastructure components, Natural hazards},
	pages = {463--479},
	file = {Full Text PDF:files/10013/Roman et al. - 2017 - The InfraRisk Ontology Enabling Semantic Interope.pdf:application/pdf},
}

@inproceedings{niccolucci_cidoc_2018-1,
	title = {A {CIDOC} {CRM}-based {Model} for the {Documentation} of {Heritage} {Sciences}},
	url = {https://ieeexplore.ieee.org/abstract/document/8810109},
	doi = {10.1109/DigitalHeritage.2018.8810109},
	abstract = {The paper describes an approach to the documentation of scientific data produced in heritage sciences interdisciplinary research. Since such activities fall within the scope of a scientific discipline (e.g. physics or chemistry) and of cultural heritage, the documentation system must draw from both. The paper proposes an overarching system based on the use of CIDOC CRM and its extensions CRMsci, CRMdig and CRMpe to model physical and digital objects, events and activities, and actors, i.e. people and teams. It is suggested that such a model could address most - if not all - of the issues encountered documenting heritage sciences results. The use of the CRM provides straightforward connection and interoperability with the general documentation of cultural heritage and thus tightly links scientific analyses to their heritage context. A number of examples demonstrate how to apply this approach to different cases and offer an overview of the whole model, which is not fully exposed here: full details will be given in a separate technical document.},
	urldate = {2023-12-06},
	booktitle = {2018 3rd {Digital} {Heritage} {International} {Congress} ({DigitalHERITAGE}) held jointly with 2018 24th {International} {Conference} on {Virtual} {Systems} \& {Multimedia} ({VSMM} 2018)},
	author = {Niccolucci, Franco and Felicetti, Achille},
	month = oct,
	year = {2018},
	pages = {1--6},
	file = {IEEE Xplore Full Text PDF:files/10015/Niccolucci e Felicetti - 2018 - A CIDOC CRM-based Model for the Documentation of H.pdf:application/pdf},
}

@article{zalamea_citygml_2016,
	title = {From a {CityGML} to an ontology-based approach to support preventive conservation of built cultural heritage},
	abstract = {Built Cultural Heritage (BCH) management requires information from several domains and sources. The integration of this information is complicated because multiple scales and dimension levels are involved, along with different data models. Therefore, sources rarely share the same information structure and/or the terminology is syntactically and semantically different. In BCH-management there is a focus on the representation of 3D features in a spatially explicit way and one of the mains standards used to create this representation is the City Geography Markup Language (CityGML) standard. However, the CityGML standard does not provide sufficient semantics as required for a proper BCHmanagement, even after extending the definition of the standard with particular classes for the BCH-domain. An ontological model could fill these semantic gaps and provide some improvements to the original model. Through the application of a use case we converted the CityGML preventive conservation model to a taxonomy, which can be used later to identify current ontologies, which partially or completely matches the classes represented in the taxonomy.},
	language = {en},
	author = {Zalamea, Olga and Orshoven, Jos Van and Steenberghen, Thérèse},
	year = {2016},
	file = {Zalamea et al. - 2016 - From a CityGML to an ontology-based approach to su.pdf:files/10016/Zalamea et al. - 2016 - From a CityGML to an ontology-based approach to su.pdf:application/pdf},
}

@incollection{lodi_semantic_2017,
	address = {Cham},
	series = {Multimedia {Systems} and {Applications}},
	title = {Semantic {Web} for {Cultural} {Heritage} {Valorisation}},
	isbn = {978-3-319-54499-1},
	url = {https://doi.org/10.1007/978-3-319-54499-1_1},
	abstract = {Cultural heritage consists of heterogeneous resources: archaeological artefacts, monuments, sites, landscapes, paintings, photos, books and expressions of human creativity, often enjoyed in different forms: tangible, intangible or digital. Each resource is usually documented, conserved and managed by cultural institutes like museums, libraries or holders of archives. These institutes make available a detailed description of the objects as catalog records. In this context, the chapter proposes both a classification of cultural heritage data types and a process for cultural heritage valorisation through the well-known Linked Open Data paradigm. The classification and process have been defined in the context of a collaboration between the Semantic Technology Laboratory of the National Research Council (STLab) and the Italian Ministry of Cultural Heritage and Activities and Tourism (MIBACT) that the chapter describes, although we claim they are sufficiently general to be adopted in every cultural heritage scenario. In particular, the chapter introduces both a suite of ontology modules named Cultural-ON to model the principal elements identified in the cultural heritage data type classification, and the process we employed for data valorisation purposes. To this end, semantic technologies are exploited; that is, technologies that allow us to conceptualise and describe the meaning of data forming the cultural heritage and including such entities as places, institutions, cultural heritage events, availability, etc. These entities have special characteristics and are connected with each other in a profound way. The result is a knowledge base consisting of semantic interconnections with also other data available in the Web to be exploited according to different tasks and users preferences. By navigating the semantic relationships between the various objects of the knowledge base, new semantic paths can be revealed and utilised with the aim to develop innovative services and applications. The process is compliant with Linked Open Data and W3C Semantic Web best practices so that to enable a wider promotion of cultural heritage, and of sharing and reuse of cultural heritage data in the Web. The chapter concludes presenting a number of methodological principles and lessons learnt from the STLab/MIBACT collaboration that are applicable to any cultural heritage context and, in some cases, also to other domains.},
	language = {en},
	urldate = {2023-12-06},
	booktitle = {Data {Analytics} in {Digital} {Humanities}},
	publisher = {Springer International Publishing},
	author = {Lodi, Giorgia and Asprino, Luigi and Nuzzolese, Andrea Giovanni and Presutti, Valentina and Gangemi, Aldo and Recupero, Diego Reforgiato and Veninata, Chiara and Orsini, Annarita},
	editor = {Hai-Jew, Shalin},
	year = {2017},
	doi = {10.1007/978-3-319-54499-1_1},
	keywords = {Cultural Heritage, Link Open Data, Cultural Institute, Ontology Module, Resource Description Framework},
	pages = {3--37},
}

@article{baker_grammar_2000,
	title = {A {Grammar} of {Dublin} {Core}},
	volume = {6},
	issn = {1082-9873},
	url = {http://www.dlib.org/dlib/october00/baker/10baker.html},
	doi = {10.1045/october2000-baker},
	language = {en},
	number = {10},
	urldate = {2023-12-06},
	journal = {D-Lib Magazine},
	author = {Baker, Thomas},
	month = oct,
	year = {2000},
	file = {Baker - 2000 - A Grammar of Dublin Core.pdf:files/10024/Baker - 2000 - A Grammar of Dublin Core.pdf:application/pdf},
}

@inproceedings{sugimoto_dublin_2002,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Dublin {Core}: {Process} and {Principles}},
	isbn = {978-3-540-36227-2},
	shorttitle = {Dublin {Core}},
	doi = {10.1007/3-540-36227-4_3},
	abstract = {The Dublin Core metadata element set has been widely adopted by cultural and scientific institutions, libraries, governments, and businesses to describe resources for discovery on the Internet. This paper provides an overview of its history and underlying principles and describes the activities of Dublin Core Metadata Initiative (DCMI) as an organization.},
	language = {en},
	booktitle = {Digital {Libraries}: {People}, {Knowledge}, and {Technology}},
	publisher = {Springer},
	author = {Sugimoto, Shigeo and Baker, Thomas and Weibel, Stuart L.},
	editor = {Lim, Ee- Peng and Foo, Schubert and Khoo, Chris and Chen, Hsinchun and Fox, Edward and Urs, Shalini and Costantino, Thanos},
	year = {2002},
	keywords = {Resource Description Framework, Application Profile, Metadata Schema, Resource Discovery, Semantic Interoperability},
	pages = {25--35},
	file = {Full Text PDF:files/10027/Sugimoto et al. - 2002 - Dublin Core Process and Principles.pdf:application/pdf},
}

@inproceedings{falco_modelling_2014,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Modelling {OWL} {Ontologies} with {Graffoo}},
	isbn = {978-3-319-11955-7},
	doi = {10.1007/978-3-319-11955-7_42},
	abstract = {In this paper we introduce Graffoo, i.e., a graphical notation to develop OWL ontologies by means of yEd, a free editor for diagrams.},
	language = {en},
	booktitle = {The {Semantic} {Web}: {ESWC} 2014 {Satellite} {Events}},
	publisher = {Springer International Publishing},
	author = {Falco, Riccardo and Gangemi, Aldo and Peroni, Silvio and Shotton, David and Vitali, Fabio},
	editor = {Presutti, Valentina and Blomqvist, Eva and Troncy, Raphael and Sack, Harald and Papadakis, Ioannis and Tordai, Anna},
	year = {2014},
	keywords = {OWL, DiTTO, Graffoo, Graphical notation, yEd},
	pages = {320--325},
	file = {Full Text PDF:files/10030/Falco et al. - 2014 - Modelling OWL Ontologies with Graffoo.pdf:application/pdf},
}

@article{noy_protege-2000_2003,
	title = {Protégé-2000: {An} {Open}-{Source} {Ontology}-{Development} and {Knowledge}-{Acquisition} {Environment}},
	volume = {2003},
	shorttitle = {Protégé-2000},
	abstract = {Protégé-2000 is an open-source tool that assists users in the construction of large electronic knowledge bases. It has an intuitive user interface that enables developers to create and edit domain ontologies. Numerous plugins provide alternative visualization mechanisms, enable management of multiple ontologies, allow the use of interference engines and problem solvers with Protégé ontologies, and provide other functionality. The Protégé user community has more than 7000 members.},
	journal = {AMIA ... Annual Symposium proceedings / AMIA Symposium. AMIA Symposium},
	author = {Noy, Natasha and Crubezy, Monica and Fergerson, Ray and Knublauch, Holger and Tu, Samson and Vendetti, Jennifer and Musen, Mark},
	month = feb,
	year = {2003},
	pages = {953},
	file = {Full Text PDF:files/10033/Noy et al. - 2003 - Protégé-2000 An Open-Source Ontology-Development .pdf:application/pdf},
}

@book{hitzler_ontology_2016,
	title = {Ontology {Engineering} with {Ontology} {Design} {Patterns}: {Foundations} and {Applications}},
	isbn = {978-1-61499-676-7},
	shorttitle = {Ontology {Engineering} with {Ontology} {Design} {Patterns}},
	abstract = {The use of ontologies for data and knowledge organization has become ubiquitous in many data-intensive and knowledge-driven application areas, in science, industry, and the humanities. At the same time, ontology engineering best practices continue to evolve. In particular, modular ontology modeling based on ontology design patterns is establishing itself as an approach for creating versatile and extendable ontologies for data management and integration. This book is the very first comprehensive treatment of Ontology Engineering with Ontology Design Patterns. It contains both advanced and introductory material accessible for readers with only a minimal background in ontology modeling. Some introductory material is written in the style of tutorials, and specific chapters are devoted to examples and to applications. Other chapters convey the state of the art in research regarding ontology design patterns. The editors and the contributing authors include the leading contributors to the development of ontology-design-pattern-driven ontology engineering.},
	language = {en},
	publisher = {IOS Press},
	author = {Hitzler, P. and Gangemi, A. and Janowicz, K.},
	month = sep,
	year = {2016},
	note = {Google-Books-ID: 9hChDQAAQBAJ},
	keywords = {Computers / Artificial Intelligence / General, Computers / System Administration / Storage \& Retrieval},
}

@inproceedings{sales_common_2018-1,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Common} {Ontology} of {Value} and {Risk}},
	isbn = {978-3-030-00847-5},
	doi = {10.1007/978-3-030-00847-5_11},
	abstract = {Risk analysis is traditionally accepted as a complex and critical activity in various contexts, such as strategic planning and software development. Given its complexity, several modeling approaches have been proposed to help analysts in representing and analyzing risks. Naturally, having a clear understanding of the nature of risk is fundamental for such an activity. Yet, risk is still a heavily overloaded and conceptually unclear notion, despite the wide number of efforts to properly characterize it, including a series of international standards. In this paper, we address this issue by means of an in-depth ontological analysis of the notion of risk. In particular, this analysis shows a surprising and important result, namely, that the notion of risk is irreducibly intertwined with the notion of value and, more specifically, that risk assessment is a particular case of value ascription. As a result, we propose a concrete artifact, namely, the Common Ontology of Value and Risk, which we employ to harmonize different conceptions of risk existing in the literature.},
	language = {en},
	booktitle = {Conceptual {Modeling}},
	publisher = {Springer International Publishing},
	author = {Sales, Tiago Prince and Baião, Fernanda and Guizzardi, Giancarlo and Almeida, João Paulo A. and Guarino, Nicola and Mylopoulos, John},
	editor = {Trujillo, Juan C. and Davis, Karen C. and Du, Xiaoyong and Li, Zhanhuai and Ling, Tok Wang and Li, Guoliang and Lee, Mong Li},
	year = {2018},
	keywords = {Risk, Enterprise modeling, OntoUML, Risk modeling, Value},
	pages = {121--135},
	file = {Full Text PDF:files/10040/Sales et al. - 2018 - The Common Ontology of Value and Risk.pdf:application/pdf},
}

@article{boccardi_authenticity_2019,
	title = {Authenticity in the {Heritage} {Context}: {A} {Reflection} beyond the {Nara} {Document}},
	volume = {10},
	issn = {1756-7505},
	shorttitle = {Authenticity in the {Heritage} {Context}},
	url = {https://doi.org/10.1080/17567505.2018.1531647},
	doi = {10.1080/17567505.2018.1531647},
	abstract = {The notion of authenticity in the cultural heritage context has been at the centre of an intense debate and policy evolution over the past decades, with significant normative implications, notably within the World Heritage Convention. Two main factors have been driving these processes: the need to integrate new cultural perspectives into the discipline, especially from the non-Western world; and the growing recognition of the role of ‘communities’ in defining heritage value.A shared understanding of what authenticity means and of how it can be demonstrated, however, seems to be still lacking among practitioners and scholars. This is shown by the continuing controversies among experts, as well as by the comparatively large number of heritage properties which, in their nominations for World Heritage inscription, are apparently unable to make a convincing case for their authenticity, at least according to ICOMOS’ evaluation.Against this background, the paper aims at providing a clearer definition of what authenticity means in the context of cultural heritage conservation. It does so by reassessing the whole question from a fresh perspective, drawing more from philosophical and semantic conceptual frameworks than from the existing corpus of doctrinal texts in the heritage field, in an attempt to clarify persisting ambiguities and contribute to the ongoing reflection. In doing so, the paper provides the key elements of a framework to operationalise the concept of authenticity within the cultural heritage context, while also highlighting issues that will require further study and exploration.},
	number = {1},
	urldate = {2023-12-08},
	journal = {The Historic Environment: Policy \& Practice},
	author = {Boccardi, Giovanni},
	month = jan,
	year = {2019},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/17567505.2018.1531647},
	keywords = {cultural heritage, Authenticity, definition, Nara Document},
	pages = {4--18},
}

@incollection{moore_ten_2023,
	title = {The {Ten} {Agents} of {Deterioration}},
	isbn = {978-1-00-316267-4},
	abstract = {The Ten Agents of Deterioration - 1},
	booktitle = {Conservation of {Books}},
	publisher = {Routledge},
	author = {Moore, Tiffany Eng, Caroline Bendix},
	year = {2023},
	note = {Num Pages: 20},
}

@incollection{guarino_what_2009,
	address = {Berlin, Heidelberg},
	series = {International {Handbooks} on {Information} {Systems}},
	title = {What {Is} an {Ontology}?},
	isbn = {978-3-540-92673-3},
	url = {https://doi.org/10.1007/978-3-540-92673-3_0},
	abstract = {The word “ontology” is used with different senses in different communities. The most radical difference is perhaps between the philosophical sense, which has of course a well-established tradition, and the computational sense, which emerged in the recent years in the knowledge engineering community, starting from an early informal definition of (computational) ontologies as “explicit specifications of conceptualizations”. In this paper we shall revisit the previous attempts to clarify and formalize such original definition, providing a detailed account of the notions of conceptualization and explicit specification, while discussing at the same time the importance of shared explicit specifications.},
	language = {en},
	urldate = {2023-12-08},
	booktitle = {Handbook on {Ontologies}},
	publisher = {Springer},
	author = {Guarino, Nicola and Oberle, Daniel and Staab, Steffen},
	editor = {Staab, Steffen and Studer, Rudi},
	year = {2009},
	doi = {10.1007/978-3-540-92673-3_0},
	keywords = {COOPERATION WITH, Explicit Specification, First-order Logic Language, Semiotic Triangle, Specific World State},
	pages = {1--17},
}

@article{barzaghi_atlas_2023,
	title = {{ATLAS} {Data} {Model}},
	url = {https://zenodo.org/records/10225594},
	abstract = {The ATLAS data model is used to structure the knowledge graph storing the data used in the ATLAS web platform within the SIRIUS project. It has been developed by using a slightly modified version of the Simplified Agile Methodology for Ontology Development (SAMOD) (http://dx.doi.org/10.6084/m9.figshare.3189769).This repository contains the full documentation produced during the development of the data model. In particular:the data directory contains the full set of refactored ABoxes, one for each iteration, written in the Turtle RDF serialization;the development directory contains a folder per development iteration, each containing a full test case with:a motivating scenario, which defines the scope of the single iteration, along with some examples;a list of informal Competency Questions, written in natural language;a glossary of terms, which defines a set of meaningful words and expressions - representing possible entities and relationships - collected from the scenario and the competency questions;a Graffoo visual diagram of the entites and relationships recorded in the glossary, rendered in .png format and coupled with the .graphml file it has been exported from;a terminology component (TBox), which defines a formal schema based on the diagram;an assertion component (ABox), which organizes the examples data according to the schema;a list of formal Competency Questions, which reformulate the informal competency questions into proper SPARQL queries;a testing notebook, which is used to test the SPARQL queries against both the TBox and the ABox;a crosswalk table, which bridges the development step with the refactoring step by documenting the alignment between the glossary terms and the refactored terms.the diagrams directory contains the full set of Graffoo diagrams representing the refactored model of each iteration;the docs directory contains the full set of files related to the final model and its versions in time;the sparql directory contains the full set of refactored Formal Competency Questions.},
	language = {eng},
	urldate = {2023-12-08},
	author = {Barzaghi, Sebastian},
	month = nov,
	year = {2023},
	note = {Publisher: Zenodo},
	keywords = {ontology, atlas, atlas-data-model, cultural-heritage, data-model, digital-humanities, environmental-heritage, risk, risk-assessment, samod, semantic-web, sirius, sirius-project},
	file = {Zenodo Snapshot:files/10045/10225594.html:text/html},
}

@incollection{ding_using_2007,
	address = {Boston, MA},
	series = {Integrated {Series} in {Information} {Systems}},
	title = {Using {Ontologies} in the {Semantic} {Web}: {A} {Survey}},
	isbn = {978-0-387-37022-4},
	shorttitle = {Using {Ontologies} in the {Semantic} {Web}},
	url = {https://doi.org/10.1007/978-0-387-37022-4_4},
	abstract = {The Semantic Web is well recognized as an effective infrastructure to enhance visibility of knowledge on the Web. The core of the Semantic Web is “ontology”, which is used to explicitly represent our conceptualizations. Ontology engineering in the Semantic Web is primarily supported by languages such as RDF, RDFS and OWL. This chapter discusses the requirements of ontology in the context of the Web, compares the above three languages with existing knowledge representation formalisms, and surveys tools for managing and applying ontology. Advantages of using ontology in both knowledge-base-style and database-style applications are demonstrated using three real world applications.},
	language = {en},
	urldate = {2023-12-08},
	booktitle = {Ontologies: {A} {Handbook} of {Principles}, {Concepts} and {Applications} in {Information} {Systems}},
	publisher = {Springer US},
	author = {Ding, Li and Kolari, Pranam and Ding, Zhongli and Avancha, Sasikanth},
	editor = {Sharman, Raj and Kishore, Rajiv and Ramesh, Ram},
	year = {2007},
	doi = {10.1007/978-0-387-37022-4_4},
	keywords = {Ontology, Semantic Web, survey, tools},
	pages = {79--113},
	file = {Versione inviata:files/10047/Ding et al. - 2007 - Using Ontologies in the Semantic Web A Survey.pdf:application/pdf},
}

@incollection{cunliffe_methods_2023-1,
	title = {Methods, {Motivations}, and {Actors}: {A} {Risk}-{Based} {Approach} to {Heritage} {Destruction} and {Protection}},
	isbn = {978-1-00-313106-9},
	shorttitle = {Methods, {Motivations}, and {Actors}},
	abstract = {This chapter provides a fresh perspective on cultural heritage damage: by creating a new framework to consider risk to cultural heritage, it provides a first step to approach damage mitigation and prevention more effectively. Damage occurs in a range of contexts: existing studies have examined specific actors and their motivations, specific heritage types, damage types, areas, and/or circumstances across the cycle of peace and conflict. Using the ABC Risk Management Approach as a departure point, this chapter untangles and explores the key facets of damage studies to understand the problem holistically: who are the stakeholders in destruction; what is lost; when does it occur; where is it most likely to occur; how does it occur; and why is it destroyed, placing them in a comparable framework. By understanding their interrelation, broad risk drivers are established, along with the magnifying and reducing factors that affect them, providing a detailed view of potential risks to sites and enabling cross-comparison to develop understanding of risk of loss to cultural heritage, and in doing so, providing steps towards prioritising mitigation.},
	booktitle = {The {Routledge} {Handbook} of {Heritage} {Destruction}},
	publisher = {Routledge},
	author = {Cunliffe, Emma},
	year = {2023},
	note = {Num Pages: 17},
}

@article{wilkinson_fair_2016,
	title = {The {FAIR} {Guiding} {Principles} for scientific data management and stewardship},
	volume = {3},
	copyright = {2016 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata201618},
	doi = {10.1038/sdata.2016.18},
	abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders—representing academia, industry, funding agencies, and scholarly publishers—have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
	language = {en},
	number = {1},
	urldate = {2023-12-08},
	journal = {Scientific Data},
	author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J. G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and ’t Hoen, Peter A. C. and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
	month = mar,
	year = {2016},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Research data, Publication characteristics},
	pages = {160018},
	file = {Full Text PDF:files/10052/Wilkinson et al. - 2016 - The FAIR Guiding Principles for scientific data ma.pdf:application/pdf},
}

@article{brokerhof_quiskscanquick_2016,
	title = {The {QuiskScan}—a quick risk scan to identify value and hazards in a collection},
	volume = {39},
	issn = {1945-5224},
	url = {https://doi.org/10.1080/19455224.2016.1152280},
	doi = {10.1080/19455224.2016.1152280},
	number = {1},
	urldate = {2023-12-08},
	journal = {Journal of the Institute of Conservation},
	author = {Brokerhof, Agnes W. and Bülow, Anna E.},
	month = jan,
	year = {2016},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/19455224.2016.1152280},
	keywords = {preventive conservation, cultural value, collection management, decision making, risk assessment, vulnerability},
	pages = {18--28},
	file = {Full Text PDF:files/10054/Brokerhof e Bülow - 2016 - The QuiskScan—a quick risk scan to identify value .pdf:application/pdf},
}

@article{crowley_cultural_2022,
	title = {Cultural heritage and risk assessments: {Gaps}, challenges, and future research directions for the inclusion of heritage within climate change adaptation and disaster management},
	volume = {1},
	copyright = {© 2022 The Authors. Climate Resilience and Sustainability published by John Wiley \& Sons Ltd on behalf of Royal Meteorological Society.},
	issn = {2692-4587},
	shorttitle = {Cultural heritage and risk assessments},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cli2.45},
	doi = {10.1002/cli2.45},
	abstract = {Cultural heritage shapes our identity, delivers capacities, and exposes vulnerabilities, yet cultural heritage value and vulnerability are largely missing from conventional risk assessments. Risk assessments are a fundamental first step in identifying effective mechanisms for Climate Change Adaptation (CCA) and disaster management. However, by ignoring the influence of heritage, decision makers are limiting their understanding of risk and therefore opportunities vital for building and maintaining local resilience. We present findings from a synthesis of peer-reviewed literature from the last 15 years on cultural heritage risk assessment for primarily CCA but with wider implications for disaster management. We identify a significant lack of research examining intangible aspects of heritage and their influence on risk and resilience. Across the literature, risk assessments focus largely on exposure in isolation from vulnerability or adaptive capacity and where vulnerability is included there is no consistent definition or criterion. We highlight that the most frequently used methods have minimal engagement with local community values, experience, and knowledge relating to heritage practice and customs. Community engagement is most often associated with ‘professional experts’ rather than members of a local community. Furthermore, the Global South is severely under-represented with a research bias towards Europe and North America. We recommend an agile approach to future assessments with the adjustment of risk tool research and development to include participatory approaches. Future climate risk frameworks must incorporate community-scale values to understand the role of cultural heritage in relation to adaptive capacity, vulnerability, and resilience.},
	language = {en},
	number = {3},
	urldate = {2023-12-10},
	journal = {Climate Resilience and Sustainability},
	author = {Crowley, Kate and Jackson, Rowan and O'Connell, Siona and Karunarthna, Dulma and Anantasari, Esti and Retnowati, Arry and Niemand, Dominique},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cli2.45},
	keywords = {cultural heritage, risk, adaptation to climate change, climate resilience, risk-based planning, sustainable development},
	pages = {e45},
	file = {Full Text PDF:files/10058/Crowley et al. - 2022 - Cultural heritage and risk assessments Gaps, chal.pdf:application/pdf;Snapshot:files/10059/cli2.html:text/html},
}

@article{minguez_garcia_resilient_2019,
	title = {Resilient cultural heritage: from global to national levels – the case of {Bhutan}},
	volume = {29},
	issn = {0965-3562},
	shorttitle = {Resilient cultural heritage},
	url = {https://doi.org/10.1108/DPM-08-2018-0285},
	doi = {10.1108/DPM-08-2018-0285},
	abstract = {Purpose Cultural heritage is about people, their history and their identity. Protecting cultural heritage from natural hazards by connecting it with disaster risk management (DRM) directly benefits local communities. Cultural heritage also has a global dimension, and collaboration and support from the international community to protect it is vital. Culture and heritage differ among countries, as do natural hazards, but practitioners face some common challenges, such as the need to create awareness. The paper aims to discuss these issues. Design/methodology/approach This paper presents: a brief overview of the current connection between DRM and cultural heritage in the global context; an analysis of how international knowledge-exchange initiatives can help countries improve the resilience of their heritage sites, using Bhutan as an example; and a proposal to keep this topic moving forward in both the international and national agendas for sustainable development and resilience. Findings International knowledge exchanges may help to find solutions, and Bhutan is a good example. This small, hazard-prone country in the Himalayas, has strong traditions and heritage, and is aware of its vulnerabilities and risks. Learning from Japan’s extensive experience, Bhutan has been working with international experts to improve the resilience of its cultural heritage sites. Originality/value The ultimate aim is that this paper serves as an inspiration for other countries, as well as international organizations such as the World Bank, to keep strengthening ties between DRM and cultural heritage.},
	number = {1},
	urldate = {2023-12-11},
	journal = {Disaster Prevention and Management: An International Journal},
	author = {Minguez Garcia, Barbara},
	month = jan,
	year = {2019},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Cultural heritage, Communities, Disaster risk management, Bhutan, International organizations, Japan},
	pages = {36--46},
	file = {Full Text PDF:files/10064/Minguez Garcia - 2019 - Resilient cultural heritage from global to nation.pdf:application/pdf},
}

@article{de_masi_cultural_2021,
	title = {Cultural heritage and disasters risk: {A} machine-human coupled analysis},
	volume = {59},
	issn = {2212-4209},
	shorttitle = {Cultural heritage and disasters risk},
	url = {https://www.sciencedirect.com/science/article/pii/S221242092100217X},
	doi = {10.1016/j.ijdrr.2021.102251},
	abstract = {Natural hazards represent a major threat to cultural heritage. Literature has analyzed this nexus using different approaches depending on their focus. To provide a comprehensive understanding of the core pillars structuring the field, we use a machine-human methodology that combines bibliometric and machine-learning text analysis. We focus on a sample of 565 peer-reviewed documents published between 1988 and 2020. Results prove there is increasing interest in the topic, covering different types of hazards depending on the area of interest and its most frequently associated risks. To enhance the granularity of the analysis we apply machine learning to the publications abstracts and we classify documents based on their core topics. We find that the field is highly diverse and includes conservation, restoration and management of historical sites and cultural heritage. Scholars use sophisticated tools and innovative methodologies to account for this heterogeneity. We highlight the need for stronger interdisciplinarity in the field and we call for further progresses in spatial-explicit analysis. Finally, we point towards more inclusion of humanities in the area to account for the cultural aspects of heritage protection.},
	urldate = {2023-12-11},
	journal = {International Journal of Disaster Risk Reduction},
	author = {De Masi, Francesco and Larosa, Francesca and Porrini, Donatella and Mysiak, Jaroslav},
	month = jun,
	year = {2021},
	keywords = {Cultural heritage, Machine learning, Natural disasters, Topic modeling},
	pages = {102251},
	file = {ScienceDirect Snapshot:files/10066/S221242092100217X.html:text/html},
}

@article{hak_sustainable_2016-1,
	title = {Sustainable {Development} {Goals}: {A} need for relevant indicators},
	volume = {60},
	issn = {1470-160X},
	shorttitle = {Sustainable {Development} {Goals}},
	url = {https://www.sciencedirect.com/science/article/pii/S1470160X15004240},
	doi = {10.1016/j.ecolind.2015.08.003},
	abstract = {At the UN in New York the Open Working Group created by the UN General Assembly proposed a set of global Sustainable Development Goals (SDGs) which comprises 17 goals and 169 targets. Further to that, a preliminary set of 330 indicators was introduced in March 2015. Some SDGs build on preceding Millennium Development Goals while others incorporate new ideas. A critical review has revealed that indicators of varied quality (in terms of the fulfilment certain criteria) have been proposed to assess sustainable development. Despite the fact that there is plenty of theoretical work on quality standards for indicators, in practice users cannot often be sure how adequately the indicators measure the monitored phenomena. Therefore we stress the need to operationalise the Sustainable Development Goals’ targets and evaluate the indicators’ relevance, the characteristic of utmost importance among the indicators’ quality traits. The current format of the proposed SDGs and their targets has laid a policy framework; however, without thorough expert and scientific follow up on their operationalisation the indicators may be ambiguous. Therefore we argue for the foundation of a conceptual framework for selecting appropriate indicators for targets from existing sets or formulating new ones. Experts should focus on the “indicator-indicated fact” relation to ensure the indicators’ relevance in order for clear, unambiguous messages to be conveyed to users (decision- and policy-makers and also the lay public). Finally we offer some recommendations for indicators providers in order to contribute to the tremendous amount of conceptual work needed to lay a strong foundation for the development of the final indicators framework.},
	urldate = {2023-12-11},
	journal = {Ecological Indicators},
	author = {Hák, Tomáš and Janoušková, Svatava and Moldan, Bedřich},
	month = jan,
	year = {2016},
	keywords = {Indicatorś framework, Indicatorś relevance, Sustainable development assessment, Sustainable Development Goals},
	pages = {565--573},
	file = {ScienceDirect Snapshot:files/10068/S1470160X15004240.html:text/html},
}

@article{rosa_investigating_2021,
	title = {Investigating the {Integration} of {Cultural} {Heritage} {Disaster} {Risk} {Management} into {Urban} {Planning} {Tools}. {The} {Ravenna} {Case} {Study}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2071-1050},
	url = {https://www.mdpi.com/2071-1050/13/2/872},
	doi = {10.3390/su13020872},
	abstract = {As increasingly recognized by scholars, climate change is posing new challenges in the field of disaster risk management and urban planning. Even though cultural heritage has passed through decades and centuries, it has never experienced such unexpected and variable events as those forecasted by climate change for the foreseeable future, making it a sensitive element of the living environment. By selecting the city of Ravenna and the cultural heritage site of the Santa Croce Church and archaeological area as a case study, the paper aims at providing an insight into the role that urban planning tools have when it comes to improving the resilience of historical areas, coping with climate change through improvements to the disaster risk management of cultural heritage. Starting from a deep analysis of the existing spatial and urban planning tools that operate at different scales on the Ravenna territory, the adaptive capacity of the historical area toward the identified risks was assessed. The results may lead, on the one hand, to improving the integration of cultural heritage risk management into urban planning tools; on the other hand, they contribute to improving the scope and the governance of the heritage management plans in order to cope with climate change risks and their effects.},
	language = {en},
	number = {2},
	urldate = {2023-12-11},
	journal = {Sustainability},
	author = {Rosa, Angela and Santangelo, Angela and Tondelli, Simona},
	month = jan,
	year = {2021},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {cultural heritage, risk management, adaptive capacity, climate change, planning tool, Ravenna, resilience, urban planning},
	pages = {872},
	file = {Full Text PDF:files/10070/Rosa et al. - 2021 - Investigating the Integration of Cultural Heritage.pdf:application/pdf},
}

@book{bonazza_safeguarding_2018-2,
	address = {Luxembourg},
	title = {Safeguarding {Cultural} {Heritage} from {Natural} and {Man}-{Made} {Disasters}: {A} comparative analysis of risk management in the {EU}},
	copyright = {cc\_by},
	isbn = {978-92-79-73945-3},
	shorttitle = {Safeguarding {Cultural} {Heritage} from {Natural} and {Man}-{Made} {Disasters}},
	url = {https://openarchive.icomos.org/id/eprint/2329/},
	abstract = {Natural and man-made hazards, anthropogenic effects and extreme climate change events, are persistently putting the cultural heritage of Europe under pressure, with a daily incremental frequency. In addition, such disasters and catastrophes compound the conservation challenges and needs of the heritage assets. These events also menace the assets’ social, cultural, historic and artistic values, the safety of citizens, and have an impact on local economies linked to tourism. Consequently, research on adaptation strategies, methodologies and other remedial tools is crucial, in order to safeguard Europe's cultural heritage from the continuous pressures it faces and the related decayinducing consequences. This Study presents a comprehensive overview of the existing knowledge, at European and international level, on safeguarding cultural heritage from the effects of natural disasters and threats caused by human action. Furthermore, it maps existing strategies and tools for disaster risk management in the 28 Member States, and provides evidencebased recommendations with the purpose of supporting European cooperation and improving the integration of cultural heritage in national platforms for Disaster Risk Reduction},
	language = {fr},
	urldate = {2023-12-11},
	publisher = {Publications Office of the European Union},
	author = {Bonazza, Alessandra and Maxwell, Ingval and Drdácký, Miloš and Vintzileou, Ellizabeth and Hanus, Christian},
	year = {2018},
	file = {Full Text PDF:files/10073/Bonazza et al. - 2018 - Safeguarding Cultural Heritage from Natural and Ma.pdf:application/pdf;Snapshot:files/10072/2329.html:text/html},
}

@article{andretta_proposal_2017,
	title = {Proposal for a new environmental risk assessment methodology in cultural heritage protection},
	volume = {23},
	issn = {1296-2074},
	url = {https://www.sciencedirect.com/science/article/pii/S1296207416301522},
	doi = {10.1016/j.culher.2016.08.001},
	abstract = {In this paper, it is proposed a new methodology for the environmental risk assessment in cultural heritage, developed in close collaboration with conservation scientists and library collection managers. This New rIsk assessment methodology for Cultural HEritage protection (NICHE) is specifically addressed to the protection of cultural heritage housed in museums, galleries and archives. At the present stage of development, our proposal can be considered as a “relative risk assessment methodology” for the environmental risks to cultural heritage, as are many other methodologies for the risk assessment of works of art. However, NICHE is grounded in a new general definition of risk; it is inserted in a more general and wider conceptual framework, as far as the definition of risk is concerned. In addition, although it is a relative risk assessment methodology, NICHE takes explicitly into account the effects of microclimatic conditions on the works of art, based on the current scientific knowledge and requirements reported in international norms. Here the NICHE approach is applied to the results of two measurement campaigns carried out in 2014 over two different periods, considered “extreme” from the climatic point of view, in the Classense Library of Ravenna (Italy), a famous historical library which houses many books of great value. In these measurement campaigns, various indoor environments were characterized. Even though we focus our attention mainly on the risks related to effects of the microclimatic environment on the works of art, future extensions to other classes of risks, such as structural, related to usage, arising from natural phenomena (earthquakes, floods, storms…), infesting agents (pests, insects, moulds…), technical malfunctions, etc., can be easily performed. In fact, all situations where the effects of the sources of risk on the targets of interest can be described with an S shaped function (for example, a Dose-Response Curve, a Probit or a Logit models) can be treated with the NICHE approach, grounded in the comparison with threshold reference values reported in the technical/scientific literature and norms.},
	urldate = {2023-12-11},
	journal = {Journal of Cultural Heritage},
	author = {Andretta, Massimo and Coppola, Floriana and Modelli, Alberto and Santopuoli, Nicola and Seccia, Leonardo},
	month = jan,
	year = {2017},
	keywords = {Analysis of the environment/artefact system, Cultural heritage protection, Environmental risk assessment, Hazard ranking indexes, Preservation management, Preventive conservation of the cultural heritage},
	pages = {22--32},
	file = {ScienceDirect Snapshot:files/10079/S1296207416301522.html:text/html},
}

@article{noauthor_challenges_2018-1,
	title = {Challenges and {Choices} : illustrating the 1914-1918-online : international {Encyclopedia} of the {First} {World} {War}.},
	shorttitle = {Challenges and {Choices}},
	url = {https://www.torrossa.com/en/resources/an/4478747},
	doi = {10.19272/201812401008},
	abstract = {Purchase online the PDF of Challenges and Choices : illustrating the 1914-1918-online : international Encyclopedia of the First World War., - Fabrizio Serra - Article},
	language = {en},
	urldate = {2023-12-19},
	journal = {Visual History : rivista internazionale di storia e critica dell'immagine : IV, 2018},
	year = {2018},
	note = {Publisher: Fabrizio Serra},
	pages = {149--159},
}

@article{wilson_good_2017,
	title = {Good enough practices in scientific computing},
	volume = {13},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510},
	doi = {10.1371/journal.pcbi.1005510},
	abstract = {Author summary Computers are now essential in all branches of science, but most researchers are never taught the equivalent of basic lab skills for research computing. As a result, data can get lost, analyses can take much longer than necessary, and researchers are limited in how effectively they can work with software and data. Computing workflows need to follow the same practices as lab projects and notebooks, with organized data, documented steps, and the project structured for reproducibility, but researchers new to computing often don't know where to start. This paper presents a set of good computing practices that every researcher can adopt, regardless of their current level of computational skill. These practices, which encompass data management, programming, collaborating with colleagues, organizing projects, tracking work, and writing manuscripts, are drawn from a wide variety of published sources from our daily lives and from our work with volunteer organizations that have delivered workshops to over 11,000 people since 2010.},
	language = {en},
	number = {6},
	urldate = {2023-12-23},
	journal = {PLOS Computational Biology},
	author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K.},
	month = jun,
	year = {2017},
	note = {Publisher: Public Library of Science},
	keywords = {Metadata, Computer software, Reproducibility, Data management, Control systems, Programming languages, Software tools, Source code},
	pages = {e1005510},
	file = {Full Text PDF:files/10158/Wilson et al. - 2017 - Good enough practices in scientific computing.pdf:application/pdf},
}

@incollection{hughes_digital_2015,
	title = {Digital {Methods} in the {Humanities}},
	copyright = {Copyright © 2016 John Wiley \& Sons, Ltd.},
	isbn = {978-1-118-68060-5},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118680605.ch11},
	abstract = {This chapter considers the impact and reach of digital methods in the humanities. Digital methods are a core element of what has been called the “methodological commons”: the intellectual, disciplinary, and methodological framework that underlies the conceptualization and understanding of digital humanities. The term “method” is used to refer to the computer-based (also called information and communications technology, or ICT) techniques for the creation, analysis, communication, and dissemination of digital research. This chapter revisits the theory of computer-based methods as a core construct (or “scholarly primitive”) of the digital humanities. It reviews two significant collaborative research support initiatives to investigate the use of ICT methods in the humanities, and explores the interdependencies between digital methods and the content and computer-based tools they are used with across these disciplines. The chapter also discusses recent initiatives to formalize the expression of ICT methods in the humanities, exploring how an emerging ontology of digital methods might contribute to wider adoption and understanding of digital humanities.},
	language = {en},
	urldate = {2023-12-23},
	booktitle = {A {New} {Companion} to {Digital} {Humanities}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Hughes, Lorna and Constantopoulos, Panos and Dallas, Costis},
	year = {2015},
	doi = {10.1002/9781118680605.ch11},
	note = {Section: 11
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118680605.ch11},
	keywords = {ontologies, digital humanities, digital methods, methodological commons, NeDiMAH, NeMO},
	pages = {150--170},
	file = {Snapshot:files/10161/9781118680605.html:text/html;Versione inviata:files/10160/Hughes et al. - 2015 - Digital Methods in the Humanities.pdf:application/pdf},
}

@incollection{kenderdine_embodiment_2015,
	title = {Embodiment, {Entanglement}, and {Immersion} in {Digital} {Cultural} {Heritage}},
	isbn = {978-1-118-68060-5},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118680605.ch2},
	abstract = {Increasingly sophisticated immersive, interactive visualization technologies are now coupled to rapid expansions in ultra-high-resolution cultural heritage datasets. This chapter situates an understanding of “embodiment” at the forefront of creating meaningful museum experiences using these tools and digital assets. The research presented in this chapter is foregrounded and contextualized with a wider discussion that amalgamates cultural heritage archives with interactive cinema, augmented reality, and embodied narrative. Following a review of embodiment theory that ranges from the phenomenological to the cognitive, the discussion analyses the embodied experience of two digital cultural heritage installations (Pure Land: Inside the Mogao Grottoes and Pure Land: Augmented Reality Edition 2012) as a way of articulating the complexity of human experience inside immersive interactive visualization environments. While the antecedents of these works may be found in the great exhibition complexes of the nineteenth century, this new exhibition machinery provides fresh opportunities to explore paradigms for interpretation and representation of tangible heritage data that subvert didactic models and encourage integrated multisensory and open-ended exploration. Through a close reading of the embodied experience we open up new ways for describing what constitutes a framework for interpretation based on biological, ecological, phenomenological, social, and cultural bodies. The discussion draws a transdisciplinary framework together from post-processural archaeology, philosophy, architecture, cybernetics, human–computer interface design, new media and its archaeology, and new museology.},
	language = {en},
	urldate = {2023-12-23},
	booktitle = {A {New} {Companion} to {Digital} {Humanities}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Kenderdine, Sarah},
	year = {2015},
	doi = {10.1002/9781118680605.ch2},
	note = {Section: 2
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118680605.ch2},
	keywords = {digital heritage, 3D, Dunhuang, embodied cognition, embodiment, enactivism, immersive, interactive, phenomenology, post-processural archaeology},
	pages = {22--41},
	file = {Snapshot:files/10177/9781118680605.html:text/html},
}

@incollection{mccarty_becoming_2015,
	title = {Becoming {Interdisciplinary}},
	isbn = {978-1-118-68060-5},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118680605.ch5},
	abstract = {Actual discussion of how to do interdisciplinary research is rare, although the abstraction “interdisciplinarity” is a popular topic and frequent claim. This abstraction, its treatment as a transcendental good, and the assumption that it is chiefly an attribute of collaborative teams divert critical attention from the question of how the attempt to expand beyond one's discipline of origin is to be made, whatever the circumstances of research. Here I offer no method or choreography, rather encouragement, qualification, commentary, and some tips from years of following bibliographic and now also hypertextual trails. I offer advice and strategies of wayfinding for an endless exploration of other epistemic cultures and some reflections on its possible effects.},
	language = {en},
	urldate = {2023-12-23},
	booktitle = {A {New} {Companion} to {Digital} {Humanities}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {McCarty, Willard},
	year = {2015},
	doi = {10.1002/9781118680605.ch5},
	note = {Section: 5
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118680605.ch5},
	keywords = {knowledge, epistemology, curiosity, disciplines, epistemic cultures, ethnography, interdisciplinary research, natural sciences},
	pages = {67--83},
	file = {Snapshot:files/10178/9781118680605.html:text/html},
}

@incollection{jones_new_2015,
	title = {New {Media} and {Modeling}},
	isbn = {978-1-118-68060-5},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118680605.ch6},
	abstract = {Games have played a crucial role in the history of humanities computing and digital humanities, in part because games have been at the center of the history of computing. Video games developed at the intersection of digital technology and modes associated with the humanities: narrative, design, social communication, and cultural expression. They represent complex systems of algorithmically configured creativity based on dynamic world models, and modeling is one of the key affordances of computing for digital humanities research. Games have historically been both sources of inspiration for digital humanities and the objects of its attention, from early MUDs and MOOs, to the “game of interpretation,” IVANHOE, to digital forensics and preservation (which have included games as boundary-testing examples), to the analysis of games as cultural expressions. Among the most widely experienced forms of digital media, games offer theoretical and practical models for the digital humanities.},
	language = {en},
	urldate = {2023-12-23},
	booktitle = {A {New} {Companion} to {Digital} {Humanities}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Jones, Steven E.},
	year = {2015},
	doi = {10.1002/9781118680605.ch6},
	note = {Section: 6
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118680605.ch6},
	keywords = {preservation, modeling, humanities, games, video games, digital media, algorithmic model, history of computing, mixed reality, play},
	pages = {84--97},
	file = {Snapshot:files/10179/9781118680605.html:text/html},
}

@incollection{montfort_exploratory_2015,
	title = {Exploratory {Programming} in {Digital} {Humanities} {Pedagogy} and {Research}},
	isbn = {978-1-118-68060-5},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118680605.ch7},
	abstract = {Using computation for inquiry is, unfortunately, not yet widely recognized as important in the humanities. Programming on digital humanities projects is often just a finishing stage. I argue that programming is not simply an implementation detail for interchangeable labor to provide, but is related to the methods humanists use to model the world. In all other fields that use computation significantly, including economics and biology, researchers frequently sketch, explore, and frame the nature of their investigations by writing programs. Understanding computation and having basic skills in programming allows researchers to question, refine, overturn, or further develop existing data representations, computational methods, and theories. I discuss cognitive, cultural, and social rationales for programming and argue that the practice of exploratory programming will be critical to innovation and revolution in the digital humanities – that it should be taught at undergraduate and graduate levels and should be used early on in research projects.},
	language = {en},
	urldate = {2023-12-23},
	booktitle = {A {New} {Companion} to {Digital} {Humanities}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Montfort, Nick},
	year = {2015},
	doi = {10.1002/9781118680605.ch7},
	note = {Section: 7
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118680605.ch7},
	keywords = {computation, exploration, inquiry, methodology, programming, sketching},
	pages = {98--109},
	file = {Snapshot:files/10180/9781118680605.html:text/html},
}

@incollection{hughes_digital_2015-1,
	title = {Digital {Methods} in the {Humanities}},
	isbn = {978-1-118-68060-5},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118680605.ch11},
	abstract = {This chapter considers the impact and reach of digital methods in the humanities. Digital methods are a core element of what has been called the “methodological commons”: the intellectual, disciplinary, and methodological framework that underlies the conceptualization and understanding of digital humanities. The term “method” is used to refer to the computer-based (also called information and communications technology, or ICT) techniques for the creation, analysis, communication, and dissemination of digital research. This chapter revisits the theory of computer-based methods as a core construct (or “scholarly primitive”) of the digital humanities. It reviews two significant collaborative research support initiatives to investigate the use of ICT methods in the humanities, and explores the interdependencies between digital methods and the content and computer-based tools they are used with across these disciplines. The chapter also discusses recent initiatives to formalize the expression of ICT methods in the humanities, exploring how an emerging ontology of digital methods might contribute to wider adoption and understanding of digital humanities.},
	language = {en},
	urldate = {2023-12-23},
	booktitle = {A {New} {Companion} to {Digital} {Humanities}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Hughes, Lorna and Constantopoulos, Panos and Dallas, Costis},
	year = {2015},
	doi = {10.1002/9781118680605.ch11},
	note = {Section: 11
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118680605.ch11},
	keywords = {ontologies, digital humanities, digital methods, methodological commons, NeDiMAH, NeMO},
	pages = {150--170},
	file = {Snapshot:files/10181/9781118680605.html:text/html;Versione inviata:files/10192/Hughes et al. - 2015 - Digital Methods in the Humanities.pdf:application/pdf},
}

@incollection{lawless_tailoring_2015,
	title = {Tailoring {Access} to {Content}},
	isbn = {978-1-118-68060-5},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118680605.ch12},
	abstract = {Supporting users in searching and exploring large volumes of content presents significant challenges, particularly when different users have different and evolving needs. The recent growth in digitization projects has resulted in the proliferation of digital archives and collections. Each individual user may wish to engage with this content in a variety of different ways. Users vary in terms of their prior knowledge, experience with a collection, and the goals they wish to achieve. Personalization techniques and technologies offer the promise of tailoring each user's access to content collections to support these individual differences. These techniques support a continuum of engagement ranging from highly prescriptive offerings based upon a model of each user's behavior to less constrained, user-centric curation of content collections. The users of digital humanities content range from interested members of the general public through to professional researchers. Personalization techniques which offer high-level overviews of the themes within a collection may be more suited to the general public, while researchers who are intimately familiar with a content collection and the context in which it may be interpreted can gain more value from on-the-side guidance and connections to related resources. This chapter presents a variety of techniques and technologies that may be used to support the continuum of personalization. It also examines the applicability of different personalization techniques for different user groups and highlights how users may be offered increasing levels of control over this personalization.},
	language = {en},
	urldate = {2023-12-23},
	booktitle = {A {New} {Companion} to {Digital} {Humanities}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Lawless, Séamus and Conlan, Owen and Hampson, Cormac},
	year = {2015},
	doi = {10.1002/9781118680605.ch12},
	note = {Section: 12
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118680605.ch12},
	keywords = {exploration, entities, guidance, personalization, recommendation, reflection, search, user modeling},
	pages = {171--184},
	file = {Snapshot:files/10182/9781118680605.html:text/html},
}

@incollection{flanders_data_2015,
	title = {Data {Modeling}},
	isbn = {978-1-118-68060-5},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118680605.ch16},
	abstract = {This chapter explores data modeling as a critical tool in digital humanities. The term data modeling refers to the process of representing data, their relationships, and their semantics in a way which is processable by humans and machines. Data modeling has long been a central activity of digital humanists, because it connects domain-specific knowledge (such as textual scholarship or classics) with the ability to formalize this knowledge through modeling systems. This chapter begins by describing some general aspects of data modeling, including the relations between conceptual, logical, and physical models, and between meta-models and modeled instances. It then explores some of the specific challenges of modeling data in the humanities, a domain where both the disciplinary context and the history of the materials being modeled are crucial dimensions of the modeling process.},
	language = {en},
	urldate = {2023-12-23},
	booktitle = {A {New} {Companion} to {Digital} {Humanities}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Flanders, Julia and Jannidis, Fotis},
	year = {2015},
	doi = {10.1002/9781118680605.ch16},
	note = {Section: 16
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118680605.ch16},
	keywords = {XML, data modeling, entity relationship model, relational model},
	pages = {229--237},
	file = {Snapshot:files/10183/9781118680605.html:text/html},
}

@incollection{oldman_zen_2015,
	title = {Zen and the {Art} of {Linked} {Data}},
	isbn = {978-1-118-68060-5},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118680605.ch18},
	abstract = {The World Wide Web of pages has revolutionized the way we publish, exchange, and collaborate with information. However, a vast network of content based on publishing pages creates problems for effective search, discovery, and reuse. The Linked Open Data movement seeks to remedy these limitations by supporting a new Web of Data. While the popularity and availability of Linked Open Data increase, it does not necessarily support understanding or provide the context and meaning to make it useful for humanist researchers. It also does not necessarily include the scientific requirements of transparency and reproducibility. The complex and heterogeneous nature of humanities datasets, together with the different contexts or perspectives that they contain, require the addition of meaning (semantics) to make them useful, yet the Semantic Web has become the poor relation in term of adoption, despite promising the elements to support high-quality digital humanities projects, and create a Web of data that better represents human knowledge.},
	language = {en},
	urldate = {2023-12-23},
	booktitle = {A {New} {Companion} to {Digital} {Humanities}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Oldman, Dominic and Doerr, Martin and Gradmann, Stefan},
	year = {2015},
	doi = {10.1002/9781118680605.ch18},
	note = {Section: 18
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118680605.ch18},
	keywords = {semantic web, modeling, linked open data, collaboration, scholarly research},
	pages = {251--273},
	file = {Full text:files/10193/Oldman et al. - 2015 - Zen and the Art of Linked Data.pdf:application/pdf;Snapshot:files/10184/9781118680605.html:text/html},
}

@incollection{sinclair_text_2015,
	title = {Text {Analysis} and {Visualization}},
	isbn = {978-1-118-68060-5},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118680605.ch19},
	abstract = {The analytical practices of the digital humanities are becoming ubiquitous as digital textuality continues to surround and overwhelm us. This chapter is an introduction to thinking through the analysis and visualization of electronic texts. We start by ask again what an electronic text is in the context of analysis. Then we look at how analysis takes apart the text to recombine it in ways that let you reread it for new insights. A concordance would be an example of such a recombination. Finally we discuss how interactive visualizations extend recombination to bear meaning.},
	language = {en},
	urldate = {2023-12-23},
	booktitle = {A {New} {Companion} to {Digital} {Humanities}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Sinclair, Stéfan and Rockwell, Geoffrey},
	year = {2015},
	doi = {10.1002/9781118680605.ch19},
	note = {Section: 19
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118680605.ch19},
	keywords = {visualization, tools, analytics, interactives, methods, text analysis, Voyant-tools},
	pages = {274--290},
	file = {Snapshot:files/10185/9781118680605.html:text/html},
}

@incollection{jockers_text-mining_2015,
	title = {Text-{Mining} the {Humanities}},
	isbn = {978-1-118-68060-5},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118680605.ch20},
	abstract = {This chapter provides a broad overview of how text mining can be usefully employed in humanistic research. The chapter begins by addressing the question of why scholars in the humanities should care about text mining and what they might expect to gain by embracing what are deeply computational and deeply quantitative methods. We then offer a quick synopsis of the key watersheds in the history of text mining. The bulk of the chapter discusses central methodologies used in humanistic text mining. Using examples from the humanities, we unpack the differences between supervised and unsupervised learning and discuss how tools developed by researchers in other fields can be usefully employed to address humanistic questions. Drawing from personal experience, we address some of the significant challenges associated with data quality, metadata, and copyright restrictions before moving to a discussion of a few exemplary projects and resources for further study.},
	language = {en},
	urldate = {2023-12-23},
	booktitle = {A {New} {Companion} to {Digital} {Humanities}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Jockers, Matthew L. and Underwood, Ted},
	year = {2015},
	doi = {10.1002/9781118680605.ch20},
	note = {Section: 20
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118680605.ch20},
	keywords = {machine learning, text analysis, supervised learning, text mining},
	pages = {291--306},
	file = {Snapshot:files/10186/9781118680605.html:text/html},
}

@incollection{sperberg-mcqueen_classification_2015,
	title = {Classification and its {Structures}},
	isbn = {978-1-118-68060-5},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118680605.ch26},
	abstract = {Classification is the grouping of objects into classes; the process is ubiquitous. A simple nominal classification simply assigns names to each class; ordinal classifications arrange classes in an order; more complex classifications arrange objects notionally in a multidimensional space. Some classification schemes define necessary and sufficient conditions for assignment to given classes; others group objects into clusters (with or without identifying exemplars which form the center of each cluster). Rules can be given which may encourage useful classification schemes, but in principle no single classification scheme can ever be exhaustive or meet all needs. For many practical needs, pre-existing classifications can sometimes be used; sometimes, however, no pre-existing system serves and needs can be met only by a new classification scheme.},
	language = {en},
	urldate = {2023-12-23},
	booktitle = {A {New} {Companion} to {Digital} {Humanities}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Sperberg-McQueen, C. M.},
	year = {2015},
	doi = {10.1002/9781118680605.ch26},
	note = {Section: 26
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118680605.ch26},
	keywords = {classification, faceted classification schemes, Jorge Luis Borges, n-dimensional space, S.R. Ranganathan},
	pages = {377--393},
	file = {Snapshot:files/10187/9781118680605.html:text/html},
}

@incollection{ramsay_hard_2015,
	title = {Hard {Constraints}},
	isbn = {978-1-118-68060-5},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118680605.ch31},
	abstract = {The design of software systems is often conceived in terms of what the user can do or what affordances are provided. This chapter argues that it is in the nature of media to constrain, and, what's more, that constraint itself is one of the most productive aspects of media as such. The chapter offers five specific guidelines for developing software systems using these ideas: conceive of what the user can and cannot do as one of the principal questions in the development of a software system; avoid substituting transparency for the harder questions of affordance; build like Plato, but think like Heraclitus; avoid punishing users for attempting to render hard constraints soft; treat developers no different from users.},
	language = {en},
	urldate = {2023-12-23},
	booktitle = {A {New} {Companion} to {Digital} {Humanities}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Ramsay, Stephen},
	year = {2015},
	doi = {10.1002/9781118680605.ch31},
	note = {Section: 31
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118680605.ch31},
	keywords = {digital humanities, software, constraint, design, media},
	pages = {449--457},
	file = {Snapshot:files/10188/9781118680605.html:text/html},
}

@incollection{svensson_sorting_2015,
	title = {Sorting {Out} the {Digital} {Humanities}},
	isbn = {978-1-118-68060-5},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118680605.ch33},
	abstract = {While ongoing debates about any field are important to the continued development of that field, this chapter suggests that for the digital humanities, we now need to go beyond day-to-day issues and visionary long-term speech, and focus on the intermediate time perspective. This means coming up with a model that resolves many of the key tensions that currently characterize the field within a given time frame. It is argued that it is not enough to enlarge the tent of digital humanities, reluctantly let in newcomers, or mount alternative movements. Such a model will need to be inclusive and accommodating, allowing for heterogeneity while also being sharp enough to be meaningful. This does not mean breaking with earlier traditions, but taking the need for a new, consolidated platform seriously. Such a platform must have an intellectual and technological foundation, and, arguably, relate to mainstream humanities and the university as a whole, while engaging in intellectual pursuit, technological innovation, building of sustainable infrastructure, and facilitating critical making. It must be built on respect, mutual interest, and, to some extent, compromise. It is argued in this chapter that the only way to achieve this is to think of the digital humanities as an intersectional meeting place and trading zone, allow for engagement with the digital across different modes of engagement, and use infrastructure as a way of channeling resources and articulating an ideational underpinning. Such a model is not territorial, but requires the digital humanities to have integrity and the ability to empower the development of research and education. In outlining this model, there is a specific focus on intermediate-term practical implementation.},
	language = {en},
	urldate = {2023-12-23},
	booktitle = {A {New} {Companion} to {Digital} {Humanities}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Svensson, Patrik},
	year = {2015},
	doi = {10.1002/9781118680605.ch33},
	note = {Section: 33
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118680605.ch33},
	keywords = {digital humanities, institutional formation, science and technology studies},
	pages = {476--492},
	file = {Snapshot:files/10189/9781118680605.html:text/html},
}

@incollection{thomas_iii_promise_2015,
	title = {The {Promise} of the {Digital} {Humanities} and the {Contested} {Nature} of {Digital} {Scholarship}},
	isbn = {978-1-118-68060-5},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118680605.ch36},
	abstract = {Numerous recent reports have addressed the state of the humanities, but none has explored the ways in which the digital humanities have expanded and opened up possibilities in the modes of scholarly production. This chapter examines the contested nature of scholarship between the disciplines and the digital humanities and within the digital humanities. It argues that between 1993 and 2013 the digital humanities led a widespread effort to repurpose the humanities for the digital age, where scholarship would take place not in the traditional formats but in the open digital environment. Despite the accomplishments of this twenty-year surge in the digital humanities, this chapter proposes ways to organize, review, and critique digital scholarship.},
	language = {en},
	urldate = {2023-12-23},
	booktitle = {A {New} {Companion} to {Digital} {Humanities}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Thomas III, William G.},
	year = {2015},
	doi = {10.1002/9781118680605.ch36},
	note = {Section: 36
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118680605.ch36},
	keywords = {interpretation, simulation, argument, digital narrative, digital scholarship, interactive scholarly work, thematic research collection},
	pages = {524--537},
	file = {Snapshot:files/10190/9781118680605.html:text/html;Versione inviata:files/10194/Thomas III - 2015 - The Promise of the Digital Humanities and the Cont.pdf:application/pdf},
}

@incollection{warwick_building_2015,
	title = {Building {Theories} or {Theories} of {Building}? {A} {Tension} at the {Heart} of {Digital} {Humanities}},
	isbn = {978-1-118-68060-5},
	shorttitle = {Building {Theories} or {Theories} of {Building}?},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118680605.ch37},
	abstract = {This chapter discusses the perceived opposition in digital humanities scholarship between making and theorizing, often encapsulated by the phrase “more hack less yack.” Proponents of technically driven digital humanities insist that we must be builders, and that digital humanities students must learn to program, code, and create digital resources. Those more interested in theory, most notoriously Stanley Fish, object that digital humanities is crudely positivist, under-theorized, and insufficiently self-critical, and does not address questions for example of representation of race, gender, and sexuality, nor engage with cultural criticism. This chapter examines details of the debate and discusses whether the two sides can, or should, be reconciled. It examines earlier discussions about theory and method in English studies and history, as they grew into mature disciplines, and asks what digital humanities can learn from the development of these two fields, as it seeks to shape its own future.},
	language = {en},
	urldate = {2023-12-23},
	booktitle = {A {New} {Companion} to {Digital} {Humanities}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Warwick, Claire},
	year = {2015},
	doi = {10.1002/9781118680605.ch37},
	note = {Section: 37
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118680605.ch37},
	keywords = {building, critical making, definition of field, hack versus yack, methodological debates, theory of digital humanities},
	pages = {538--552},
	file = {Snapshot:files/10191/9781118680605.html:text/html},
}

@book{hp_lovecraft_complete_2011,
	title = {The {Complete} {Works} {Of} {H}.{P}. {Lovecraft}},
	copyright = {http://creativecommons.org/licenses/by-nc/3.0/},
	url = {http://archive.org/details/TheCompleteWorksOfHPLovecraft_201412},
	abstract = {"The Complete Works of H.P. Lovecraft contains all the original stories which Lovecraft wrote as an adult. It begins in 1917 with “The Tomb” and ends in 1935 with his last original work “The Haunter of the Dark.” The book is ordered chronologically by the date the story was written. Because Lovecraft was a terrible businessman and left no heirs to his intellectual property, all of his works are already in the public domain. I did not include collaborations or revisions because some of those works may still be under the co-author’s copyright.

3/4/11 – I’ve updated the eBook with a cover created by Santiago Casares, an artist and Lovecraftian fan."

This collection of stories was originally compiled by Cthulu Chick, who created the EPUB, MOBI and PDF formats. The original files were downloaded from http://cthulhuchick.com/free-complete-lovecraft-ebook-nook-kindle/.

Table of ContentsThe Tomb (1917)Dagon (1917)Polaris (1918)Beyond the Wall of Sleep (1919)Memory (1919)Old Bugs (1919)The Transition of Juan Romero (1919)The White Ship (1919)The Doom That Came to Sarnath (1919)The Statement of Randolph Carter (1919)The Terrible Old Man (1920)The Tree (1920)The Cats of Ulthar (1920)The Temple (1920)Facts Concerning the Late Arthur Jermyn and His Family (1920)The Street (1920)Celephaïs (1920)From Beyond (1920)Nyarlathotep (1920)The Picture in the House (1920)Ex Oblivione (1921)The Nameless City (1921)The Quest of Iranon (1921)The Moon-Bog (1921)The Outsider (1921)The Other Gods (1921)The Music of Erich Zann (1921)Herbert West — Reanimator (1922)Hypnos (1922)What the Moon Brings (1922)Azathoth (1922)The Hound (1922)The Lurking Fear (1922)The Rats in the Walls (1923)The Unnamable (1923)The Festival (1923)The Shunned House (1924)The Horror at Red Hook (1925)He (1925)In the Vault (1925)The Descendant (1926)Cool Air (1926)The Call of Cthulhu (1926)Pickman’s Model (1926)The Silver Key (1926)The Strange High House in the Mist (1926)The Dream-Quest of Unknown Kadath (1927)The Case of Charles Dexter Ward (1927)The Colour Out of Space (1927)The Very Old Folk (1927)The Thing in the Moonlight (1927)The History of the Necronomicon (1927)Ibid (1928)The Dunwich Horror (1928)The Whisperer in Darkness (1930)At the Mountains of Madness (1931)The Shadow Over Innsmouth (1931)The Dreams in the Witch House (1932)The Thing on the Doorstep (1933)The Evil Clergyman (1933)The Book (1933)The Shadow out of Time (1934)The Haunter of the Dark (1935)},
	language = {eng},
	urldate = {2023-12-23},
	author = {{H.P. Lovecraft}},
	year = {2011},
	keywords = {lovecraft},
}

@article{balzani_saving_2024,
	title = {Saving temporary exhibitions in virtual environments: {The} {Digital} {Renaissance} of {Ulisse} {Aldrovandi} – {Acquisition} and digitisation of cultural heritage objects},
	volume = {32},
	copyright = {All rights reserved},
	issn = {2212-0548},
	shorttitle = {Saving temporary exhibitions in virtual environments},
	url = {https://www.sciencedirect.com/science/article/pii/S2212054823000541},
	doi = {10.1016/j.daach.2023.e00309},
	abstract = {As per the objectives of Project CHANGES, particularly its thematic sub-project on the use of virtual technologies for museums and art collections, our goal was to obtain a digital twin of the temporary exhibition on Ulisse Aldrovandi called “The Other Renaissance”, and make it accessible to users online. After a preliminary study of the exhibition, focusing on acquisition constraints and related solutions, we proceeded with the digital twin creation by acquiring, processing, modelling, optimising, exporting, and metadating the exhibition. We made hybrid use of two acquisition techniques to create new digital cultural heritage objects and environments, and we used open technologies, formats, and protocols to make available the final digital product. Here, we describe the process of collecting and curating bibliographical exhibition (meta) data and the beginning of the digital twin creation to foster its findability, accessibility, interoperability, and reusability. The creation of the digital twin is currently ongoing.},
	urldate = {2024-01-10},
	journal = {Digital Applications in Archaeology and Cultural Heritage},
	author = {Balzani, Roberto and Barzaghi, Sebastian and Bitelli, Gabriele and Bonifazi, Federica and Bordignon, Alice and Cipriani, Luca and Colitti, Simona and Collina, Federica and Daquino, Marilena and Fabbri, Francesca and Fanini, Bruno and Fantini, Filippo and Ferdani, Daniele and Fiorini, Giulia and Formia, Elena and Forte, Anna and Giacomini, Federica and Girelli, Valentina Alena and Gualandi, Bianca and Heibi, Ivan and Iannucci, Alessandro and Manganelli Del Fà, Rachele and Massari, Arcangelo and Moretti, Arianna and Peroni, Silvio and Pescarin, Sofia and Renda, Giulia and Ronchi, Diego and Sullini, Mattia and Tini, Maria Alessandra and Tomasi, Francesca and Travaglini, Laura and Vittuari, Luca},
	month = mar,
	year = {2024},
	keywords = {Photogrammetry, Digital cultural heritage objects, Digital twins, Preservation of temporary exhibitions, Structured light projection scanning},
	pages = {e00309},
	file = {ScienceDirect Snapshot:files/10198/S2212054823000541.html:text/html},
}

@inproceedings{thoden_modeling_2019,
	address = {Marseille, France},
	title = {Modeling scholarly publications for sustainable workflows},
	volume = {Academic publishing and digital bibliodiversity},
	url = {https://hal.science/hal-02143240},
	doi = {10.4000/proceedings.elpub.2019.2},
	abstract = {This study deals with the strategy of converting the workflow and document basis from a proprietary format to a fully standards-compliant system in the context of a publishing platform, that offers multiple output formats of monographs in the arts and humanities. It stresses the importance of creating an abstract document model as the basis for this single-source publishing approach and how a model offers guidance on each step of the way in book production.},
	urldate = {2024-01-16},
	booktitle = {{ELPUB} 2019 23rd edition of the {International} {Conference} on {Electronic} {Publishing}},
	publisher = {INRIA},
	author = {Thoden, Klaus},
	month = jun,
	year = {2019},
	keywords = {workflow, XML, legacy data, literate programming, single source publishing},
	file = {HAL PDF Full Text:files/10202/Thoden - 2019 - Modeling scholarly publications for sustainable wo.pdf:application/pdf},
}

@article{baker_key_2013,
	title = {Key choices in the design of {Simple} {Knowledge} {Organization} {System} ({SKOS})},
	volume = {20},
	issn = {1570-8268},
	url = {https://www.sciencedirect.com/science/article/pii/S1570826813000176},
	doi = {10.1016/j.websem.2013.05.001},
	abstract = {Simple Knowledge Organization System (SKOS) provides a data model and vocabulary for expressing Knowledge Organization Systems (KOSs) such as thesauri and classification schemes in Semantic Web applications. This paper presents the main components of SKOS and their formal expression in Web Ontology Language (OWL), providing an extensive account of the design decisions taken by the Semantic Web Deployment (SWD) Working Group of the World Wide Web Consortium (W3C), which between 2006 and 2009 brought SKOS to the status of W3C Recommendation. The paper explains key design principles such as “minimal ontological commitment” and systematically cites the requirements and issues that influenced the design of SKOS components. By reconstructing the discussion around alternative features and design options and presenting the rationale for design decisions, the paper aims at providing insight into how SKOS turned out as it did, and why. Assuming that SKOS, like any other successful technology, may eventually be subject to revision and improvement, the critical account offered here may help future editors approach such a task with deeper understanding.},
	urldate = {2024-01-22},
	journal = {Journal of Web Semantics},
	author = {Baker, Thomas and Bechhofer, Sean and Isaac, Antoine and Miles, Alistair and Schreiber, Guus and Summers, Ed},
	month = may,
	year = {2013},
	keywords = {Controlled vocabularies, Knowledge organization systems, Thesauri, Web standards},
	pages = {35--49},
	file = {ScienceDirect Snapshot:files/10304/S1570826813000176.html:text/html;Versione inviata:files/10305/Baker et al. - 2013 - Key choices in the design of Simple Knowledge Orga.pdf:application/pdf},
}

@inproceedings{hartig_publishing_2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Publishing and {Consuming} {Provenance} {Metadata} on the {Web} of {Linked} {Data}},
	isbn = {978-3-642-17819-1},
	doi = {10.1007/978-3-642-17819-1_10},
	abstract = {The World Wide Web evolves into a Web of Data, a huge, globally distributed dataspace that contains a rich body of machine-processable information from a virtually unbound set of providers covering a wide range of topics. However, due to the openness of the Web little is known about who created the data and how. The fact that a large amount of the data on the Web is derived by replication, query processing, modification, or merging raises concerns of information quality. Poor quality data may propagate quickly and contaminate the Web of Data. Provenance information about who created and published the data and how, provides the means for quality assessment. This paper takes a first step towards creating a quality-aware Web of Data: we present approaches to integrate provenance information into the Web of Data and we illustrate how this information can be consumed. In particular, we introduce a vocabulary to describe provenance of Web data as metadata and we discuss possibilities to make such provenance metadata accessible as part of the Web of Data. Furthermore, we describe how this metadata can be queried and consumed to identify outdated information.},
	language = {en},
	booktitle = {Provenance and {Annotation} of {Data} and {Processes}},
	publisher = {Springer},
	author = {Hartig, Olaf and Zhao, Jun},
	editor = {McGuinness, Deborah L. and Michaelis, James R. and Moreau, Luc},
	year = {2010},
	pages = {78--90},
	file = {Full Text PDF:files/10307/Hartig e Zhao - 2010 - Publishing and Consuming Provenance Metadata on th.pdf:application/pdf},
}

@article{li_provenance_2017,
	title = {Provenance {Description} of {Metadata} {Vocabularies} for the {Long}-term {Maintenance} of {Metadata}},
	volume = {2},
	url = {https://sciendo.com/article/10.1515/jdis-2017-0007},
	abstract = {PurposeThe purpose of this paper is to discuss provenance description of metadata terms and metadata vocabularies as a set of metadata terms. Provenance is crucial information to keep track of changes of metadata terms and metadata vocabularies for their consistent maintenance.Design/methodology/approachThe W3C PROV standard for general provenance description and Resource Description Framework (RDF) are adopted as the base models to formally define provenance description for metadata vocabularies.FindingsThis paper defines a few primitive change types of metadata terms, and a provenance description model of the metadata terms based on the primitive change types. We also provide examples of provenance description in RDF graphs to show the proposed model.Research limitationsThe model proposed in this paper is defined based on a few primitive relationships (e.g. addition, deletion, and replacement) between pre-version and post-version of a metadata term. The model is simplified and the practical changes of metadata terms can be more complicated than the primitive relationships discussed in the model.Practical implicationsFormal provenance description of metadata vocabularies can improve maintainability of metadata vocabularies over time. Conventional maintenance of metadata terms is the maintenance of documents of terms. The proposed model enables effective and automated tracking of change history of metadata vocabularies using simple formal description scheme defined based on widely-used standards.Originality/valueChanges in metadata vocabularies may cause inconsistencies in the longterm use of metadata. This paper proposes a simple and formal scheme of provenance description of metadata vocabularies. The proposed model works as the basis of automated maintenance of metadata terms and their vocabularies and is applicable to various types of changes.},
	language = {en},
	number = {2},
	urldate = {2024-01-22},
	journal = {Journal of Data and Information Science},
	author = {Li, Chunqiu and Sugimoto, Shigeo},
	month = may,
	year = {2017},
	pages = {41--55},
	file = {Full Text PDF:files/10309/Li e Sugimoto - 2017 - Provenance Description of Metadata Vocabularies fo.pdf:application/pdf},
}

@incollection{tomaszuk_covome_2022-1,
	title = {{CoVoMe}: {New} {Methodology} for {Building} {Controlled} {Vocabulary}},
	isbn = {978-3-030-98875-3},
	shorttitle = {{CoVoMe}},
	abstract = {The use of methodologies in knowledge management and engineering is deeply comprehensive due to their important advantages. In this paper, we propose CoVoMe that is a methodology for building controlled vocabularies. This methodology covers almost all variants of that vocabularies, and it is designed to be close to the currently available languages for creating thesauri, subject headings, taxonomies, authority files, synonym rings, and glossaries.KeywordsKnowledge organization systemControlled vocabularyMethodology},
	author = {Tomaszuk, Dominik},
	month = jan,
	year = {2022},
	doi = {10.1007/978-3-030-98876-0_4},
	pages = {41--56},
	file = {Full Text PDF:files/10312/Tomaszuk - 2022 - CoVoMe New Methodology for Building Controlled Vo.pdf:application/pdf},
}

@article{mcgillivray_challenges_2020-1,
	title = {The challenges and prospects of the intersection of humanities and data science: {A} white paper from {The} {Alan} {Turing} {Institute}},
	shorttitle = {The challenges and prospects of the intersection of humanities and data science},
	url = {https://www.repository.cam.ac.uk/handle/1810/309670},
	abstract = {This paper was produced as part of the activities of the Humanities and Data Science Special Interest Group based at The Alan Turing Institute. The group has created the opportunity for fruitful conversations in this area and has brought together voices from a range of different disciplinary backgrounds. This document shows an example of how conversations of this type can benefit and advance computational methods and understandings in and between the humanities and data science, bringing together a diverse community. We believe the Turing can act as a nexus of discussion on humanities and data science research at the national (and international) level, in areas such as education strategy, research best practices, and funding policy, and can promote and encourage research activities in this interdisciplinary area.},
	language = {eng},
	urldate = {2024-01-23},
	author = {McGillivray, Barbara and Alex, Beatrice and Ames, Sarah and Armstrong, Guyda and Beavan, David and Ciula, Arianna and Colavizza, Giovanni and Cummings, James and De Roure, David and Farquhar, Adam and Hengchen, Simon and Lang, Anouk and Loxley, James and Goudarouli, Eirini and Nanni, Federico and Nini, Andrea and Nyhan, Julianne and Osborne, Nicola and Poibeau, Thierry and Ridge, Mia and Ranade, Sonia and Smithies, James and Terras, Melissa and Vlachidis, Andreas and Willcox, Pip},
	month = aug,
	year = {2020},
	file = {Full Text PDF:files/10314/McGillivray et al. - 2020 - The challenges and prospects of the intersection o.pdf:application/pdf},
}

@article{turco_physical_2021,
	title = {Physical, digital, virtual, intangible. {Research} experiences in {Museums}},
	volume = {10},
	copyright = {Copyright (c) 2021 Massimiliano Lo Turco, Elisabetta Caterina Giovannini, Andrea Tomalini},
	issn = {2532-683X},
	url = {http://agathon.it/agathon/article/view/272},
	doi = {10.19229/2464-9309/10122021},
	abstract = {This paper dwells on the many meanings the digital artefacts can have, their value and their replicability. It presents some critical and methodological thoughts on the use of digital tools in the museums. Using consolidated taxonomies and redefining the digital tools to be innovatively applied to Cultural Assets, the essay describes some research experiences carried out over the last years. From the creation of virtual reconstructions of the past, to the opportunity to work on virtual models, operating on informative stratification not perceptible by simply observing the collection’s item and avoiding its evolution into a simple repetition of the perceptual experience of the real object.},
	language = {en},
	urldate = {2024-01-23},
	journal = {AGATHÓN {\textbar} International Journal of Architecture, Art and Design},
	author = {Turco, Massimiliano Lo and Giovannini, Elisabetta Caterina and Tomalini, Andrea},
	month = dec,
	year = {2021},
	keywords = {storytelling, digital cultural heritage, museums, virtual reality, digital modelling for reconstruction},
	pages = {140--149},
	file = {Full Text PDF:files/10316/Turco et al. - 2021 - Physical, digital, virtual, intangible. Research e.pdf:application/pdf},
}

@article{nova_knowledge_2023,
	title = {A knowledge management system for sharing knowledge about cultural heritage projects},
	volume = {63},
	issn = {1296-2074},
	url = {https://www.sciencedirect.com/science/article/pii/S1296207423001358},
	doi = {10.1016/j.culher.2023.07.013},
	abstract = {Cultural Heritage Projects (CHP) are complex activities that involve multiple and heterogeneous actors attempting to harmonize their different and diverse ontological and epistemological perspectives, while simultaneously coordinating and sharing knowledge about heritage objects. Projects involve a multitude of related data, information, and knowledge, and require information technologies for coordination. In this context, the socio-technical approach to designing information systems (IS) has become widely adopted but it is contradictory in knowledge coordination scenarios in which heritage experts and coordination technologies form inseparable sociomaterial assemblages that evolve through routines and affordances, depending on the contextual dimensions of particular projects. This paper adopts a design science approach to present the sociomaterial design of a Knowledge Management System (KMS) for cultural heritage projects. The KMS aims to overcome coordination issues for sharing knowledge within and between heritage projects. Evaluation results outline that the KMS provides enhanced knowledge access and visualization, greater flexibility in sharing practices, and improved decision-making capabilities. The designed system meets the specific requirements of an international knowledge sharing network and introduces innovative design and coordination insights that can be successfully deployed in heritage projects and networks with similar coordination and collaborative features.},
	urldate = {2024-01-23},
	journal = {Journal of Cultural Heritage},
	author = {Nova, Néstor A. and González, Rafael A. and Beltrán, Lina C. and Nieto, Carlos E.},
	month = sep,
	year = {2023},
	keywords = {Cultural heritage, Coordination, Design science, Knowledge management system, Knowledge sharing, Sociomateriality},
	pages = {61--70},
	file = {ScienceDirect Snapshot:files/10320/S1296207423001358.html:text/html},
}

@article{padilla_santa_2019,
	title = {Santa {Barbara} {Statement} on {Collections} as {Data} --- {Always} {Already} {Computational}: {Collections} as {Data}},
	copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International, Open Access},
	shorttitle = {Santa {Barbara} {Statement} on {Collections} as {Data} --- {Always} {Already} {Computational}},
	url = {https://zenodo.org/record/3066208},
	doi = {10.5281/ZENODO.3066208},
	abstract = {The Santa Barbara Statement on Collections as Data was written by the Institute of Museum and Library Services supported Always Already Computational: Collections as Data project team. The first version was based on the collaborative work of participants at the first Collections as Data National Forum (UC Santa Barbara, March 1-3 2017). After its release, the team gathered comments from the Hypothesis web annotation tool and sought additional feedback across a series of conversations and workshops (April 2017 - April 2018). The current version of the statement was revised based on that community feedback, especially the close, directed feedback provided by workshop participants at the Digital Library Federation Forum 2017.

This publication is part of the Collections as Data Framework hosted at https://osf.io/mx6uk/.},
	language = {en},
	urldate = {2024-01-23},
	author = {Padilla, Thomas and Allen, Laurie and Frost, Hannah and Potvin, Sarah and Russey Roke, Elizabeth and Varner, Stewart},
	month = may,
	year = {2019},
	note = {Publisher: Zenodo
Version Number: 2},
	keywords = {data, museums, archives, collections, libraries},
	file = {paper2.pdf:files/10321/paper2.pdf:application/pdf},
}

@article{zabulis_representation_2022,
	title = {A {Representation} {Protocol} for {Traditional} {Crafts}},
	volume = {5},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2571-9408},
	url = {https://www.mdpi.com/2571-9408/5/2/40},
	doi = {10.3390/heritage5020040},
	abstract = {A protocol for the representation of traditional crafts and the tools to implement this are proposed. The proposed protocol is a method for the systematic collection and organization of digital assets and knowledge, their representation into a formal model, and their utilization for research, education, and preservation. A set of digital tools accompanies this protocol that enables the online curation of craft representations. The proposed approach was elaborated and evaluated with craft practitioners in three case studies. Lessons learned are shared and an outlook for future work is provided.},
	language = {en},
	number = {2},
	urldate = {2024-01-23},
	journal = {Heritage},
	author = {Zabulis, Xenophon and Partarakis, Nikolaos and Meghini, Carlo and Dubois, Arnaud and Manitsaris, Sotiris and Hauser, Hansgeorg and Magnenat Thalmann, Nadia and Ringas, Chris and Panesse, Lucia and Cadi, Nedjma and Baka, Evangelia and Beisswenger, Cynthia and Makrygiannis, Dimitrios and Glushkova, Alina and Padilla, Brenda Elizabeth Olivas and Kaplanidi, Danae and Tasiopoulou, Eleana and Cuenca, Catherine and Carre, Anne-Laure and Nitti, Vito and Adami, Ilia and Zidianakis, Emmanouil and Doulgeraki, Paraskevi and Karouzaki, Effie and Bartalesi, Valentina and Metilli, Daniele},
	month = jun,
	year = {2022},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {cultural heritage, digital curation, digitization, documentation, craft preservation},
	pages = {716--741},
	file = {Full Text PDF:files/10324/Zabulis et al. - 2022 - A Representation Protocol for Traditional Crafts.pdf:application/pdf},
}

@article{antonini_experiential_2023,
	title = {Experiential {Observations}: {An} {Ontology} {Pattern}-{Based} {Study} on {Capturing} the {Potential} {Content} within {Evidences} of {Experiences}},
	volume = {16},
	issn = {1556-4673},
	shorttitle = {Experiential {Observations}},
	url = {https://dl.acm.org/doi/10.1145/3586078},
	doi = {10.1145/3586078},
	abstract = {Modelling the knowledge behind human experiences is a complex process: it should take into account, among others, the activities performed, human observations and the documentation of the evidence. To represent this knowledge in a declarative way means to support data interoperability in the context of cultural heritage artefacts, as linked datasets on experience documentation have started to appear. With this objective in mind, we describe a study based on an ontology design pattern for modelling experiences through observations, which are considered indirect evidence of a mental process (i.e., the experience). This pattern highlights the structural differences between types of experiential documentation, such as diaries and social media, providing a guideline for the comparability between different domains and for supporting the construction of heterogeneous datasets based on an epistemic compatibility. We have performed not only a formal evaluation over the pattern but also an assessment through a series of case studies. This approach includes (a) the analysis of interoperability among two case studies (reading through social media and historical sources); (b) the development of an ontology for collecting evidences of reading, which reuses the proposed pattern; and (c) the inspection of experience in humanities datasets.},
	number = {3},
	urldate = {2024-01-23},
	journal = {Journal on Computing and Cultural Heritage},
	author = {Antonini, Alessio and Adamou, Alessandro and Suárez-Figueroa, Mari Carmen and Benatti, Francesca},
	month = aug,
	year = {2023},
	keywords = {classification schema, ICT technologies in support of creating new cultural experiences or digital artefacts; metadata, ontologies and semantic processing for CH multimedia repositories; knowledge patterns; digital humanities; intangible cultural heritage; human experience studies},
	pages = {58:1--58:30},
	file = {Full Text PDF:files/10326/Antonini et al. - 2023 - Experiential Observations An Ontology Pattern-Bas.pdf:application/pdf},
}

@article{karoune_removing_2022-2,
	title = {Removing {Barriers} to {Reproducible} {Research} in {Archaeology}},
	doi = {10.5281/zenodo.7320029},
	abstract = {Reproducible research is being implemented at different speeds in different disciplines, and Archaeology is at the start of this journey. Reproducibility is the practice of reanalysing data by taking the same steps and producing the same or similar results. Enabling reproducibility is an important step to ensure research quality and validate interpretations. There are currently many barriers to moving towards reproducible research such as the skill level of researchers in the practices, software and infrastructure needed to do reproducible research and concerns relating to opening up research such as how to share sensitive data. In this article, we seek to introduce reproducible research in an understandable manner so that archaeologists can learn where and how to start improving the reproducibility of their research. We describe what reproducible archaeological research can look like and propose three different computational skill levels of reproducible workflows with examples. Finally, in an extensive appendix, we address common questions about reproducible research to remove the stigma about these issues and suggest ways to overcome them.},
	journal = {Pci Journal},
	author = {Karoune, Emma and Plomp, Esther},
	month = nov,
	year = {2022},
	file = {Full Text PDF:files/10329/Karoune e Plomp - 2022 - Removing Barriers to Reproducible Research in Arch.pdf:application/pdf},
}

@misc{institute_abc_2017,
	title = {The {ABC} {Method}: a risk management approach to the preservation of cultural heritage},
	shorttitle = {The {ABC} {Method}},
	url = {https://www.canada.ca/en/conservation-institute/services/risk-management-heritage-collections/abc-method-risk-management-approach.html},
	language = {eng},
	urldate = {2024-02-20},
	author = {Institute, Canadian Conservation},
	month = sep,
	year = {2017},
	note = {Last Modified: 2021-05-05},
	file = {Snapshot:files/10399/abc-method-risk-management-approach.html:text/html},
}

@article{van_rossem_ontology_2022,
	title = {The ontology explorer: {A} method to make visible data infrastructures for population management},
	volume = {9},
	issn = {2053-9517},
	shorttitle = {The ontology explorer},
	url = {https://doi.org/10.1177/20539517221104087},
	doi = {10.1177/20539517221104087},
	abstract = {This article introduces the methodology of the ‘Ontology Explorer’, a semantic method and JavaScript-based open-source tool to analyse data models underpinning information systems. The Ontology Explorer has been devised and developed by the authors, who recognized a need to compare data models collected in different formats and used by diverse systems. The Ontology Explorer is distinctive firstly because it supports analyses of information systems that are not immediately comparable and, secondly, because it systematically and quantitatively supports discursive analysis of ‘thin’ data models – also by detecting differences and absences through comparison. When applied to data models underpinning systems for population management, the Ontology Explorer enables the apprehension of how people are ‘inscribed’ in information systems: which assumptions are made about them, and which possibilities are excluded by design. The Ontology Explorer thus constitutes a methodology to capture authorities’ own imaginaries of populations and the ‘scripts’ through which they enact actual people. Furthermore, the method allows the comparison of scripts from diverse authorities. This is exemplified by illustrating its functioning with information systems for population management deployed at the European border. Our approach integrates a number of insights from early infrastructure studies and extends their methods and analytical depth to account for contemporary data infrastructures. By doing so, we hope to trigger a systematic discussion on how to extend those early methodical innovations at the semantic level to contemporary developments in digital methods.},
	language = {en},
	number = {1},
	urldate = {2024-04-03},
	journal = {Big Data \& Society},
	author = {Van Rossem, Wouter and Pelizza, Annalisa},
	month = jan,
	year = {2022},
	note = {Publisher: SAGE Publications Ltd},
	pages = {20539517221104087},
	file = {SAGE PDF Full Text:files/10590/Van Rossem e Pelizza - 2022 - The ontology explorer A method to make visible da.pdf:application/pdf},
}

@article{alkemade_datasheets_2023,
	title = {Datasheets for {Digital} {Cultural} {Heritage} {Datasets}},
	volume = {9},
	issn = {2059-481X},
	url = {https://openhumanitiesdata.metajnl.com/articles/10.5334/johd.124},
	doi = {10.5334/johd.124},
	abstract = {The Journal of Open Humanities Data (JOHD) aims to be a key part of a thriving community of scholars sharing humanities data. The journal features peer reviewed publications describing humanities research objects or techniques with high potential for reuse. Humanities subjects of interest to JOHD include, but are not limited to Art History, Classics, History, Library Science, Linguistics, Literature, Media Studies, Modern Languages, Music and musicology, Philosophy, Religious Studies, etc. Submissions that cross one or more of these traditional disciplines are particularly encouraged.},
	language = {en-US},
	number = {1},
	urldate = {2024-04-03},
	journal = {Journal of Open Humanities Data},
	author = {Alkemade, Henk and Claeyssens, Steven and Colavizza, Giovanni and Freire, Nuno and Lehmann, Jörg and Neudecker, Clemens and Osti, Giulia and Strien, Daniel van},
	month = oct,
	year = {2023},
	file = {Full Text PDF:files/10592/Alkemade et al. - 2023 - Datasheets for Digital Cultural Heritage Datasets.pdf:application/pdf},
}

@article{peer_reproducible_2022,
	title = {Reproducible {Research} {Publication} {Workflow}: {A} {Canonical} {Workflow} {Framework} and {FAIR} {Digital} {Object} {Approach} to {Quality} {Research} {Output}},
	volume = {4},
	issn = {2641-435X},
	shorttitle = {Reproducible {Research} {Publication} {Workflow}},
	url = {https://doi.org/10.1162/dint_a_00133},
	doi = {10.1162/dint_a_00133},
	abstract = {In this paper we present the Reproducible Research Publication Workflow (RRPW) as
an example of how generic canonical workflows can be applied to a specific
context. The RRPW includes essential steps between submission and final
publication of the manuscript and the research artefacts (i.e., data, code,
etc.) that underlie the scholarly claims in the manuscript. A key aspect of the
RRPW is the inclusion of artefact review and metadata creation as part of the
publication workflow. The paper discusses a formalized technical structure
around a set of canonical steps which helps codify and standardize the process
for researchers, curators, and publishers. The proposed application of canonical
workflows can help achieve the goals of improved transparency and
reproducibility, increase FAIR compliance of all research artefacts at all
steps, and facilitate better exchange of annotated and machine-readable
metadata.},
	number = {2},
	urldate = {2024-04-03},
	journal = {Data Intelligence},
	author = {Peer, Limor and Biniossek, Claudia and Betz, Dirk and Christian, Thu-Mai},
	month = apr,
	year = {2022},
	pages = {306--319},
	file = {Full Text PDF:files/10595/Peer et al. - 2022 - Reproducible Research Publication Workflow A Cano.pdf:application/pdf;Snapshot:files/10596/Reproducible-Research-Publication-Workflow-A.html:text/html},
}

@inproceedings{barbuti_creating_2020-2,
	address = {Cham},
	title = {Creating {Digital} {Cultural} {Heritage} with {Open} {Data}: {From} {FAIR} to {FAIR5} {Principles}},
	isbn = {978-3-030-39905-4},
	shorttitle = {Creating {Digital} {Cultural} {Heritage} with {Open} {Data}},
	doi = {10.1007/978-3-030-39905-4_17},
	abstract = {The Art. 2 of the EU Council Conclusions of 21 May 2014 on cultural heritage as a strategic resource for a sustainable Europe (2014/C 183/08) states the existence of the new Digital Cultural Heritage (born digital and digitized). Starting from this assumption, we must rethink digitization, digitalization and digital transformation as recording and representing the processes of contemporary life cycles, no longer as simple tools to improve access to reality. So, we must define clear and homogeneous criteria to validate and certify what among contemporary digital magma we can identify as Digital Cultural Heritage (DCH). This paper outlines a proposal in such way starting from the extension of the R: Reusable requirement of FAIR Principles to R5 adding the requirements: Readable, Relevant, Reliable and Resilient. These requirements should lead the design and creation of descriptive metadata in open format for indexing and managing digital cultural resources. The Terra delle Gravine between sharing economy and experiential tourism project was a case study for testing this proposal. Three digital libraries of the municipal libraries of Massafra, Mottola and Grottaglie were designed and implemented by creating an open data schema for indexing and describing the digital resources.},
	language = {en},
	booktitle = {Digital {Libraries}: {The} {Era} of {Big} {Data} and {Data} {Science}},
	publisher = {Springer International Publishing},
	author = {Barbuti, Nicola},
	editor = {Ceci, Michelangelo and Ferilli, Stefano and Poggi, Antonella},
	year = {2020},
	keywords = {Digital Cultural Heritage, Relevant, Reliable, Resilient, Digitization, Born digital, Metadati descrittivi, R5, Readable, Reusable},
	pages = {173--181},
}

@inproceedings{presutti_role_2016-1,
	address = {Cham},
	title = {The {Role} of {Ontology} {Design} {Patterns} in {Linked} {Data} {Projects}},
	isbn = {978-3-319-46397-1},
	doi = {10.1007/978-3-319-46397-1_9},
	abstract = {The contribution of this paper is twofold: (i) a UML stereotype for component diagrams that allows for representing ontologies as a set of interconnected Ontology Design Patterns, aimed at supporting the communication between domain experts and ontology engineers; (ii) an analysis of possible approaches to ontology reuse and the definition of four methods according to their impact on the sustainability and stability of the resulting ontologies and knowledge bases. To conceptually prove the effectiveness of our proposals, we present two real LOD projects.},
	language = {en},
	booktitle = {Conceptual {Modeling}},
	publisher = {Springer International Publishing},
	author = {Presutti, Valentina and Lodi, Giorgia and Nuzzolese, Andrea and Gangemi, Aldo and Peroni, Silvio and Asprino, Luigi},
	editor = {Comyn-Wattiau, Isabelle and Tanaka, Katsumi and Song, Il-Yeol and Yamamoto, Shuichiro and Saeki, Motoshi},
	year = {2016},
	keywords = {Ontology, Linked data, eXtreme Design, Ontology design patterns, Ontology reuse},
	pages = {113--121},
	file = {Full Text PDF:files/10599/Presutti et al. - 2016 - The Role of Ontology Design Patterns in Linked Dat.pdf:application/pdf},
}

@book{berrueta_best_2008,
	title = {Best {Practice} {Recipes} for {Publishing} {RDF} {Vocabularies}},
	author = {Berrueta, Diego and Phipps, Jon},
	month = aug,
	year = {2008},
}

@inproceedings{wentzel_extensive_2023,
	address = {Cham},
	title = {An {Extensive} {Methodology} and {Framework} for {Quality} {Assessment} of {DCAT}-{AP} {Datasets}},
	isbn = {978-3-031-41138-0},
	doi = {10.1007/978-3-031-41138-0_17},
	abstract = {The DCAT Application Profile for Data Portals is a crucial cornerstone for publishing and reusing Open Data in Europe. It supports the harmonization and interoperability of Open Data by providing an expressive set of properties, guidelines, and reusable vocabularies. However, a qualitative and accurate implementation by Open Data providers remains challenging. To improve the informative value and the compliance with RDF-based specifications, we propose a methodology to measure and assess the quality of DCAT-AP datasets. Our approach is based on the FAIR and the 5-star principles for Linked Open Data. We define a set of metrics, where each one covers a specific quality aspect. For example, if a certain property has a compliant value, if mandatory vocabularies are applied or if the actual data is available. The values for the metrics are stored as a custom data model based on the Data Quality Vocabulary and is used to calculate an overall quality score for each dataset. We implemented our approach as a scalable and reusable Open Source solution to demonstrate its feasibility. It is applied in a large-scale production environment (data.europa.eu) and constantly checks more than 1.6 million DCAT-AP datasets and delivers quality reports.},
	language = {en},
	booktitle = {Electronic {Government}},
	publisher = {Springer Nature Switzerland},
	author = {Wentzel, Bianca and Kirstein, Fabian and Jastrow, Torben and Sturm, Raphael and Peters, Michael and Schimmler, Sonja},
	editor = {Lindgren, Ida and Csáki, Csaba and Kalampokis, Evangelos and Janssen, Marijn and Viale Pereira, Gabriela and Virkar, Shefali and Tambouris, Efthimios and Zuiderwijk, Anneke},
	year = {2023},
	keywords = {DCAT-AP, Open Data, Data Quality},
	pages = {262--278},
	file = {Full Text PDF:files/10603/Wentzel et al. - 2023 - An Extensive Methodology and Framework for Quality.pdf:application/pdf},
}

@incollection{krogstie_information_2007,
	address = {Berlin, Heidelberg},
	title = {From {Information} {Algebra} to {Enterprise} {Modelling} and {Ontologies} — a {Historical} {Perspective} on {Modelling} for {Information} {Systems}},
	isbn = {978-3-540-72676-0 978-3-540-72677-7},
	url = {http://link.springer.com/10.1007/978-3-540-72677-7_1},
	language = {en},
	urldate = {2024-04-03},
	booktitle = {Conceptual {Modelling} in {Information} {Systems} {Engineering}},
	publisher = {Springer Berlin Heidelberg},
	author = {Bubenko, Janis A.},
	editor = {Krogstie, John and Opdahl, Andreas Lothe and Brinkkemper, Sjaak},
	year = {2007},
	doi = {10.1007/978-3-540-72677-7_1},
	pages = {1--18},
}

@incollection{hutchison_what_2005,
	address = {Berlin, Heidelberg},
	title = {What {Is} a {Concept}?},
	volume = {3596},
	isbn = {978-3-540-27783-5 978-3-540-31885-9},
	url = {http://link.springer.com/10.1007/11524564_4},
	urldate = {2024-04-03},
	booktitle = {Conceptual {Structures}: {Common} {Semantics} for {Sharing} {Knowledge}},
	publisher = {Springer Berlin Heidelberg},
	author = {Goguen, Joseph},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Dau, Frithjof and Mugnier, Marie-Laure and Stumme, Gerd},
	year = {2005},
	doi = {10.1007/11524564_4},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {52--77},
}

@article{chen_entity-relationship_1976,
	title = {The entity-relationship model—toward a unified view of data},
	volume = {1},
	issn = {0362-5915, 1557-4644},
	url = {https://dl.acm.org/doi/10.1145/320434.320440},
	doi = {10.1145/320434.320440},
	abstract = {A data model, called the entity-relationship model, is proposed. This model incorporates some of the important semantic information about the real world. A special diagrammatic technique is introduced as a tool for database design. An example of database design and description using the model and the diagrammatic technique is given. Some implications for data integrity, information retrieval, and data manipulation are discussed.
            The entity-relationship model can be used as a basis for unification of different views of data: the network model, the relational model, and the entity set model. Semantic ambiguities in these models are analyzed. Possible ways to derive their views of data from the entity-relationship model are presented.},
	language = {en},
	number = {1},
	urldate = {2024-04-03},
	journal = {ACM Transactions on Database Systems},
	author = {Chen, Peter Pin-Shan},
	month = mar,
	year = {1976},
	pages = {9--36},
	file = {Full text:files/10612/Chen - 1976 - The entity-relationship model—toward a unified vie.pdf:application/pdf},
}

@article{ludewig_models_2003,
	title = {Models in software engineering ? an introduction},
	volume = {2},
	copyright = {http://www.springer.com/tdm},
	issn = {1619-1366, 1619-1374},
	shorttitle = {Models in software engineering ?},
	url = {http://link.springer.com/10.1007/s10270-003-0020-3},
	doi = {10.1007/s10270-003-0020-3},
	number = {1},
	urldate = {2024-04-03},
	journal = {Software and Systems Modeling},
	author = {Ludewig, Jochen},
	month = mar,
	year = {2003},
	pages = {5--14},
}

@article{pisanski_mental_2010,
	title = {Mental models of the bibliographic universe. {Part} 1: mental models of descriptions},
	volume = {66},
	copyright = {https://www.emerald.com/insight/site-policies},
	issn = {0022-0418},
	shorttitle = {Mental models of the bibliographic universe. {Part} 1},
	url = {https://www.emerald.com/insight/content/doi/10.1108/00220411011066772/full/html},
	doi = {10.1108/00220411011066772},
	abstract = {Purpose
              The paper aims to present the results of the first two tasks of a user study looking into mental models of the bibliographic universe and especially their comparison to the Functional Requirements for Bibliographic Records (FRBR) conceptual model, which has not yet been user tested.
            
            
              Design/methodology/approach
              The paper employes a combination of techniques for eliciting mental models and consisted of three tasks, two of which, card sorting and concept mapping, are presented herein. Its participants were 30 individuals residing in the general area of Ljubljana, Slovenia.
            
            
              Findings
              Cumulative results of concept mapping show a strong resemblance to FRBR. Card sorts did not produce conclusive results. In both tasks, participants paid special attention to the original expression, indicating that a special place for it should be considered.
            
            
              Research limitations/implications
              The study was performed using a relatively small sample of participants living in a geographically limited space using relatively straight‐forward examples.
            
            
              Practical implications
              Some solid evidence is provided for adoption of FRBR as the conceptual basis for cataloguing.
            
            
              Originality/value
              This is the first widely published user study of FRBR, applying novel methodological approaches in the field of Library and Information Science.},
	language = {en},
	number = {5},
	urldate = {2024-04-03},
	journal = {Journal of Documentation},
	author = {Pisanski, Jan and Žumer, Maja},
	month = sep,
	year = {2010},
	pages = {643--667},
}

@article{pisanski_mental_2010-1,
	title = {Mental models of the bibliographic universe. {Part} 2: comparison task and conclusions},
	volume = {66},
	copyright = {https://www.emerald.com/insight/site-policies},
	issn = {0022-0418},
	shorttitle = {Mental models of the bibliographic universe. {Part} 2},
	url = {https://www.emerald.com/insight/content/doi/10.1108/00220411011066781/full/html},
	doi = {10.1108/00220411011066781},
	abstract = {Purpose
              The paper aims to provide some insight into mental models of the bibliographic universe and how they compare with functional requirements for bibliographic records (FRBR) as a conceptual model of the bibliographic universe.
            
            
              Design/methodology/approach
              To get a more complete picture of the mental models, different elicitation techniques were used. The three tasks of the paper were: card‐sorting, concept mapping and comparison task. The paper deals with comparison task, which consisted of interviews and rankings, and provides a discussion of the results of the paper as a whole.
            
            
              Findings
              Results of the ranking part of the comparison task confirm the findings of concept mapping task. In both cases, while there are individual differences between mental models, on average they gravitate towards FRBR.
            
            
              Research limitations/implications
              This is a small study and it provides only a glimpse of the implications of using FRBR as a conceptual basis for cataloguing. More FRBR‐related user studies are needed, including similar studies on different groups of individuals and different types of materials, as well as practical studies of user needs and user interfaces.
            
            
              Practical implications
              The results of this study are the first user‐tested indication of the validity of FRBR as a conceptual basis for the future of cataloguing.
            
            
              Originality/value
              This is the first published paper of mental models of the bibliographic universe and uses a unique combination of mental model elicitation techniques.},
	language = {en},
	number = {5},
	urldate = {2024-04-03},
	journal = {Journal of Documentation},
	author = {Pisanski, Jan and Žumer, Maja},
	month = sep,
	year = {2010},
	pages = {668--680},
}

@book{borgida_conceptual_2009,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Conceptual {Modeling}: {Foundations} and {Applications}: {Essays} in {Honor} of {John} {Mylopoulos}},
	volume = {5600},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-3-642-02462-7 978-3-642-02463-4},
	shorttitle = {Conceptual {Modeling}},
	url = {http://link.springer.com/10.1007/978-3-642-02463-4},
	language = {en},
	urldate = {2024-04-03},
	publisher = {Springer Berlin Heidelberg},
	editor = {Borgida, Alexander T. and Chaudhri, Vinay K. and Giorgini, Paolo and Yu, Eric S.},
	year = {2009},
	doi = {10.1007/978-3-642-02463-4},
	file = {Versione inviata:files/10613/Borgida et al. - 2009 - Conceptual Modeling Foundations and Applications.pdf:application/pdf},
}

@incollection{embley_theory_2011,
	address = {Berlin, Heidelberg},
	title = {The {Theory} of {Conceptual} {Models}, the {Theory} of {Conceptual} {Modelling} and {Foundations} of {Conceptual} {Modelling}},
	isbn = {978-3-642-15864-3 978-3-642-15865-0},
	url = {http://link.springer.com/10.1007/978-3-642-15865-0_17},
	language = {en},
	urldate = {2024-04-03},
	booktitle = {Handbook of {Conceptual} {Modeling}},
	publisher = {Springer Berlin Heidelberg},
	author = {Thalheim, Bernhard},
	editor = {Embley, David W. and Thalheim, Bernhard},
	year = {2011},
	doi = {10.1007/978-3-642-15865-0_17},
	pages = {543--577},
}

@article{vassallo_towards_2021,
	title = {Towards an ontological cross-disciplinary solution for multidisciplinary data: {VI}-{SEEM} data management and the {FAIR} principles},
	volume = {22},
	issn = {1432-1300},
	shorttitle = {Towards an ontological cross-disciplinary solution for multidisciplinary data},
	url = {https://doi.org/10.1007/s00799-020-00285-5},
	doi = {10.1007/s00799-020-00285-5},
	abstract = {Different scientific communities produce different kinds of datasets that rely on different data descriptions, approaches, and logical organisations. In such an environment, it is essential to establish a knowledge communication framework that can guarantee some fundamentals, such as an inclusive description and documentation of the interdisciplinary digital resources, their long-term preservation, access, use, and reuse. The establishment of semantic knowledge integration aims at overcoming such inhomogeneity between data produced by different research communities. Specifically, we refer to those communities aggregated within the e-Infrastructure developed by the European project VI-SEEM: Life Science, Climate Science, and Digital Cultural Heritage. The current research proposes a framework based on CIDOC CRM and its extensions, in particular the CRMsci and CRMdig, and tested on examples identified as interdisciplinary respect to the different and various research areas of the project. Moreover, the semantic solution aims at fulfilling the FAIR principles.},
	language = {en},
	number = {3},
	urldate = {2024-04-03},
	journal = {International Journal on Digital Libraries},
	author = {Vassallo, Valentina and Felicetti, Achille},
	month = sep,
	year = {2021},
	keywords = {CIDOC CRM, Digital Cultural Heritage, FAIR principles, Cross-disciplinarity, Climate Science, Life Science},
	pages = {297--307},
	file = {Full Text PDF:files/10615/Vassallo e Felicetti - 2021 - Towards an ontological cross-disciplinary solution.pdf:application/pdf},
}

@inproceedings{ball_overview_2011,
	title = {Overview of scientific metadata for data publishing, citation, and curation: {Eleventh} {International} {Conference} on {Dublin} {Core} and {Metadata} {Applications} ({DC}-2011)},
	shorttitle = {Overview of scientific metadata for data publishing, citation, and curation},
	url = {http://www.ukoln.ac.uk/projects/sdapss/},
	abstract = {Scientific data as a resource type is very hard to characterize, not least because of the sheer variety of requirements placed on it by different areas of research. It is no surprise, then, that scientific metadata has traditionally been very discipline- and application-specific. With the rise of interdisciplinary research and data sharing, though, there is increasing pressure for common standards in areas such as data discovery and curation. Mr. Ball will report on his research assessing the feasibility of a common metadata profile for scientific data discovery and ask, "Is it worth a try?"},
	urldate = {2024-04-03},
	author = {Ball, Alexander},
	month = sep,
	year = {2011},
}

@article{abedjan_profiling_2015,
	title = {Profiling relational data: a survey},
	volume = {24},
	issn = {1066-8888, 0949-877X},
	shorttitle = {Profiling relational data},
	url = {http://link.springer.com/10.1007/s00778-015-0389-y},
	doi = {10.1007/s00778-015-0389-y},
	abstract = {Proﬁling data to determine metadata about a given dataset is an important and frequent activity of any IT professional and researcher, and is necessary for various use-cases. It encompasses a vast array of methods to examine datasets and produce metadata. Among the simpler results are statistics, such as the number of null values and distinct values in a column, its data type, or the most frequent patterns of its data values. Metadata that are more diﬃcult to compute involve multiple columns, namely correlations, unique column combinations, functional dependencies, and inclusion dependencies. Further techniques detect conditional properties of the dataset at hand.},
	language = {en},
	number = {4},
	urldate = {2024-04-04},
	journal = {The VLDB Journal},
	author = {Abedjan, Ziawasch and Golab, Lukasz and Naumann, Felix},
	month = aug,
	year = {2015},
	pages = {557--581},
	file = {Abedjan et al. - 2015 - Profiling relational data a survey.pdf:files/10623/Abedjan et al. - 2015 - Profiling relational data a survey.pdf:application/pdf},
}

@article{zaveri_quality_2015,
	title = {Quality assessment for {Linked} {Data}: {A} {Survey}: {A} systematic literature review and conceptual framework},
	volume = {7},
	issn = {22104968, 15700844},
	shorttitle = {Quality assessment for {Linked} {Data}},
	url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/SW-150175},
	doi = {10.3233/SW-150175},
	abstract = {The development and standardization of semantic web technologies has resulted in an unprecedented volume of data being published on the Web as Linked Data (LD). However, we observe widely varying data quality ranging from extensively curated datasets to crowdsourced and extracted data of relatively low quality. In this article, we present the results of a systematic review of approaches for assessing the quality of LD. We gather existing approaches and analyze them qualitatively. In particular, we unify and formalize commonly used terminologies across papers related to data quality and provide a comprehensive list of 18 quality dimensions and 69 metrics. Additionally, we qualitatively analyze the 30 core approaches and 12 tools using a set of attributes. The aim of this article is to provide researchers and data curators a comprehensive understanding of existing work, thereby encouraging further experimentation and development of new approaches focused towards data quality, speciﬁcally for LD.},
	language = {en},
	number = {1},
	urldate = {2024-04-04},
	journal = {Semantic Web},
	author = {Zaveri, Amrapali and Rula, Anisa and Maurino, Andrea and Pietrobon, Ricardo and Lehmann, Jens and Auer, Sören},
	editor = {Hitzler, Pascal},
	month = mar,
	year = {2015},
	pages = {63--93},
	file = {Zaveri et al. - 2015 - Quality assessment for Linked Data A Survey A sy.pdf:files/10625/Zaveri et al. - 2015 - Quality assessment for Linked Data A Survey A sy.pdf:application/pdf},
}

@incollection{gomez-perez_ontology_2004,
	address = {Berlin, Heidelberg},
	title = {Ontology {Evaluation}},
	isbn = {978-3-540-24750-0},
	url = {https://doi.org/10.1007/978-3-540-24750-0_13},
	abstract = {The evaluation of ontologies is an emerging field. At present, a deep core of preliminary ideas and guidelines for evaluating ontologies is missing. This paper presents a brief summary of previous works on evaluating ontologies and the criteria (consistency, completeness, conciseness, expandability and sensitiveness) used to evaluate and assess ontologies. It also addresses the possible types of errors made when domain knowledge is structured in taxonomies in an ontology: circularity errors, exhaustive and non-exhaustive class partition errors, redundancy errors, grammatical errors, semantic errors and incompleteness errors. The paper is based on the experience of evaluating ontologies in the Ontolingua Server.},
	language = {en},
	urldate = {2024-04-04},
	booktitle = {Handbook on {Ontologies}},
	publisher = {Springer},
	author = {Gómez-Pérez, Asunción},
	editor = {Staab, Steffen and Studer, Rudi},
	year = {2004},
	doi = {10.1007/978-3-540-24750-0_13},
	keywords = {Description Logic, Ontology Language, Resource Description Framework, Building Ontology, Competency Question},
	pages = {251--273},
}

@article{heacock_enhancing_2022,
	title = {Enhancing {Data} {Integration}, {Interoperability}, and {Reuse} to {Address} {Complex} and {Emerging} {Environmental} {Health} {Problems}},
	volume = {56},
	issn = {0013-936X},
	url = {https://doi.org/10.1021/acs.est.1c08383},
	doi = {10.1021/acs.est.1c08383},
	abstract = {Environmental health sciences (EHS) span many diverse disciplines. Within the EHS community, the National Institute of Environmental Health Sciences Superfund Research Program (SRP) funds multidisciplinary research aimed to address pressing and complex issues on how people are exposed to hazardous substances and their related health consequences with the goal of identifying strategies to reduce exposures and protect human health. While disentangling the interrelationships that contribute to environmental exposures and their effects on human health over the course of life remains difficult, advances in data science and data sharing offer a path forward to explore data across disciplines to reveal new insights. Multidisciplinary SRP-funded teams are well-positioned to examine how to best integrate EHS data across diverse research domains to address multifaceted environmental health problems. As such, SRP supported collaborative research projects designed to foster and enhance the interoperability and reuse of diverse and complex data streams. This perspective synthesizes those experiences as a landscape view of the challenges identified while working to increase the FAIR-ness (Findable, Accessible, Interoperable, and Reusable) of EHS data and opportunities to address them.},
	number = {12},
	urldate = {2024-04-06},
	journal = {Environmental Science \& Technology},
	author = {Heacock, Michelle L. and Lopez, Adeline R. and Amolegbe, Sara M. and Carlin, Danielle J. and Henry, Heather F. and Trottier, Brittany A. and Velasco, Maria L. and Suk, William A.},
	month = jun,
	year = {2022},
	note = {Publisher: American Chemical Society},
	pages = {7544--7552},
	file = {Full Text PDF:files/10641/Heacock et al. - 2022 - Enhancing Data Integration, Interoperability, and .pdf:application/pdf},
}

@article{groth_fair_2020,
	title = {{FAIR} {Data} {Reuse} – the {Path} through {Data} {Citation}},
	volume = {2},
	issn = {2641-435X},
	url = {https://doi.org/10.1162/dint_a_00030},
	doi = {10.1162/dint_a_00030},
	abstract = {One of the key goals of the FAIR guiding principles is defined by its final principle – to optimize data sets for reuse by both
humans and machines. To do so, data providers need to implement and support consistent machine readable metadata to describe their data sets. This can seem like a daunting task for data providers, whether it is determining what level of detail should be provided in the provenance metadata or figuring out what common shared vocabularies should be used. Additionally, for existing data sets it is
often unclear what steps should be taken to enable maximal, appropriate reuse. Data citation already plays an important role in making
data findable and accessible, providing persistent and unique identifiers plus
metadata on over 16 million data sets. In this paper, we discuss how data
citation and its underlying infrastructures, in particular associated metadata,
provide an important pathway for enabling FAIR data reuse.},
	number = {1-2},
	urldate = {2024-04-06},
	journal = {Data Intelligence},
	author = {Groth, Paul and Cousijn, Helena and Clark, Tim and Goble, Carole},
	month = jan,
	year = {2020},
	pages = {78--86},
	file = {Full Text PDF:files/10643/Groth et al. - 2020 - FAIR Data Reuse – the Path through Data Citation.pdf:application/pdf;Snapshot:files/10644/FAIR-Data-Reuse-the-Path-through-Data-Citation.html:text/html},
}

@article{sinaci_raw_2020,
	title = {From {Raw} {Data} to {FAIR} {Data}: {The} {FAIRification} {Workflow} for {Health} {Research}},
	volume = {59},
	copyright = {Georg Thieme Verlag KG Stuttgart · New York},
	issn = {0026-1270, 2511-705X},
	shorttitle = {From {Raw} {Data} to {FAIR} {Data}},
	url = {http://www.thieme-connect.de/DOI/DOI?10.1055/s-0040-1713684},
	doi = {10.1055/s-0040-1713684},
	abstract = {Background FAIR (findability, accessibility, interoperability, and reusability) guiding principles seek the reuse of data and other digital research input, output, and objects (algorithms, tools, and workflows that led to that data) making them findable, accessible, interoperable, and reusable. GO FAIR - a bottom-up, stakeholder driven and self-governed initiative - defined a seven-step FAIRification process focusing on data, but also indicating the required work for metadata. This FAIRification process aims at addressing the translation of raw datasets into FAIR datasets in a general way, without considering specific requirements and challenges that may arise when dealing with some particular types of data.

  Objectives This scientific contribution addresses the architecture design of an open technological solution built upon the FAIRification process proposed by “GO FAIR” which addresses the identified gaps that such process has when dealing with health datasets.

  Methods A common FAIRification workflow was developed by applying restrictions on existing steps and introducing new steps for specific requirements of health data. These requirements have been elicited after analyzing the FAIRification workflow from different perspectives: technical barriers, ethical implications, and legal framework. This analysis identified gaps when applying the FAIRification process proposed by GO FAIR to health research data management in terms of data curation, validation, deidentification, versioning, and indexing.

  Results A technological architecture based on the use of Health Level Seven International (HL7) FHIR (fast health care interoperability resources) resources is proposed to support the revised FAIRification workflow.

  Discussion Research funding agencies all over the world increasingly demand the application of the FAIR guiding principles to health research output. Existing tools do not fully address the identified needs for health data management. Therefore, researchers may benefit in the coming years from a common framework that supports the proposed FAIRification workflow applied to health datasets.

  Conclusion Routine health care datasets or data resulting from health research can be FAIRified, shared and reused within the health research community following the proposed FAIRification workflow and implementing technical architecture.},
	language = {en},
	number = {S 1},
	urldate = {2024-04-06},
	journal = {Methods of Information in Medicine},
	author = {Sinaci, A. Anil and Núñez-Benjumea, Francisco J. and Gencturk, Mert and Jauer, Malte-Levin and Deserno, Thomas and Chronaki, Catherine and Cangioli, Giorgio and Cavero-Barca, Carlos and Rodríguez-Pérez, Juan M. and Pérez-Pérez, Manuel M. and Erturkmen, Gokce B. Laleci and Hernández-Pérez, Tony and Méndez-Rodríguez, Eva and Parra-Calderón, Carlos L.},
	month = jun,
	year = {2020},
	note = {Publisher: Georg Thieme Verlag KG},
	keywords = {interoperability, metadata, data science, data curation, data anonymization},
	pages = {e21--e32},
	file = {Full Text PDF:files/10646/Sinaci et al. - 2020 - From Raw Data to FAIR Data The FAIRification Work.pdf:application/pdf},
}

@article{stvilia_model_2007,
	title = {A model for ontology quality evaluation},
	copyright = {Copyright (c)},
	issn = {1396-0466},
	url = {https://firstmonday.org/ojs/index.php/fm/article/view/2043},
	doi = {10.5210/fm.v12i12.2043},
	abstract = {Ontologies are important knowledge representation and sharing tools in the workflow of biology research. The high cost of creating and maintaining ontologies encourages their sharing and reuse, and an increasing number of ontologies have been made available from different sources, with different models of curation. To enable effective selection, reuse, integration, and maintenance of these ontologies, however, one needs to have a systematic method of evaluating and connecting their quality to the context of an intended use. Based on an analysis of the activity system and Web server logs of the morphbank biodiversity research data repository, a model was developed to evaluate ontology quality. The model connects the types of quality problems with the types of research activities and suggests relevant metrics. The paper also describes the structure of some of the research activities and the types and patterns of end-user searches in morphbank.},
	language = {en},
	urldate = {2024-04-06},
	journal = {First Monday},
	author = {Stvilia, Besiki},
	month = nov,
	year = {2007},
	keywords = {Ontologies, activity theory, biodiversity, quality measurement},
}

@article{guizzardi_ontology_2020,
	title = {Ontology, {Ontologies} and the “{I}” of {FAIR}},
	volume = {2},
	issn = {2641-435X},
	url = {https://doi.org/10.1162/dint_a_00040},
	doi = {10.1162/dint_a_00040},
	abstract = {According to the FAIR guiding principles, one of the central attributes for maximizing the added value of information artifacts is interoperability. In this
paper, I discuss the importance, and propose a characterization of the notion of Semantic Interoperability. Moreover, I show that a direct
consequence of this view is that Semantic Interoperability cannot be achieved
without the support of, on one hand, (i) ontologies, as meaning contracts capturing the conceptualizations
represented in information artifacts and, on the other hand, of (ii) Ontology, as a discipline proposing formal meth- ods and
theories for clarifying these conceptualizations and articulating their
representations. In particular, I discuss the fundamental role of formal
ontological theories (in the latter sense) to properly ground the construction
of representation languages, as well as methodological and computational tools
for supporting the engineering of ontologies (in the former
sense) in the context of FAIR.},
	number = {1-2},
	urldate = {2024-04-07},
	journal = {Data Intelligence},
	author = {Guizzardi, Giancarlo},
	month = jan,
	year = {2020},
	pages = {181--191},
	file = {Full Text PDF:files/10653/Guizzardi - 2020 - Ontology, Ontologies and the “I” of FAIR.pdf:application/pdf;Snapshot:files/10654/Ontology-Ontologies-and-the-I-of-FAIR.html:text/html},
}

@article{ciula_model_2023,
	title = {Model and {Modelling} in {Digital} {Humanities}: {Towards} a {Renewed} {Language}},
	shorttitle = {Model and {Modelling} in {Digital} {Humanities}},
	url = {https://www.openbookpublishers.com/books/10.11647/obp.0369/chapters/10.11647/obp.0369.01},
	doi = {10.11647/obp.0369.01},
	abstract = {Chapter 1, Towards a new language for modelling, proposes a selection of lexical ramifications and a semantic excursus on the terms model/modelling. Some etymological reflections on these terms and selected occurrences in the Western history of thought are mapped out. The focus of the chapter is on the history and the polysemy characterising the terms model and modelling with the aim to offer some reflections on their current use, and to foreground the pragmatic elements implied by the concept of model in modelling practices and by the use of language (metalanguage). The underlying assumption is that by analysing this metalanguage, we can acquire a deeper understanding of the practices of modelling and the related processes of conceptualisation, representation, visualisation and communication. In addition, the concept of “pragmatic modelling” (further discussed in chapter 2), is introduced and contextualised.},
	language = {English},
	urldate = {2024-04-09},
	author = {Ciula, Arianna and Eide, Øyvind and Marras, Cristina and Sahle, Patrick},
	month = dec,
	year = {2023},
	note = {Publisher: Open Book Publishers},
	pages = {19--42},
	file = {Full Text PDF:files/10658/Ciula et al. - 2023 - Model and Modelling in Digital Humanities Towards.pdf:application/pdf},
}

@article{ciula_modelling_2023,
	title = {Modelling as {Semiotic} {Process}},
	url = {https://www.openbookpublishers.com/books/10.11647/obp.0369/chapters/10.11647/obp.0369.03},
	doi = {10.11647/obp.0369.03},
	abstract = {Chapter 3, Modelling as semiotic process, refers to model-making as theorised within a semiotic framework. This is complementary to but also in contrast with the common theorisation of the practice of modelling in DH informed by the techno-sciences and computer science in particular. Modelling is framed as a process of signification (semiotic process or meaning making). This semiotic framework allows us to see modelling primarily as a strategy to make sense (signification) via practical thinking (creating and manipulating models). It enables to stress the dynamic nature of models and modelling, and to reinstate in renewed terms the understanding of modelling as an open process of signification enacting a triadic cooperation (among object, representamen and interpreter). Referring to Charles Sanders Peirce’s classification of hypoicons, we reflect on some DH examples of modelling in the form of images, diagrams and metaphors, claiming that a semiotic understanding of modelling could ultimately allow us to surpass the rigid duality object vs. model, as well as sign vs. context.},
	language = {English},
	urldate = {2024-04-09},
	author = {Ciula, Arianna and Eide, Øyvind and Marras, Cristina and Sahle, Patrick},
	month = dec,
	year = {2023},
	note = {Publisher: Open Book Publishers},
	pages = {63--94},
	file = {Full Text PDF:files/10660/Ciula et al. - 2023 - Modelling as Semiotic Process.pdf:application/pdf},
}

@article{ciula_metaphoric_2023,
	title = {Metaphoric {Reasoning} and {Pragmatic} {Modelling}},
	url = {https://www.openbookpublishers.com/books/10.11647/obp.0369/chapters/10.11647/obp.0369.02},
	doi = {10.11647/obp.0369.02},
	abstract = {Chapter 2, Modelling and metaphoric reasoning, discusses the act of modelling, especially, its representative and descriptive functions and how it operates within a context which includes a metaphorical language. Metaphors adapt to and at the same time transform this language. The concept of “pragmatic modelling” is discussed further and is connected to how metaphorical language operates in Digital Humanities (DH) as well as other (mainly interdisciplinary) modelling contexts. Furthermore, the chapter exemplifies how metaphors themselves are models of knowledge, as they define the schemes within which specific concepts operate and knowledge is established and expressed. In particular, in a DH context, the use of metaphors can have practical outcomes in how affordances influence data processing, storage, and design, and in how data are presented and interfaces are built. In this chapter, we propose to consider modelling as a creative and usually highly pragmatic process of thinking and reasoning in which metaphors assume a central role and where meaning is negotiated through the creation and manipulation of external representations combined with an imaginative use of formal and informal languages.},
	language = {English},
	urldate = {2024-04-09},
	author = {Ciula, Arianna and Eide, Øyvind and Marras, Cristina and Sahle, Patrick},
	month = dec,
	year = {2023},
	note = {Publisher: Open Book Publishers},
	pages = {43--62},
	file = {Full Text PDF:files/10662/Ciula et al. - 2023 - Metaphoric Reasoning and Pragmatic Modelling.pdf:application/pdf},
}

@article{ciula_modelling_2023-1,
	title = {Modelling as {Media} {Transformations}},
	url = {https://www.openbookpublishers.com/books/10.11647/obp.0369/chapters/10.11647/obp.0369.04},
	doi = {10.11647/obp.0369.04},
	abstract = {Chapter 4, Modelling as media transformation, dwells on the tangible physical forms of models as material and mediated media products expressed and shared in human communication. The forms models take are discussed in terms of configurations of media modalities. This intermedia studies approach, whereby modelling is studied as a media transformation process, complements the semiotic perspective of chapter 3 by revisiting some of the previous examples and integrating them with a variety of heterogeneous models, from archaeology and theatre studies to numerical mathematics, and media transformation processes, including formalisations undertaken in DH research.},
	language = {English},
	urldate = {2024-04-09},
	author = {Ciula, Arianna and Eide, Øyvind and Marras, Cristina and Sahle, Patrick},
	month = dec,
	year = {2023},
	note = {Publisher: Open Book Publishers},
	pages = {95--130},
	file = {Full Text PDF:files/10664/Ciula et al. - 2023 - Modelling as Media Transformations.pdf:application/pdf},
}

@article{ciula_modelling_2023-2,
	title = {Modelling {Text}: {A} {Case} {Study}},
	shorttitle = {Modelling {Text}},
	url = {https://www.openbookpublishers.com/books/10.11647/obp.0369/chapters/10.11647/obp.0369.05},
	doi = {10.11647/obp.0369.05},
	abstract = {Chapter 5, Modelling text – a case study, presents a case study examining examples of activities of modelling around the concepts of text and textuality. It qualifies as an anthology, a gallery, an empirical study, and an experiment on finding a different mode of argumentation to “change the launch pad” into future discussions around modelling. In this chapter, models are exposed primarily as specific and situated visual representations we experience when studying and modelling texts. They are presented following a What You See is What You Get approach. The argument takes a different form of expression from the other chapters by discussing models and their visualisations with the presentation of topical quotes extracted from the literature alongside their iconic counterparts, either in their original version or as interpreted visually by the authors and the designers. This effort is in itself an example of modelling as a translation process in action. The chapter spans various disciplines and illustrates different modes of making implicit and explicit models, covering a broad range from theoretical descriptions to concrete applications in the realm of text technologies and knowledge representation. The overall selection for examples aims to offer a “graphical” argument of how different models represent conceptualisations of and perspectives on texts in different ways, illustrating key concepts discussed in the previous chapters, and encouraging the readers to engage with the topic further.},
	language = {English},
	urldate = {2024-04-09},
	author = {Ciula, Arianna and Eide, Øyvind and Marras, Cristina and Sahle, Patrick},
	month = dec,
	year = {2023},
	note = {Publisher: Open Book Publishers},
	pages = {131--205},
	file = {Full Text PDF:files/10666/Ciula et al. - 2023 - Modelling Text A Case Study.pdf:application/pdf},
}

@techreport{horstmann_towards_2020,
	type = {Report},
	title = {Towards a {Best} {Practice} for {Developing} {Best} {Practices} in {Ocean} {Observation} ({BP4BP}): {Supporting} {Methodological} {Evolution} through {Actionable} {Documentation},},
	copyright = {Attribution  4.0 International},
	shorttitle = {Towards a {Best} {Practice} for {Developing} {Best} {Practices} in {Ocean} {Observation} ({BP4BP})},
	url = {https://repository.oceanbestpractices.org/handle/11329/1266},
	abstract = {In this document, we provide details on how to best use the Ocean Best Practices System (OBPS) templates, thus allowing greater discovery, machine readability, sharing and understandability of methods and best practices (Buttigieg et al. 2019). This document clarifies how to optimally populate the different sections of an OBPS template. We describe how those sections can help the OBPS evolve each submission towards more global best practices. Further, we discuss key challenges in developing methods into community-wide best practices.},
	language = {en},
	urldate = {2024-04-10},
	institution = {UNESCO},
	author = {Horstmann, Cora and Buttigieg, Pier Luigi and Simpson, Pauline and Pearlman, Jay and Karstensen, J. and Waite, Anya M.},
	year = {2020},
	doi = {10.25607/OBP-781},
	note = {Accepted: 2020-04-11T12:19:54Z},
	file = {Full Text PDF:files/10671/Horstmann et al. - 2020 - Towards a Best Practice for Developing Best Practi.pdf:application/pdf},
}

@article{barzaghi_hero_nodate,
	title = {{HeRO}: {A} {Semantic} {Framework} for {Heritage} {Risk} {Assessment} in the {SIRIUS} {Project}},
	abstract = {In recent decades there has been a change in perspective towards risk assessment in cultural and environmental heritage. Despite the positive impact of heritage on various aspects of society, it is often neglected in disaster risk management, mostly due to lack of strategies in sharing common methodologies and process knowledge. The SIRIUS project, centered in Ravenna (Italy), aims to localize global disaster management guidelines applied to cultural and environmental heritage. In the context of SIRIUS, a pattern-based OWL 2 DL ontology called the Heritage Risk Assessment Ontology (HeRO) is being developed to standardize risk assessment procedures and manage complex heritage risk data. In this contribution, its effectiveness is demonstrated through an in-depth exposition of its modules and an example scenario, promising practical application in an upcoming web-based tool. Future work involves semantic expansion, alignment with other heritage risk assessment methodologies, and further testing.},
	language = {en},
	author = {Barzaghi, Sebastian},
	file = {Barzaghi - HeRO A Semantic Framework for Heritage Risk Asses.pdf:files/10690/Barzaghi - HeRO A Semantic Framework for Heritage Risk Asses.pdf:application/pdf},
}

@misc{barzaghi_thinking_2024,
	title = {Thinking {Outside} the {Black} {Box}: {Insights} from a {Digital} {Exhibition} in the {Humanities}},
	shorttitle = {Thinking {Outside} the {Black} {Box}},
	url = {http://arxiv.org/abs/2402.12000},
	doi = {10.48550/arXiv.2402.12000},
	abstract = {One of the main goals of Open Science is to make research more reproducible. There is no consensus, however, on what exactly "reproducibility" is, as opposed for example to "replicability", and how it applies to different research fields. After a short review of the literature on reproducibility/replicability with a focus on the humanities, we describe how the creation of the digital twin of the temporary exhibition "The Other Renaissance" has been documented throughout, with different methods, but with constant attention to research transparency, openness and accountability. A careful documentation of the study design, data collection and analysis techniques helps reflect and make all possible influencing factors explicit, and is a fundamental tool for reliability and rigour and for opening the "black box" of research.},
	urldate = {2024-04-20},
	publisher = {arXiv},
	author = {Barzaghi, Sebastian and Bordignon, Alice and Gualandi, Bianca and Peroni, Silvio},
	month = apr,
	year = {2024},
	note = {arXiv:2402.12000 [cs]},
	keywords = {Computer Science - Digital Libraries},
	file = {arXiv Fulltext PDF:files/10694/Barzaghi et al. - 2024 - Thinking Outside the Black Box Insights from a Di.pdf:application/pdf;arXiv.org Snapshot:files/10695/2402.html:text/html},
}

@misc{barzaghi_developing_2024,
	title = {Developing {Application} {Profiles} for {Enhancing} {Data} and {Workflows} in {Cultural} {Heritage} {Digitisation} {Processes}},
	url = {http://arxiv.org/abs/2404.12069},
	doi = {10.48550/arXiv.2404.12069},
	abstract = {As a result of the proliferation of 3D digitisation in the context of cultural heritage projects, digital assets and digitisation processes - being considered as proper research objects - must prioritise adherence to FAIR principles. Existing standards and ontologies, such as CIDOC CRM, play a crucial role in this regard, but they are often over-engineered for the need of a particular application context, thus making their understanding and adoption difficult. Application profiles of a given standard - defined as sets of ontological entities drawn from one or more semantic artefacts for a particular context or application - are usually proposed as tools for promoting interoperability and reuse while being tied entirely to the particular application context they refer to. In this paper, we present an adaptation and application of an ontology development methodology, i.e. SAMOD, to guide the creation of robust, semantically sound application profiles of large standard models. Using an existing pilot study we have developed in a project dedicated to leveraging virtual technologies to preserve and valorise cultural heritage, we introduce an application profile named CHAD-AP, that we have developed following our customised version of SAMOD. We reflect on the use of SAMOD and similar ontology development methodologies for this purpose, highlighting its strengths and current limitations, future developments, and possible adoption in other similar projects.},
	urldate = {2024-04-20},
	publisher = {arXiv},
	author = {Barzaghi, Sebastian and Heibi, Ivan and Moretti, Arianna and Peroni, Silvio},
	month = apr,
	year = {2024},
	note = {arXiv:2404.12069 [cs]},
	keywords = {Computer Science - Digital Libraries},
	file = {arXiv Fulltext PDF:files/10697/Barzaghi et al. - 2024 - Developing Application Profiles for Enhancing Data.pdf:application/pdf;arXiv.org Snapshot:files/10698/2404.html:text/html},
}

@misc{dublin_manage_2017,
	title = {Manage, {Improve} and {Open} up your {Research} and {Data} – {Parthenos} training},
	url = {https://training.parthenos-project.eu/sample-page/manage-improve-and-open-up-your-research-and-data/},
	language = {en-US},
	urldate = {2024-04-22},
	author = {Dublin, Trinity College},
	month = jul,
	year = {2017},
	file = {Snapshot:files/10700/manage-improve-and-open-up-your-research-and-data.html:text/html},
}

@misc{barzaghi_thinking_2024-1,
	title = {Thinking {Outside} the {Black} {Box}: {Insights} from a {Digital} {Exhibition} in the {Humanities}},
	copyright = {All rights reserved},
	shorttitle = {Thinking {Outside} the {Black} {Box}},
	url = {http://arxiv.org/abs/2402.12000},
	doi = {10.48550/arXiv.2402.12000},
	abstract = {One of the main goals of Open Science is to make research more reproducible. There is no consensus, however, on what exactly "reproducibility" is, as opposed for example to "replicability", and how it applies to different research fields. After a short review of the literature on reproducibility/replicability with a focus on the humanities, we describe how the creation of the digital twin of the temporary exhibition "The Other Renaissance" has been documented throughout, with different methods, but with constant attention to research transparency, openness and accountability. A careful documentation of the study design, data collection and analysis techniques helps reflect and make all possible influencing factors explicit, and is a fundamental tool for reliability and rigour and for opening the "black box" of research.},
	urldate = {2024-04-30},
	publisher = {arXiv},
	author = {Barzaghi, Sebastian and Bordignon, Alice and Gualandi, Bianca and Peroni, Silvio},
	month = apr,
	year = {2024},
	note = {arXiv:2402.12000 [cs]},
	keywords = {Computer Science - Digital Libraries},
	file = {arXiv Fulltext PDF:files/10707/Barzaghi et al. - 2024 - Thinking Outside the Black Box Insights from a Di.pdf:application/pdf;arXiv.org Snapshot:files/10708/2402.html:text/html},
}

@incollection{krogstie_information_2007-1,
	address = {Berlin, Heidelberg},
	title = {From {Information} {Algebra} to {Enterprise} {Modelling} and {Ontologies} — a {Historical} {Perspective} on {Modelling} for {Information} {Systems}},
	isbn = {978-3-540-72676-0 978-3-540-72677-7},
	url = {http://link.springer.com/10.1007/978-3-540-72677-7_1},
	language = {en},
	urldate = {2024-05-13},
	booktitle = {Conceptual {Modelling} in {Information} {Systems} {Engineering}},
	publisher = {Springer Berlin Heidelberg},
	author = {Bubenko, Janis A.},
	editor = {Krogstie, John and Opdahl, Andreas Lothe and Brinkkemper, Sjaak},
	year = {2007},
	doi = {10.1007/978-3-540-72677-7_1},
	pages = {1--18},
}

@incollection{hutchison_what_2005-1,
	address = {Berlin, Heidelberg},
	title = {What {Is} a {Concept}?},
	volume = {3596},
	isbn = {978-3-540-27783-5 978-3-540-31885-9},
	url = {http://link.springer.com/10.1007/11524564_4},
	urldate = {2024-05-13},
	booktitle = {Conceptual {Structures}: {Common} {Semantics} for {Sharing} {Knowledge}},
	publisher = {Springer Berlin Heidelberg},
	author = {Goguen, Joseph},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Dau, Frithjof and Mugnier, Marie-Laure and Stumme, Gerd},
	year = {2005},
	doi = {10.1007/11524564_4},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {52--77},
}

@article{chen_entity-relationship_1976-1,
	title = {The entity-relationship model—toward a unified view of data},
	volume = {1},
	issn = {0362-5915, 1557-4644},
	url = {https://dl.acm.org/doi/10.1145/320434.320440},
	doi = {10.1145/320434.320440},
	abstract = {A data model, called the entity-relationship model, is proposed. This model incorporates some of the important semantic information about the real world. A special diagrammatic technique is introduced as a tool for database design. An example of database design and description using the model and the diagrammatic technique is given. Some implications for data integrity, information retrieval, and data manipulation are discussed.
            The entity-relationship model can be used as a basis for unification of different views of data: the network model, the relational model, and the entity set model. Semantic ambiguities in these models are analyzed. Possible ways to derive their views of data from the entity-relationship model are presented.},
	language = {en},
	number = {1},
	urldate = {2024-05-13},
	journal = {ACM Transactions on Database Systems},
	author = {Chen, Peter Pin-Shan},
	month = mar,
	year = {1976},
	pages = {9--36},
	file = {Full text:files/10851/Chen - 1976 - The entity-relationship model—toward a unified vie.pdf:application/pdf},
}

@article{ludewig_models_2003-1,
	title = {Models in software engineering ? an introduction},
	volume = {2},
	copyright = {http://www.springer.com/tdm},
	issn = {1619-1366, 1619-1374},
	shorttitle = {Models in software engineering ?},
	url = {http://link.springer.com/10.1007/s10270-003-0020-3},
	doi = {10.1007/s10270-003-0020-3},
	number = {1},
	urldate = {2024-05-13},
	journal = {Software and Systems Modeling},
	author = {Ludewig, Jochen},
	month = mar,
	year = {2003},
	pages = {5--14},
}

@article{pisanski_mental_2010-2,
	title = {Mental models of the bibliographic universe. {Part} 1: mental models of descriptions},
	volume = {66},
	copyright = {https://www.emerald.com/insight/site-policies},
	issn = {0022-0418},
	shorttitle = {Mental models of the bibliographic universe. {Part} 1},
	url = {https://www.emerald.com/insight/content/doi/10.1108/00220411011066772/full/html},
	doi = {10.1108/00220411011066772},
	abstract = {Purpose
              The paper aims to present the results of the first two tasks of a user study looking into mental models of the bibliographic universe and especially their comparison to the Functional Requirements for Bibliographic Records (FRBR) conceptual model, which has not yet been user tested.
            
            
              Design/methodology/approach
              The paper employes a combination of techniques for eliciting mental models and consisted of three tasks, two of which, card sorting and concept mapping, are presented herein. Its participants were 30 individuals residing in the general area of Ljubljana, Slovenia.
            
            
              Findings
              Cumulative results of concept mapping show a strong resemblance to FRBR. Card sorts did not produce conclusive results. In both tasks, participants paid special attention to the original expression, indicating that a special place for it should be considered.
            
            
              Research limitations/implications
              The study was performed using a relatively small sample of participants living in a geographically limited space using relatively straight‐forward examples.
            
            
              Practical implications
              Some solid evidence is provided for adoption of FRBR as the conceptual basis for cataloguing.
            
            
              Originality/value
              This is the first widely published user study of FRBR, applying novel methodological approaches in the field of Library and Information Science.},
	language = {en},
	number = {5},
	urldate = {2024-05-13},
	journal = {Journal of Documentation},
	author = {Pisanski, Jan and Žumer, Maja},
	month = sep,
	year = {2010},
	pages = {643--667},
}

@article{pisanski_mental_2010-3,
	title = {Mental models of the bibliographic universe. {Part} 2: comparison task and conclusions},
	volume = {66},
	copyright = {https://www.emerald.com/insight/site-policies},
	issn = {0022-0418},
	shorttitle = {Mental models of the bibliographic universe. {Part} 2},
	url = {https://www.emerald.com/insight/content/doi/10.1108/00220411011066781/full/html},
	doi = {10.1108/00220411011066781},
	abstract = {Purpose
              The paper aims to provide some insight into mental models of the bibliographic universe and how they compare with functional requirements for bibliographic records (FRBR) as a conceptual model of the bibliographic universe.
            
            
              Design/methodology/approach
              To get a more complete picture of the mental models, different elicitation techniques were used. The three tasks of the paper were: card‐sorting, concept mapping and comparison task. The paper deals with comparison task, which consisted of interviews and rankings, and provides a discussion of the results of the paper as a whole.
            
            
              Findings
              Results of the ranking part of the comparison task confirm the findings of concept mapping task. In both cases, while there are individual differences between mental models, on average they gravitate towards FRBR.
            
            
              Research limitations/implications
              This is a small study and it provides only a glimpse of the implications of using FRBR as a conceptual basis for cataloguing. More FRBR‐related user studies are needed, including similar studies on different groups of individuals and different types of materials, as well as practical studies of user needs and user interfaces.
            
            
              Practical implications
              The results of this study are the first user‐tested indication of the validity of FRBR as a conceptual basis for the future of cataloguing.
            
            
              Originality/value
              This is the first published paper of mental models of the bibliographic universe and uses a unique combination of mental model elicitation techniques.},
	language = {en},
	number = {5},
	urldate = {2024-05-13},
	journal = {Journal of Documentation},
	author = {Pisanski, Jan and Žumer, Maja},
	month = sep,
	year = {2010},
	pages = {668--680},
}

@book{borgida_conceptual_2009-1,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Conceptual {Modeling}: {Foundations} and {Applications}: {Essays} in {Honor} of {John} {Mylopoulos}},
	volume = {5600},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-3-642-02462-7 978-3-642-02463-4},
	shorttitle = {Conceptual {Modeling}},
	url = {http://link.springer.com/10.1007/978-3-642-02463-4},
	language = {en},
	urldate = {2024-05-13},
	publisher = {Springer Berlin Heidelberg},
	editor = {Borgida, Alexander T. and Chaudhri, Vinay K. and Giorgini, Paolo and Yu, Eric S.},
	year = {2009},
	doi = {10.1007/978-3-642-02463-4},
	file = {Versione inviata:files/10852/Borgida et al. - 2009 - Conceptual Modeling Foundations and Applications.pdf:application/pdf},
}

@incollection{embley_theory_2011-1,
	address = {Berlin, Heidelberg},
	title = {The {Theory} of {Conceptual} {Models}, the {Theory} of {Conceptual} {Modelling} and {Foundations} of {Conceptual} {Modelling}},
	isbn = {978-3-642-15864-3 978-3-642-15865-0},
	url = {http://link.springer.com/10.1007/978-3-642-15865-0_17},
	language = {en},
	urldate = {2024-05-13},
	booktitle = {Handbook of {Conceptual} {Modeling}},
	publisher = {Springer Berlin Heidelberg},
	author = {Thalheim, Bernhard},
	editor = {Embley, David W. and Thalheim, Bernhard},
	year = {2011},
	doi = {10.1007/978-3-642-15865-0_17},
	pages = {543--577},
}

@incollection{ravankhah_integration_2017,
	address = {Cham},
	title = {Integration of {Cultural} {Heritage} into {Disaster} {Risk} {Management}: {Challenges} and {Opportunities} for {Increased} {Disaster} {Resilience}},
	isbn = {978-3-319-57165-2},
	shorttitle = {Integration of {Cultural} {Heritage} into {Disaster} {Risk} {Management}},
	url = {https://doi.org/10.1007/978-3-319-57165-2_22},
	abstract = {This chapter explores the integration of cultural heritage into the overall framework of DRM, outlines potential challenges and emphasises that, aside from enhancing heritage protection from natural hazards and climate change-related extreme events, this can promote the overall disaster resilience of the social, built and environmental systems to which cultural heritage belongs. The World Heritage Site of ‘Bam and its Cultural Landscape’, as a unique example of a traditional human settlement, is investigated through analysis of its multidimensional values associated with its contribution to post-disaster recovery, development and resilience of the city of Bam following the earthquake in 2003. In drawing upon this example, the integration and contribution of cultural heritage in the DRM framework are discussed through an interdisciplinary review of existing literature. This review demonstrates that despite the opportunities for proactive long-term economic and social coping capacity, potential challenges, primarily in respect to safeguarding heritage values within overall risk reduction policies, may also be generated.},
	language = {en},
	urldate = {2024-05-14},
	booktitle = {Going {Beyond}: {Perceptions} of {Sustainability} in {Heritage} {Studies} {No}. 2},
	publisher = {Springer International Publishing},
	author = {Ravankhah, Mohammad and Chmutina, Ksenia and Schmidt, Michael and Bosher, Lee},
	editor = {Albert, Marie-Theres and Bandarin, Francesco and Pereira Roders, Ana},
	year = {2017},
	doi = {10.1007/978-3-319-57165-2_22},
	pages = {307--321},
}

@article{minguez_garcia_resilient_2019-1,
	title = {Resilient cultural heritage: from global to national levels – the case of {Bhutan}},
	volume = {29},
	issn = {0965-3562},
	shorttitle = {Resilient cultural heritage},
	url = {https://doi.org/10.1108/DPM-08-2018-0285},
	doi = {10.1108/DPM-08-2018-0285},
	abstract = {Purpose Cultural heritage is about people, their history and their identity. Protecting cultural heritage from natural hazards by connecting it with disaster risk management (DRM) directly benefits local communities. Cultural heritage also has a global dimension, and collaboration and support from the international community to protect it is vital. Culture and heritage differ among countries, as do natural hazards, but practitioners face some common challenges, such as the need to create awareness. The paper aims to discuss these issues. Design/methodology/approach This paper presents: a brief overview of the current connection between DRM and cultural heritage in the global context; an analysis of how international knowledge-exchange initiatives can help countries improve the resilience of their heritage sites, using Bhutan as an example; and a proposal to keep this topic moving forward in both the international and national agendas for sustainable development and resilience. Findings International knowledge exchanges may help to find solutions, and Bhutan is a good example. This small, hazard-prone country in the Himalayas, has strong traditions and heritage, and is aware of its vulnerabilities and risks. Learning from Japan’s extensive experience, Bhutan has been working with international experts to improve the resilience of its cultural heritage sites. Originality/value The ultimate aim is that this paper serves as an inspiration for other countries, as well as international organizations such as the World Bank, to keep strengthening ties between DRM and cultural heritage.},
	number = {1},
	urldate = {2024-05-14},
	journal = {Disaster Prevention and Management: An International Journal},
	author = {Minguez Garcia, Barbara},
	month = jan,
	year = {2019},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Cultural heritage, Communities, Disaster risk management, Bhutan, International organizations, Japan},
	pages = {36--46},
	file = {Snapshot:files/10855/html.html:text/html},
}

@article{bullock_marriage_2012,
	title = {The {Marriage} of {Risk} {Assessment} and {Significance} {Assessment}: {Challenges} and {Opportunities}},
	volume = {8},
	issn = {1550-1906},
	shorttitle = {The {Marriage} of {Risk} {Assessment} and {Significance} {Assessment}},
	url = {https://doi.org/10.1177/155019061200800405},
	doi = {10.1177/155019061200800405},
	abstract = {The results of risk assessments and significance assessments can help collecting organisations set work priorities. However, the complementary nature of the two methods, deriving from different professional traditions, means that recommended priorities may differ. The desire of cultural heritage risk analysts to include significance determinations in their workings is understandable. In the more comprehensive risk analysis systems, this inclusion depends on the quantification of changes in value due to changes in states of objects or collections, which can be difficult to deliver. Significance assessment purists reject the reduction of complex, shifting meanings to numerical values because of the apparent rigidity and certainty this implies.
The purpose of this essay is to provoke discussion. Should risk assessment or significance assessment come first when decisionmaking for collections? Who has the power of veto if opinions differ? Do concepts of ‘value,’ as differentiated from significance, assist? Will professional demarcations doom the marriage of these two hopefuls?},
	language = {en},
	number = {4},
	urldate = {2024-05-14},
	journal = {Collections},
	author = {Bullock, Veronica M.},
	month = dec,
	year = {2012},
	note = {Publisher: SAGE Publications Inc},
	pages = {307--321},
}

@article{durrant_disaster_2023-1,
	title = {Disaster risk management and cultural heritage: {The} perceptions of {European} world heritage site managers on disaster risk management},
	volume = {89},
	issn = {2212-4209},
	shorttitle = {Disaster risk management and cultural heritage},
	url = {https://www.sciencedirect.com/science/article/pii/S221242092300105X},
	doi = {10.1016/j.ijdrr.2023.103625},
	abstract = {Research into the sustainable management of the world's cultural heritage (CH) is increasing. This is due to the vulnerability of CH to climate-related disasters and the perceived contribution of CH to the achievement of broader sustainability goals. Despite the perceived benefits of bringing together CH and sustainability, researchers have identified barriers that slow integration. These barriers are theoretical and practical, and targeted research would help improve the resilience of our CH. This article aims to explore the perceptions of a group of UNESCO world heritage site managers (WHSM) on disaster risk management. A questionnaire was sent to WHSM via professional email boxes. The questionnaire consisted of 26 questions designed to explore the perception of WHSM. In total, 58 responses were received, and the results produced findings worthy of discussion. WHSM still have limited access to disaster risk management strategies or practical implementation experience. Practitioners in this field perceive multiple risks, not just those related to climate change. The researchers noted that there was a tendency to focus on the most immediate problem, rather than the full range of risks they might face. It is clear that there is an opportunity to improve resilience through knowledge sharing and better communication across all CH. This is also true of individual world cultural heritage sites, with opportunities to engage more effectively with local stakeholders. This article pinpoints the current perceptions of WHSM for the academic community and highlights critical avenues of research that will aid in the overarching theoretical and operational integration of CH and sustainability.},
	urldate = {2024-05-14},
	journal = {International Journal of Disaster Risk Reduction},
	author = {Durrant, Louis J. and Vadher, Atish N. and Teller, Jacques},
	month = apr,
	year = {2023},
	keywords = {Cultural heritage, Survey, Disaster risk management, Perceptions, World heritage site managers},
	pages = {103625},
	file = {Full text:files/10860/Durrant et al. - 2023 - Disaster risk management and cultural heritage Th.pdf:application/pdf;ScienceDirect Snapshot:files/10859/S221242092300105X.html:text/html},
}

@article{crowley_cultural_2022-1,
	title = {Cultural heritage and risk assessments: {Gaps}, challenges, and future research directions for the inclusion of heritage within climate change adaptation and disaster management},
	volume = {1},
	copyright = {© 2022 The Authors. Climate Resilience and Sustainability published by John Wiley \& Sons Ltd on behalf of Royal Meteorological Society.},
	issn = {2692-4587},
	shorttitle = {Cultural heritage and risk assessments},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cli2.45},
	doi = {10.1002/cli2.45},
	abstract = {Cultural heritage shapes our identity, delivers capacities, and exposes vulnerabilities, yet cultural heritage value and vulnerability are largely missing from conventional risk assessments. Risk assessments are a fundamental first step in identifying effective mechanisms for Climate Change Adaptation (CCA) and disaster management. However, by ignoring the influence of heritage, decision makers are limiting their understanding of risk and therefore opportunities vital for building and maintaining local resilience. We present findings from a synthesis of peer-reviewed literature from the last 15 years on cultural heritage risk assessment for primarily CCA but with wider implications for disaster management. We identify a significant lack of research examining intangible aspects of heritage and their influence on risk and resilience. Across the literature, risk assessments focus largely on exposure in isolation from vulnerability or adaptive capacity and where vulnerability is included there is no consistent definition or criterion. We highlight that the most frequently used methods have minimal engagement with local community values, experience, and knowledge relating to heritage practice and customs. Community engagement is most often associated with ‘professional experts’ rather than members of a local community. Furthermore, the Global South is severely under-represented with a research bias towards Europe and North America. We recommend an agile approach to future assessments with the adjustment of risk tool research and development to include participatory approaches. Future climate risk frameworks must incorporate community-scale values to understand the role of cultural heritage in relation to adaptive capacity, vulnerability, and resilience.},
	language = {en},
	number = {3},
	urldate = {2024-05-14},
	journal = {Climate Resilience and Sustainability},
	author = {Crowley, Kate and Jackson, Rowan and O'Connell, Siona and Karunarthna, Dulma and Anantasari, Esti and Retnowati, Arry and Niemand, Dominique},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cli2.45},
	keywords = {cultural heritage, risk, adaptation to climate change, climate resilience, risk-based planning, sustainable development},
	pages = {e45},
	file = {Full Text PDF:files/10862/Crowley et al. - 2022 - Cultural heritage and risk assessments Gaps, chal.pdf:application/pdf;Snapshot:files/10863/cli2.html:text/html},
}

@article{andrew_mchugh_risk_2007,
	title = {Risk management foundations for digital libraries: {DRAMBORA} ({Digital} {Repository} {Audit} {Method} {Based} on {Risk} {Assessment})},
	shorttitle = {Risk management foundations for digital libraries},
	abstract = {This paper proposes the use of the DRAMBORA (Digital Repository Audit Method Based on Risk Assessment), the Digital Curation Centre (DCC) and DigitalPreservationEurope (DPE) audit toolkit for digital repositories, as a tool to ensure the preservation capabilities of digital libraries. Digital repositories lie at the heart of digital libraries: ensuring long-term sustainability of their content is a fundamental responsibility of a digital library system and environment. DRAMBORA is designed to facilitate the assessment of digital repositories’ risk exposure: it facilitates internal audit by providing repository administrators with a means to assess their capabilities, identify their weaknesses, and recognize their strengths. The toolkit represents the latest complementary development in an ongoing international effort to conceive criteria, means and methodologies for audit and certification of trustworthy digital repositories. DRAMBORA already includes the ten CRL principles for digital preservation repositories. As part of the ongoing developments of the toolkit we are investigating its applicability within the digital library domain, and the identification of core principles of digital preservation that can be incorporated into the DELOS Digital Library Reference Model, to ensure that digital libraries conforming to the reference model have preservation functionality.},
	journal = {Pre-proceedings of the Second Workshop on Foundations of Digital Libraries},
	author = {{Andrew McHugh} and Innocenti, Perla and {Seamus Ross} and {Raivo Ruusalepp}},
	year = {2007},
	note = {Place: Pisa},
	keywords = {digital curation, digital preservation, digital repositories, digital libraries, risk assessment, digital technologies, ICT, risk managenent},
	pages = {1--13},
}

@inproceedings{sales_common_2018-2,
	address = {Cham},
	title = {The {Common} {Ontology} of {Value} and {Risk}},
	isbn = {978-3-030-00847-5},
	doi = {10.1007/978-3-030-00847-5_11},
	abstract = {Risk analysis is traditionally accepted as a complex and critical activity in various contexts, such as strategic planning and software development. Given its complexity, several modeling approaches have been proposed to help analysts in representing and analyzing risks. Naturally, having a clear understanding of the nature of risk is fundamental for such an activity. Yet, risk is still a heavily overloaded and conceptually unclear notion, despite the wide number of efforts to properly characterize it, including a series of international standards. In this paper, we address this issue by means of an in-depth ontological analysis of the notion of risk. In particular, this analysis shows a surprising and important result, namely, that the notion of risk is irreducibly intertwined with the notion of value and, more specifically, that risk assessment is a particular case of value ascription. As a result, we propose a concrete artifact, namely, the Common Ontology of Value and Risk, which we employ to harmonize different conceptions of risk existing in the literature.},
	language = {en},
	booktitle = {Conceptual {Modeling}},
	publisher = {Springer International Publishing},
	author = {Sales, Tiago Prince and Baião, Fernanda and Guizzardi, Giancarlo and Almeida, João Paulo A. and Guarino, Nicola and Mylopoulos, John},
	editor = {Trujillo, Juan C. and Davis, Karen C. and Du, Xiaoyong and Li, Zhanhuai and Ling, Tok Wang and Li, Guoliang and Lee, Mong Li},
	year = {2018},
	keywords = {Risk, Enterprise modeling, OntoUML, Risk modeling, Value},
	pages = {121--135},
	file = {Full Text PDF:files/10866/Sales et al. - 2018 - The Common Ontology of Value and Risk.pdf:application/pdf},
}

@article{aven_ontological_2011-1,
	title = {On the ontological status of the concept of risk},
	volume = {49},
	issn = {0925-7535},
	url = {https://www.sciencedirect.com/science/article/pii/S0925753511000981},
	doi = {10.1016/j.ssci.2011.04.015},
	abstract = {In this paper we review a set of frequently used risk definitions and analyze their ontological status, i.e. to what extent risk exists in itself independent of any specific assessor. According to some prevailing risk perspectives in the social sciences, risk exists as objective states of the world, but for other common risk perspectives the status of risk is not as clear, for example if risk is viewed as uncertainty about and severity of the consequences of an activity with respect to something that humans value. The principal aim of this paper is to contribute to a clarification of the issue in order to strengthen the foundations of the meaning of risk.},
	number = {8},
	urldate = {2024-05-14},
	journal = {Safety Science},
	author = {Aven, Terje and Renn, Ortwin and Rosa, Eugene A.},
	month = oct,
	year = {2011},
	keywords = {Ontology, Objectivity, Risk, Subjectivity, Uncertainties},
	pages = {1074--1079},
	file = {ScienceDirect Snapshot:files/10868/S0925753511000981.html:text/html},
}

@article{uschold_ontologies_1996,
	title = {Ontologies: principles, methods and applications},
	volume = {11},
	issn = {1469-8005, 0269-8889},
	shorttitle = {Ontologies},
	url = {https://www.cambridge.org/core/journals/knowledge-engineering-review/article/abs/ontologies-principles-methods-and-applications/2443E0A8E5D81A144D8C611EF20043E6},
	doi = {10.1017/S0269888900007797},
	abstract = {This paper is intended to serve as a comprehensive introduction to the emerging field concerned with the design and use of ontologies. We observe that disparate backgrounds, languages, tools and techniques are a major barrier to effective communication among people, organisations and/or software understanding (i.e. an “ontology”) in a given subject area, can improve such communication, which in turn, can give rise to greater reuse and sharing, inter-operability, and more reliable software. After motivating their need, we clarify just what ontologies are and what purpose they serve. We outline a methodology for developing and evaluating ontologies, first discussing informal techniques, concerning such issues as scoping, handling ambiguity, reaching agreement and producing definitions. We then consider the benefits and describe, a more formal approach. We re-visit the scoping phase, and discuss the role of formal languages and techniques in the specification, implementation and evalution of ontologies. Finally, we review the state of the art and practice in this emerging field, considering various case studies, software tools for ontology development, key research issues and future prospects.},
	language = {en},
	number = {2},
	urldate = {2024-05-14},
	journal = {The Knowledge Engineering Review},
	author = {Uschold, Mike and Gruninger, Michael},
	month = jun,
	year = {1996},
	pages = {93--136},
	file = {Versione inviata:files/10870/Uschold e Gruninger - 1996 - Ontologies principles, methods and applications.pdf:application/pdf},
}

@incollection{guarino_what_2009-1,
	address = {Berlin, Heidelberg},
	title = {What {Is} an {Ontology}?},
	isbn = {978-3-540-92673-3},
	url = {https://doi.org/10.1007/978-3-540-92673-3_0},
	abstract = {The word “ontology” is used with different senses in different communities. The most radical difference is perhaps between the philosophical sense, which has of course a well-established tradition, and the computational sense, which emerged in the recent years in the knowledge engineering community, starting from an early informal definition of (computational) ontologies as “explicit specifications of conceptualizations”. In this paper we shall revisit the previous attempts to clarify and formalize such original definition, providing a detailed account of the notions of conceptualization and explicit specification, while discussing at the same time the importance of shared explicit specifications.},
	language = {en},
	urldate = {2024-05-14},
	booktitle = {Handbook on {Ontologies}},
	publisher = {Springer},
	author = {Guarino, Nicola and Oberle, Daniel and Staab, Steffen},
	editor = {Staab, Steffen and Studer, Rudi},
	year = {2009},
	doi = {10.1007/978-3-540-92673-3_0},
	pages = {1--17},
}

@inproceedings{nota_ontology_2010,
	address = {Milano},
	title = {Ontology {Based} {Risk} {Management}},
	isbn = {978-88-470-1778-8},
	doi = {10.1007/978-88-470-1778-8_14},
	abstract = {Risk management in several application domains is receiving increasing attention in the last years especially when the risk management must be pursued in a network made of interacting systems. The motivation is that although risk management models and techniques are mature enough to handle risk in the context of a single system, risk evaluation in the setting of a network of systems is much more difficult to model and manage. Because of the lack of awareness of risk, it is difficult to perceive risks propagation within the network of systems. On the other hand, the lack of shared goals and knowledge represents itself a risk, so that we need a good paradigm to organize and communicate information.},
	language = {en},
	booktitle = {Decision {Theory} and {Choices}: a {Complexity} {Approach}},
	publisher = {Springer Milan},
	author = {Nota, Giancarlo and Aiello, Rossella and Di Gregorio, Maria Pia},
	editor = {Faggini, Marisa and Vinci, Concetto Paolo},
	year = {2010},
	pages = {235--251},
}

@incollection{ding_using_2007-1,
	address = {Boston, MA},
	title = {Using {Ontologies} in the {Semantic} {Web}: {A} {Survey}},
	isbn = {978-0-387-37022-4},
	shorttitle = {Using {Ontologies} in the {Semantic} {Web}},
	url = {https://doi.org/10.1007/978-0-387-37022-4_4},
	abstract = {The Semantic Web is well recognized as an effective infrastructure to enhance visibility of knowledge on the Web. The core of the Semantic Web is “ontology”, which is used to explicitly represent our conceptualizations. Ontology engineering in the Semantic Web is primarily supported by languages such as RDF, RDFS and OWL. This chapter discusses the requirements of ontology in the context of the Web, compares the above three languages with existing knowledge representation formalisms, and surveys tools for managing and applying ontology. Advantages of using ontology in both knowledge-base-style and database-style applications are demonstrated using three real world applications.},
	language = {en},
	urldate = {2024-05-14},
	booktitle = {Ontologies: {A} {Handbook} of {Principles}, {Concepts} and {Applications} in {Information} {Systems}},
	publisher = {Springer US},
	author = {Ding, Li and Kolari, Pranam and Ding, Zhongli and Avancha, Sasikanth},
	editor = {Sharman, Raj and Kishore, Rajiv and Ramesh, Ram},
	year = {2007},
	doi = {10.1007/978-0-387-37022-4_4},
	pages = {79--113},
	file = {Versione inviata:files/10874/Ding et al. - 2007 - Using Ontologies in the Semantic Web A Survey.pdf:application/pdf},
}

@article{barzaghi_hero_nodate-1,
	title = {{HeRO}: {A} {Semantic} {Framework} for {Heritage} {Risk} {Assessment} in the {SIRIUS} {Project}},
	abstract = {In recent decades there has been a change in perspective towards risk assessment in cultural and environmental heritage. Despite the positive impact of heritage on various aspects of society, it is often neglected in disaster risk management, mostly due to lack of strategies in sharing common methodologies and process knowledge. The SIRIUS project, centered in Ravenna (Italy), aims to localize global disaster management guidelines applied to cultural and environmental heritage. In the context of SIRIUS, a pattern-based OWL 2 DL ontology called the Heritage Risk Assessment Ontology (HeRO) is being developed to standardize risk assessment procedures and manage complex heritage risk data. In this contribution, its effectiveness is demonstrated through an in-depth exposition of its modules and an example scenario, promising practical application in an upcoming web-based tool. Future work involves semantic expansion, alignment with other heritage risk assessment methodologies, and further testing.},
	language = {en},
	author = {Barzaghi, Sebastian},
	file = {Barzaghi - HeRO A Semantic Framework for Heritage Risk Asses.pdf:files/10875/Barzaghi - HeRO A Semantic Framework for Heritage Risk Asses.pdf:application/pdf},
}

@book{coelho_risk_2023,
	title = {Risk management as a strategy for the preservation of cultural heritage in sciences and health},
	isbn = {9786581315627},
	abstract = {This publication aims to share the work process and main results of the pilot cycle in the implementation of risk management for the cultural heritage of the Oswaldo Cruz Foundation (Fiocruz). The initiative was coordinated by Casa de Oswaldo Cruz (COC) through an interdisciplinary Working Group and enjoyed the collaboration of other technical and scientific units of the institution, especially the Oswaldo Cruz Institute (IOC) and the Institute of Scientific and Technological Communication and Information in Health (ICICT). Since the preventive approach is still not a consolidated reality in the Brazilian context, our objective in publishing this book is to contribute to the dissemination of risk management by reporting a real-world experience that involved various stakeholders, analyzing the main work stages, difficulties, and strategies employed in the process. The ABC Method for cultural heritage risk management, developed by the International Centre for the Study of the Preservation and Restoration of Cultural Property (ICCROM) and the Canadian Conservation Institute (CCI) with the collaboration of the Cultural Heritage Agency of the Netherlands (RCE), was chosen by the group for conducting its work. The method is relatively complex and there are few examples to date of published Brazilian case studies.},
	language = {en},
	publisher = {Mórula Editorial},
	author = {Coelho, Carla and Pinheiro, Marcos José and Sá, Bruno and Serrano, Nathália Vieira},
	month = jun,
	year = {2023},
	note = {Google-Books-ID: z8zDEAAAQBAJ},
	keywords = {Business \& Economics / Insurance / Risk Assessment \& Management},
}

@article{madsen_terminological_2009,
	title = {Terminological concept modelling and conceptual data modelling},
	volume = {4},
	issn = {1744-2621},
	url = {https://www.inderscienceonline.com/doi/abs/10.1504/IJMSO.2009.029228},
	doi = {10.1504/IJMSO.2009.029228},
	abstract = {Ontologies are useful for many purposes. The use of an ontology is, for example, crucial for writing consistent definitions of concepts within a specific domain. In this paper, we will argue that the principles of rigorous terminology work are useful for building consistent ontologies. In many cases, developers of IT systems encounter severe problems, because they neglect the necessity of developing a proper ontology (concept model) before they develop a conceptual data model as a basis for an IT system. In this paper, we will argue that the development of an ontology is crucial for setting up a conceptual data model, and therefore it should always be added as an initial stage to data modelling. Also we will give some examples of the mapping between ontologies and conceptual data models. Future research will reveal to what extent it will be possible to set up rules for automatic mapping of concepts of an ontology into classes and attributes of a conceptual data model.},
	number = {4},
	urldate = {2024-05-14},
	journal = {International Journal of Metadata, Semantics and Ontologies},
	author = {Madsen, Bodil Nistrup and Thomsen, Hanne Erdman},
	month = jan,
	year = {2009},
	note = {Publisher: Inderscience Publishers},
	keywords = {ontologies, data modelling, characteristics, concept clarification, concept diagrams, concept modelling, individual concepts, ontology construction, properties, terminology, UML},
	pages = {239--249},
}

@article{newbury_loud_nodate,
	title = {{LOUD}: {Linked} {Open} {Usable} {Data} and linked.art},
	language = {en},
	author = {Newbury, David},
	file = {Newbury - LOUD Linked Open Usable Data and linked.art.pdf:files/10880/Newbury - LOUD Linked Open Usable Data and linked.art.pdf:application/pdf},
}

@incollection{stead_new_2023,
	address = {Cham},
	title = {A {New} {Approach} to {Interoperable} {Argumentation} {Documentation}},
	isbn = {978-3-031-37156-1},
	url = {https://doi.org/10.1007/978-3-031-37156-1_2},
	abstract = {The chapter outlines the development of support for inference chains in the CIDOC Conceptual Reference Model family of standards. It illustrates the capabilities available in CRMbase and notes the limitation that the evolution of any assertion or knowledge revision cannot be adequately documented. It then continues by detailing the extended facilities delivered by CRMinf that address this short-coming. Next it considers the added potential to document the scholarly reading of texts that are considered specious and finally looks to future work on the extension.},
	language = {en},
	urldate = {2024-05-14},
	booktitle = {Discourse and {Argumentation} in {Archaeology}: {Conceptual} and {Computational} {Approaches}},
	publisher = {Springer International Publishing},
	author = {Stead, Stephen},
	editor = {Gonzalez-Perez, Cesar and Martin-Rodilla, Patricia and Pereira-Fariña, Martín},
	year = {2023},
	doi = {10.1007/978-3-031-37156-1_2},
	pages = {29--36},
}

@article{hellmund_introducing_2018,
	title = {Introducing the {HERACLES} {Ontology}—{Semantics} for {Cultural} {Heritage} {Management}},
	volume = {1},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2571-9408},
	url = {https://www.mdpi.com/2571-9408/1/2/26},
	doi = {10.3390/heritage1020026},
	abstract = {Cultural Heritage (CH) (In the context of this paper, we consider cultural heritage built tangible cultural heritage, such as buildings or monuments.) is an important source of identity for humankind and needs to be conserved for future generations. Climate change (CC) will morph the environmental landscape, thus leading to climate stress imposed on CH. Experts from different domains, including, but not limited to, material scientists, conservators and managers of cultural heritage collaborate to find out how CC affects CH and how potentially harmful impacts can be mitigated. To find and understand correlations and effects of different factors, researchers collect and analyse vast amounts of data. Still, experts often cannot exchange or make efficient use of data since it often is unstructured, incompatible, or its plain existence is simply unknown. This article introduces means to achieve consent about available knowledge, to exploit synergy effects through the combination of available information and to provide a flexible multisource information platform in collaborative cultural heritage management projects. In the context of the European project HERACLES (HERACLES—HEritage Resilience Against CLimate Events on Site. Further information: http://www.heracles-project.eu/), an application-ontology was developed. The ontology facilitates reuse and integration of data through structuring and representing its semantics. The involvement in the HERACLES project guaranteed end-user driven development, practical results and encompassment of all domains represented in the project.},
	language = {en},
	number = {2},
	urldate = {2024-05-14},
	journal = {Heritage},
	author = {Hellmund, Tobias and Hertweck, Philipp and Hilbring, Désirée and Mossgraber, Jürgen and Alexandrakis, George and Pouli, Paraskevi and Siatou, Amalia and Padeletti, Giuseppina},
	month = dec,
	year = {2018},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {cultural heritage, ontology, semantics, climate change, knowledge base},
	pages = {377--391},
	file = {Full Text PDF:files/10886/Hellmund et al. - 2018 - Introducing the HERACLES Ontology—Semantics for Cu.pdf:application/pdf},
}

@article{cacciotti_monument_2013-1,
	title = {{MONUMENT} {DAMAGE} {INFORMATION} {SYSTEM} ({MONDIS}): {AN} {ONTOLOGICAL} {APPROACH} {TO} {CULTURAL} {HERITAGE} {DOCUMENTATION}},
	volume = {II-5-W1},
	issn = {2194-9042},
	shorttitle = {{MONUMENT} {DAMAGE} {INFORMATION} {SYSTEM} ({MONDIS})},
	url = {https://isprs-annals.copernicus.org/articles/II-5-W1/55/2013/isprsannals-II-5-W1-55-2013.html},
	doi = {10.5194/isprsannals-II-5-W1-55-2013},
	abstract = {Deriving from the complex nature of cultural heritage conservation it is the need for enhancing a systematic but flexible organization of expert knowledge in the field. Such organization should address comprehensively the interrelations and complementariness among the different factors that come into play in the understanding of diagnostic and intervention problems. The purpose of MONDIS is to endorse this kind of organization. The approach consists in applying an ontological representation to the field of heritage conservation in order to establish an appropriate processing of data. The system allows replicating in a computer readable form the basic dependence among factors influencing the description, diagnosis and intervention of damages to immovable objects. More specifically MONDIS allows to input and search entries concerning object description, structural evolution, location characteristics and risk, component, material properties, surveys and measurements, damage typology, damage triggering events and possible interventions. The system supports searching features typical of standard databases, as it allows for the digitalization of a wide range of information including professional reports, books, articles and scientific papers. It also allows for computer aided retrieval of information tailored to user's requirements. The foreseen outputs will include a web user interface and a mobile application for visual inspection purposes.},
	language = {English},
	urldate = {2024-05-14},
	journal = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Cacciotti, R. and Valach, J. and Kuneš, P. and Čerňanský, M. and Blaško, M. and Křemen, P.},
	month = jul,
	year = {2013},
	note = {Conference Name: TC V {\textless}br/{\textgreater} XXIV International CIPA Symposium (Volume II-5/W1) - 2\&ndash;6 September 2013, Strasbourg, France
Publisher: Copernicus GmbH},
	keywords = {semantic web, Cultural heritage, ontologies, documentation, damages},
	pages = {55--60},
	file = {Full Text PDF:files/10888/Cacciotti et al. - 2013 - MONUMENT DAMAGE INFORMATION SYSTEM (MONDIS) AN ON.pdf:application/pdf},
}

@article{lawrynowicz_hazardous_nodate-1,
	title = {The {Hazardous} {Situation} {Ontology} {Design} {Pattern}},
	abstract = {This extended abstract describes an ontology design pattern for modeling hazardous situations. We build upon state-of-art models for hazards and hazardous events, and on existing standards in the domain of occupational safety. We also present an example of the application of the pattern in the occupational safety and health domain.},
	language = {en},
	author = {Lawrynowicz, Agnieszka and Lawniczak, Ilona},
	file = {Lawrynowicz e Lawniczak - The Hazardous Situation Ontology Design Pattern.pdf:files/10889/Lawrynowicz e Lawniczak - The Hazardous Situation Ontology Design Pattern.pdf:application/pdf},
}

@article{mazimwe_pattern_2020-1,
	title = {A {Pattern} {Driven} {Approach} to {Knowledge} {Representation} in the {Disaster} {Domain}},
	volume = {1},
	issn = {2661-8907},
	url = {https://doi.org/10.1007/s42979-020-00342-5},
	doi = {10.1007/s42979-020-00342-5},
	abstract = {Access to integrated disaster-related data through querying is still a problem due to associated semantic barriers. The disaster domain largely relies on the top–down approach of ontology development. This limits reuse due to associated commitments and complex alignments within ontologies. Therefore, there is a need to utilize a bottom-up approach that reuses patterns for representing disaster knowledge. To bridge the availability gap of patterns for representing disaster knowledge, this study identifies existing and emerging patterns for reuse while organizing disaster data from multiple sector stakeholders. Based on the eXtreme Design (XD) methodology and key informant interviews, competency questions (CQs) were elicited from domain stakeholders. The CQs are matched with existing patterns from other contexts. Emerging patterns (e.g the Event Classification and Quality Dependence Description for Objects) are also developed for CQs not captured and subsequently tested using SPARQL queries characterising the CQs. It is in this context that this paper presents a characterisation of disaster risk knowledge using CQs and corresponding patterns (reusable and emerging) covering the knowledge. Accordingly, we illustrate a pattern-driven use case to organise drought hazard data for early warning purposes. This provides a powerful use case for adopting a pattern-based approach to knowledge representation in the disaster domain.},
	language = {en},
	number = {6},
	urldate = {2024-05-14},
	journal = {SN Computer Science},
	author = {Mazimwe, Allan and Hammouda, Imed and Gidudu, Anthony and Barasa, Bernard},
	month = oct,
	year = {2020},
	keywords = {Vulnerability, Ontology design patterns, Risk, Hazard},
	pages = {353},
	file = {Full Text PDF:files/10892/Mazimwe et al. - 2020 - A Pattern Driven Approach to Knowledge Representat.pdf:application/pdf},
}

@inproceedings{peroni_simplified_2017-1,
	address = {Cham},
	title = {A {Simplified} {Agile} {Methodology} for {Ontology} {Development}},
	isbn = {978-3-319-54627-8},
	doi = {10.1007/978-3-319-54627-8_5},
	abstract = {In this paper we introduce SAMOD, a.k.a. Simplified Agile Methodology for Ontology Development, a novel agile methodology for the development of ontologies by means of small steps of an iterative workflow that focuses on creating well-developed and documented models starting from exemplar domain descriptions. In addition, we discuss the results of an experiment where we asked nine people (with no or limited expertise in Semantic Web technologies and Ontology Engineering) to use SAMOD for developing a small ontology.},
	language = {en},
	booktitle = {{OWL}: {Experiences} and {Directions} – {Reasoner} {Evaluation}},
	publisher = {Springer International Publishing},
	author = {Peroni, Silvio},
	editor = {Dragoni, Mauro and Poveda-Villalón, María and Jimenez-Ruiz, Ernesto},
	year = {2017},
	keywords = {Agile ontology development methodology, Conceptual modelling, Knowledge engineering, Ontology engineering, OWL Ontologies, SAMOD, Test-driven development},
	pages = {55--69},
	file = {Full Text PDF:files/10894/Peroni - 2017 - A Simplified Agile Methodology for Ontology Develo.pdf:application/pdf},
}

@incollection{bendix_ten_2023,
	title = {The {Ten} {Agents} of {Deterioration}},
	isbn = {978-1-00-316267-4},
	abstract = {The Ten Agents of Deterioration - 1},
	booktitle = {Conservation of {Books}},
	publisher = {Routledge},
	author = {Bendix, Caroline and Moore, Tiffany Eng},
	year = {2023},
	note = {Num Pages: 20},
}

@article{doerr_cidoc_2005,
	title = {The {CIDOC} {CRM}, an {Ontological} {Approach} to {Schema} {Heterogeneity}},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	url = {https://drops.dagstuhl.de/entities/document/10.4230/DagSemProc.04391.22},
	doi = {10.4230/DagSemProc.04391.22},
	abstract = {The CIDOC Conceptual Reference Model (CRM), now ISO/CD21127, is a core ontology that aims at enabling information exchange and integration between heterogeneous sources of cultural heritage information, archives and libraries. It provides semantic definitions and clarifications
needed to transform disparate, heterogeneous information sources into a coherent global resource, be it within a larger institution, in intranets or on the Internet. It is argued that such an ontology is property-centric, compact and highly generic, in contrast to terminological systems. The presentation will demonstrate how such a well-crafted core ontology can help to achieve a very high precision of schema integration at reasonable cost in a huge, diverse domain. It is further argued that such ontologies are widely reusable and adaptable to other domains which makes their development cost effective.},
	language = {en},
	urldate = {2024-05-14},
	journal = {DROPS-IDN/v2/document/10.4230/DagSemProc.04391.22},
	author = {Doerr, Martin},
	year = {2005},
	note = {Publisher: Schloss Dagstuhl – Leibniz-Zentrum für Informatik},
	file = {Full Text PDF:files/10897/Doerr - 2005 - The CIDOC CRM, an Ontological Approach to Schema H.pdf:application/pdf},
}

@incollection{gangemi_ontology_2009-3,
	address = {Berlin, Heidelberg},
	title = {Ontology {Design} {Patterns}},
	isbn = {978-3-540-92673-3},
	url = {https://doi.org/10.1007/978-3-540-92673-3_10},
	abstract = {Computational ontologies in the context of information systems are artifacts that encode a description of some world, for some purpose. Under the assumption that there exist classes of problems that can be solved by applying common solutions (as it has been experienced in software engineering), we envision small, task-oriented ontologies with explicit documentation of design rationales. In this chapter, we describe components called Ontology Design Patterns (OP), and methods that support pattern-based ontology design.},
	language = {en},
	urldate = {2024-05-14},
	booktitle = {Handbook on {Ontologies}},
	publisher = {Springer},
	author = {Gangemi, Aldo and Presutti, Valentina},
	editor = {Staab, Steffen and Studer, Rudi},
	year = {2009},
	doi = {10.1007/978-3-540-92673-3_10},
	pages = {221--243},
}

@article{lynch_digital_2002,
	title = {Digital {Collections}, {Digital} {Libraries} \& the {Digitization} of {Cultural} {Heritage} {Information}},
	volume = {31},
	copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
	url = {https://www.degruyter.com/document/doi/10.1515/MFIR.2002.131/html},
	doi = {10.1515/MFIR.2002.131},
	abstract = {This paper is based on the transcript of a largely extemporaneous keynote address given at the Web-Wise 2002 Conference on March 20, 2002 at Johns Hopkins University. It has been edited, but it preserves the character of an informal talk rather than a formal paper. I have taken the opportunity to expand upon or clarify a few points, and have also added a few footnotes and pointers to additional information on some of the topics discussed. Parts of the question and answer segment that were captured as part of the transcript have also been included, though I've had the advantage of being able to reconsider some of my answers while the questioners have not had that opportunity; my apologies to them.},
	language = {en},
	number = {4},
	urldate = {2024-05-15},
	author = {Lynch, Clifford},
	month = dec,
	year = {2002},
	note = {Publisher: De Gruyter
Section: Microform \& Digitization Review},
	pages = {131--145},
}

@article{flanders_knowledge_nodate,
	title = {Knowledge {Organization} and {Data} {Modeling} in the {Humanities}},
	language = {en},
	author = {Flanders, Julia},
	file = {Flanders - Knowledge Organization and Data Modeling in the Hu.pdf:files/10900/Flanders - Knowledge Organization and Data Modeling in the Hu.pdf:application/pdf},
}

@book{knowles_placing_2008,
	title = {Placing {History}: {How} {Maps}, {Spatial} {Data}, and {GIS} are {Changing} {Historical} {Scholarship}},
	isbn = {978-1-58948-013-1},
	shorttitle = {Placing {History}},
	abstract = {In the last decade, historical GIS (geographic information systems) has emerged as a promising new methodology for studying the past. This work offers case studies and essays involving historical GIS, highlighting the unprecedented range of tools to visualize historical information in a geographical context.},
	language = {en},
	publisher = {ESRI, Inc.},
	author = {Knowles, Anne Kelly and Hillier, Amy},
	year = {2008},
	note = {Google-Books-ID: VN1v7rzhSQEC},
	keywords = {History / Historical Geography, History / Study \& Teaching, Technology \& Engineering / Cartography, Technology \& Engineering / Remote Sensing \& Geographic Information Systems},
}

@misc{barzaghi_developing_2024-1,
	title = {Developing {Application} {Profiles} for {Enhancing} {Data} and {Workflows} in {Cultural} {Heritage} {Digitisation} {Processes}},
	copyright = {All rights reserved},
	url = {http://arxiv.org/abs/2404.12069},
	doi = {10.48550/arXiv.2404.12069},
	abstract = {As a result of the proliferation of 3D digitisation in the context of cultural heritage projects, digital assets and digitisation processes - being considered as proper research objects - must prioritise adherence to FAIR principles. Existing standards and ontologies, such as CIDOC CRM, play a crucial role in this regard, but they are often over-engineered for the need of a particular application context, thus making their understanding and adoption difficult. Application profiles of a given standard - defined as sets of ontological entities drawn from one or more semantic artefacts for a particular context or application - are usually proposed as tools for promoting interoperability and reuse while being tied entirely to the particular application context they refer to. In this paper, we present an adaptation and application of an ontology development methodology, i.e. SAMOD, to guide the creation of robust, semantically sound application profiles of large standard models. Using an existing pilot study we have developed in a project dedicated to leveraging virtual technologies to preserve and valorise cultural heritage, we introduce an application profile named CHAD-AP, that we have developed following our customised version of SAMOD. We reflect on the use of SAMOD and similar ontology development methodologies for this purpose, highlighting its strengths and current limitations, future developments, and possible adoption in other similar projects.},
	urldate = {2024-06-27},
	publisher = {arXiv},
	author = {Barzaghi, Sebastian and Heibi, Ivan and Moretti, Arianna and Peroni, Silvio},
	month = apr,
	year = {2024},
	note = {arXiv:2404.12069 [cs]},
	keywords = {Computer Science - Digital Libraries},
	file = {arXiv Fulltext PDF:files/10941/Barzaghi et al. - 2024 - Developing Application Profiles for Enhancing Data.pdf:application/pdf;arXiv.org Snapshot:files/10942/2404.html:text/html},
}

@misc{barzaghi_thinking_2024-2,
	title = {Thinking {Outside} the {Black} {Box}: {Insights} from a {Digital} {Exhibition} in the {Humanities}},
	copyright = {All rights reserved},
	shorttitle = {Thinking {Outside} the {Black} {Box}},
	url = {https://zenodo.org/records/11487997},
	abstract = {One of the main goals of Open Science is to make research more reproducible. There is no consensus, however, on what exactly “reproducibility” is, as opposed for example to “replicability”, and how it applies to different research fields. After a short review of the literature on reproducibility/replicability with a focus on the humanities, we describe how the creation of the digital twin of the temporary exhibition “The Other Renaissance” has been documented throughout, with different methods, but with constant attention to research transparency, openness and accountability. A careful documentation of the study design, data collection and analysis techniques helps reflect and make all possible influencing factors explicit, and is a fundamental tool for reliability and rigour and for opening the “black box” of research.},
	urldate = {2024-06-27},
	author = {Barzaghi, Sebastian and Bordignon, Alice and Gualandi, Bianca and Peroni, Silvio},
	month = jun,
	year = {2024},
	doi = {10.5281/zenodo.11487997},
	file = {Full Text PDF:files/10944/Barzaghi et al. - 2024 - Thinking Outside the Black Box Insights from a Di.pdf:application/pdf},
}
